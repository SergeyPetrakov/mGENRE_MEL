{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Python version and upgrading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiLr036GIvcc",
    "outputId": "58e463c0-0c4f-4990-a4ef-227b12e090ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/petrakov/anaconda3/lib/python3.7/site-packages (22.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "init_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !conda update -n base -c defaults conda -y\n",
    "# !conda install -y pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.21.6\n",
      "Uninstalling numpy-1.21.6:\n",
      "  Successfully uninstalled numpy-1.21.6\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.0 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
      "allennlp 2.9.3 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.21.6\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy \n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations of 3 key libraries: KILT, GENRE and fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFeVVTtwDUAl",
    "outputId": "d2c065f5-98ad-4602-f925-f80df0c4a31f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KILT'...\n",
      "remote: Enumerating objects: 401, done.\u001b[K\n",
      "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
      "remote: Total 401 (delta 106), reused 91 (delta 91), pack-reused 252\u001b[K\n",
      "Receiving objects: 100% (401/401), 829.83 KiB | 3.40 MiB/s, done.\n",
      "Resolving deltas: 100% (224/224), done.\n",
      "/home/petrakov/mGENRE_MEL/KILT\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mrunning install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating kilt.egg-info\n",
      "writing kilt.egg-info/PKG-INFO\n",
      "writing dependency_links to kilt.egg-info/dependency_links.txt\n",
      "writing requirements to kilt.egg-info/requires.txt\n",
      "writing top-level names to kilt.egg-info/top_level.txt\n",
      "writing manifest file 'kilt.egg-info/SOURCES.txt'\n",
      "reading manifest file 'kilt.egg-info/SOURCES.txt'\n",
      "writing manifest file 'kilt.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/tests\n",
      "copying tests/__init__.py -> build/lib/tests\n",
      "copying tests/test_eval_downstream.py -> build/lib/tests\n",
      "copying tests/test_eval_retrieval.py -> build/lib/tests\n",
      "creating build/lib/kilt\n",
      "copying kilt/__init__.py -> build/lib/kilt\n",
      "copying kilt/dataset_mapper.py -> build/lib/kilt\n",
      "copying kilt/retrieval.py -> build/lib/kilt\n",
      "copying kilt/eval_retrieval.py -> build/lib/kilt\n",
      "copying kilt/knowledge_source.py -> build/lib/kilt\n",
      "copying kilt/eval_downstream.py -> build/lib/kilt\n",
      "copying kilt/kilt_utils.py -> build/lib/kilt\n",
      "creating build/lib/tests/test_data\n",
      "copying tests/test_data/__init__.py -> build/lib/tests/test_data\n",
      "creating build/lib/kilt/configs\n",
      "copying kilt/configs/__init__.py -> build/lib/kilt/configs\n",
      "creating build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/__init__.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/BLINK_connector.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/BM25_connector.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/DPR_connector.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/DPR_distr_connector.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/DrQA_tfidf.py -> build/lib/kilt/retrievers\n",
      "copying kilt/retrievers/base_retriever.py -> build/lib/kilt/retrievers\n",
      "creating build/lib/kilt/datasets\n",
      "copying kilt/datasets/__init__.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/fact_verification.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/zero_shot_re.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/natural_questions.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/base_dataset.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/triviaqa.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/hotpotqa_ks.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/hotpotqa.py -> build/lib/kilt/datasets\n",
      "copying kilt/datasets/entity_linking.py -> build/lib/kilt/datasets\n",
      "creating build/lib/kilt/configs/retriever\n",
      "copying kilt/configs/retriever/__init__.py -> build/lib/kilt/configs/retriever\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/tests\n",
      "copying build/lib/tests/__init__.py -> build/bdist.linux-x86_64/egg/tests\n",
      "copying build/lib/tests/test_eval_downstream.py -> build/bdist.linux-x86_64/egg/tests\n",
      "creating build/bdist.linux-x86_64/egg/tests/test_data\n",
      "copying build/lib/tests/test_data/__init__.py -> build/bdist.linux-x86_64/egg/tests/test_data\n",
      "copying build/lib/tests/test_eval_retrieval.py -> build/bdist.linux-x86_64/egg/tests\n",
      "creating build/bdist.linux-x86_64/egg/kilt\n",
      "copying build/lib/kilt/__init__.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "copying build/lib/kilt/dataset_mapper.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "copying build/lib/kilt/retrieval.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "copying build/lib/kilt/eval_retrieval.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "creating build/bdist.linux-x86_64/egg/kilt/configs\n",
      "copying build/lib/kilt/configs/__init__.py -> build/bdist.linux-x86_64/egg/kilt/configs\n",
      "creating build/bdist.linux-x86_64/egg/kilt/configs/retriever\n",
      "copying build/lib/kilt/configs/retriever/__init__.py -> build/bdist.linux-x86_64/egg/kilt/configs/retriever\n",
      "creating build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/__init__.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/BLINK_connector.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/BM25_connector.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/DPR_connector.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/DPR_distr_connector.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/DrQA_tfidf.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/retrievers/base_retriever.py -> build/bdist.linux-x86_64/egg/kilt/retrievers\n",
      "copying build/lib/kilt/knowledge_source.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "creating build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/__init__.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/fact_verification.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/zero_shot_re.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/natural_questions.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/base_dataset.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/triviaqa.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/hotpotqa_ks.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/hotpotqa.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/datasets/entity_linking.py -> build/bdist.linux-x86_64/egg/kilt/datasets\n",
      "copying build/lib/kilt/eval_downstream.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "copying build/lib/kilt/kilt_utils.py -> build/bdist.linux-x86_64/egg/kilt\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/test_eval_downstream.py to test_eval_downstream.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/test_data/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/test_eval_retrieval.py to test_eval_retrieval.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/dataset_mapper.py to dataset_mapper.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrieval.py to retrieval.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/eval_retrieval.py to eval_retrieval.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/configs/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/configs/retriever/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/BLINK_connector.py to BLINK_connector.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/BM25_connector.py to BM25_connector.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/DPR_connector.py to DPR_connector.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/DPR_distr_connector.py to DPR_distr_connector.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/DrQA_tfidf.py to DrQA_tfidf.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/retrievers/base_retriever.py to base_retriever.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/knowledge_source.py to knowledge_source.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/fact_verification.py to fact_verification.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/zero_shot_re.py to zero_shot_re.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/natural_questions.py to natural_questions.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/base_dataset.py to base_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/triviaqa.py to triviaqa.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/hotpotqa_ks.py to hotpotqa_ks.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/hotpotqa.py to hotpotqa.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/datasets/entity_linking.py to entity_linking.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/eval_downstream.py to eval_downstream.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/kilt/kilt_utils.py to kilt_utils.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying kilt.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying kilt.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying kilt.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying kilt.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying kilt.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/kilt-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing kilt-0.1.0-py3.7.egg\n",
      "Removing /home/petrakov/anaconda3/lib/python3.7/site-packages/kilt-0.1.0-py3.7.egg\n",
      "Copying kilt-0.1.0-py3.7.egg to /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "kilt 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/petrakov/anaconda3/lib/python3.7/site-packages/kilt-0.1.0-py3.7.egg\n",
      "Processing dependencies for kilt==0.1.0\n",
      "Searching for tqdm==4.64.0\n",
      "Best match: tqdm 4.64.0\n",
      "Adding tqdm 4.64.0 to easy-install.pth file\n",
      "Installing tqdm script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for torch==1.11.0\n",
      "Best match: torch 1.11.0\n",
      "Adding torch 1.11.0 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /home/petrakov/anaconda3/bin\n",
      "Installing convert-onnx-to-caffe2 script to /home/petrakov/anaconda3/bin\n",
      "Installing torchrun script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for spacy==2.3.7\n",
      "Best match: spacy 2.3.7\n",
      "Adding spacy 2.3.7 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for rouge==1.0.1\n",
      "Best match: rouge 1.0.1\n",
      "Adding rouge 1.0.1 to easy-install.pth file\n",
      "Installing rouge script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pytest==5.2.1\n",
      "Best match: pytest 5.2.1\n",
      "Adding pytest 5.2.1 to easy-install.pth file\n",
      "Installing py.test script to /home/petrakov/anaconda3/bin\n",
      "Installing pytest script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pymongo==4.1.1\n",
      "Best match: pymongo 4.1.1\n",
      "Adding pymongo 4.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for prettytable==3.3.0\n",
      "Best match: prettytable 3.3.0\n",
      "Adding prettytable 3.3.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for nltk==3.4.5\n",
      "Best match: nltk 3.4.5\n",
      "Adding nltk 3.4.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for jsonlines==3.1.0\n",
      "Best match: jsonlines 3.1.0\n",
      "Adding jsonlines 3.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for flair==0.11.3\n",
      "Best match: flair 0.11.3\n",
      "Adding flair 0.11.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for bs4==0.0.1\n",
      "Best match: bs4 0.0.1\n",
      "Adding bs4 0.0.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for typing-extensions==4.1.1\n",
      "Best match: typing-extensions 4.1.1\n",
      "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for murmurhash==1.0.7\n",
      "Best match: murmurhash 1.0.7\n",
      "Adding murmurhash 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for preshed==3.0.6\n",
      "Best match: preshed 3.0.6\n",
      "Adding preshed 3.0.6 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3 script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3.7 script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for blis==0.7.8\n",
      "Best match: blis 0.7.8\n",
      "Adding blis 0.7.8 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for setuptools==41.4.0\n",
      "Best match: setuptools 41.4.0\n",
      "Adding setuptools 41.4.0 to easy-install.pth file\n",
      "Installing easy_install script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for thinc==7.4.5\n",
      "Best match: thinc 7.4.5\n",
      "Adding thinc 7.4.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for requests==2.28.1\n",
      "Best match: requests 2.28.1\n",
      "Adding requests 2.28.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for plac==1.1.3\n",
      "Best match: plac 1.1.3\n",
      "Adding plac 1.1.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for srsly==1.0.5\n",
      "Best match: srsly 1.0.5\n",
      "Adding srsly 1.0.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for wasabi==0.9.1\n",
      "Best match: wasabi 0.9.1\n",
      "Adding wasabi 0.9.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for catalogue==1.0.0\n",
      "Best match: catalogue 1.0.0\n",
      "Adding catalogue 1.0.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cymem==2.0.6\n",
      "Best match: cymem 2.0.6\n",
      "Adding cymem 2.0.6 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for importlib-metadata==3.10.1\n",
      "Best match: importlib-metadata 3.10.1\n",
      "Adding importlib-metadata 3.10.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for wcwidth==0.2.5\n",
      "Best match: wcwidth 0.2.5\n",
      "Adding wcwidth 0.2.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pluggy==0.13.0\n",
      "Best match: pluggy 0.13.0\n",
      "Adding pluggy 0.13.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for atomicwrites==1.3.0\n",
      "Best match: atomicwrites 1.3.0\n",
      "Adding atomicwrites 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for more-itertools==7.2.0\n",
      "Best match: more-itertools 7.2.0\n",
      "Adding more-itertools 7.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for attrs==19.2.0\n",
      "Best match: attrs 19.2.0\n",
      "Adding attrs 19.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for packaging==21.3\n",
      "Best match: packaging 21.3\n",
      "Adding packaging 21.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for py==1.8.0\n",
      "Best match: py 1.8.0\n",
      "Adding py 1.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for segtok==1.5.11\n",
      "Best match: segtok 1.5.11\n",
      "Adding segtok 1.5.11 to easy-install.pth file\n",
      "Installing segmenter script to /home/petrakov/anaconda3/bin\n",
      "Installing tokenizer script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for regex==2022.7.9\n",
      "Best match: regex 2022.7.9\n",
      "Adding regex 2022.7.9 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for scikit-learn==0.21.3\n",
      "Best match: scikit-learn 0.21.3\n",
      "Adding scikit-learn 0.21.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for conllu==4.5\n",
      "Best match: conllu 4.5\n",
      "Adding conllu 4.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for hyperopt==0.2.7\n",
      "Best match: hyperopt 0.2.7\n",
      "Adding hyperopt 0.2.7 to easy-install.pth file\n",
      "Installing hyperopt-mongo-worker script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for Deprecated==1.2.13\n",
      "Best match: Deprecated 1.2.13\n",
      "Adding Deprecated 1.2.13 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for transformers==4.18.0\n",
      "Best match: transformers 4.18.0\n",
      "Adding transformers 4.18.0 to easy-install.pth file\n",
      "Installing transformers-cli script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tabulate==0.8.10\n",
      "Best match: tabulate 0.8.10\n",
      "Adding tabulate 0.8.10 to easy-install.pth file\n",
      "Installing tabulate script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pptree==3.1\n",
      "Best match: pptree 3.1\n",
      "Adding pptree 3.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for lxml==4.4.1\n",
      "Best match: lxml 4.4.1\n",
      "Adding lxml 4.4.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for sqlitedict==2.0.0\n",
      "Best match: sqlitedict 2.0.0\n",
      "Adding sqlitedict 2.0.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for mpld3==0.3\n",
      "Best match: mpld3 0.3\n",
      "Adding mpld3 0.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for langdetect==1.0.9\n",
      "Best match: langdetect 1.0.9\n",
      "Adding langdetect 1.0.9 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for sentencepiece==0.1.95\n",
      "Best match: sentencepiece 0.1.95\n",
      "Adding sentencepiece 0.1.95 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for matplotlib==3.1.1\n",
      "Best match: matplotlib 3.1.1\n",
      "Adding matplotlib 3.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for konoha==4.6.5\n",
      "Best match: konoha 4.6.5\n",
      "Adding konoha 4.6.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for ftfy==6.1.1\n",
      "Best match: ftfy 6.1.1\n",
      "Adding ftfy 6.1.1 to easy-install.pth file\n",
      "Installing ftfy script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for python-dateutil==2.8.0\n",
      "Best match: python-dateutil 2.8.0\n",
      "Adding python-dateutil 2.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for Janome==0.4.2\n",
      "Best match: Janome 0.4.2\n",
      "Adding Janome 0.4.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for bpemb==0.3.3\n",
      "Best match: bpemb 0.3.3\n",
      "Adding bpemb 0.3.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for huggingface-hub==0.8.1\n",
      "Best match: huggingface-hub 0.8.1\n",
      "Adding huggingface-hub 0.8.1 to easy-install.pth file\n",
      "Installing huggingface-cli script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for gensim==4.2.0\n",
      "Best match: gensim 4.2.0\n",
      "Adding gensim 4.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for gdown==4.4.0\n",
      "Best match: gdown 4.4.0\n",
      "Adding gdown 4.4.0 to easy-install.pth file\n",
      "Installing gdown script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for Wikipedia-API==0.5.4\n",
      "Best match: Wikipedia-API 0.5.4\n",
      "Adding Wikipedia-API 0.5.4 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for beautifulsoup4==4.8.0\n",
      "Best match: beautifulsoup4 4.8.0\n",
      "Adding beautifulsoup4 4.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for certifi==2019.9.11\n",
      "Best match: certifi 2019.9.11\n",
      "Adding certifi 2019.9.11 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for charset-normalizer==2.1.0\n",
      "Best match: charset-normalizer 2.1.0\n",
      "Adding charset-normalizer 2.1.0 to easy-install.pth file\n",
      "Installing normalizer script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for idna==2.8\n",
      "Best match: idna 2.8\n",
      "Adding idna 2.8 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for urllib3==1.26.10\n",
      "Best match: urllib3 1.26.10\n",
      "Adding urllib3 1.26.10 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for zipp==3.8.1\n",
      "Best match: zipp 3.8.1\n",
      "Adding zipp 3.8.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pyparsing==2.4.2\n",
      "Best match: pyparsing 2.4.2\n",
      "Adding pyparsing 2.4.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for scipy==1.3.1\n",
      "Best match: scipy 1.3.1\n",
      "Adding scipy 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for joblib==0.13.2\n",
      "Best match: joblib 0.13.2\n",
      "Adding joblib 0.13.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for networkx==2.3\n",
      "Best match: networkx 2.3\n",
      "Adding networkx 2.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for py4j==0.10.9.5\n",
      "Best match: py4j 0.10.9.5\n",
      "Adding py4j 0.10.9.5 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cloudpickle==1.2.2\n",
      "Best match: cloudpickle 1.2.2\n",
      "Adding cloudpickle 1.2.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for future==0.18.2\n",
      "Best match: future 0.18.2\n",
      "Adding future 0.18.2 to easy-install.pth file\n",
      "Installing futurize script to /home/petrakov/anaconda3/bin\n",
      "Installing pasteurize script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for wrapt==1.11.2\n",
      "Best match: wrapt 1.11.2\n",
      "Adding wrapt 1.11.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for filelock==3.6.0\n",
      "Best match: filelock 3.6.0\n",
      "Adding filelock 3.6.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for sacremoses==0.0.53\n",
      "Best match: sacremoses 0.0.53\n",
      "Adding sacremoses 0.0.53 to easy-install.pth file\n",
      "Installing sacremoses script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for PyYAML==5.1.2\n",
      "Best match: PyYAML 5.1.2\n",
      "Adding PyYAML 5.1.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tokenizers==0.12.1\n",
      "Best match: tokenizers 0.12.1\n",
      "Adding tokenizers 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for kiwisolver==1.1.0\n",
      "Best match: kiwisolver 1.1.0\n",
      "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for overrides==3.1.0\n",
      "Best match: overrides 3.1.0\n",
      "Adding overrides 3.1.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for smart-open==5.2.1\n",
      "Best match: smart-open 5.2.1\n",
      "Adding smart-open 5.2.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for soupsieve==1.9.3\n",
      "Best match: soupsieve 1.9.3\n",
      "Adding soupsieve 1.9.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for decorator==4.4.0\n",
      "Best match: decorator 4.4.0\n",
      "Adding decorator 4.4.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for click==8.1.3\n",
      "Best match: click 8.1.3\n",
      "Adding click 8.1.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for PySocks==1.7.1\n",
      "Best match: PySocks 1.7.1\n",
      "Adding PySocks 1.7.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Finished processing dependencies for kilt==0.1.0\n",
      "/home/petrakov/mGENRE_MEL\n",
      "Cloning into 'GENRE'...\n",
      "remote: Enumerating objects: 454, done.\u001b[K\n",
      "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 454 (delta 112), reused 104 (delta 80), pack-reused 284\u001b[K\n",
      "Receiving objects: 100% (454/454), 10.99 MiB | 3.40 MiB/s, done.\n",
      "Resolving deltas: 100% (259/259), done.\n",
      "/home/petrakov/mGENRE_MEL/GENRE\n",
      "Processing /home/petrakov/mGENRE_MEL/GENRE\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: genre\n",
      "  Building wheel for genre (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for genre: filename=genre-0.1.3-py3-none-any.whl size=22437 sha256=e5f57fadb4825a194e3cfa7828365ad92a8a0d4a651ef71a2ebaae19b354a186\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kdabhd14/wheels/10/f4/1a/a66e1f993c95b018a997b9d7d243fce5e1fca4269606199516\n",
      "Successfully built genre\n",
      "Installing collected packages: genre\n",
      "  Attempting uninstall: genre\n",
      "    Found existing installation: genre 0.1.3\n",
      "    Uninstalling genre-0.1.3:\n",
      "      Successfully uninstalled genre-0.1.3\n",
      "Successfully installed genre-0.1.3\n",
      "running build\n",
      "running build_py\n",
      "running develop\n",
      "running egg_info\n",
      "writing genre.egg-info/PKG-INFO\n",
      "writing dependency_links to genre.egg-info/dependency_links.txt\n",
      "writing top-level names to genre.egg-info/top_level.txt\n",
      "reading manifest file 'genre.egg-info/SOURCES.txt'\n",
      "writing manifest file 'genre.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /home/petrakov/anaconda3/lib/python3.7/site-packages/genre.egg-link (link to .)\n",
      "Removing genre 0.1.3 from easy-install.pth file\n",
      "Adding genre 0.1.3 to easy-install.pth file\n",
      "\n",
      "Installed /home/petrakov/mGENRE_MEL/GENRE\n",
      "Processing dependencies for genre==0.1.3\n",
      "Finished processing dependencies for genre==0.1.3\n",
      "running install\n",
      "running bdist_egg\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/__init__.py -> build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/fairseq_model.py -> build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/hf_model.py -> build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/utils.py -> build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/trie.py -> build/bdist.linux-x86_64/egg/genre\n",
      "copying build/lib/genre/entity_linking.py -> build/bdist.linux-x86_64/egg/genre\n",
      "creating build/bdist.linux-x86_64/egg/tests\n",
      "copying build/lib/tests/__init__.py -> build/bdist.linux-x86_64/egg/tests\n",
      "copying build/lib/tests/test_example.py -> build/bdist.linux-x86_64/egg/tests\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/fairseq_model.py to fairseq_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/hf_model.py to hf_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/trie.py to trie.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/genre/entity_linking.py to entity_linking.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/tests/test_example.py to test_example.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying genre.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying genre.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying genre.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying genre.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/genre-0.1.3-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing genre-0.1.3-py3.7.egg\n",
      "Removing /home/petrakov/anaconda3/lib/python3.7/site-packages/genre-0.1.3-py3.7.egg\n",
      "Copying genre-0.1.3-py3.7.egg to /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Removing genre 0.1.3 from easy-install.pth file\n",
      "Adding genre 0.1.3 to easy-install.pth file\n",
      "\n",
      "Installed /home/petrakov/anaconda3/lib/python3.7/site-packages/genre-0.1.3-py3.7.egg\n",
      "Processing dependencies for genre==0.1.3\n",
      "Finished processing dependencies for genre==0.1.3\n",
      "Requirement already satisfied: sentencepiece in /home/petrakov/anaconda3/lib/python3.7/site-packages (0.1.95)\n",
      "Requirement already satisfied: marisa_trie in /home/petrakov/anaconda3/lib/python3.7/site-packages (0.7.7)\n",
      "Requirement already satisfied: setuptools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from marisa_trie) (41.4.0)\n",
      "/home/petrakov/mGENRE_MEL\n",
      "Cloning into 'fairseq'...\n",
      "remote: Enumerating objects: 25465, done.\u001b[K\n",
      "remote: Total 25465 (delta 0), reused 0 (delta 0), pack-reused 25465\u001b[K\n",
      "Receiving objects: 100% (25465/25465), 19.79 MiB | 3.76 MiB/s, done.\n",
      "Resolving deltas: 100% (18504/18504), done.\n",
      "/home/petrakov/mGENRE_MEL/fairseq\n",
      "Obtaining file:///home/petrakov/mGENRE_MEL/fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.12.3)\n",
      "Requirement already satisfied: tqdm in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (4.64.0)\n",
      "Requirement already satisfied: numpy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.21.6)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2.1.0)\n",
      "Requirement already satisfied: omegaconf<2.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2.0.6)\n",
      "Requirement already satisfied: torch in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.11.0)\n",
      "Requirement already satisfied: hydra-core<1.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.0.7)\n",
      "Requirement already satisfied: regex in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2022.7.9)\n",
      "Requirement already satisfied: cython in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (0.29.13)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (5.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /home/petrakov/anaconda3/lib/python3.7/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4c4d5a7) (5.1.2)\n",
      "Requirement already satisfied: typing-extensions in /home/petrakov/anaconda3/lib/python3.7/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4c4d5a7) (4.1.1)\n",
      "Requirement already satisfied: portalocker in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (2.5.1)\n",
      "Requirement already satisfied: colorama in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (0.4.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (0.8.10)\n",
      "Requirement already satisfied: pycparser in /home/petrakov/anaconda3/lib/python3.7/site-packages (from cffi->fairseq==1.0.0a0+4c4d5a7) (2.19)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (3.8.1)\n",
      "Installing collected packages: fairseq\n",
      "  Running setup.py develop for fairseq\n",
      "Successfully installed fairseq-1.0.0a0+4c4d5a7\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/search.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/quantization_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/options.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/binarizer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/registry.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/file_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/pdb.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/token_generation_constraints.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/ngram_repeat_block.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/hub_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/version.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/incremental_decoding_utils.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/nan_detector.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "copying fairseq/file_io.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "creating build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/train.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/generate.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/score.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/validate.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/hydra_train.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-3.7/fairseq_cli\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/utils.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/distributed_timeout_wrapper.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/module_proxy_wrapper.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/tpu_distributed_data_parallel.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "copying fairseq/distributed/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-3.7/fairseq/distributed\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/logging\n",
      "copying fairseq/logging/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/logging\n",
      "copying fairseq/logging/metrics.py -> build/lib.linux-x86_64-3.7/fairseq/logging\n",
      "copying fairseq/logging/progress_bar.py -> build/lib.linux-x86_64-3.7/fairseq/logging\n",
      "copying fairseq/logging/meters.py -> build/lib.linux-x86_64-3.7/fairseq/logging\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/lstm_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/transformer_align.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-3.7/fairseq/models\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/multi_corpus_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/shorten_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/fasta_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/add_target_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/bucket_pad_length_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/noising.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/config\n",
      "copying fairseq/config/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/config\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "copying fairseq/benchmark/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "copying fairseq/benchmark/dummy_lm.py -> build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "copying fairseq/benchmark/dummy_model.py -> build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "copying fairseq/benchmark/dummy_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "copying fairseq/benchmark/dummy_mt.py -> build/lib.linux-x86_64-3.7/fairseq/benchmark\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/dynamic_crf_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/transpose_last.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/kmeans_vector_quantizer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/quant_noise.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/same_pad.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/layer_drop.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/fairseq_dropout.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/fp32_group_norm.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/checkpoint_activations.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/gumbel_vector_quantizer.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-3.7/fairseq/modules\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel\n",
      "copying fairseq/model_parallel/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel\n",
      "copying fairseq/model_parallel/megatron_trainer.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples\n",
      "copying fairseq/examples/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "copying fairseq/dataclass/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "copying fairseq/dataclass/initialize.py -> build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "copying fairseq/dataclass/utils.py -> build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "copying fairseq/dataclass/constants.py -> build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "copying fairseq/dataclass/configs.py -> build/lib.linux-x86_64-3.7/fairseq/dataclass\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/cpu_adam.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/dynamic_loss_scaler.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/fused_adam.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/fused_lamb.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/shard.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "copying fairseq/optim/composite.py -> build/lib.linux-x86_64-3.7/fairseq/optim\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/translation_from_pretrained_bart.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/multilingual_denoising.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/translation_multi_simple_epoch.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/speech_to_text.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/tasks\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "copying fairseq/scoring/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "copying fairseq/scoring/bleu.py -> build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "copying fairseq/scoring/tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "copying fairseq/scoring/wer.py -> build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "copying fairseq/scoring/chrf.py -> build/lib.linux-x86_64-3.7/fairseq/scoring\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/ctc.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/wav2vec_criterion.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "copying fairseq/criterions/model_criterion.py -> build/lib.linux-x86_64-3.7/fairseq/criterions\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/model_gottbert.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/model_xlmr.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/model_camembert.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-3.7/fairseq/models/roberta\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/huggingface\n",
      "copying fairseq/models/huggingface/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/huggingface\n",
      "copying fairseq/models/huggingface/hf_gpt2.py -> build/lib.linux-x86_64-3.7/fairseq/models/huggingface\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/wav2vec\n",
      "copying fairseq/models/wav2vec/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/wav2vec\n",
      "copying fairseq/models/wav2vec/wav2vec2.py -> build/lib.linux-x86_64-3.7/fairseq/models/wav2vec\n",
      "copying fairseq/models/wav2vec/wav2vec2_asr.py -> build/lib.linux-x86_64-3.7/fairseq/models/wav2vec\n",
      "copying fairseq/models/wav2vec/wav2vec.py -> build/lib.linux-x86_64-3.7/fairseq/models/wav2vec\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "copying fairseq/models/speech_to_text/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "copying fairseq/models/speech_to_text/berard.py -> build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "copying fairseq/models/speech_to_text/utils.py -> build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "copying fairseq/models/speech_to_text/convtransformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "copying fairseq/models/speech_to_text/s2t_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-3.7/fairseq/models/bart\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/cmlm_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/levenshtein_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/insertion_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/fairseq_nat_model.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/levenshtein_utils.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "copying fairseq/models/nat/nat_crf_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/models/nat\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "copying fairseq/data/audio/speech_to_text_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "copying fairseq/data/audio/audio_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/legacy\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/multilingual_data_manager.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/multilingual_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/sampled_multi_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "copying fairseq/data/multilingual/sampling_method.py -> build/lib.linux-x86_64-3.7/fairseq/data/multilingual\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/hf_byte_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/characters.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/bytes.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/byte_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/byte_utils.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-3.7/fairseq/data/encoders\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms\n",
      "copying fairseq/data/audio/feature_transforms/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms\n",
      "copying fairseq/data/audio/feature_transforms/specaugment.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms\n",
      "copying fairseq/data/audio/feature_transforms/global_cmvn.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms\n",
      "copying fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/quantization\n",
      "copying fairseq/modules/quantization/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization\n",
      "copying fairseq/modules/quantization/quantization_options.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq\n",
      "copying fairseq/modules/quantization/pq/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq\n",
      "copying fairseq/modules/quantization/pq/em.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq\n",
      "copying fairseq/modules/quantization/pq/utils.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq\n",
      "copying fairseq/modules/quantization/pq/pq.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar\n",
      "copying fairseq/modules/quantization/scalar/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar\n",
      "copying fairseq/modules/quantization/scalar/utils.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar\n",
      "copying fairseq/modules/quantization/scalar/ops.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules\n",
      "copying fairseq/modules/quantization/pq/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules\n",
      "copying fairseq/modules/quantization/pq/modules/qemb.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules\n",
      "copying fairseq/modules/quantization/pq/modules/qlinear.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules\n",
      "copying fairseq/modules/quantization/pq/modules/qconv.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "copying fairseq/modules/quantization/scalar/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "copying fairseq/modules/quantization/scalar/modules/qemb.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "copying fairseq/modules/quantization/scalar/modules/qlinear.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "copying fairseq/modules/quantization/scalar/modules/qconv.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "copying fairseq/modules/quantization/scalar/modules/qact.py -> build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel/models\n",
      "copying fairseq/model_parallel/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models\n",
      "copying fairseq/model_parallel/models/transformer_lm.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models\n",
      "copying fairseq/model_parallel/models/transformer.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules\n",
      "copying fairseq/model_parallel/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules\n",
      "copying fairseq/model_parallel/modules/multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules\n",
      "copying fairseq/model_parallel/modules/transformer_layer.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel/criterions\n",
      "copying fairseq/model_parallel/criterions/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/criterions\n",
      "copying fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/criterions\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/roberta\n",
      "copying fairseq/model_parallel/models/roberta/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/roberta\n",
      "copying fairseq/model_parallel/models/roberta/model.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/roberta\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation\n",
      "copying fairseq/examples/simultaneous_translation/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition\n",
      "copying fairseq/examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition\n",
      "copying fairseq/examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition\n",
      "copying fairseq/examples/speech_recognition/infer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "copying fairseq/examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/rxf\n",
      "copying fairseq/examples/rxf/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/rxf\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/adaptive_span_model.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "copying fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt\n",
      "copying fairseq/examples/truncated_bptt/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt\n",
      "copying fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt\n",
      "copying fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\n",
      "copying fairseq/examples/fast_noisy_channel/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\n",
      "copying fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\n",
      "copying fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\n",
      "copying fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models\n",
      "copying fairseq/examples/simultaneous_translation/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models\n",
      "copying fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models\n",
      "copying fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "copying fairseq/examples/simultaneous_translation/eval/evaluate.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "copying fairseq/examples/simultaneous_translation/eval/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "copying fairseq/examples/simultaneous_translation/eval/eval_latency.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "copying fairseq/examples/simultaneous_translation/eval/client.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "copying fairseq/examples/simultaneous_translation/eval/server.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules\r\n",
      "copying fairseq/examples/simultaneous_translation/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules\r\n",
      "copying fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules\r\n",
      "copying fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules\r\n",
      "copying fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils\r\n",
      "copying fairseq/examples/simultaneous_translation/utils/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils\r\n",
      "copying fairseq/examples/simultaneous_translation/utils/functions.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils\r\n",
      "copying fairseq/examples/simultaneous_translation/utils/latency.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils\r\n",
      "copying fairseq/examples/simultaneous_translation/utils/data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/scorers/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/scorers/scorer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/scorers/text_scorer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/agents/word_splitter.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/agents/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/agents/simul_trans_agent.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/agents/agent.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "copying fairseq/examples/simultaneous_translation/eval/agents/simul_trans_text_agent.py -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models\r\n",
      "copying fairseq/examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models\r\n",
      "copying fairseq/examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models\r\n",
      "copying fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "copying fairseq/examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "copying fairseq/examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "copying fairseq/examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "copying fairseq/examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "copying fairseq/examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/tasks\r\n",
      "copying fairseq/examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/tasks\r\n",
      "copying fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/tasks\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions\r\n",
      "copying fairseq/examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions\r\n",
      "copying fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions\r\n",
      "copying fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src\r\n",
      "copying fairseq/examples/rxf/rxf_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src\r\n",
      "copying fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src\r\n",
      "copying fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/pass_through.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler\r\n",
      "copying fairseq/examples/.gitignore -> build/lib.linux-x86_64-3.7/fairseq/examples\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding\r\n",
      "copying fairseq/examples/constrained_decoding/normalize.py -> build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding\r\n",
      "copying fairseq/examples/constrained_decoding/tok.py -> build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding\r\n",
      "copying fairseq/examples/constrained_decoding/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/pay_less_attention_paper\r\n",
      "copying fairseq/examples/pay_less_attention_paper/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/pay_less_attention_paper\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/scaling_nmt\r\n",
      "copying fairseq/examples/scaling_nmt/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/scaling_nmt\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/README.glue.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/preprocess_RACE.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/README.pretraining.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/README.race.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/README.custom_classification.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/preprocess_RACE.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "copying fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "copying fairseq/examples/roberta/wsc/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "copying fairseq/examples/roberta/wsc/wsc_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "copying fairseq/examples/roberta/wsc/wsc_criterion.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "copying fairseq/examples/roberta/wsc/wsc_task.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "copying fairseq/examples/roberta/wsc/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa\r\n",
      "copying fairseq/examples/roberta/commonsense_qa/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa\r\n",
      "copying fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa\r\n",
      "copying fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa\r\n",
      "copying fairseq/examples/roberta/commonsense_qa/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator\r\n",
      "copying fairseq/examples/pointer_generator/preprocess.py -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator\r\n",
      "copying fairseq/examples/pointer_generator/postprocess.py -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator\r\n",
      "copying fairseq/examples/pointer_generator/README.xsum.md -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator\r\n",
      "copying fairseq/examples/pointer_generator/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/pointer_generator_src\r\n",
      "copying fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/pointer_generator_src\r\n",
      "copying fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/pointer_generator_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/nonautoregressive_translation\r\n",
      "copying fairseq/examples/nonautoregressive_translation/scripts.md -> build/lib.linux-x86_64-3.7/fairseq/examples/nonautoregressive_translation\r\n",
      "copying fairseq/examples/nonautoregressive_translation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/nonautoregressive_translation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/cross_lingual_language_model\r\n",
      "copying fairseq/examples/cross_lingual_language_model/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/cross_lingual_language_model\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wmt20\r\n",
      "copying fairseq/examples/wmt20/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/wmt20\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/quant_noise\r\n",
      "copying fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/quant_noise\r\n",
      "copying fairseq/examples/quant_noise/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/quant_noise\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "copying fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "copying fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "copying fairseq/examples/multilingual/train_multilingual_model.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "copying fairseq/examples/multilingual/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "copying fairseq/examples/multilingual/ML50_langs.txt -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/requirement.txt -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "copying fairseq/examples/multilingual/data_scripts/binarize.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils\r\n",
      "copying fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils\r\n",
      "copying fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils\r\n",
      "copying fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/linformer\r\n",
      "copying fairseq/examples/linformer/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src\r\n",
      "copying fairseq/examples/linformer/linformer_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/models\r\n",
      "copying fairseq/examples/linformer/linformer_src/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/models\r\n",
      "copying fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/models\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules\r\n",
      "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules\r\n",
      "copying fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules\r\n",
      "copying fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules\r\n",
      "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wmt19\r\n",
      "copying fairseq/examples/wmt19/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/wmt19\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe\r\n",
      "copying fairseq/examples/byte_level_bpe/gru_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe\r\n",
      "copying fairseq/examples/byte_level_bpe/get_data.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe\r\n",
      "copying fairseq/examples/byte_level_bpe/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe\r\n",
      "copying fairseq/examples/byte_level_bpe/get_bitext.py -> build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100\r\n",
      "copying fairseq/examples/m2m_100/install_dependecies.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100\r\n",
      "copying fairseq/examples/m2m_100/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100\r\n",
      "copying fairseq/examples/m2m_100/tok.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/thirdparty\r\n",
      "copying fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/thirdparty\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data\r\n",
      "copying fairseq/examples/m2m_100/process_data/dedup_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data\r\n",
      "copying fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data\r\n",
      "copying fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/mbart\r\n",
      "copying fairseq/examples/mbart/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/mbart\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "copying fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "copying fairseq/examples/wav2vec/wav2vec_featurize.py -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "copying fairseq/examples/wav2vec/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "copying fairseq/examples/wav2vec/libri_labels.py -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "copying fairseq/examples/wav2vec/wav2vec_manifest.py -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/pretraining\r\n",
      "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/pretraining\r\n",
      "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/pretraining\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning\r\n",
      "copying fairseq/examples/simultaneous_translation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/xlmr\r\n",
      "copying fairseq/examples/xlmr/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/xlmr\r\n",
      "copying fairseq/examples/speech_recognition/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra\r\n",
      "copying fairseq/examples/speech_recognition/hydra/infer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra\r\n",
      "copying fairseq/examples/speech_recognition/hydra/decoder.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra\r\n",
      "copying fairseq/examples/speech_recognition/hydra/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf\r\n",
      "copying fairseq/examples/speech_recognition/hydra/conf/infer.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf/hydra\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper\r\n",
      "copying fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper/ax.yaml -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/datasets\r\n",
      "copying fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/datasets\r\n",
      "copying fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/datasets\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/utils\r\n",
      "copying fairseq/examples/speech_recognition/utils/wer_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/utils\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/camembert\r\n",
      "copying fairseq/examples/camembert/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/camembert\r\n",
      "copying fairseq/examples/noisychannel/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/stories\r\n",
      "copying fairseq/examples/stories/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/stories\r\n",
      "copying fairseq/examples/rxf/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/rxf\r\n",
      "copying fairseq/examples/adaptive_span/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span\r\n",
      "copying fairseq/examples/truncated_bptt/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/prep_mustc_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/prep_covost_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "copying fairseq/examples/speech_to_text/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "copying fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "copying fairseq/examples/speech_to_text/docs/mustc_example.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "copying fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "copying fairseq/examples/speech_to_text/docs/covost_example.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "copying fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/simul_trans_agent.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/extract_bt_data.py -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/sacrebleu.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/tokenized_bleu.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "copying fairseq/examples/backtranslation/deduplicate_lines.py -> build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "copying fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "copying fairseq/examples/translation/prepare-wmt14en2de.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "copying fairseq/examples/translation/prepare-iwslt14.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "copying fairseq/examples/translation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "copying fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/translation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/bart\r\n",
      "copying fairseq/examples/bart/README.summarization.md -> build/lib.linux-x86_64-3.7/fairseq/examples/bart\r\n",
      "copying fairseq/examples/bart/README.glue.md -> build/lib.linux-x86_64-3.7/fairseq/examples/bart\r\n",
      "copying fairseq/examples/bart/summarize.py -> build/lib.linux-x86_64-3.7/fairseq/examples/bart\r\n",
      "copying fairseq/examples/bart/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/bart\r\n",
      "copying fairseq/examples/fast_noisy_channel/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/language_model\r\n",
      "copying fairseq/examples/language_model/prepare-wikitext-103.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/language_model\r\n",
      "copying fairseq/examples/language_model/README.conv.md -> build/lib.linux-x86_64-3.7/fairseq/examples/language_model\r\n",
      "copying fairseq/examples/language_model/README.adaptive_inputs.md -> build/lib.linux-x86_64-3.7/fairseq/examples/language_model\r\n",
      "copying fairseq/examples/language_model/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/language_model\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/megatron_11b\r\n",
      "copying fairseq/examples/megatron_11b/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/megatron_11b\r\n",
      "copying fairseq/examples/megatron_11b/detok.py -> build/lib.linux-x86_64-3.7/fairseq/examples/megatron_11b\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/criss\r\n",
      "copying fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/criss\r\n",
      "copying fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/criss\r\n",
      "copying fairseq/examples/criss/save_encoder.py -> build/lib.linux-x86_64-3.7/fairseq/examples/criss\r\n",
      "copying fairseq/examples/criss/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/criss\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/criss/sentence_retrieval\r\n",
      "copying fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/lib.linux-x86_64-3.7/fairseq/examples/criss/sentence_retrieval\r\n",
      "copying fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/criss/sentence_retrieval\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/criss/mining\r\n",
      "copying fairseq/examples/criss/mining/mine_example.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/criss/mining\r\n",
      "copying fairseq/examples/criss/mining/mine.py -> build/lib.linux-x86_64-3.7/fairseq/examples/criss/mining\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/criss/unsupervised_mt\r\n",
      "copying fairseq/examples/criss/unsupervised_mt/eval.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/criss/unsupervised_mt\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/conv_seq2seq\r\n",
      "copying fairseq/examples/conv_seq2seq/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/conv_seq2seq\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/layerdrop\r\n",
      "copying fairseq/examples/layerdrop/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/layerdrop\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/laser\r\n",
      "copying fairseq/examples/laser/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/laser\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "copying fairseq/examples/laser/laser_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "copying fairseq/examples/laser/laser_src/laser_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "copying fairseq/examples/laser/laser_src/laser_task.py -> build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "copying fairseq/examples/laser/laser_src/laser_lstm.py -> build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "copying fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth\r\n",
      "copying fairseq/examples/latent_depth/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "copying fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/joint_alignment_translation\r\n",
      "copying fairseq/examples/joint_alignment_translation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/joint_alignment_translation\r\n",
      "copying fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/lib.linux-x86_64-3.7/fairseq/examples/joint_alignment_translation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying fairseq/examples/unsupervised_quality_estimation/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe\r\n",
      "copying fairseq/examples/translation_moe/score.py -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe\r\n",
      "copying fairseq/examples/translation_moe/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/gottbert\r\n",
      "copying fairseq/examples/gottbert/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/gottbert\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/examples/paraphraser\r\n",
      "copying fairseq/examples/paraphraser/paraphrase.py -> build/lib.linux-x86_64-3.7/fairseq/examples/paraphraser\r\n",
      "copying fairseq/examples/paraphraser/README.md -> build/lib.linux-x86_64-3.7/fairseq/examples/paraphraser\r\n",
      "copying fairseq/config/config.yaml -> build/lib.linux-x86_64-3.7/fairseq/config\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/config/model\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec\r\n",
      "copying fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "copying fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm\r\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec2\r\n",
      "copying fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec2\r\n",
      "copying fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec2\r\n",
      "running build_ext\r\n",
      "/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/utils/cpp_extension.py:387: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\r\n",
      "building 'fairseq.libbleu' extension\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/fairseq\n",
      "creating build/temp.linux-x86_64-3.7/fairseq/clib\n",
      "creating build/temp.linux-x86_64-3.7/fairseq/clib/libbleu\n",
      "gcc -pthread -B /home/petrakov/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/petrakov/anaconda3/include/python3.7m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option \u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K is valid for C/ObjC but not for C++\n",
      "gcc -pthread -B /home/petrakov/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/petrakov/anaconda3/include/python3.7m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option \u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K is valid for C/ObjC but not for C++\n",
      "g++ -pthread -shared -B /home/petrakov/anaconda3/compiler_compat -L/home/petrakov/anaconda3/lib -Wl,-rpath=/home/petrakov/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n",
      "skipping 'fairseq/data/data_utils_fast.cpp' Cython extension (up-to-date)\n",
      "building 'fairseq.data.data_utils_fast' extension\n",
      "creating build/temp.linux-x86_64-3.7/fairseq/data\n",
      "gcc -pthread -B /home/petrakov/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include -I/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include -I/home/petrakov/anaconda3/include/python3.7m -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option \u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K is valid for C/ObjC but not for C++\n",
      "In file included from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kfairseq/data/data_utils_fast.cpp:712\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "g++ -pthread -shared -B /home/petrakov/anaconda3/compiler_compat -L/home/petrakov/anaconda3/lib -Wl,-rpath=/home/petrakov/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "skipping 'fairseq/data/token_block_utils_fast.cpp' Cython extension (up-to-date)\n",
      "building 'fairseq.data.token_block_utils_fast' extension\n",
      "gcc -pthread -B /home/petrakov/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include -I/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include -I/home/petrakov/anaconda3/include/python3.7m -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option \u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K is valid for C/ObjC but not for C++\n",
      "In file included from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:713\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/petrakov/anaconda3/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:\u001b[m\u001b[K In function \u001b[01m\u001b[KPyArrayObject* __pyx_f_7fairseq_4data_22token_block_utils_fast__get_slice_indices_fast(PyArrayObject*, PyObject*, int, int, int)\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:3417:36:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[K__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong int\u001b[m\u001b[K} and \u001b[01m\u001b[Ksize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      " 3417 |       __pyx_t_4 = ((\u001b[01;35m\u001b[K__pyx_v_sz_idx < __pyx_t_10\u001b[m\u001b[K) != 0);\n",
      "      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:3612:36:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: \u001b[01m\u001b[K__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong int\u001b[m\u001b[K} and \u001b[01m\u001b[Ksize_t\u001b[m\u001b[K {aka \u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K} [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
      " 3612 |       __pyx_t_3 = ((\u001b[01;35m\u001b[K__pyx_v_sz_idx < __pyx_t_10\u001b[m\u001b[K) != 0);\n",
      "      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "g++ -pthread -shared -B /home/petrakov/anaconda3/compiler_compat -L/home/petrakov/anaconda3/lib -Wl,-rpath=/home/petrakov/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.libnat' extension\n",
      "creating build/temp.linux-x86_64-3.7/fairseq/clib/libnat\n",
      "gcc -pthread -B /home/petrakov/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/include -I/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/include/TH -I/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/include/THC -I/home/petrakov/anaconda3/include/python3.7m -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option \u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K is valid for C/ObjC but not for C++\n",
      "g++ -pthread -shared -B /home/petrakov/anaconda3/compiler_compat -L/home/petrakov/anaconda3/lib -Wl,-rpath=/home/petrakov/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -L/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "running egg_info\n",
      "writing fairseq.egg-info/PKG-INFO\n",
      "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
      "writing entry points to fairseq.egg-info/entry_points.txt\n",
      "writing requirements to fairseq.egg-info/requires.txt\n",
      "writing top-level names to fairseq.egg-info/top_level.txt\n",
      "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
      "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so -> fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so -> fairseq\n",
      "Creating /home/petrakov/anaconda3/lib/python3.7/site-packages/fairseq.egg-link (link to .)\n",
      "fairseq 1.0.0a0+4c4d5a7 is already the active version in easy-install.pth\n",
      "Installing fairseq-eval-lm script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-generate script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-hydra-train script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-interactive script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-preprocess script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-score script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-train script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-validate script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Installed /home/petrakov/mGENRE_MEL/fairseq\n",
      "Processing dependencies for fairseq==1.0.0a0+4c4d5a7\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3 script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3.7 script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tqdm==4.64.0\n",
      "Best match: tqdm 4.64.0\n",
      "Adding tqdm 4.64.0 to easy-install.pth file\n",
      "Installing tqdm script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for torch==1.11.0\n",
      "Best match: torch 1.11.0\n",
      "Adding torch 1.11.0 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /home/petrakov/anaconda3/bin\n",
      "Installing convert-onnx-to-caffe2 script to /home/petrakov/anaconda3/bin\n",
      "Installing torchrun script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for sacrebleu==2.1.0\n",
      "Best match: sacrebleu 2.1.0\n",
      "Adding sacrebleu 2.1.0 to easy-install.pth file\n",
      "Installing sacrebleu script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for regex==2022.7.9\n",
      "Best match: regex 2022.7.9\n",
      "Adding regex 2022.7.9 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for omegaconf==2.0.6\n",
      "Best match: omegaconf 2.0.6\n",
      "Adding omegaconf 2.0.6 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for hydra-core==1.0.7\n",
      "Best match: hydra-core 1.0.7\n",
      "Adding hydra-core 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for Cython==0.29.13\n",
      "Best match: Cython 0.29.13\n",
      "Adding Cython 0.29.13 to easy-install.pth file\n",
      "Installing cygdb script to /home/petrakov/anaconda3/bin\n",
      "Installing cython script to /home/petrakov/anaconda3/bin\n",
      "Installing cythonize script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cffi==1.12.3\n",
      "Best match: cffi 1.12.3\n",
      "Adding cffi 1.12.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for typing-extensions==4.1.1\n",
      "Best match: typing-extensions 4.1.1\n",
      "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for colorama==0.4.1\n",
      "Best match: colorama 0.4.1\n",
      "Adding colorama 0.4.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for portalocker==2.5.1\n",
      "Best match: portalocker 2.5.1\n",
      "Adding portalocker 2.5.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tabulate==0.8.10\n",
      "Best match: tabulate 0.8.10\n",
      "Adding tabulate 0.8.10 to easy-install.pth file\n",
      "Installing tabulate script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for PyYAML==5.1.2\n",
      "Best match: PyYAML 5.1.2\n",
      "Adding PyYAML 5.1.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for antlr4-python3-runtime==4.8\n",
      "Best match: antlr4-python3-runtime 4.8\n",
      "Adding antlr4-python3-runtime 4.8 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for importlib-resources==5.8.0\n",
      "Best match: importlib-resources 5.8.0\n",
      "Adding importlib-resources 5.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pycparser==2.19\n",
      "Best match: pycparser 2.19\n",
      "Adding pycparser 2.19 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for zipp==3.8.1\n",
      "Best match: zipp 3.8.1\n",
      "Adding zipp 3.8.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Finished processing dependencies for fairseq==1.0.0a0+4c4d5a7\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing fairseq.egg-info/PKG-INFO\n",
      "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
      "writing entry points to fairseq.egg-info/entry_points.txt\n",
      "writing requirements to fairseq.egg-info/requires.txt\n",
      "writing top-level names to fairseq.egg-info/top_level.txt\n",
      "/home/petrakov/anaconda3/lib/python3.7/site-packages/torch/utils/cpp_extension.py:387: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
      "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying fairseq/version.py -> build/lib.linux-x86_64-3.7/fairseq\n",
      "running build_ext\n",
      "skipping 'fairseq/data/data_utils_fast.cpp' Cython extension (up-to-date)\n",
      "skipping 'fairseq/data/token_block_utils_fast.cpp' Cython extension (up-to-date)\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/__init__.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/utils.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/distributed_timeout_wrapper.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/module_proxy_wrapper.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/tpu_distributed_data_parallel.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/distributed/legacy_distributed_data_parallel.py -> build/bdist.linux-x86_64/egg/fairseq/distributed\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/search.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/quantization_utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/options.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/logging\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/logging/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/logging\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/logging/metrics.py -> build/bdist.linux-x86_64/egg/fairseq/logging\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/logging/progress_bar.py -> build/bdist.linux-x86_64/egg/fairseq/logging\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/logging/meters.py -> build/bdist.linux-x86_64/egg/fairseq/logging\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/binarizer.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fairseq_incremental_decoder.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/model_gottbert.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/alignment_utils.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/model_xlmr.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/model_camembert.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/hub_interface.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/roberta/model.py -> build/bdist.linux-x86_64/egg/fairseq/models/roberta\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/huggingface\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/huggingface/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/huggingface\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/huggingface/hf_gpt2.py -> build/bdist.linux-x86_64/egg/fairseq/models/huggingface\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fairseq_model.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fconv.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/transformer_from_pretrained_xlm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/wav2vec/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/wav2vec/wav2vec2.py -> build/bdist.linux-x86_64/egg/fairseq/models/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/wav2vec/wav2vec2_asr.py -> build/bdist.linux-x86_64/egg/fairseq/models/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/wav2vec/wav2vec.py -> build/bdist.linux-x86_64/egg/fairseq/models/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fconv_self_att.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/model_utils.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/transformer_lm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/composite_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text/berard.py -> build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text/utils.py -> build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text/convtransformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/speech_to_text/s2t_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/lstm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/bart\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/bart/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/bart\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/bart/hub_interface.py -> build/bdist.linux-x86_64/egg/fairseq/models/bart\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/bart/model.py -> build/bdist.linux-x86_64/egg/fairseq/models/bart\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fairseq_decoder.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/distributed_fairseq_model.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fconv_lm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/lstm_lm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/transformer_align.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/multilingual_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/nonautoregressive_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/cmlm_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/levenshtein_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/insertion_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/nonautoregressive_ensembles.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/fairseq_nat_model.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/levenshtein_utils.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/nat/nat_crf_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/models/nat\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/fairseq_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/lightconv_lm.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/models/lightconv.py -> build/bdist.linux-x86_64/egg/fairseq/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/iterative_refinement_generator.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/trainer.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/sequence_generator.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data/audio\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/raw_audio_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/speech_to_text_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/audio_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms/specaugment.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms/global_cmvn.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/num_samples_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multi_corpus_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/fairseq_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/language_pair_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/base_wrapper_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data/legacy\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/legacy/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data/legacy\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/legacy/masked_lm_dictionary.py -> build/bdist.linux-x86_64/egg/fairseq/data/legacy\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/legacy/block_pair_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/legacy\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/legacy/masked_lm_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/legacy\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/pad_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/sort_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/multilingual_data_manager.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/multilingual_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/sampled_multi_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multilingual/sampling_method.py -> build/bdist.linux-x86_64/egg/fairseq/data/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/concat_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/nested_dictionary_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/iterators.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/roll_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/plasma_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/prepend_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/prepend_token_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/numel_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/shorten_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/mask_tokens_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/denoising_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/monolingual_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/replace_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/fasta_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/round_robin_zip_datasets.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/raw_label_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/multi_corpus_sampled_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/fastbpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/gpt2_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/utils.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/moses_tokenizer.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/nltk_tokenizer.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/hf_byte_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/sentencepiece_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/subword_nmt_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/characters.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/bytes.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/gpt2_bpe_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/byte_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/hf_bert_bpe.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/byte_utils.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/encoders/space_tokenizer.py -> build/bdist.linux-x86_64/egg/fairseq/data/encoders\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/subsample_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/append_token_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/add_target_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/backtranslation_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/list_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/lru_cache_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/strip_token_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/resampling_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/bucket_pad_length_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/lm_context_window_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/noising.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/offset_tokens_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/transform_eos_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/id_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/indexed_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/concat_sentences_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/colorize_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/dictionary.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/transform_eos_lang_pair_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/registry.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/file_utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/pdb.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/sequence_scorer.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tokenizer.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/token_generation_constraints.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/config\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/config\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/config.yaml -> build/bdist.linux-x86_64/egg/fairseq/config\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/config/model\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/config/model/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/wav2vec\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/transformer_lm\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/config/model/wav2vec2\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/wav2vec2\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/bdist.linux-x86_64/egg/fairseq/config/model/wav2vec2\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/checkpoint_utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/ngram_repeat_block.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/hub_utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/benchmark/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/benchmark/dummy_lm.py -> build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/benchmark/dummy_model.py -> build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/benchmark/dummy_masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/benchmark/dummy_mt.py -> build/bdist.linux-x86_64/egg/fairseq/benchmark\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/downsampled_multihead_attention.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/gelu.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamic_crf_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/linearized_convolution.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/sinusoidal_positional_embedding.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/transpose_last.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/kmeans_vector_quantizer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer/setup.py -> build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quant_noise.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/conv_tbc.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/adaptive_softmax.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/cross_entropy.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/same_pad.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/layer_drop.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/fairseq_dropout.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/fp32_group_norm.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/unfold.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/beamable_mm.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/multihead_attention.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/transformer_sentence_encoder_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/character_token_embedder.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer/lightconv_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/lightconv_layer/setup.py -> build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/layer_norm.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/scalar_bias.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/quantization\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/em.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/utils.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/pq.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules/qemb.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules/qlinear.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/pq/modules/qconv.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/utils.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/ops.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules/qemb.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules/qlinear.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules/qconv.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/scalar/modules/qact.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/quantization/quantization_options.py -> build/bdist.linux-x86_64/egg/fairseq/modules/quantization\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/transformer_layer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/learned_positional_embedding.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/lightweight_convolution.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/positional_embedding.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/checkpoint_activations.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/grad_multiply.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/adaptive_input.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/sparse_transformer_sentence_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/transformer_sentence_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/dynamic_convolution.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/sparse_multihead_attention.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/gumbel_vector_quantizer.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/modules/vggblock.py -> build/bdist.linux-x86_64/egg/fairseq/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/version.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/incremental_decoding_utils.py -> build/bdist.linux-x86_64/egg/fairseq\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/roberta/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/roberta/model.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/transformer_lm.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/transformer.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/megatron_trainer.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules/multihead_attention.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/modules/transformer_layer.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/model_parallel/criterions\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/criterions/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/criterions\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/bdist.linux-x86_64/egg/fairseq/model_parallel/criterions\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding/normalize.py -> build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding/tok.py -> build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/constrained_decoding/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/pay_less_attention_paper\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pay_less_attention_paper/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/pay_less_attention_paper\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/scaling_nmt\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/scaling_nmt/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/scaling_nmt\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/README.glue.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/preprocess_RACE.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/README.pretraining.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc/wsc_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc/wsc_criterion.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc/wsc_task.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/wsc/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/commonsense_qa/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/README.race.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/README.custom_classification.md -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/preprocess_RACE.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/examples/roberta\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/preprocess.py -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/postprocess.py -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/README.xsum.md -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/pointer_generator_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/pointer_generator_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/pointer_generator_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/pointer_generator/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/nonautoregressive_translation\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/nonautoregressive_translation/scripts.md -> build/bdist.linux-x86_64/egg/fairseq/examples/nonautoregressive_translation\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/nonautoregressive_translation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/nonautoregressive_translation\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/cross_lingual_language_model\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/cross_lingual_language_model/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/cross_lingual_language_model\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wmt20\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wmt20/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/wmt20\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/quant_noise\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/quant_noise\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/quant_noise/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/quant_noise\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/requirement.txt -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/data_scripts/binarize.py -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/train_multilingual_model.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/multilingual/ML50_langs.txt -> build/bdist.linux-x86_64/egg/fairseq/examples/multilingual\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/linformer\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/linformer/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/linformer\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wmt19\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wmt19/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/wmt19\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe/gru_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe/get_data.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/byte_level_bpe/get_bitext.py -> build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/install_dependecies.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data/dedup_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/m2m_100/tok.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/mbart\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/mbart/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/mbart\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/pretraining\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/pretraining\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/pretraining\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/config/finetuning\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/wav2vec_featurize.py -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/libri_labels.py -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/wav2vec/wav2vec_manifest.py -> build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/evaluate.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/eval_latency.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers/scorer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/scorers/text_scorer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/client.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents/word_splitter.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents/simul_trans_agent.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents/agent.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/agents/simul_trans_text_agent.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/eval/server.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils/functions.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils/latency.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/simultaneous_translation/utils/data_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/xlmr\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/xlmr/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/xlmr\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/conf\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/conf/hydra\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper/ax.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/conf/hydra/sweeper\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/conf/infer.yaml -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/conf\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/infer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/decoder.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/hydra/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models/vggtransformer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/w2l_decoder.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data/data_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data/asr_dataset.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data/collaters.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/data/replabels.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/infer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/datasets\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/datasets\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/datasets\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/utils\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/utils/wer_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/utils\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/tasks\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/tasks/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/tasks\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/tasks\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/camembert\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/camembert/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/camembert\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_tune.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_options.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_score_bw.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_score_lm.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/noisychannel/rerank_generate.py -> build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/stories\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/stories/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/stories\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/rxf\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/rxf/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/rxf\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/rxf/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/rxf\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/adaptive_span_model.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs/mustc_example.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs/covost_example.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/docs\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/prep_mustc_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation/agents/simul_trans_agent.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation/agents\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/data_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/prep_covost_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/speech_to_text/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/extract_bt_data.py -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/sacrebleu.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/tokenized_bleu.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/backtranslation/deduplicate_lines.py -> build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation/prepare-wmt14en2de.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation/prepare-iwslt14.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/translation\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/bart\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/bart/README.summarization.md -> build/bdist.linux-x86_64/egg/fairseq/examples/bart\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/bart/README.glue.md -> build/bdist.linux-x86_64/egg/fairseq/examples/bart\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/bart/summarize.py -> build/bdist.linux-x86_64/egg/fairseq/examples/bart\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/bart/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/bart\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/fast_noisy_channel/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/language_model\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/language_model/prepare-wikitext-103.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/language_model\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/language_model/README.conv.md -> build/bdist.linux-x86_64/egg/fairseq/examples/language_model\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/language_model/README.adaptive_inputs.md -> build/bdist.linux-x86_64/egg/fairseq/examples/language_model\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/language_model/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/language_model\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/megatron_11b\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/megatron_11b/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/megatron_11b\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/megatron_11b/detok.py -> build/bdist.linux-x86_64/egg/fairseq/examples/megatron_11b\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/criss\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/criss\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/criss/sentence_retrieval\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/bdist.linux-x86_64/egg/fairseq/examples/criss/sentence_retrieval\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/criss/sentence_retrieval\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/criss/mining\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/mining/mine_example.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/criss/mining\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/mining/mine.py -> build/bdist.linux-x86_64/egg/fairseq/examples/criss/mining\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/criss\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/criss/unsupervised_mt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/unsupervised_mt/eval.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/criss/unsupervised_mt\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/save_encoder.py -> build/bdist.linux-x86_64/egg/fairseq/examples/criss\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/criss/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/criss\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/conv_seq2seq\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/conv_seq2seq/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/conv_seq2seq\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/layerdrop\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/layerdrop/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/layerdrop\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/laser\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src/laser_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src/laser_task.py -> build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src/laser_lstm.py -> build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/laser/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/laser\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/loss\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/modules\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/.gitignore -> build/bdist.linux-x86_64/egg/fairseq/examples\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/joint_alignment_translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/joint_alignment_translation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/joint_alignment_translation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/bdist.linux-x86_64/egg/fairseq/examples/joint_alignment_translation\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/unsupervised_quality_estimation/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/score.py -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/translation_moe/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/gottbert\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/gottbert/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/gottbert\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/examples/paraphraser\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/paraphraser/paraphrase.py -> build/bdist.linux-x86_64/egg/fairseq/examples/paraphraser\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/examples/paraphraser/README.md -> build/bdist.linux-x86_64/egg/fairseq/examples/paraphraser\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/nan_detector.py -> build/bdist.linux-x86_64/egg/fairseq\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/dataclass/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/dataclass/initialize.py -> build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/dataclass/utils.py -> build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/dataclass/constants.py -> build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/dataclass/configs.py -> build/bdist.linux-x86_64/egg/fairseq/dataclass\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/file_io.py -> build/bdist.linux-x86_64/egg/fairseq\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/adadelta.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/adafactor.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/bmuf.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/sgd.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/adamax.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/nag.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/cpu_adam.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/fixed_schedule.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/pass_through.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/adagrad.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/dynamic_loss_scaler.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/fused_adam.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/fairseq_optimizer.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/fused_lamb.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/adam.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/shard.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/optim/composite.py -> build/bdist.linux-x86_64/egg/fairseq/optim\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/multilingual_translation.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/translation_from_pretrained_bart.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/semisupervised_translation.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/language_modeling.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/multilingual_denoising.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/translation_multi_simple_epoch.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/sentence_prediction.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/sentence_ranking.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/audio_pretraining.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/denoising.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/legacy_masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/translation_from_pretrained_xlm.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/fairseq_task.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/translation.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/speech_to_text.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/cross_lingual_lm.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/translation_lev.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/tasks/multilingual_masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/tasks\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/scoring/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/scoring/bleu.py -> build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/scoring/tokenizer.py -> build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/scoring/wer.py -> build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/scoring/chrf.py -> build/bdist.linux-x86_64/egg/fairseq/scoring\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/__init__.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/ctc.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/cross_entropy.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/wav2vec_criterion.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/sentence_prediction.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/fairseq_criterion.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/sentence_ranking.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/legacy_masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/label_smoothed_cross_entropy.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/adaptive_loss.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/composite_loss.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/masked_lm.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/nat_loss.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/criterions/model_criterion.py -> build/bdist.linux-x86_64/egg/fairseq/criterions\r\n",
      "creating build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/__init__.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/train.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/generate.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/score.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/preprocess.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/validate.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/hydra_train.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/eval_lm.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "copying build/lib.linux-x86_64-3.7/fairseq_cli/interactive.py -> build/bdist.linux-x86_64/egg/fairseq_cli\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/utils.py to utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/distributed_timeout_wrapper.py to distributed_timeout_wrapper.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/module_proxy_wrapper.py to module_proxy_wrapper.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/tpu_distributed_data_parallel.py to tpu_distributed_data_parallel.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/distributed/legacy_distributed_data_parallel.py to legacy_distributed_data_parallel.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/search.py to search.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/quantization_utils.py to quantization_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/options.py to options.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/logging/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/logging/metrics.py to metrics.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/logging/progress_bar.py to progress_bar.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/logging/meters.py to meters.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/binarizer.py to binarizer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fairseq_incremental_decoder.py to fairseq_incremental_decoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/model_gottbert.py to model_gottbert.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/alignment_utils.py to alignment_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/model_xlmr.py to model_xlmr.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/model_camembert.py to model_camembert.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/hub_interface.py to hub_interface.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/roberta/model.py to model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/huggingface/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/huggingface/hf_gpt2.py to hf_gpt2.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fairseq_model.py to fairseq_model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fconv.py to fconv.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/transformer_from_pretrained_xlm.py to transformer_from_pretrained_xlm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/wav2vec/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/wav2vec/wav2vec2.py to wav2vec2.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/wav2vec/wav2vec2_asr.py to wav2vec2_asr.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/wav2vec/wav2vec.py to wav2vec.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fconv_self_att.py to fconv_self_att.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/model_utils.py to model_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/transformer_lm.py to transformer_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/composite_encoder.py to composite_encoder.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text/berard.py to berard.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text/convtransformer.py to convtransformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/speech_to_text/s2t_transformer.py to s2t_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/lstm.py to lstm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/bart/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/bart/hub_interface.py to hub_interface.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/bart/model.py to model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fairseq_decoder.py to fairseq_decoder.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/distributed_fairseq_model.py to distributed_fairseq_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fconv_lm.py to fconv_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/lstm_lm.py to lstm_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/masked_lm.py to masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/transformer_align.py to transformer_align.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/transformer.py to transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/multilingual_transformer.py to multilingual_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/nonautoregressive_transformer.py to nonautoregressive_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/cmlm_transformer.py to cmlm_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/levenshtein_transformer.py to levenshtein_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/insertion_transformer.py to insertion_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/nonautoregressive_ensembles.py to nonautoregressive_ensembles.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/fairseq_nat_model.py to fairseq_nat_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/iterative_nonautoregressive_transformer.py to iterative_nonautoregressive_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/levenshtein_utils.py to levenshtein_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/nat/nat_crf_transformer.py to nat_crf_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/fairseq_encoder.py to fairseq_encoder.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/lightconv_lm.py to lightconv_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/models/lightconv.py to lightconv.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/iterative_refinement_generator.py to iterative_refinement_generator.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/trainer.py to trainer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/sequence_generator.py to sequence_generator.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/raw_audio_dataset.py to raw_audio_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/speech_to_text_dataset.py to speech_to_text_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/audio_utils.py to audio_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms/specaugment.py to specaugment.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms/global_cmvn.py to global_cmvn.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/audio/feature_transforms/utterance_cmvn.py to utterance_cmvn.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/num_samples_dataset.py to num_samples_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multi_corpus_dataset.py to multi_corpus_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/fairseq_dataset.py to fairseq_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/language_pair_dataset.py to language_pair_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/base_wrapper_dataset.py to base_wrapper_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/legacy/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/legacy/masked_lm_dictionary.py to masked_lm_dictionary.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/legacy/block_pair_dataset.py to block_pair_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/legacy/masked_lm_dataset.py to masked_lm_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/pad_dataset.py to pad_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/sort_dataset.py to sort_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/multilingual_data_manager.py to multilingual_data_manager.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/multilingual_utils.py to multilingual_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/sampled_multi_epoch_dataset.py to sampled_multi_epoch_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/sampled_multi_dataset.py to sampled_multi_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multilingual/sampling_method.py to sampling_method.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/concat_dataset.py to concat_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/nested_dictionary_dataset.py to nested_dictionary_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/iterators.py to iterators.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/roll_dataset.py to roll_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/plasma_utils.py to plasma_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/prepend_dataset.py to prepend_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/prepend_token_dataset.py to prepend_token_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/numel_dataset.py to numel_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/data_utils.py to data_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/shorten_dataset.py to shorten_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/mask_tokens_dataset.py to mask_tokens_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/denoising_dataset.py to denoising_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/monolingual_dataset.py to monolingual_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/replace_dataset.py to replace_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/fasta_dataset.py to fasta_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/round_robin_zip_datasets.py to round_robin_zip_datasets.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/raw_label_dataset.py to raw_label_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/multi_corpus_sampled_dataset.py to multi_corpus_sampled_dataset.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/fastbpe.py to fastbpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/gpt2_bpe.py to gpt2_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/moses_tokenizer.py to moses_tokenizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/nltk_tokenizer.py to nltk_tokenizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/hf_byte_bpe.py to hf_byte_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/sentencepiece_bpe.py to sentencepiece_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/subword_nmt_bpe.py to subword_nmt_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/characters.py to characters.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/bytes.py to bytes.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/gpt2_bpe_utils.py to gpt2_bpe_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/byte_bpe.py to byte_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/hf_bert_bpe.py to hf_bert_bpe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/byte_utils.py to byte_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/encoders/space_tokenizer.py to space_tokenizer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/subsample_dataset.py to subsample_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/append_token_dataset.py to append_token_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/add_target_dataset.py to add_target_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/backtranslation_dataset.py to backtranslation_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/list_dataset.py to list_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/lru_cache_dataset.py to lru_cache_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/strip_token_dataset.py to strip_token_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/resampling_dataset.py to resampling_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/bucket_pad_length_dataset.py to bucket_pad_length_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/lm_context_window_dataset.py to lm_context_window_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/token_block_dataset.py to token_block_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/noising.py to noising.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/offset_tokens_dataset.py to offset_tokens_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/transform_eos_dataset.py to transform_eos_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/id_dataset.py to id_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/indexed_dataset.py to indexed_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/concat_sentences_dataset.py to concat_sentences_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/colorize_dataset.py to colorize_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/dictionary.py to dictionary.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/transform_eos_lang_pair_dataset.py to transform_eos_lang_pair_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/registry.py to registry.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/utils.py to utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/file_utils.py to file_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/pdb.py to pdb.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/sequence_scorer.py to sequence_scorer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tokenizer.py to tokenizer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/token_generation_constraints.py to token_generation_constraints.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/config/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/checkpoint_utils.py to checkpoint_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/ngram_repeat_block.py to ngram_repeat_block.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/hub_utils.py to hub_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/benchmark/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/benchmark/dummy_lm.py to dummy_lm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/benchmark/dummy_model.py to dummy_model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/benchmark/dummy_masked_lm.py to dummy_masked_lm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/benchmark/dummy_mt.py to dummy_mt.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/downsampled_multihead_attention.py to downsampled_multihead_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/gelu.py to gelu.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamic_crf_layer.py to dynamic_crf_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/linearized_convolution.py to linearized_convolution.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/sinusoidal_positional_embedding.py to sinusoidal_positional_embedding.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/transpose_last.py to transpose_last.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/kmeans_vector_quantizer.py to kmeans_vector_quantizer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer/cuda_function_gen.py to cuda_function_gen.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer/setup.py to setup.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamicconv_layer/dynamicconv_layer.py to dynamicconv_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quant_noise.py to quant_noise.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/sparse_transformer_sentence_encoder_layer.py to sparse_transformer_sentence_encoder_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/conv_tbc.py to conv_tbc.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/adaptive_softmax.py to adaptive_softmax.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/cross_entropy.py to cross_entropy.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/same_pad.py to same_pad.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/layer_drop.py to layer_drop.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/fairseq_dropout.py to fairseq_dropout.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/fp32_group_norm.py to fp32_group_norm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/unfold.py to unfold.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/beamable_mm.py to beamable_mm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/multihead_attention.py to multihead_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/transformer_sentence_encoder_layer.py to transformer_sentence_encoder_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/character_token_embedder.py to character_token_embedder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer/cuda_function_gen.py to cuda_function_gen.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer/lightconv_layer.py to lightconv_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/lightconv_layer/setup.py to setup.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/layer_norm.py to layer_norm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/scalar_bias.py to scalar_bias.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/em.py to em.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/utils.py to utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/pq.py to pq.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules/qemb.py to qemb.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules/qlinear.py to qlinear.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/pq/modules/qconv.py to qconv.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/utils.py to utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/ops.py to ops.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules/qemb.py to qemb.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules/qlinear.py to qlinear.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules/qconv.py to qconv.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/scalar/modules/qact.py to qact.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/quantization/quantization_options.py to quantization_options.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/transformer_layer.py to transformer_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/learned_positional_embedding.py to learned_positional_embedding.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/lightweight_convolution.py to lightweight_convolution.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/positional_embedding.py to positional_embedding.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/checkpoint_activations.py to checkpoint_activations.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/grad_multiply.py to grad_multiply.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/adaptive_input.py to adaptive_input.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/sparse_transformer_sentence_encoder.py to sparse_transformer_sentence_encoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/transformer_sentence_encoder.py to transformer_sentence_encoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/dynamic_convolution.py to dynamic_convolution.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/sparse_multihead_attention.py to sparse_multihead_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/gumbel_vector_quantizer.py to gumbel_vector_quantizer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/modules/vggblock.py to vggblock.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/version.py to version.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/incremental_decoding_utils.py to incremental_decoding_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/roberta/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/roberta/model.py to model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/transformer_lm.py to transformer_lm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/transformer.py to transformer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py to layers.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py to model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/megatron_trainer.py to megatron_trainer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules/multihead_attention.py to multihead_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/modules/transformer_layer.py to transformer_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/criterions/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py to vocab_parallel_cross_entropy.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding/normalize.py to normalize.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/constrained_decoding/tok.py to tok.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/preprocess_RACE.py to preprocess_RACE.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc/wsc_utils.py to wsc_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc/wsc_criterion.py to wsc_criterion.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/wsc/wsc_task.py to wsc_task.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py to commonsense_qa_task.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/roberta/multiprocessing_bpe_encoder.py to multiprocessing_bpe_encoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/preprocess.py to preprocess.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/postprocess.py to postprocess.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/pointer_generator_src/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py to transformer_pg.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py to check_valid_test_overlaps.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py to check_iswlt_test_data.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py to remove_valid_test_in_train.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py to download_ted_and_extract.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py to download_wmt19_and_before.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/dedup_all.py to dedup_all.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/check_self_overlaps.py to check_self_overlaps.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils/dedup.py to dedup.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py to fasttext_multi_filter.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/multilingual/data_scripts/binarize.py to binarize.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/models/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/models/linformer_roberta.py to linformer_roberta.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py to linformer_sentence_encoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py to multihead_linear_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py to linformer_sentence_encoder_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe/gru_transformer.py to gru_transformer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/byte_level_bpe/get_bitext.py to get_bitext.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers/tokenize_indic.py to tokenize_indic.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers/tokenize_thai.py to tokenize_thai.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/tokenizers/tokenize_zh.py to tokenize_zh.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data/dedup_data.py to dedup_data.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data/clean_histogram.py to clean_histogram.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/m2m_100/process_data/remove_too_much_punc.py to remove_too_much_punc.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/vq-wav2vec_featurize.py to vq-wav2vec_featurize.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/wav2vec_featurize.py to wav2vec_featurize.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/libri_labels.py to libri_labels.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/wav2vec/wav2vec_manifest.py to wav2vec_manifest.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py to transformer_monotonic_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py to convtransformer_simul_trans.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/evaluate.py to evaluate.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/eval_latency.py to eval_latency.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers/scorer.py to scorer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/scorers/text_scorer.py to text_scorer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/client.py to client.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents/word_splitter.py to word_splitter.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents/simul_trans_agent.py to simul_trans_agent.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents/agent.py to agent.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/agents/simul_trans_text_agent.py to simul_trans_text_agent.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/eval/server.py to server.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py to fixed_pre_decision.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py to monotonic_multihead_attention.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py to monotonic_transformer_layer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils/functions.py to functions.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils/latency.py to latency.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/simultaneous_translation/utils/data_utils.py to data_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/infer.py to infer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/hydra/decoder.py to decoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models/vggtransformer.py to vggtransformer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py to w2l_conv_glu_enc.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/w2l_decoder.py to w2l_decoder.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data/data_utils.py to data_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data/asr_dataset.py to asr_dataset.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data/collaters.py to collaters.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/data/replabels.py to replabels.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/infer.py to infer.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/datasets/asr_prep_json.py to asr_prep_json.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/utils/wer_utils.py to wer_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/tasks/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/tasks/speech_recognition.py to speech_recognition.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py to cross_entropy_acc.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_recognition/criterions/ASG_loss.py to ASG_loss.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_tune.py to rerank_tune.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_options.py to rerank_options.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_score_bw.py to rerank_score_bw.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_utils.py to rerank_utils.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_score_lm.py to rerank_score_lm.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank.py to rerank.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/noisychannel/rerank_generate.py to rerank_generate.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/rxf/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py to sentence_prediction_r3f.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py to label_smoothed_cross_entropy_r3f.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/__init__.py to __init__.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/adaptive_span_model.py to adaptive_span_model.cpython-37.pyc\r\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py to adaptive_span_model_wrapper.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/adaptive_span_attention.py to adaptive_span_attention.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/adaptive_span_loss.py to adaptive_span_loss.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/adagrad_with_grad_clip.py to adagrad_with_grad_clip.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/adaptive_span/truncated_bptt_lm_task.py to truncated_bptt_lm_task.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt/transformer_xl_model.py to transformer_xl_model.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py to truncated_bptt_lm_task.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/prep_librispeech_data.py to prep_librispeech_data.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/prep_mustc_data.py to prep_mustc_data.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/prep_mtedx_data.py to prep_mtedx_data.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation/agents/simul_trans_agent.py to simul_trans_agent.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py to fairseq_simul_st_agent.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/data_utils.py to data_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/speech_to_text/prep_covost_data.py to prep_covost_data.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation/extract_bt_data.py to extract_bt_data.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/backtranslation/deduplicate_lines.py to deduplicate_lines.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/bart/summarize.py to summarize.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py to noisy_channel_sequence_generator.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel/noisy_channel_translation.py to noisy_channel_translation.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py to noisy_channel_beam_search.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/megatron_11b/detok.py to detok.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/criss/sentence_retrieval/encoder_analysis.py to encoder_analysis.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/criss/mining/mine.py to mine.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/criss/save_encoder.py to save_encoder.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src/laser_transformer.py to laser_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src/laser_task.py to laser_task.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src/laser_lstm.py to laser_lstm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/laser/laser_src/multitask_data_utils.py to multitask_data_utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py to latent_multilingual_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py to latent_transformer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py to latent_depth.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py to latent_layers.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py to multilingual_translation_latent_depth.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py to aggregate_scores.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation/repeat_lines.py to repeat_lines.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/unsupervised_quality_estimation/meteor.py to meteor.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/score.py to score.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py to mean_pool_gating_network.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src/translation_moe.py to translation_moe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py to logsumexp_moe.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/examples/paraphraser/paraphrase.py to paraphrase.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/nan_detector.py to nan_detector.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/dataclass/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/dataclass/initialize.py to initialize.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/dataclass/utils.py to utils.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/dataclass/constants.py to constants.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/dataclass/configs.py to configs.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/file_io.py to file_io.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/adadelta.py to adadelta.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/adafactor.py to adafactor.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/bmuf.py to bmuf.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/sgd.py to sgd.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/adamax.py to adamax.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/nag.py to nag.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/cpu_adam.py to cpu_adam.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/fixed_schedule.py to fixed_schedule.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py to tri_stage_lr_scheduler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py to fairseq_lr_scheduler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/manual_lr_scheduler.py to manual_lr_scheduler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py to cosine_lr_scheduler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/inverse_square_root_schedule.py to inverse_square_root_schedule.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/polynomial_decay_schedule.py to polynomial_decay_schedule.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/pass_through.py to pass_through.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/triangular_lr_scheduler.py to triangular_lr_scheduler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py to reduce_lr_on_plateau.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/adagrad.py to adagrad.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/dynamic_loss_scaler.py to dynamic_loss_scaler.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/fused_adam.py to fused_adam.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/fairseq_optimizer.py to fairseq_optimizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/adam.py to adam.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/shard.py to shard.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/optim/composite.py to composite.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/multilingual_translation.py to multilingual_translation.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/translation_from_pretrained_bart.py to translation_from_pretrained_bart.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/semisupervised_translation.py to semisupervised_translation.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/language_modeling.py to language_modeling.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/multilingual_denoising.py to multilingual_denoising.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/translation_multi_simple_epoch.py to translation_multi_simple_epoch.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/sentence_prediction.py to sentence_prediction.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/sentence_ranking.py to sentence_ranking.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/audio_pretraining.py to audio_pretraining.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/denoising.py to denoising.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/legacy_masked_lm.py to legacy_masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/translation_from_pretrained_xlm.py to translation_from_pretrained_xlm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/fairseq_task.py to fairseq_task.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/translation.py to translation.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/speech_to_text.py to speech_to_text.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/masked_lm.py to masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/cross_lingual_lm.py to cross_lingual_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/translation_lev.py to translation_lev.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/tasks/multilingual_masked_lm.py to multilingual_masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/scoring/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/scoring/bleu.py to bleu.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/scoring/tokenizer.py to tokenizer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/scoring/wer.py to wer.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/scoring/chrf.py to chrf.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/ctc.py to ctc.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py to label_smoothed_cross_entropy_with_alignment.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/cross_entropy.py to cross_entropy.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/wav2vec_criterion.py to wav2vec_criterion.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/sentence_prediction.py to sentence_prediction.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/fairseq_criterion.py to fairseq_criterion.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/sentence_ranking.py to sentence_ranking.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/legacy_masked_lm.py to legacy_masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/label_smoothed_cross_entropy.py to label_smoothed_cross_entropy.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/adaptive_loss.py to adaptive_loss.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/composite_loss.py to composite_loss.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/masked_lm.py to masked_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py to label_smoothed_cross_entropy_latency_augmented.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/nat_loss.py to nat_loss.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/criterions/model_criterion.py to model_criterion.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/train.py to train.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/generate.py to generate.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/score.py to score.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/preprocess.py to preprocess.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/validate.py to validate.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/hydra_train.py to hydra_train.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/eval_lm.py to eval_lm.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq_cli/interactive.py to interactive.cpython-37.pyc\n",
      "creating stub loader for fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "creating stub loader for fairseq/libnat.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/libbleu.py to libbleu.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/data_utils_fast.py to data_utils_fast.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/data/token_block_utils_fast.py to token_block_utils_fast.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fairseq/libnat.py to libnat.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying fairseq.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "creating dist\n",
      "creating 'dist/fairseq-1.0.0a0+4c4d5a7-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing fairseq-1.0.0a0+4c4d5a7-py3.7-linux-x86_64.egg\n",
      "creating /home/petrakov/anaconda3/lib/python3.7/site-packages/fairseq-1.0.0a0+4c4d5a7-py3.7-linux-x86_64.egg\n",
      "Extracting fairseq-1.0.0a0+4c4d5a7-py3.7-linux-x86_64.egg to /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Removing fairseq 1.0.0a0+4c4d5a7 from easy-install.pth file\n",
      "Adding fairseq 1.0.0a0+4c4d5a7 to easy-install.pth file\n",
      "Installing fairseq-eval-lm script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-generate script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-hydra-train script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-interactive script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-preprocess script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-score script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-train script to /home/petrakov/anaconda3/bin\n",
      "Installing fairseq-validate script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Installed /home/petrakov/anaconda3/lib/python3.7/site-packages/fairseq-1.0.0a0+4c4d5a7-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for fairseq==1.0.0a0+4c4d5a7\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3 script to /home/petrakov/anaconda3/bin\n",
      "Installing f2py3.7 script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tqdm==4.64.0\n",
      "Best match: tqdm 4.64.0\n",
      "Adding tqdm 4.64.0 to easy-install.pth file\n",
      "Installing tqdm script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for torch==1.11.0\n",
      "Best match: torch 1.11.0\n",
      "Adding torch 1.11.0 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /home/petrakov/anaconda3/bin\n",
      "Installing convert-onnx-to-caffe2 script to /home/petrakov/anaconda3/bin\n",
      "Installing torchrun script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for sacrebleu==2.1.0\n",
      "Best match: sacrebleu 2.1.0\n",
      "Adding sacrebleu 2.1.0 to easy-install.pth file\n",
      "Installing sacrebleu script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for regex==2022.7.9\n",
      "Best match: regex 2022.7.9\n",
      "Adding regex 2022.7.9 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for omegaconf==2.0.6\n",
      "Best match: omegaconf 2.0.6\n",
      "Adding omegaconf 2.0.6 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for hydra-core==1.0.7\n",
      "Best match: hydra-core 1.0.7\n",
      "Adding hydra-core 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for Cython==0.29.13\n",
      "Best match: Cython 0.29.13\n",
      "Adding Cython 0.29.13 to easy-install.pth file\n",
      "Installing cygdb script to /home/petrakov/anaconda3/bin\n",
      "Installing cython script to /home/petrakov/anaconda3/bin\n",
      "Installing cythonize script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for cffi==1.12.3\n",
      "Best match: cffi 1.12.3\n",
      "Adding cffi 1.12.3 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for typing-extensions==4.1.1\n",
      "Best match: typing-extensions 4.1.1\n",
      "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for colorama==0.4.1\n",
      "Best match: colorama 0.4.1\n",
      "Adding colorama 0.4.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for tabulate==0.8.10\n",
      "Best match: tabulate 0.8.10\n",
      "Adding tabulate 0.8.10 to easy-install.pth file\n",
      "Installing tabulate script to /home/petrakov/anaconda3/bin\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for portalocker==2.5.1\n",
      "Best match: portalocker 2.5.1\n",
      "Adding portalocker 2.5.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for PyYAML==5.1.2\n",
      "Best match: PyYAML 5.1.2\n",
      "Adding PyYAML 5.1.2 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for importlib-resources==5.8.0\n",
      "Best match: importlib-resources 5.8.0\n",
      "Adding importlib-resources 5.8.0 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for antlr4-python3-runtime==4.8\n",
      "Best match: antlr4-python3-runtime 4.8\n",
      "Adding antlr4-python3-runtime 4.8 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for pycparser==2.19\n",
      "Best match: pycparser 2.19\n",
      "Adding pycparser 2.19 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Searching for zipp==3.8.1\n",
      "Best match: zipp 3.8.1\n",
      "Adding zipp 3.8.1 to easy-install.pth file\n",
      "\n",
      "Using /home/petrakov/anaconda3/lib/python3.7/site-packages\n",
      "Finished processing dependencies for fairseq==1.0.0a0+4c4d5a7\n",
      "/home/petrakov/mGENRE_MEL\n",
      "Requirement already satisfied: kilt in /home/petrakov/anaconda3/lib/python3.7/site-packages/kilt-0.1.0-py3.7.egg (0.1.0)\n",
      "Requirement already satisfied: bs4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (0.0.1)\n",
      "Requirement already satisfied: flair in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (0.11.3)\n",
      "Requirement already satisfied: jsonlines in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (3.1.0)\n",
      "Requirement already satisfied: nltk in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (3.4.5)\n",
      "Requirement already satisfied: prettytable in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (3.3.0)\n",
      "Requirement already satisfied: pymongo in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (4.1.1)\n",
      "Requirement already satisfied: pytest in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (5.2.1)\n",
      "Requirement already satisfied: rouge in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (1.0.1)\n",
      "Requirement already satisfied: spacy>=2.1.8 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (2.3.7)\n",
      "Requirement already satisfied: torch in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (1.11.0)\n",
      "Requirement already satisfied: tqdm in /home/petrakov/anaconda3/lib/python3.7/site-packages (from kilt) (4.64.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (0.7.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (2.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (1.0.7)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (1.21.6)\n",
      "Requirement already satisfied: setuptools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (41.4.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy>=2.1.8->kilt) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from bs4->kilt) (4.8.0)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (2.0.0)\n",
      "Requirement already satisfied: tabulate in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.8.10)\n",
      "Requirement already satisfied: wikipedia-api in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.5.4)\n",
      "Requirement already satisfied: gdown==4.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.4.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (1.2.13)\n",
      "Requirement already satisfied: conllu>=4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.5)\n",
      "Requirement already satisfied: pptree in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (3.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (3.1.1)\n",
      "Requirement already satisfied: mpld3==0.3 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.3)\n",
      "Requirement already satisfied: lxml in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.21.3)\n",
      "Requirement already satisfied: janome in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.4.2)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.3.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.1.95)\n",
      "Requirement already satisfied: regex in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (2022.7.9)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (1.5.11)\n",
      "Requirement already satisfied: huggingface-hub in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (2.8.0)\n",
      "Requirement already satisfied: more-itertools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (7.2.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.18.0)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (4.6.5)\n",
      "Requirement already satisfied: ftfy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (6.1.1)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (0.2.7)\n",
      "Requirement already satisfied: langdetect in /home/petrakov/anaconda3/lib/python3.7/site-packages (from flair->kilt) (1.0.9)\n",
      "Requirement already satisfied: six in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown==4.4.0->flair->kilt) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown==4.4.0->flair->kilt) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/petrakov/anaconda3/lib/python3.7/site-packages (from torch->kilt) (4.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from jsonlines->kilt) (19.2.0)\n",
      "Requirement already satisfied: wcwidth in /home/petrakov/anaconda3/lib/python3.7/site-packages (from prettytable->kilt) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata in /home/petrakov/anaconda3/lib/python3.7/site-packages (from prettytable->kilt) (3.10.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->kilt) (1.8.0)\n",
      "Requirement already satisfied: packaging in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->kilt) (21.3)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->kilt) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->kilt) (0.13.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.4->flair->kilt) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gensim>=3.4.0->flair->kilt) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gensim>=3.4.0->flair->kilt) (1.3.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.2.7->flair->kilt) (2.3)\n",
      "Requirement already satisfied: cloudpickle in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.2.7->flair->kilt) (1.2.2)\n",
      "Requirement already satisfied: py4j in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.2.7->flair->kilt) (0.10.9.5)\n",
      "Requirement already satisfied: future in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.2.7->flair->kilt) (0.18.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from importlib-metadata->prettytable->kilt) (3.8.1)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from konoha<5.0.0,>=4.0.0->flair->kilt) (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair->kilt) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair->kilt) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair->kilt) (2.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->kilt) (2019.9.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->kilt) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->kilt) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->kilt) (1.26.10)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair->kilt) (0.13.2)\n",
      "Requirement already satisfied: sacremoses in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers>=4.0.0->flair->kilt) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers>=4.0.0->flair->kilt) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers>=4.0.0->flair->kilt) (5.1.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->bs4->kilt) (1.9.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from networkx>=2.2->hyperopt>=0.2.7->flair->kilt) (4.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->kilt) (1.7.1)\n",
      "Requirement already satisfied: click in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers>=4.0.0->flair->kilt) (8.1.3)\n",
      "/home/petrakov/mGENRE_MEL/fairseq\n",
      "Obtaining file:///home/petrakov/mGENRE_MEL/fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cython in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (0.29.13)\n",
      "Requirement already satisfied: regex in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2022.7.9)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (4.64.0)\n",
      "Requirement already satisfied: torch in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.11.0)\n",
      "Requirement already satisfied: cffi in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.12.3)\n",
      "Requirement already satisfied: numpy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.21.6)\n",
      "Requirement already satisfied: hydra-core<1.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from fairseq==1.0.0a0+4c4d5a7) (2.0.6)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /home/petrakov/anaconda3/lib/python3.7/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (5.8.0)\n",
      "Requirement already satisfied: typing-extensions in /home/petrakov/anaconda3/lib/python3.7/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4c4d5a7) (4.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /home/petrakov/anaconda3/lib/python3.7/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+4c4d5a7) (5.1.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (0.8.10)\n",
      "Requirement already satisfied: portalocker in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (2.5.1)\n",
      "Requirement already satisfied: colorama in /home/petrakov/anaconda3/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+4c4d5a7) (0.4.1)\n",
      "Requirement already satisfied: pycparser in /home/petrakov/anaconda3/lib/python3.7/site-packages (from cffi->fairseq==1.0.0a0+4c4d5a7) (2.19)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1->fairseq==1.0.0a0+4c4d5a7) (3.8.1)\n",
      "Installing collected packages: fairseq\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 1.0.0a0+4c4d5a7\n",
      "    Uninstalling fairseq-1.0.0a0+4c4d5a7:\n",
      "      Successfully uninstalled fairseq-1.0.0a0+4c4d5a7\n",
      "  Running setup.py develop for fairseq\n",
      "Successfully installed fairseq-1.0.0a0+4c4d5a7\n",
      "/home/petrakov/mGENRE_MEL\n"
     ]
    }
   ],
   "source": [
    "#KILT\n",
    "%rm -rf KILT\n",
    "!git clone https://github.com/facebookresearch/KILT.git\n",
    "%cd KILT\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py install\n",
    "sys.path.append(os.getcwd())\n",
    "%cd ..\n",
    "\n",
    "#GENRE\n",
    "%rm -rf GENRE\n",
    "!git clone https://github.com/facebookresearch/GENRE.git\n",
    "%cd GENRE\n",
    "!pip install ./\n",
    "!python ./setup.py build develop install\n",
    "!pip install sentencepiece marisa_trie\n",
    "sys.path.append(os.getcwd())\n",
    "%cd ..\n",
    "\n",
    "# fairseq\n",
    "%rm -rf fairseq\n",
    "!git clone --branch fixing_prefix_allowed_tokens_fn https://github.com/nicola-decao/fairseq\n",
    "%cd fairseq\n",
    "!sed -i -e '26,27d' fairseq/registry.py\n",
    "!pip install --editable ./\n",
    "!python setup.py build develop\n",
    "!python setup.py install\n",
    "sys.path.append(os.getcwd())\n",
    "%cd ..\n",
    "\n",
    "!pip install kilt\n",
    "\n",
    "#####\n",
    "%cd fairseq\n",
    "!pip install --editable ./\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/petrakov/anaconda3/lib/python3.7/site-packages (4.4.0)\r\n",
      "Requirement already satisfied: requests[socks] in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown) (2.28.1)\r\n",
      "Requirement already satisfied: six in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown) (4.8.0)\r\n",
      "Requirement already satisfied: filelock in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown) (3.6.0)\r\n",
      "Requirement already satisfied: tqdm in /home/petrakov/anaconda3/lib/python3.7/site-packages (from gdown) (4.64.0)\r\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->gdown) (1.9.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (2.8)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.10)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "from wikidata.client import Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import compress\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data and model (comment cell below if already downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pretrained model\n",
    "# ! rm -rf fairseq_multilingual_entity_disambiguation*\n",
    "# ! wget https://dl.fbaipublicfiles.com/GENRE/fairseq_multilingual_entity_disambiguation.tar.gz\n",
    "# ! tar -xvf fairseq_multilingual_entity_disambiguation.tar.gz\n",
    "\n",
    "# # data\n",
    "# ! wget https://dl.fbaipublicfiles.com/GENRE/lang_title2wikidataID-normalized_with_redirect.pkl\n",
    "# ! wget http://dl.fbaipublicfiles.com/GENRE/titles_lang_all105_marisa_trie_with_redirect.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QpLVXGahVjAoEq8TrE70aKtMLJCNeASh\n",
      "To: /home/petrakov/mGENRE_MEL/mentions_test.json\n",
      "100%|| 65.1M/65.1M [00:00<00:00, 70.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mentions_test.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = \"1QpLVXGahVjAoEq8TrE70aKtMLJCNeASh\"\n",
    "gdown.download('https://drive.google.com/uc?id=1QpLVXGahVjAoEq8TrE70aKtMLJCNeASh', output=\"mentions_test.json\", quiet=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mentions_test.json\") as f:\n",
    "    test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In original version there were serious of troubles that's why correct version we add here from external google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fairseq_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fairseq_model.py\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "\n",
    "import torch\n",
    "from fairseq import search, utils\n",
    "from fairseq.models.bart import BARTHubInterface, BARTModel\n",
    "from omegaconf import open_dict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class GENREHubInterface(BARTHubInterface):\n",
    "    def sample(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        beam: int = 5,\n",
    "        verbose: bool = False,\n",
    "        text_to_id=None,\n",
    "        marginalize=False,\n",
    "        marginalize_lenpen=0.5,\n",
    "        max_len_a=1024,\n",
    "        max_len_b=1024,\n",
    "        **kwargs,\n",
    "    ) -> List[str]:\n",
    "        if isinstance(sentences, str):\n",
    "            return self.sample([sentences], beam=beam, verbose=verbose, **kwargs)[0]\n",
    "        tokenized_sentences = [self.encode(sentence) for sentence in sentences]\n",
    "\n",
    "        batched_hypos = self.generate(\n",
    "            tokenized_sentences,\n",
    "            beam,\n",
    "            verbose,\n",
    "            max_len_a=max_len_a,\n",
    "            max_len_b=max_len_b,\n",
    "            **kwargs,\n",
    "        )\n",
    "        #print(\"batched_hypos\", batched_hypos)\n",
    "        \n",
    "        outputs = [\n",
    "            [\n",
    "                {\"text\": self.decode(hypo[\"tokens\"]), \"score\": hypo[\"score\"]}\n",
    "                for hypo in hypos\n",
    "            ]\n",
    "            for hypos in batched_hypos\n",
    "        ]\n",
    "        if text_to_id:\n",
    "            outputs = [\n",
    "                [{**hypo, \"id\": text_to_id(hypo[\"text\"])} for hypo in hypos]\n",
    "                for hypos in outputs\n",
    "            ]\n",
    "\n",
    "            if marginalize:\n",
    "                for (i, hypos), hypos_tok in zip(enumerate(outputs), batched_hypos):\n",
    "                    outputs_dict = defaultdict(list)\n",
    "                    for hypo, hypo_tok in zip(hypos, hypos_tok):\n",
    "                        outputs_dict[hypo[\"id\"]].append(\n",
    "                            {**hypo, \"len\": len(hypo_tok[\"tokens\"])}\n",
    "                        )\n",
    "\n",
    "                    outputs[i] = sorted(\n",
    "                        [\n",
    "                            {\n",
    "                                \"id\": _id,\n",
    "                                \"texts\": [hypo[\"text\"] for hypo in hypos],\n",
    "                                \"scores\": torch.stack(\n",
    "                                    [hypo[\"score\"] for hypo in hypos]\n",
    "                                ),\n",
    "                                \"score\": torch.stack(\n",
    "                                    [\n",
    "                                        hypo[\"score\"]\n",
    "                                        * hypo[\"len\"]\n",
    "                                        / (hypo[\"len\"] ** marginalize_lenpen)\n",
    "                                        for hypo in hypos\n",
    "                                    ]\n",
    "                                ).logsumexp(-1),\n",
    "                            }\n",
    "                            for _id, hypos in outputs_dict.items()\n",
    "                        ],\n",
    "                        key=lambda x: x[\"score\"],\n",
    "                        reverse=True,\n",
    "                    )\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, *args, **kwargs) -> List[List[Dict[str, torch.Tensor]]]:\n",
    "        return super(BARTHubInterface, self).generate(*args, **kwargs)\n",
    "\n",
    "    def encode(self, sentence) -> torch.LongTensor:\n",
    "        tokens = super(BARTHubInterface, self).encode(sentence)\n",
    "        tokens[\n",
    "            tokens >= len(self.task.target_dictionary)\n",
    "        ] = self.task.target_dictionary.unk_index\n",
    "        if tokens[0] != self.task.target_dictionary.bos_index:\n",
    "            return torch.cat(\n",
    "                (torch.tensor([self.task.target_dictionary.bos_index]), tokens)\n",
    "            )\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    \n",
    "class GENRE(BARTModel):\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_name_or_path,\n",
    "        checkpoint_file=\"model.pt\",\n",
    "        data_name_or_path=\".\",\n",
    "        bpe=\"gpt2\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        from fairseq import hub_utils\n",
    "\n",
    "        x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=cls.hub_models(),\n",
    "            bpe=bpe,\n",
    "            load_checkpoint_heads=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return GENREHubInterface(x[\"args\"], x[\"task\"], x[\"models\"][0])\n",
    "\n",
    "\n",
    "class mGENRE(BARTModel):\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_name_or_path,\n",
    "        sentencepiece_model=\"spm_256000.model\",\n",
    "        checkpoint_file=\"model.pt\",\n",
    "        data_name_or_path=\".\",\n",
    "        bpe=\"sentencepiece\",\n",
    "        layernorm_embedding=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        from fairseq import hub_utils\n",
    "\n",
    "        x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=cls.hub_models(),\n",
    "            bpe=bpe,\n",
    "            load_checkpoint_heads=True,\n",
    "            sentencepiece_model=os.path.join(model_name_or_path, sentencepiece_model),\n",
    "            **kwargs,\n",
    "        )\n",
    "        return GENREHubInterface(x[\"args\"], x[\"task\"], x[\"models\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv fairseq_model.py GENRE/genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL/fairseq/fairseq/models\n"
     ]
    }
   ],
   "source": [
    "%cd fairseq/fairseq/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fairseq_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fairseq_model.py\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "Base classes for various fairseq models.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fairseq import utils\n",
    "from fairseq.data import Dictionary\n",
    "from fairseq.dataclass.utils import (\n",
    "    convert_namespace_to_omegaconf,\n",
    "    gen_parser_from_dataclass,\n",
    ")\n",
    "from fairseq.models import FairseqDecoder, FairseqEncoder\n",
    "from omegaconf import DictConfig\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class BaseFairseqModel(nn.Module):\n",
    "    \"\"\"Base class for fairseq models.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._is_generation_fast = False\n",
    "\n",
    "    @classmethod\n",
    "    def add_args(cls, parser):\n",
    "        \"\"\"Add model-specific arguments to the parser.\"\"\"\n",
    "        dc = getattr(cls, \"__dataclass\", None)\n",
    "        if dc is not None:\n",
    "            # do not set defaults so that settings defaults from various architectures still works\n",
    "            gen_parser_from_dataclass(parser, dc(), delete_default=True)\n",
    "\n",
    "    @classmethod\n",
    "    def build_model(cls, args, task):\n",
    "        \"\"\"Build a new model instance.\"\"\"\n",
    "        raise NotImplementedError(\"Model must implement the build_model method\")\n",
    "\n",
    "    def get_targets(self, sample, net_output):\n",
    "        \"\"\"Get targets from either the sample or the net's output.\"\"\"\n",
    "        return sample[\"target\"]\n",
    "\n",
    "    def get_normalized_probs(\n",
    "        self,\n",
    "        net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]],\n",
    "        log_probs: bool,\n",
    "        sample: Optional[Dict[str, Tensor]] = None,\n",
    "    ):\n",
    "        \"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\n",
    "        return self.get_normalized_probs_scriptable(net_output, log_probs, sample)\n",
    "\n",
    "    # TorchScript doesn't support super() method so that the scriptable Subclass\n",
    "    # can't access the base class model in Torchscript.\n",
    "    # Current workaround is to add a helper function with different name and\n",
    "    # call the helper function from scriptable Subclass.\n",
    "    def get_normalized_probs_scriptable(\n",
    "        self,\n",
    "        net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]],\n",
    "        log_probs: bool,\n",
    "        sample: Optional[Dict[str, Tensor]] = None,\n",
    "    ):\n",
    "        \"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"\n",
    "        if hasattr(self, \"decoder\"):\n",
    "            return self.decoder.get_normalized_probs(net_output, log_probs, sample)\n",
    "        elif torch.is_tensor(net_output):\n",
    "            # syntactic sugar for simple models which don't have a decoder\n",
    "            # (e.g., the classification tutorial)\n",
    "            logits = net_output.float()\n",
    "            if log_probs:\n",
    "                return F.log_softmax(logits, dim=-1)\n",
    "            else:\n",
    "                return F.softmax(logits, dim=-1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extract_features(self, *args, **kwargs):\n",
    "        \"\"\"Similar to *forward* but only return features.\"\"\"\n",
    "        return self(*args, **kwargs)\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def load_state_dict(\n",
    "        self,\n",
    "        state_dict,\n",
    "        strict=True,\n",
    "        model_cfg: Optional[DictConfig] = None,\n",
    "        args: Optional[Namespace] = None,\n",
    "    ):\n",
    "        \"\"\"Copies parameters and buffers from *state_dict* into this module and\n",
    "        its descendants.\n",
    "\n",
    "        Overrides the method in :class:`nn.Module`. Compared with that method\n",
    "        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n",
    "        \"\"\"\n",
    "\n",
    "        if model_cfg is None and args is not None:\n",
    "            logger.warn(\"using 'args' is deprecated, please update your code to use dataclass config\")\n",
    "            model_cfg = convert_namespace_to_omegaconf(args).model\n",
    "\n",
    "        self.upgrade_state_dict(state_dict)\n",
    "\n",
    "        from fairseq.checkpoint_utils import prune_state_dict\n",
    "\n",
    "        new_state_dict = prune_state_dict(state_dict, model_cfg)\n",
    "        return super().load_state_dict(new_state_dict, strict)\n",
    "\n",
    "    def upgrade_state_dict(self, state_dict):\n",
    "        \"\"\"Upgrade old state dicts to work with newer code.\"\"\"\n",
    "        self.upgrade_state_dict_named(state_dict, \"\")\n",
    "\n",
    "    def upgrade_state_dict_named(self, state_dict, name):\n",
    "        \"\"\"Upgrade old state dicts to work with newer code.\n",
    "\n",
    "        Args:\n",
    "            state_dict (dict): state dictionary to upgrade, in place\n",
    "            name (str): the state dict key corresponding to the current module\n",
    "        \"\"\"\n",
    "        assert state_dict is not None\n",
    "\n",
    "        def do_upgrade(m, prefix):\n",
    "            if len(prefix) > 0:\n",
    "                prefix += \".\"\n",
    "\n",
    "            for n, c in m.named_children():\n",
    "                name = prefix + n\n",
    "                if hasattr(c, \"upgrade_state_dict_named\"):\n",
    "                    c.upgrade_state_dict_named(state_dict, name)\n",
    "                elif hasattr(c, \"upgrade_state_dict\"):\n",
    "                    c.upgrade_state_dict(state_dict)\n",
    "                do_upgrade(c, name)\n",
    "\n",
    "        do_upgrade(self, name)\n",
    "\n",
    "    def set_num_updates(self, num_updates):\n",
    "        \"\"\"State from trainer to pass along to model at every update.\"\"\"\n",
    "\n",
    "        def _apply(m):\n",
    "            if hasattr(m, \"set_num_updates\") and m != self:\n",
    "                m.set_num_updates(num_updates)\n",
    "\n",
    "        self.apply(_apply)\n",
    "\n",
    "    def prepare_for_inference_(self, cfg: DictConfig):\n",
    "        \"\"\"Prepare model for inference.\"\"\"\n",
    "        kwargs = {}\n",
    "        kwargs[\"beamable_mm_beam_size\"] = (\n",
    "            None\n",
    "            if getattr(cfg.generation, \"no_beamable_mm\", False)\n",
    "            else getattr(cfg.generation, \"beam\", 5)\n",
    "        )\n",
    "        kwargs[\"need_attn\"] = getattr(cfg.generation, \"print_alignment\", False)\n",
    "        if getattr(cfg.generation, \"retain_dropout\", False):\n",
    "            kwargs[\"retain_dropout\"] = cfg.generation.retain_dropout\n",
    "            kwargs[\"retain_dropout_modules\"] = cfg.generation.retain_dropout_modules\n",
    "        self.make_generation_fast_(**kwargs)\n",
    "\n",
    "    def make_generation_fast_(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Legacy entry point to optimize model for faster generation.\n",
    "        Prefer prepare_for_inference_.\n",
    "        \"\"\"\n",
    "        if self._is_generation_fast:\n",
    "            return  # only apply once\n",
    "        self._is_generation_fast = True\n",
    "\n",
    "        # remove weight norm from all modules in the network\n",
    "        def apply_remove_weight_norm(module):\n",
    "            try:\n",
    "                nn.utils.remove_weight_norm(module)\n",
    "            except (AttributeError, ValueError):  # this module didn't have weight norm\n",
    "                return\n",
    "\n",
    "        self.apply(apply_remove_weight_norm)\n",
    "\n",
    "        def apply_make_generation_fast_(module, prefix):\n",
    "            if len(prefix) > 0:\n",
    "                prefix += \".\"\n",
    "\n",
    "            base_func = BaseFairseqModel.make_generation_fast_\n",
    "            for n, m in module.named_modules():\n",
    "                if (\n",
    "                    m != self\n",
    "                    and hasattr(m, \"make_generation_fast_\")\n",
    "                    # don't call this implementation again, e.g., if\n",
    "                    # children modules also inherit from BaseFairseqModel\n",
    "                    and m.make_generation_fast_.__func__ is not base_func\n",
    "                ):\n",
    "                    name = prefix + n\n",
    "                    m.make_generation_fast_(name=name, **kwargs)\n",
    "\n",
    "        apply_make_generation_fast_(self, \"\")\n",
    "\n",
    "        def train(mode=True):\n",
    "            #self.train = train\n",
    "            self.train()\n",
    "\n",
    "#     def prepare_for_onnx_export_(self, **kwargs):\n",
    "#         \"\"\"Make model exportable via ONNX trace.\"\"\"\n",
    "#         seen = set()\n",
    "\n",
    "#         def apply_prepare_for_onnx_export_(module):\n",
    "#             if (\n",
    "#                 module != self\n",
    "#                 and hasattr(module, \"prepare_for_onnx_export_\")\n",
    "#                 and module not in seen\n",
    "#             ):\n",
    "#                 seen.add(module)\n",
    "#                 module.prepare_for_onnx_export_(**kwargs)\n",
    "\n",
    "#         self.apply(apply_prepare_for_onnx_export_)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_name_or_path,\n",
    "        checkpoint_file=\"model.pt\",\n",
    "        data_name_or_path=\".\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Load a :class:`~fairseq.models.FairseqModel` from a pre-trained model\n",
    "        file. Downloads and caches the pre-trained model file if needed.\n",
    "\n",
    "        The base implementation returns a\n",
    "        :class:`~fairseq.hub_utils.GeneratorHubInterface`, which can be used to\n",
    "        generate translations or sample from language models. The underlying\n",
    "        :class:`~fairseq.models.FairseqModel` can be accessed via the\n",
    "        *generator.models* attribute.\n",
    "\n",
    "        Other models may override this to implement custom hub interfaces.\n",
    "\n",
    "        Args:\n",
    "            model_name_or_path (str): either the name of a pre-trained model to\n",
    "                load or a path/URL to a pre-trained model state dict\n",
    "            checkpoint_file (str, optional): colon-separated list of checkpoint\n",
    "                files in the model archive to ensemble (default: 'model.pt')\n",
    "            data_name_or_path (str, optional): point args.data to the archive\n",
    "                at the given path/URL. Can start with '.' or './' to reuse the\n",
    "                model archive path.\n",
    "        \"\"\"\n",
    "        from fairseq import hub_utils\n",
    "\n",
    "        x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=cls.hub_models(),\n",
    "            **kwargs,\n",
    "        )\n",
    "        logger.info(x[\"args\"])\n",
    "        return hub_utils.GeneratorHubInterface(x[\"args\"], x[\"task\"], x[\"models\"])\n",
    "\n",
    "    @classmethod\n",
    "    def hub_models(cls):\n",
    "        return {}\n",
    "\n",
    "\n",
    "class FairseqEncoderDecoderModel(BaseFairseqModel):\n",
    "    \"\"\"Base class for encoder-decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (FairseqEncoder): the encoder\n",
    "        decoder (FairseqDecoder): the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        assert isinstance(self.encoder, FairseqEncoder)\n",
    "        assert isinstance(self.decoder, FairseqDecoder)\n",
    "\n",
    "    def forward(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the forward pass for an encoder-decoder model.\n",
    "\n",
    "        First feed a batch of source tokens through the encoder. Then, feed the\n",
    "        encoder output and previous decoder outputs (i.e., teacher forcing) to\n",
    "        the decoder to produce the next outputs::\n",
    "\n",
    "            encoder_out = self.encoder(src_tokens, src_lengths)\n",
    "            return self.decoder(prev_output_tokens, encoder_out)\n",
    "\n",
    "        Args:\n",
    "            src_tokens (LongTensor): tokens in the source language of shape\n",
    "                `(batch, src_len)`\n",
    "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n",
    "            prev_output_tokens (LongTensor): previous decoder outputs of shape\n",
    "                `(batch, tgt_len)`, for teacher forcing\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - the decoder's output of shape `(batch, tgt_len, vocab)`\n",
    "                - a dictionary with any model-specific outputs\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)\n",
    "        decoder_out = self.decoder(\n",
    "            prev_output_tokens, encoder_out=encoder_out, **kwargs\n",
    "        )\n",
    "        return decoder_out\n",
    "\n",
    "    def forward_decoder(self, prev_output_tokens, **kwargs):\n",
    "        return self.decoder(prev_output_tokens, **kwargs)\n",
    "\n",
    "    def extract_features(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\n",
    "        \"\"\"\n",
    "        Similar to *forward* but only return features.\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n",
    "                - a dictionary with any model-specific outputs\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)\n",
    "        features = self.decoder.extract_features(\n",
    "            prev_output_tokens, encoder_out=encoder_out, **kwargs\n",
    "        )\n",
    "        return features\n",
    "\n",
    "    def output_layer(self, features, **kwargs):\n",
    "        \"\"\"Project features to the default output size (typically vocabulary size).\"\"\"\n",
    "        return self.decoder.output_layer(features, **kwargs)\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return (self.encoder.max_positions(), self.decoder.max_positions())\n",
    "\n",
    "    def max_decoder_positions(self):\n",
    "        \"\"\"Maximum length supported by the decoder.\"\"\"\n",
    "        return self.decoder.max_positions()\n",
    "\n",
    "\n",
    "class FairseqModel(FairseqEncoderDecoderModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        utils.deprecation_warning(\n",
    "            \"FairseqModel is deprecated, please use FairseqEncoderDecoderModel \"\n",
    "            \"or BaseFairseqModel instead\",\n",
    "            stacklevel=4,\n",
    "        )\n",
    "\n",
    "\n",
    "class FairseqMultiModel(BaseFairseqModel):\n",
    "    \"\"\"Base class for combining multiple encoder-decoder models.\"\"\"\n",
    "\n",
    "    def __init__(self, encoders, decoders):\n",
    "        super().__init__()\n",
    "        assert encoders.keys() == decoders.keys()\n",
    "        self.keys = list(encoders.keys())\n",
    "        for key in self.keys:\n",
    "            assert isinstance(encoders[key], FairseqEncoder)\n",
    "            assert isinstance(decoders[key], FairseqDecoder)\n",
    "\n",
    "        self.models = nn.ModuleDict(\n",
    "            {\n",
    "                key: FairseqEncoderDecoderModel(encoders[key], decoders[key])\n",
    "                for key in self.keys\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_shared_embeddings(\n",
    "        dicts: Dict[str, Dictionary],\n",
    "        langs: List[str],\n",
    "        embed_dim: int,\n",
    "        build_embedding: callable,\n",
    "        pretrained_embed_path: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Helper function to build shared embeddings for a set of languages after\n",
    "        checking that all dicts corresponding to those languages are equivalent.\n",
    "\n",
    "        Args:\n",
    "            dicts: Dict of lang_id to its corresponding Dictionary\n",
    "            langs: languages that we want to share embeddings for\n",
    "            embed_dim: embedding dimension\n",
    "            build_embedding: callable function to actually build the embedding\n",
    "            pretrained_embed_path: Optional path to load pretrained embeddings\n",
    "        \"\"\"\n",
    "        shared_dict = dicts[langs[0]]\n",
    "        if any(dicts[lang] != shared_dict for lang in langs):\n",
    "            raise ValueError(\n",
    "                \"--share-*-embeddings requires a joined dictionary: \"\n",
    "                \"--share-encoder-embeddings requires a joined source \"\n",
    "                \"dictionary, --share-decoder-embeddings requires a joined \"\n",
    "                \"target dictionary, and --share-all-embeddings requires a \"\n",
    "                \"joint source + target dictionary.\"\n",
    "            )\n",
    "        return build_embedding(shared_dict, embed_dim, pretrained_embed_path)\n",
    "\n",
    "    def forward(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return {\n",
    "            key: (\n",
    "                self.models[key].encoder.max_positions(),\n",
    "                self.models[key].decoder.max_positions(),\n",
    "            )\n",
    "            for key in self.keys\n",
    "        }\n",
    "\n",
    "    def max_decoder_positions(self):\n",
    "        \"\"\"Maximum length supported by the decoder.\"\"\"\n",
    "        return min(model.decoder.max_positions() for model in self.models.values())\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self.models[self.keys[0]].encoder\n",
    "\n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return self.models[self.keys[0]].decoder\n",
    "\n",
    "    def forward_decoder(self, prev_output_tokens, **kwargs):\n",
    "        return self.decoder(prev_output_tokens, **kwargs)\n",
    "\n",
    "    def load_state_dict(\n",
    "        self,\n",
    "        state_dict,\n",
    "        strict=True,\n",
    "        model_cfg=None,\n",
    "        args: Optional[Namespace] = None,\n",
    "    ):\n",
    "        \"\"\"Copies parameters and buffers from *state_dict* into this module and\n",
    "        its descendants.\n",
    "\n",
    "        Overrides the method in :class:`nn.Module`. Compared with that method\n",
    "        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n",
    "        \"\"\"\n",
    "\n",
    "        if model_cfg is None and args is not None:\n",
    "            logger.warn(\"using 'args' is deprecated, please update your code to use dataclass config\")\n",
    "            model_cfg = convert_namespace_to_omegaconf(args).model\n",
    "\n",
    "        self.upgrade_state_dict(state_dict)\n",
    "\n",
    "        from fairseq.checkpoint_utils import prune_state_dict\n",
    "\n",
    "        new_state_dict = prune_state_dict(state_dict, model_cfg)\n",
    "        return super().load_state_dict(new_state_dict, strict)\n",
    "\n",
    "\n",
    "class FairseqLanguageModel(BaseFairseqModel):\n",
    "    \"\"\"Base class for decoder-only models.\n",
    "\n",
    "    Args:\n",
    "        decoder (FairseqDecoder): the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, decoder):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        assert isinstance(self.decoder, FairseqDecoder)\n",
    "\n",
    "    def forward(self, src_tokens, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the forward pass for a decoder-only model.\n",
    "\n",
    "        Feeds a batch of tokens through the decoder to predict the next tokens.\n",
    "\n",
    "        Args:\n",
    "            src_tokens (LongTensor): tokens on which to condition the decoder,\n",
    "                of shape `(batch, tgt_len)`\n",
    "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - the decoder's output of shape `(batch, seq_len, vocab)`\n",
    "                - a dictionary with any model-specific outputs\n",
    "        \"\"\"\n",
    "        return self.decoder(src_tokens, **kwargs)\n",
    "\n",
    "    def forward_decoder(self, prev_output_tokens, **kwargs):\n",
    "        return self.decoder(prev_output_tokens, **kwargs)\n",
    "\n",
    "    def extract_features(self, src_tokens, **kwargs):\n",
    "        \"\"\"\n",
    "        Similar to *forward* but only return features.\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - the decoder's features of shape `(batch, seq_len, embed_dim)`\n",
    "                - a dictionary with any model-specific outputs\n",
    "        \"\"\"\n",
    "        return self.decoder.extract_features(src_tokens, **kwargs)\n",
    "\n",
    "    def output_layer(self, features, **kwargs):\n",
    "        \"\"\"Project features to the default output size (typically vocabulary size).\"\"\"\n",
    "        return self.decoder.output_layer(features, **kwargs)\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return self.decoder.max_positions()\n",
    "\n",
    "    def max_decoder_positions(self):\n",
    "        \"\"\"Maximum length supported by the decoder.\"\"\"\n",
    "        return self.decoder.max_positions()\n",
    "\n",
    "    @property\n",
    "    def supported_targets(self):\n",
    "        return {\"future\"}\n",
    "\n",
    "\n",
    "class FairseqEncoderModel(BaseFairseqModel):\n",
    "    \"\"\"Base class for encoder-only models.\n",
    "\n",
    "    Args:\n",
    "        encoder (FairseqEncoder): the encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        assert isinstance(self.encoder, FairseqEncoder)\n",
    "\n",
    "    def forward(self, src_tokens, src_lengths, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the forward pass for a encoder-only model.\n",
    "\n",
    "        Feeds a batch of tokens through the encoder to generate features.\n",
    "\n",
    "        Args:\n",
    "            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\n",
    "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n",
    "\n",
    "        Returns:\n",
    "            the encoder's output, typically of shape `(batch, src_len, features)`\n",
    "        \"\"\"\n",
    "        return self.encoder(src_tokens, src_lengths, **kwargs)\n",
    "\n",
    "    def get_normalized_probs(self, net_output, log_probs, sample=None):\n",
    "        \"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\n",
    "        encoder_out = net_output[\"encoder_out\"]\n",
    "        if torch.is_tensor(encoder_out):\n",
    "            logits = encoder_out.float()\n",
    "            if log_probs:\n",
    "                return F.log_softmax(logits, dim=-1)\n",
    "            else:\n",
    "                return F.softmax(logits, dim=-1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def max_positions(self):\n",
    "        \"\"\"Maximum length supported by the model.\"\"\"\n",
    "        return self.encoder.max_positions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Autoregressive Entity Linking\n",
    "\n",
    "![](s.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are starting with importing our model mGENRE and it's important part, it was slightly changed in previous cells in order to reach stable work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XURCH8bMyn2S"
   },
   "outputs": [],
   "source": [
    "from GENRE.genre.trie import Trie, MarisaTrie\n",
    "from GENRE.genre.fairseq_model import mGENRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load data that connects titles with wikidata ids and trie that is an important part of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lang_title2wikidataID-normalized_with_redirect.pkl\", \"rb\") as f:\n",
    "    lang_title2wikidataID = pickle.load(f)\n",
    "  \n",
    "# with open(\"titles_lang_all105_trie_with_redirect.pkl\", \"rb\") as f:\n",
    "#     trie = Trie.load_from_dict(pickle.load(f))\n",
    "\n",
    "with open(\"titles_lang_all105_marisa_trie_with_redirect.pkl\", \"rb\") as f:\n",
    "    trie = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPU leads to faster inference, so if possible it is recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we chosen 4 because there were lot's of free memory on our own server, you can check the memory available for you using the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver version: \u001b[1m470.103.01\u001b[m\r\n",
      "------------------- \u001b[1mDevice 0\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:   159MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m29C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 1\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:     8MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m22C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 2\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  4077MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m26C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 3\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  5949MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m24C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 4\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  9077MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m21C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 5\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:     8MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m24C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 6\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:     8MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m23C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 7\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  1131MiB / 11019MiB\r\n",
      "Temperature: \u001b[92m23C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Oruf5Ng61T33",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate Wikipedia titles and language IDs\n",
    "model_mGENRE = mGENRE.from_pretrained(\"fairseq_multilingual_entity_disambiguation\").eval()\n",
    "model_mGENRE.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q937',\n",
       "   'texts': ['Albert Einstein >> en'],\n",
       "   'scores': tensor([-0.7137], device='cuda:5'),\n",
       "   'score': tensor(-1.5959, device='cuda:5')},\n",
       "  {'id': 'Q363005',\n",
       "   'texts': ['John Singleton >> en'],\n",
       "   'scores': tensor([-0.7909], device='cuda:5'),\n",
       "   'score': tensor(-1.9374, device='cuda:5')},\n",
       "  {'id': 'Q7374',\n",
       "   'texts': ['Alfred Hitchcock >> en'],\n",
       "   'scores': tensor([-0.8762], device='cuda:5'),\n",
       "   'score': tensor(-2.3182, device='cuda:5')},\n",
       "  {'id': 'Q715110',\n",
       "   'texts': ['Robert Maynard >> en'],\n",
       "   'scores': tensor([-0.8954], device='cuda:5'),\n",
       "   'score': tensor(-2.3689, device='cuda:5')},\n",
       "  {'id': 'Q9353',\n",
       "   'texts': ['John Locke >> en'],\n",
       "   'scores': tensor([-1.0060], device='cuda:5'),\n",
       "   'score': tensor(-2.4641, device='cuda:5')}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"[START] The founder of the theory of relativity [END] received the Nobel Prize.\"]\n",
    "model_mGENRE.sample(\n",
    "    sentences,\n",
    "    beam = 5,\n",
    "    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "        e for e in trie.get(sent.tolist())\n",
    "        if e < len(model_mGENRE.task.target_dictionary)\n",
    "    ],\n",
    "    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "    marginalize=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results above demonstrate that each *text* has it's own id and via marginalization procedure we have unique score for predicted entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis of no [START] and [END]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this part we check that [START] and [END] tokens are really needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q1517374',\n",
       "   'texts': ['History of radio >> en'],\n",
       "   'scores': tensor([-0.4300], device='cuda:5'),\n",
       "   'score': tensor(-1.0534, device='cuda:5')},\n",
       "  {'id': 'Q1516738',\n",
       "   'texts': ['Invention of radio >> en'],\n",
       "   'scores': tensor([-0.6202], device='cuda:5'),\n",
       "   'score': tensor(-1.6408, device='cuda:5')},\n",
       "  {'id': 'Q16887156',\n",
       "   'texts': ['List of inventions in the medieval Islamic world >> en',\n",
       "    'List of inventions in the medieval Islamic world >> ar'],\n",
       "   'scores': tensor([-0.5023, -1.5995], device='cuda:5'),\n",
       "   'score': tensor(-1.7181, device='cuda:5')},\n",
       "  {'id': 'Q4501817',\n",
       "   'texts': ['Timeline of radio >> en'],\n",
       "   'scores': tensor([-0.9116], device='cuda:5'),\n",
       "   'score': tensor(-2.4119, device='cuda:5')}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"Who invented radio?\"]\n",
    "model_mGENRE.sample(\n",
    "    sentences,\n",
    "    beam = 5,\n",
    "    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "        e for e in trie.get(sent.tolist())\n",
    "        if e < len(model_mGENRE.task.target_dictionary)\n",
    "    ],\n",
    "    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "    marginalize=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q362',\n",
       "   'texts': ['World War II >> en', 'Second World War >> en'],\n",
       "   'scores': tensor([-0.4641, -0.6737], device='cuda:4'),\n",
       "   'score': tensor(-0.6678, device='cuda:4')},\n",
       "  {'id': 'Q5370388',\n",
       "   'texts': ['Military history of the United States during World War II >> en'],\n",
       "   'scores': tensor([-0.2719], device='cuda:4'),\n",
       "   'score': tensor(-0.9804, device='cuda:4')},\n",
       "  {'id': 'Q192781',\n",
       "   'texts': ['Military history >> en'],\n",
       "   'scores': tensor([-0.8395], device='cuda:4'),\n",
       "   'score': tensor(-1.8772, device='cuda:4')},\n",
       "  {'id': 'Q131110',\n",
       "   'texts': ['History of the United States >> en'],\n",
       "   'scores': tensor([-0.7007], device='cuda:4'),\n",
       "   'score': tensor(-1.9820, device='cuda:4')}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"When Second World war started?\"]\n",
    "model_mGENRE.sample(\n",
    "    sentences,\n",
    "    beam = 5,\n",
    "    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "        e for e in trie.get(sent.tolist())\n",
    "        if e < len(model_mGENRE.task.target_dictionary)\n",
    "    ],\n",
    "    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "    marginalize=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can say that entities within simple questions like above correctly determine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative assessment of the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!!before that you have to clone wikidata-simplequestions github repository (https://github.com/askplatypus/wikidata-simplequestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov\n",
      "Cloning into 'wikidata-simplequestions'...\n",
      "remote: Enumerating objects: 130, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 130 (delta 9), reused 37 (delta 9), pack-reused 92\u001b[K\n",
      "Receiving objects: 100% (130/130), 41.95 MiB | 10.00 MiB/s, done.\n",
      "Resolving deltas: 100% (50/50), done.\n",
      "Downloading qald-format/annotated_wd_data_test.json (65 MB)\n",
      "Error downloading object: qald-format/annotated_wd_data_test.json (c44a001): Smudge error: Error downloading qald-format/annotated_wd_data_test.json (c44a0018eeadcbad409fec3f0f032dd9f22fcaa3c9e05d06a4640a97b37c3d40): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n",
      "\n",
      "Errors logged to /home/petrakov/wikidata-simplequestions/.git/lfs/logs/20220713T202858.12718045.log\n",
      "Use `git lfs logs last` to view the log.\n",
      "error: external filter 'git-lfs filter-process' failed\n",
      "fatal: qald-format/annotated_wd_data_test.json: smudge filter lfs failed\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n",
      "/home/petrakov/mGENRE_MEL\n"
     ]
    }
   ],
   "source": [
    "# %cd $init_dir\n",
    "# %cd ..\n",
    "# !git clone https://github.com/askplatypus/wikidata-simplequestions\n",
    "\n",
    "\n",
    "# %cd $init_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_simple_questions = \"/home/petrakov/wikidata-simplequestions/annotated_wd_data_train_answerable.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>property</th>\n",
       "      <th>subject</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q12439</td>\n",
       "      <td>R19</td>\n",
       "      <td>Q6106580</td>\n",
       "      <td>who is a musician born in detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q6817891</td>\n",
       "      <td>P364</td>\n",
       "      <td>Q1568</td>\n",
       "      <td>what is the language in which mera shikar was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q1297</td>\n",
       "      <td>R276</td>\n",
       "      <td>Q2888523</td>\n",
       "      <td>Whats the name of a battle that happened in ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q193592</td>\n",
       "      <td>R413</td>\n",
       "      <td>Q5822614</td>\n",
       "      <td>what player plays the position midfielder?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q6849115</td>\n",
       "      <td>P413</td>\n",
       "      <td>Q336286</td>\n",
       "      <td>what is the position that  mike twellman plays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19476</td>\n",
       "      <td>Q223960</td>\n",
       "      <td>P171</td>\n",
       "      <td>Q128001</td>\n",
       "      <td>what classification does  mountain tapir come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19477</td>\n",
       "      <td>Q1535153</td>\n",
       "      <td>R136</td>\n",
       "      <td>Q7727315</td>\n",
       "      <td>What's a superhero movie that premiered on too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19478</td>\n",
       "      <td>Q157443</td>\n",
       "      <td>R136</td>\n",
       "      <td>Q966690</td>\n",
       "      <td>What is the name of a comedy film that is also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19479</td>\n",
       "      <td>Q16093542</td>\n",
       "      <td>P27</td>\n",
       "      <td>Q145</td>\n",
       "      <td>What is the nationality of anthony bailey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19480</td>\n",
       "      <td>Q926822</td>\n",
       "      <td>P21</td>\n",
       "      <td>Q6581097</td>\n",
       "      <td>What gender is gastn filgueira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19481 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          object property   subject  \\\n",
       "0         Q12439      R19  Q6106580   \n",
       "1       Q6817891     P364     Q1568   \n",
       "2          Q1297     R276  Q2888523   \n",
       "3        Q193592     R413  Q5822614   \n",
       "4       Q6849115     P413   Q336286   \n",
       "...          ...      ...       ...   \n",
       "19476    Q223960     P171   Q128001   \n",
       "19477   Q1535153     R136  Q7727315   \n",
       "19478    Q157443     R136   Q966690   \n",
       "19479  Q16093542      P27      Q145   \n",
       "19480    Q926822      P21  Q6581097   \n",
       "\n",
       "                                                question  \n",
       "0                      who is a musician born in detroit  \n",
       "1      what is the language in which mera shikar was ...  \n",
       "2      Whats the name of a battle that happened in ch...  \n",
       "3             what player plays the position midfielder?  \n",
       "4         what is the position that  mike twellman plays  \n",
       "...                                                  ...  \n",
       "19476  what classification does  mountain tapir come ...  \n",
       "19477  What's a superhero movie that premiered on too...  \n",
       "19478  What is the name of a comedy film that is also...  \n",
       "19479          What is the nationality of anthony bailey  \n",
       "19480                    What gender is gastn filgueira  \n",
       "\n",
       "[19481 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(path_to_train_simple_questions, header=None).rename(columns = {0:\"object\", 1:\"property\", 2:\"subject\", 3:\"question\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:50.320952\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "mGENRE_results = model_mGENRE.sample(\n",
    "                                    list(data.loc[:n, \"question\"]),\n",
    "                                    beam = 3,\n",
    "                                    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                        e for e in trie.get(sent.tolist())\n",
    "                                        if e < len(model_mGENRE.task.target_dictionary)\n",
    "                                    ],\n",
    "                                    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                    marginalize=True,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [i[0]['id'] for i in mGENRE_results]\n",
    "y_true = list(data.loc[:n, \"object\"])\n",
    "result = [x in y_pred for x in y_true] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we take only the most probable score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2475"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(sum(result)/len(result), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we take an account all predicted ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [[i['id'] for i in mGENRE_results[j]] for j in range(len(mGENRE_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, out_list in enumerate(out):\n",
    "    if y_true[index] in out_list:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3168"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(sum(res)/len(res), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we take on account only those questions where we certain (top 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [-3, -2, -1.5, -1, -0.75, -0.6, -0.4, -0.2, -0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  -3 \t accuracy =  2.8400000000000003 %\t number of observations =  387 \t share of observations =  96.75 %\n",
      "threshold =  -2 \t accuracy =  3.0700000000000003 %\t number of observations =  326 \t share of observations =  81.5 %\n",
      "threshold =  -1.5 \t accuracy =  3.35 %\t number of observations =  239 \t share of observations =  59.75 %\n",
      "threshold =  -1 \t accuracy =  3.36 %\t number of observations =  149 \t share of observations =  37.25 %\n",
      "threshold =  -0.75 \t accuracy =  1.87 %\t number of observations =  107 \t share of observations =  26.75 %\n",
      "threshold =  -0.6 \t accuracy =  0.0 %\t number of observations =  78 \t share of observations =  19.5 %\n",
      "threshold =  -0.4 \t accuracy =  0.0 %\t number of observations =  40 \t share of observations =  10.0 %\n",
      "threshold =  -0.2 \t accuracy =  0.0 %\t number of observations =  12 \t share of observations =  3.0 %\n",
      "threshold =  -0.1 \t accuracy =  0.0 %\t number of observations =  5 \t share of observations =  1.25 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_100_top_1 = []\n",
    "share_of_observations_100_top_1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    certain_out = [i[0]['id'] for i in mGENRE_results if i[0]['score'] > threshold]\n",
    "    indexes = [1 if i[0]['score'] > threshold else 0 for i in mGENRE_results]\n",
    "    y_true = list(compress(list(data.loc[:n, \"object\"]), indexes))\n",
    "    result = [x in certain_out for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 4)*100\n",
    "    accuracy_100_top_1.append(accuracy)\n",
    "    share = len(result)/n*100\n",
    "    share_of_observations_100_top_1.append(share)\n",
    "    \n",
    "    print(\"threshold = \", threshold, \"\\t\",\n",
    "          \"accuracy = \", accuracy, \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \", len(result)/n*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.plot(share_of_observations_100_top_1[::-1], accuracy_100_top_1, marker = '.', markersize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petrakov/success/mGENRE_MEL/fairseq/fairseq/search.py:205: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beams_buf = indices_buf // vocab_size\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 752.00 MiB (GPU 3; 10.76 GiB total capacity; 4.90 GiB already allocated; 615.56 MiB free; 5.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-57517dbc3a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m mGENRE_results = model_mGENRE.sample(\n\u001b[0m\u001b[1;32m      6\u001b[0m                                     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mbeam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/genre/fairseq_model.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sentences, beam, verbose, text_to_id, marginalize, marginalize_lenpen, max_len_a, max_len_b, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtokenized_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         batched_hypos = self.generate(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/genre/fairseq_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBARTHubInterface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokenized_sentences, beam, verbose, skip_invalid_size_inputs, inference_step_args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_invalid_size_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             translations = self.task.inference_step(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minference_step_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             )\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/tasks/fairseq_task.py\u001b[0m in \u001b[0;36minference_step\u001b[0;34m(self, generator, models, sample, prefix_tokens, constraints)\u001b[0m\n\u001b[1;32m    499\u001b[0m     ):\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             return generator.generate(\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, models, sample, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0mfinalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0msrc_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, sample, prefix_tokens, constraints, bos_token)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 )\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             lprobs, avg_attn_scores = self.model.forward_decoder(\n\u001b[0m\u001b[1;32m    322\u001b[0m                 \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mencoder_outs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mforward_decoder\u001b[0;34m(self, tokens, encoder_outs, incremental_states, temperature)\u001b[0m\n\u001b[1;32m    800\u001b[0m             )\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             probs = model.get_normalized_probs(\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0mdecoder_out_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             )\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/models/transformer.py\u001b[0m in \u001b[0;36mget_normalized_probs\u001b[0;34m(self, net_output, log_probs, sample)\u001b[0m\n\u001b[1;32m    311\u001b[0m     ):\n\u001b[1;32m    312\u001b[0m         \u001b[0;34m\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalized_probs_scriptable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mget_normalized_probs_scriptable\u001b[0;34m(self, net_output, log_probs, sample)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalized_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# syntactic sugar for simple models which don't have a decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/models/fairseq_decoder.py\u001b[0m in \u001b[0;36mget_normalized_probs\u001b[0;34m(self, net_output, log_probs, sample)\u001b[0m\n\u001b[1;32m     65\u001b[0m     ):\n\u001b[1;32m     66\u001b[0m         \u001b[0;34m\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalized_probs_scriptable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# TorchScript doesn't support super() method so that the scriptable Subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/models/fairseq_decoder.py\u001b[0m in \u001b[0;36mget_normalized_probs_scriptable\u001b[0;34m(self, net_output, log_probs, sample)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/fairseq/fairseq/utils.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(x, dim, onnx_trace)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 752.00 MiB (GPU 3; 10.76 GiB total capacity; 4.90 GiB already allocated; 615.56 MiB free; 5.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "n = 400\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "mGENRE_results = model_mGENRE.sample(\n",
    "                                    list(data.sample(n = n, replace = False, random_state=1).loc[:, \"question\"]),\n",
    "                                    beam = 3,\n",
    "                                    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                        e for e in trie.get(sent.tolist())\n",
    "                                        if e < len(model_mGENRE.task.target_dictionary)\n",
    "                                    ],\n",
    "                                    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                    marginalize=True,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [-10, -3, -2, -1.5, -1, -0.75, -0.6, -0.4, -0.2, -0.1]\n",
    "accuracy_400_top_1 = []\n",
    "share_of_observations_400_top_1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    certain_out = [i[0]['id'] for i in mGENRE_results if i[0]['score'] > threshold]\n",
    "    indexes = [1 if i[0]['score'] > threshold else 0 for i in mGENRE_results]\n",
    "    y_true = list(compress(list(data.loc[list(data.sample(n = n, replace = False, random_state=1).index), \"object\"]), indexes))\n",
    "    result = [x in certain_out for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 2)*100\n",
    "    accuracy_400_top_1.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 2)\n",
    "    share_of_observations_400_top_1.append(share)\n",
    "    \n",
    "    print(\"threshold = \", threshold, \"\\t\",\n",
    "          \"accuracy = \", accuracy, \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \", share, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.title(\"mGENRE certainty basing on 400 random samples\")\n",
    "plt.plot(share_of_observations_400_top_1[::-1], accuracy_400_top_1, marker = '.', markersize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch approach to add observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part  0  done!\n",
      "part  1  done!\n",
      "part  2  done!\n",
      "part  3  done!\n",
      "part  4  done!\n",
      "part  5  done!\n",
      "part  6  done!\n",
      "part  7  done!\n",
      "part  8  done!\n",
      "part  9  done!\n",
      "part  10  done!\n",
      "part  11  done!\n",
      "part  12  done!\n",
      "part  13  done!\n",
      "part  14  done!\n",
      "part  15  done!\n",
      "part  16  done!\n",
      "part  17  done!\n",
      "part  18  done!\n",
      "part  19  done!\n",
      "part  20  done!\n",
      "part  21  done!\n",
      "part  22  done!\n",
      "part  23  done!\n",
      "part  24  done!\n",
      "part  25  done!\n",
      "part  26  done!\n",
      "part  27  done!\n",
      "part  28  done!\n",
      "part  29  done!\n",
      "part  30  done!\n",
      "part  31  done!\n",
      "part  32  done!\n",
      "part  33  done!\n",
      "part  34  done!\n",
      "part  35  done!\n",
      "part  36  done!\n",
      "part  37  done!\n",
      "part  38  done!\n",
      "part  39  done!\n",
      "part  40  done!\n",
      "part  41  done!\n",
      "part  42  done!\n",
      "part  43  done!\n",
      "part  44  done!\n",
      "part  45  done!\n",
      "part  46  done!\n",
      "part  47  done!\n",
      "part  48  done!\n",
      "part  49  done!\n",
      "part  50  done!\n",
      "part  51  done!\n",
      "part  52  done!\n",
      "part  53  done!\n",
      "part  54  done!\n",
      "part  55  done!\n",
      "part  56  done!\n",
      "part  57  done!\n",
      "part  58  done!\n",
      "part  59  done!\n",
      "part  60  done!\n",
      "part  61  done!\n",
      "part  62  done!\n",
      "part  63  done!\n",
      "part  64  done!\n",
      "part  65  done!\n",
      "part  66  done!\n",
      "part  67  done!\n",
      "part  68  done!\n",
      "part  69  done!\n",
      "part  70  done!\n",
      "part  71  done!\n",
      "part  72  done!\n",
      "part  73  done!\n",
      "part  74  done!\n",
      "part  75  done!\n",
      "part  76  done!\n",
      "part  77  done!\n",
      "part  78  done!\n",
      "part  79  done!\n",
      "Duration: 0:08:17.836753\n"
     ]
    }
   ],
   "source": [
    "n = 400\n",
    "start_time = datetime.now()\n",
    "\n",
    "divider = 80\n",
    "\n",
    "mGENRE_results = []\n",
    "for i in range(divider):\n",
    "\n",
    "    mGENRE_results_i = model_mGENRE.sample(\n",
    "                                        list(data.sample(n = 5, replace = False, random_state=i).loc[:, \"question\"]),\n",
    "                                        beam = 3,\n",
    "                                        prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                            e for e in trie.get(sent.tolist())\n",
    "                                            if e < len(model_mGENRE.task.target_dictionary)\n",
    "                                        ],\n",
    "                                        text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                        marginalize=True,\n",
    "                                        verbose = True\n",
    "                                    )\n",
    "    mGENRE_results.append(mGENRE_results_i)\n",
    "    print(\"part \", i, \" done!\")\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mGENRE_results = sum(mGENRE_results, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "for i in range(divider): \n",
    "    objects.append(list(data.sample(n = 5, replace = False, random_state=i).loc[:, \"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = sum(objects, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  -10 \t accuracy =  23.0 %\t number of observations =  400 \t share of observations =  100.0 %\n",
      "threshold =  -3 \t accuracy =  24.0 %\t number of observations =  383 \t share of observations =  95.75 %\n",
      "threshold =  -2 \t accuracy =  27.0 %\t number of observations =  331 \t share of observations =  82.75 %\n",
      "threshold =  -1.5 \t accuracy =  31.0 %\t number of observations =  249 \t share of observations =  62.25 %\n",
      "threshold =  -1 \t accuracy =  39.0 %\t number of observations =  141 \t share of observations =  35.25 %\n",
      "threshold =  -0.75 \t accuracy =  43.0 %\t number of observations =  95 \t share of observations =  23.75 %\n",
      "threshold =  -0.6 \t accuracy =  45.0 %\t number of observations =  76 \t share of observations =  19.0 %\n",
      "threshold =  -0.4 \t accuracy =  61.0 %\t number of observations =  46 \t share of observations =  11.5 %\n",
      "threshold =  -0.2 \t accuracy =  68.0 %\t number of observations =  19 \t share of observations =  4.75 %\n",
      "threshold =  -0.1 \t accuracy =  67.0 %\t number of observations =  6 \t share of observations =  1.5 %\n"
     ]
    }
   ],
   "source": [
    "thresholds = [-10, -3, -2, -1.5, -1, -0.75, -0.6, -0.4, -0.2, -0.1]\n",
    "accuracy_400_top_1 = []\n",
    "share_of_observations_400_top_1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    certain_out = [i[0]['id'] for i in mGENRE_results if i[0]['score'] > threshold]\n",
    "    indexes = [1 if i[0]['score'] > threshold else 0 for i in mGENRE_results]\n",
    "    y_true = list(compress(objects, indexes))\n",
    "    result = [x in certain_out for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 2)*100\n",
    "    accuracy_400_top_1.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 2)\n",
    "    share_of_observations_400_top_1.append(share)\n",
    "    \n",
    "    print(\"threshold = \", threshold, \"\\t\",\n",
    "          \"accuracy = \", accuracy, \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \", share, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.title(\"mGENRE certainty basing on 400 random samples\")\n",
    "plt.plot(share_of_observations_400_top_1[::-1], accuracy_400_top_1, marker = '.', markersize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENRE.genre.fairseq_model import mGENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Facebook, Inc. and its affiliates.\r\n",
      "#\r\n",
      "# This source code is licensed under the MIT license found in the\r\n",
      "# LICENSE file in the root directory of this source tree.\r\n",
      "\"\"\"\r\n",
      "Base classes for various fairseq models.\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "import logging\r\n",
      "from argparse import Namespace\r\n",
      "from typing import Dict, List, Optional, Tuple\r\n",
      "\r\n",
      "import torch\r\n",
      "import torch.nn as nn\r\n",
      "import torch.nn.functional as F\r\n",
      "from fairseq import utils\r\n",
      "from fairseq.data import Dictionary\r\n",
      "from fairseq.dataclass.utils import (\r\n",
      "    convert_namespace_to_omegaconf,\r\n",
      "    gen_parser_from_dataclass,\r\n",
      ")\r\n",
      "from fairseq.models import FairseqDecoder, FairseqEncoder\r\n",
      "from omegaconf import DictConfig\r\n",
      "from torch import Tensor\r\n",
      "\r\n",
      "\r\n",
      "logger = logging.getLogger(__name__)\r\n",
      "\r\n",
      "\r\n",
      "class BaseFairseqModel(nn.Module):\r\n",
      "    \"\"\"Base class for fairseq models.\"\"\"\r\n",
      "\r\n",
      "    def __init__(self):\r\n",
      "        super().__init__()\r\n",
      "        self._is_generation_fast = False\r\n",
      "\r\n",
      "    @classmethod\r\n",
      "    def add_args(cls, parser):\r\n",
      "        \"\"\"Add model-specific arguments to the parser.\"\"\"\r\n",
      "        dc = getattr(cls, \"__dataclass\", None)\r\n",
      "        if dc is not None:\r\n",
      "            # do not set defaults so that settings defaults from various architectures still works\r\n",
      "            gen_parser_from_dataclass(parser, dc(), delete_default=True)\r\n",
      "\r\n",
      "    @classmethod\r\n",
      "    def build_model(cls, args, task):\r\n",
      "        \"\"\"Build a new model instance.\"\"\"\r\n",
      "        raise NotImplementedError(\"Model must implement the build_model method\")\r\n",
      "\r\n",
      "    def get_targets(self, sample, net_output):\r\n",
      "        \"\"\"Get targets from either the sample or the net's output.\"\"\"\r\n",
      "        return sample[\"target\"]\r\n",
      "\r\n",
      "    def get_normalized_probs(\r\n",
      "        self,\r\n",
      "        net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]],\r\n",
      "        log_probs: bool,\r\n",
      "        sample: Optional[Dict[str, Tensor]] = None,\r\n",
      "    ):\r\n",
      "        \"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\r\n",
      "        return self.get_normalized_probs_scriptable(net_output, log_probs, sample)\r\n",
      "\r\n",
      "    # TorchScript doesn't support super() method so that the scriptable Subclass\r\n",
      "    # can't access the base class model in Torchscript.\r\n",
      "    # Current workaround is to add a helper function with different name and\r\n",
      "    # call the helper function from scriptable Subclass.\r\n",
      "    def get_normalized_probs_scriptable(\r\n",
      "        self,\r\n",
      "        net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]],\r\n",
      "        log_probs: bool,\r\n",
      "        sample: Optional[Dict[str, Tensor]] = None,\r\n",
      "    ):\r\n",
      "        \"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"\r\n",
      "        if hasattr(self, \"decoder\"):\r\n",
      "            return self.decoder.get_normalized_probs(net_output, log_probs, sample)\r\n",
      "        elif torch.is_tensor(net_output):\r\n",
      "            # syntactic sugar for simple models which don't have a decoder\r\n",
      "            # (e.g., the classification tutorial)\r\n",
      "            logits = net_output.float()\r\n",
      "            if log_probs:\r\n",
      "                return F.log_softmax(logits, dim=-1)\r\n",
      "            else:\r\n",
      "                return F.softmax(logits, dim=-1)\r\n",
      "        raise NotImplementedError\r\n",
      "\r\n",
      "    def extract_features(self, *args, **kwargs):\r\n",
      "        \"\"\"Similar to *forward* but only return features.\"\"\"\r\n",
      "        return self(*args, **kwargs)\r\n",
      "\r\n",
      "    def max_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the model.\"\"\"\r\n",
      "        return None\r\n",
      "\r\n",
      "    def load_state_dict(\r\n",
      "        self,\r\n",
      "        state_dict,\r\n",
      "        strict=True,\r\n",
      "        model_cfg: Optional[DictConfig] = None,\r\n",
      "        args: Optional[Namespace] = None,\r\n",
      "    ):\r\n",
      "        \"\"\"Copies parameters and buffers from *state_dict* into this module and\r\n",
      "        its descendants.\r\n",
      "\r\n",
      "        Overrides the method in :class:`nn.Module`. Compared with that method\r\n",
      "        this additionally \"upgrades\" *state_dicts* from old checkpoints.\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "        if model_cfg is None and args is not None:\r\n",
      "            logger.warn(\"using 'args' is deprecated, please update your code to use dataclass config\")\r\n",
      "            model_cfg = convert_namespace_to_omegaconf(args).model\r\n",
      "\r\n",
      "        self.upgrade_state_dict(state_dict)\r\n",
      "\r\n",
      "        from fairseq.checkpoint_utils import prune_state_dict\r\n",
      "\r\n",
      "        new_state_dict = prune_state_dict(state_dict, model_cfg)\r\n",
      "        return super().load_state_dict(new_state_dict, strict)\r\n",
      "\r\n",
      "    def upgrade_state_dict(self, state_dict):\r\n",
      "        \"\"\"Upgrade old state dicts to work with newer code.\"\"\"\r\n",
      "        self.upgrade_state_dict_named(state_dict, \"\")\r\n",
      "\r\n",
      "    def upgrade_state_dict_named(self, state_dict, name):\r\n",
      "        \"\"\"Upgrade old state dicts to work with newer code.\r\n",
      "\r\n",
      "        Args:\r\n",
      "            state_dict (dict): state dictionary to upgrade, in place\r\n",
      "            name (str): the state dict key corresponding to the current module\r\n",
      "        \"\"\"\r\n",
      "        assert state_dict is not None\r\n",
      "\r\n",
      "        def do_upgrade(m, prefix):\r\n",
      "            if len(prefix) > 0:\r\n",
      "                prefix += \".\"\r\n",
      "\r\n",
      "            for n, c in m.named_children():\r\n",
      "                name = prefix + n\r\n",
      "                if hasattr(c, \"upgrade_state_dict_named\"):\r\n",
      "                    c.upgrade_state_dict_named(state_dict, name)\r\n",
      "                elif hasattr(c, \"upgrade_state_dict\"):\r\n",
      "                    c.upgrade_state_dict(state_dict)\r\n",
      "                do_upgrade(c, name)\r\n",
      "\r\n",
      "        do_upgrade(self, name)\r\n",
      "\r\n",
      "    def set_num_updates(self, num_updates):\r\n",
      "        \"\"\"State from trainer to pass along to model at every update.\"\"\"\r\n",
      "\r\n",
      "        def _apply(m):\r\n",
      "            if hasattr(m, \"set_num_updates\") and m != self:\r\n",
      "                m.set_num_updates(num_updates)\r\n",
      "\r\n",
      "        self.apply(_apply)\r\n",
      "\r\n",
      "    def prepare_for_inference_(self, cfg: DictConfig):\r\n",
      "        \"\"\"Prepare model for inference.\"\"\"\r\n",
      "        kwargs = {}\r\n",
      "        kwargs[\"beamable_mm_beam_size\"] = (\r\n",
      "            None\r\n",
      "            if getattr(cfg.generation, \"no_beamable_mm\", False)\r\n",
      "            else getattr(cfg.generation, \"beam\", 5)\r\n",
      "        )\r\n",
      "        kwargs[\"need_attn\"] = getattr(cfg.generation, \"print_alignment\", False)\r\n",
      "        if getattr(cfg.generation, \"retain_dropout\", False):\r\n",
      "            kwargs[\"retain_dropout\"] = cfg.generation.retain_dropout\r\n",
      "            kwargs[\"retain_dropout_modules\"] = cfg.generation.retain_dropout_modules\r\n",
      "        self.make_generation_fast_(**kwargs)\r\n",
      "\r\n",
      "    def make_generation_fast_(self, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Legacy entry point to optimize model for faster generation.\r\n",
      "        Prefer prepare_for_inference_.\r\n",
      "        \"\"\"\r\n",
      "        if self._is_generation_fast:\r\n",
      "            return  # only apply once\r\n",
      "        self._is_generation_fast = True\r\n",
      "\r\n",
      "        # remove weight norm from all modules in the network\r\n",
      "        def apply_remove_weight_norm(module):\r\n",
      "            try:\r\n",
      "                nn.utils.remove_weight_norm(module)\r\n",
      "            except (AttributeError, ValueError):  # this module didn't have weight norm\r\n",
      "                return\r\n",
      "\r\n",
      "        self.apply(apply_remove_weight_norm)\r\n",
      "\r\n",
      "        def apply_make_generation_fast_(module, prefix):\r\n",
      "            if len(prefix) > 0:\r\n",
      "                prefix += \".\"\r\n",
      "\r\n",
      "            base_func = BaseFairseqModel.make_generation_fast_\r\n",
      "            for n, m in module.named_modules():\r\n",
      "                if (\r\n",
      "                    m != self\r\n",
      "                    and hasattr(m, \"make_generation_fast_\")\r\n",
      "                    # don't call this implementation again, e.g., if\r\n",
      "                    # children modules also inherit from BaseFairseqModel\r\n",
      "                    and m.make_generation_fast_.__func__ is not base_func\r\n",
      "                ):\r\n",
      "                    name = prefix + n\r\n",
      "                    m.make_generation_fast_(name=name, **kwargs)\r\n",
      "\r\n",
      "        apply_make_generation_fast_(self, \"\")\r\n",
      "\r\n",
      "        def train(mode=True):\r\n",
      "            #self.train = train\r\n",
      "            self.train()\r\n",
      "\r\n",
      "#     def prepare_for_onnx_export_(self, **kwargs):\r\n",
      "#         \"\"\"Make model exportable via ONNX trace.\"\"\"\r\n",
      "#         seen = set()\r\n",
      "\r\n",
      "#         def apply_prepare_for_onnx_export_(module):\r\n",
      "#             if (\r\n",
      "#                 module != self\r\n",
      "#                 and hasattr(module, \"prepare_for_onnx_export_\")\r\n",
      "#                 and module not in seen\r\n",
      "#             ):\r\n",
      "#                 seen.add(module)\r\n",
      "#                 module.prepare_for_onnx_export_(**kwargs)\r\n",
      "\r\n",
      "#         self.apply(apply_prepare_for_onnx_export_)\r\n",
      "\r\n",
      "    @classmethod\r\n",
      "    def from_pretrained(\r\n",
      "        cls,\r\n",
      "        model_name_or_path,\r\n",
      "        checkpoint_file=\"model.pt\",\r\n",
      "        data_name_or_path=\".\",\r\n",
      "        **kwargs,\r\n",
      "    ):\r\n",
      "        \"\"\"\r\n",
      "        Load a :class:`~fairseq.models.FairseqModel` from a pre-trained model\r\n",
      "        file. Downloads and caches the pre-trained model file if needed.\r\n",
      "\r\n",
      "        The base implementation returns a\r\n",
      "        :class:`~fairseq.hub_utils.GeneratorHubInterface`, which can be used to\r\n",
      "        generate translations or sample from language models. The underlying\r\n",
      "        :class:`~fairseq.models.FairseqModel` can be accessed via the\r\n",
      "        *generator.models* attribute.\r\n",
      "\r\n",
      "        Other models may override this to implement custom hub interfaces.\r\n",
      "\r\n",
      "        Args:\r\n",
      "            model_name_or_path (str): either the name of a pre-trained model to\r\n",
      "                load or a path/URL to a pre-trained model state dict\r\n",
      "            checkpoint_file (str, optional): colon-separated list of checkpoint\r\n",
      "                files in the model archive to ensemble (default: 'model.pt')\r\n",
      "            data_name_or_path (str, optional): point args.data to the archive\r\n",
      "                at the given path/URL. Can start with '.' or './' to reuse the\r\n",
      "                model archive path.\r\n",
      "        \"\"\"\r\n",
      "        from fairseq import hub_utils\r\n",
      "\r\n",
      "        x = hub_utils.from_pretrained(\r\n",
      "            model_name_or_path,\r\n",
      "            checkpoint_file,\r\n",
      "            data_name_or_path,\r\n",
      "            archive_map=cls.hub_models(),\r\n",
      "            **kwargs,\r\n",
      "        )\r\n",
      "        logger.info(x[\"args\"])\r\n",
      "        return hub_utils.GeneratorHubInterface(x[\"args\"], x[\"task\"], x[\"models\"])\r\n",
      "\r\n",
      "    @classmethod\r\n",
      "    def hub_models(cls):\r\n",
      "        return {}\r\n",
      "\r\n",
      "\r\n",
      "class FairseqEncoderDecoderModel(BaseFairseqModel):\r\n",
      "    \"\"\"Base class for encoder-decoder models.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        encoder (FairseqEncoder): the encoder\r\n",
      "        decoder (FairseqDecoder): the decoder\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    def __init__(self, encoder, decoder):\r\n",
      "        super().__init__()\r\n",
      "\r\n",
      "        self.encoder = encoder\r\n",
      "        self.decoder = decoder\r\n",
      "        assert isinstance(self.encoder, FairseqEncoder)\r\n",
      "        assert isinstance(self.decoder, FairseqDecoder)\r\n",
      "\r\n",
      "    def forward(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Run the forward pass for an encoder-decoder model.\r\n",
      "\r\n",
      "        First feed a batch of source tokens through the encoder. Then, feed the\r\n",
      "        encoder output and previous decoder outputs (i.e., teacher forcing) to\r\n",
      "        the decoder to produce the next outputs::\r\n",
      "\r\n",
      "            encoder_out = self.encoder(src_tokens, src_lengths)\r\n",
      "            return self.decoder(prev_output_tokens, encoder_out)\r\n",
      "\r\n",
      "        Args:\r\n",
      "            src_tokens (LongTensor): tokens in the source language of shape\r\n",
      "                `(batch, src_len)`\r\n",
      "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\r\n",
      "            prev_output_tokens (LongTensor): previous decoder outputs of shape\r\n",
      "                `(batch, tgt_len)`, for teacher forcing\r\n",
      "\r\n",
      "        Returns:\r\n",
      "            tuple:\r\n",
      "                - the decoder's output of shape `(batch, tgt_len, vocab)`\r\n",
      "                - a dictionary with any model-specific outputs\r\n",
      "        \"\"\"\r\n",
      "        encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)\r\n",
      "        decoder_out = self.decoder(\r\n",
      "            prev_output_tokens, encoder_out=encoder_out, **kwargs\r\n",
      "        )\r\n",
      "        return decoder_out\r\n",
      "\r\n",
      "    def forward_decoder(self, prev_output_tokens, **kwargs):\r\n",
      "        return self.decoder(prev_output_tokens, **kwargs)\r\n",
      "\r\n",
      "    def extract_features(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Similar to *forward* but only return features.\r\n",
      "\r\n",
      "        Returns:\r\n",
      "            tuple:\r\n",
      "                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\r\n",
      "                - a dictionary with any model-specific outputs\r\n",
      "        \"\"\"\r\n",
      "        encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)\r\n",
      "        features = self.decoder.extract_features(\r\n",
      "            prev_output_tokens, encoder_out=encoder_out, **kwargs\r\n",
      "        )\r\n",
      "        return features\r\n",
      "\r\n",
      "    def output_layer(self, features, **kwargs):\r\n",
      "        \"\"\"Project features to the default output size (typically vocabulary size).\"\"\"\r\n",
      "        return self.decoder.output_layer(features, **kwargs)\r\n",
      "\r\n",
      "    def max_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the model.\"\"\"\r\n",
      "        return (self.encoder.max_positions(), self.decoder.max_positions())\r\n",
      "\r\n",
      "    def max_decoder_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the decoder.\"\"\"\r\n",
      "        return self.decoder.max_positions()\r\n",
      "\r\n",
      "\r\n",
      "class FairseqModel(FairseqEncoderDecoderModel):\r\n",
      "    def __init__(self, *args, **kwargs):\r\n",
      "        super().__init__(*args, **kwargs)\r\n",
      "        utils.deprecation_warning(\r\n",
      "            \"FairseqModel is deprecated, please use FairseqEncoderDecoderModel \"\r\n",
      "            \"or BaseFairseqModel instead\",\r\n",
      "            stacklevel=4,\r\n",
      "        )\r\n",
      "\r\n",
      "\r\n",
      "class FairseqMultiModel(BaseFairseqModel):\r\n",
      "    \"\"\"Base class for combining multiple encoder-decoder models.\"\"\"\r\n",
      "\r\n",
      "    def __init__(self, encoders, decoders):\r\n",
      "        super().__init__()\r\n",
      "        assert encoders.keys() == decoders.keys()\r\n",
      "        self.keys = list(encoders.keys())\r\n",
      "        for key in self.keys:\r\n",
      "            assert isinstance(encoders[key], FairseqEncoder)\r\n",
      "            assert isinstance(decoders[key], FairseqDecoder)\r\n",
      "\r\n",
      "        self.models = nn.ModuleDict(\r\n",
      "            {\r\n",
      "                key: FairseqEncoderDecoderModel(encoders[key], decoders[key])\r\n",
      "                for key in self.keys\r\n",
      "            }\r\n",
      "        )\r\n",
      "\r\n",
      "    @staticmethod\r\n",
      "    def build_shared_embeddings(\r\n",
      "        dicts: Dict[str, Dictionary],\r\n",
      "        langs: List[str],\r\n",
      "        embed_dim: int,\r\n",
      "        build_embedding: callable,\r\n",
      "        pretrained_embed_path: Optional[str] = None,\r\n",
      "    ):\r\n",
      "        \"\"\"\r\n",
      "        Helper function to build shared embeddings for a set of languages after\r\n",
      "        checking that all dicts corresponding to those languages are equivalent.\r\n",
      "\r\n",
      "        Args:\r\n",
      "            dicts: Dict of lang_id to its corresponding Dictionary\r\n",
      "            langs: languages that we want to share embeddings for\r\n",
      "            embed_dim: embedding dimension\r\n",
      "            build_embedding: callable function to actually build the embedding\r\n",
      "            pretrained_embed_path: Optional path to load pretrained embeddings\r\n",
      "        \"\"\"\r\n",
      "        shared_dict = dicts[langs[0]]\r\n",
      "        if any(dicts[lang] != shared_dict for lang in langs):\r\n",
      "            raise ValueError(\r\n",
      "                \"--share-*-embeddings requires a joined dictionary: \"\r\n",
      "                \"--share-encoder-embeddings requires a joined source \"\r\n",
      "                \"dictionary, --share-decoder-embeddings requires a joined \"\r\n",
      "                \"target dictionary, and --share-all-embeddings requires a \"\r\n",
      "                \"joint source + target dictionary.\"\r\n",
      "            )\r\n",
      "        return build_embedding(shared_dict, embed_dim, pretrained_embed_path)\r\n",
      "\r\n",
      "    def forward(self, src_tokens, src_lengths, prev_output_tokens, **kwargs):\r\n",
      "        raise NotImplementedError\r\n",
      "\r\n",
      "    def max_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the model.\"\"\"\r\n",
      "        return {\r\n",
      "            key: (\r\n",
      "                self.models[key].encoder.max_positions(),\r\n",
      "                self.models[key].decoder.max_positions(),\r\n",
      "            )\r\n",
      "            for key in self.keys\r\n",
      "        }\r\n",
      "\r\n",
      "    def max_decoder_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the decoder.\"\"\"\r\n",
      "        return min(model.decoder.max_positions() for model in self.models.values())\r\n",
      "\r\n",
      "    @property\r\n",
      "    def encoder(self):\r\n",
      "        return self.models[self.keys[0]].encoder\r\n",
      "\r\n",
      "    @property\r\n",
      "    def decoder(self):\r\n",
      "        return self.models[self.keys[0]].decoder\r\n",
      "\r\n",
      "    def forward_decoder(self, prev_output_tokens, **kwargs):\r\n",
      "        return self.decoder(prev_output_tokens, **kwargs)\r\n",
      "\r\n",
      "    def load_state_dict(\r\n",
      "        self,\r\n",
      "        state_dict,\r\n",
      "        strict=True,\r\n",
      "        model_cfg=None,\r\n",
      "        args: Optional[Namespace] = None,\r\n",
      "    ):\r\n",
      "        \"\"\"Copies parameters and buffers from *state_dict* into this module and\r\n",
      "        its descendants.\r\n",
      "\r\n",
      "        Overrides the method in :class:`nn.Module`. Compared with that method\r\n",
      "        this additionally \"upgrades\" *state_dicts* from old checkpoints.\r\n",
      "        \"\"\"\r\n",
      "\r\n",
      "        if model_cfg is None and args is not None:\r\n",
      "            logger.warn(\"using 'args' is deprecated, please update your code to use dataclass config\")\r\n",
      "            model_cfg = convert_namespace_to_omegaconf(args).model\r\n",
      "\r\n",
      "        self.upgrade_state_dict(state_dict)\r\n",
      "\r\n",
      "        from fairseq.checkpoint_utils import prune_state_dict\r\n",
      "\r\n",
      "        new_state_dict = prune_state_dict(state_dict, model_cfg)\r\n",
      "        return super().load_state_dict(new_state_dict, strict)\r\n",
      "\r\n",
      "\r\n",
      "class FairseqLanguageModel(BaseFairseqModel):\r\n",
      "    \"\"\"Base class for decoder-only models.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        decoder (FairseqDecoder): the decoder\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    def __init__(self, decoder):\r\n",
      "        super().__init__()\r\n",
      "        self.decoder = decoder\r\n",
      "        assert isinstance(self.decoder, FairseqDecoder)\r\n",
      "\r\n",
      "    def forward(self, src_tokens, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Run the forward pass for a decoder-only model.\r\n",
      "\r\n",
      "        Feeds a batch of tokens through the decoder to predict the next tokens.\r\n",
      "\r\n",
      "        Args:\r\n",
      "            src_tokens (LongTensor): tokens on which to condition the decoder,\r\n",
      "                of shape `(batch, tgt_len)`\r\n",
      "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\r\n",
      "\r\n",
      "        Returns:\r\n",
      "            tuple:\r\n",
      "                - the decoder's output of shape `(batch, seq_len, vocab)`\r\n",
      "                - a dictionary with any model-specific outputs\r\n",
      "        \"\"\"\r\n",
      "        return self.decoder(src_tokens, **kwargs)\r\n",
      "\r\n",
      "    def forward_decoder(self, prev_output_tokens, **kwargs):\r\n",
      "        return self.decoder(prev_output_tokens, **kwargs)\r\n",
      "\r\n",
      "    def extract_features(self, src_tokens, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Similar to *forward* but only return features.\r\n",
      "\r\n",
      "        Returns:\r\n",
      "            tuple:\r\n",
      "                - the decoder's features of shape `(batch, seq_len, embed_dim)`\r\n",
      "                - a dictionary with any model-specific outputs\r\n",
      "        \"\"\"\r\n",
      "        return self.decoder.extract_features(src_tokens, **kwargs)\r\n",
      "\r\n",
      "    def output_layer(self, features, **kwargs):\r\n",
      "        \"\"\"Project features to the default output size (typically vocabulary size).\"\"\"\r\n",
      "        return self.decoder.output_layer(features, **kwargs)\r\n",
      "\r\n",
      "    def max_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the model.\"\"\"\r\n",
      "        return self.decoder.max_positions()\r\n",
      "\r\n",
      "    def max_decoder_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the decoder.\"\"\"\r\n",
      "        return self.decoder.max_positions()\r\n",
      "\r\n",
      "    @property\r\n",
      "    def supported_targets(self):\r\n",
      "        return {\"future\"}\r\n",
      "\r\n",
      "\r\n",
      "class FairseqEncoderModel(BaseFairseqModel):\r\n",
      "    \"\"\"Base class for encoder-only models.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        encoder (FairseqEncoder): the encoder\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    def __init__(self, encoder):\r\n",
      "        super().__init__()\r\n",
      "        self.encoder = encoder\r\n",
      "        assert isinstance(self.encoder, FairseqEncoder)\r\n",
      "\r\n",
      "    def forward(self, src_tokens, src_lengths, **kwargs):\r\n",
      "        \"\"\"\r\n",
      "        Run the forward pass for a encoder-only model.\r\n",
      "\r\n",
      "        Feeds a batch of tokens through the encoder to generate features.\r\n",
      "\r\n",
      "        Args:\r\n",
      "            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\r\n",
      "            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\r\n",
      "\r\n",
      "        Returns:\r\n",
      "            the encoder's output, typically of shape `(batch, src_len, features)`\r\n",
      "        \"\"\"\r\n",
      "        return self.encoder(src_tokens, src_lengths, **kwargs)\r\n",
      "\r\n",
      "    def get_normalized_probs(self, net_output, log_probs, sample=None):\r\n",
      "        \"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\r\n",
      "        encoder_out = net_output[\"encoder_out\"]\r\n",
      "        if torch.is_tensor(encoder_out):\r\n",
      "            logits = encoder_out.float()\r\n",
      "            if log_probs:\r\n",
      "                return F.log_softmax(logits, dim=-1)\r\n",
      "            else:\r\n",
      "                return F.softmax(logits, dim=-1)\r\n",
      "        raise NotImplementedError\r\n",
      "\r\n",
      "    def max_positions(self):\r\n",
      "        \"\"\"Maximum length supported by the model.\"\"\"\r\n",
      "        return self.encoder.max_positions()\r\n"
     ]
    }
   ],
   "source": [
    "%cat fairseq/fairseq/models/fairseq_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL/GENRE/genre\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir/GENRE/genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fairseq_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fairseq_model.py\n",
    "\n",
    "\n",
    "#Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from fairseq import search, utils\n",
    "from fairseq.models.bart import BARTHubInterface, BARTModel\n",
    "from omegaconf import open_dict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GENREHubInterface(BARTHubInterface):\n",
    "    def set_seed(self, seed):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def sample(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        beam: int = 5,\n",
    "        verbose: bool = False,\n",
    "        text_to_id=None,\n",
    "        marginalize=False,\n",
    "        marginalize_lenpen=0.5,\n",
    "        max_len_a=1024,\n",
    "        max_len_b=1024,\n",
    "        seed=13,\n",
    "        **kwargs,\n",
    "    ) -> List[str]:\n",
    "        \n",
    "        \n",
    "        if isinstance(sentences, str):\n",
    "            return self.sample([sentences], beam=beam, verbose=verbose, **kwargs)[0]\n",
    "        tokenized_sentences = [self.encode(sentence) for sentence in sentences]\n",
    "        \n",
    "        self.set_seed(seed)\n",
    "        \n",
    "        batched_hypos = self.generate(\n",
    "            tokenized_sentences,\n",
    "            beam,\n",
    "            verbose,\n",
    "            max_len_a=max_len_a,\n",
    "            max_len_b=max_len_b,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "        \n",
    "        outputs = [\n",
    "            [\n",
    "                {\"text\": self.decode(hypo[\"tokens\"]), \"score\": hypo[\"score\"]}\n",
    "                for hypo in hypos\n",
    "            ]\n",
    "            for hypos in batched_hypos\n",
    "        ]\n",
    "        if text_to_id:\n",
    "            outputs = [\n",
    "                [{**hypo, \"id\": text_to_id(hypo[\"text\"])} for hypo in hypos]\n",
    "                for hypos in outputs\n",
    "            ]\n",
    "\n",
    "            if marginalize:\n",
    "                for (i, hypos), hypos_tok in zip(enumerate(outputs), batched_hypos):\n",
    "                    outputs_dict = defaultdict(list)\n",
    "                    for hypo, hypo_tok in zip(hypos, hypos_tok):\n",
    "                        outputs_dict[hypo[\"id\"]].append(\n",
    "                            {**hypo, \"len\": len(hypo_tok[\"tokens\"])}\n",
    "                        )\n",
    "\n",
    "                    outputs[i] = sorted(\n",
    "                        [\n",
    "                            {\n",
    "                                \"id\": _id,\n",
    "                                \"texts\": [hypo[\"text\"] for hypo in hypos],\n",
    "                                \"scores\": torch.stack(\n",
    "                                    [hypo[\"score\"] for hypo in hypos]\n",
    "                                ),\n",
    "                                \"score\": torch.stack(\n",
    "                                    [\n",
    "                                        hypo[\"score\"]\n",
    "                                        * hypo[\"len\"]\n",
    "                                        / (hypo[\"len\"] ** marginalize_lenpen)\n",
    "                                        for hypo in hypos\n",
    "                                    ]\n",
    "                                ).logsumexp(-1),\n",
    "                            }\n",
    "                            for _id, hypos in outputs_dict.items()\n",
    "                        ],\n",
    "                        key=lambda x: x[\"score\"],\n",
    "                        reverse=True,\n",
    "                    )\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def generate(self, *args, **kwargs) -> List[List[Dict[str, torch.Tensor]]]:\n",
    "        return super(BARTHubInterface, self).generate(*args, **kwargs)\n",
    "\n",
    "    def encode(self, sentence) -> torch.LongTensor:\n",
    "        tokens = super(BARTHubInterface, self).encode(sentence)\n",
    "        tokens[\n",
    "            tokens >= len(self.task.target_dictionary)\n",
    "        ] = self.task.target_dictionary.unk_index\n",
    "        if tokens[0] != self.task.target_dictionary.bos_index:\n",
    "            return torch.cat(\n",
    "                (torch.tensor([self.task.target_dictionary.bos_index]), tokens)\n",
    "            )\n",
    "        else:\n",
    "            return tokens\n",
    "\n",
    "    \n",
    "class GENRE(BARTModel):\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_name_or_path,\n",
    "        checkpoint_file=\"model.pt\",\n",
    "        data_name_or_path=\".\",\n",
    "        bpe=\"gpt2\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        from fairseq import hub_utils\n",
    "\n",
    "        x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=cls.hub_models(),\n",
    "            bpe=bpe,\n",
    "            load_checkpoint_heads=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return GENREHubInterface(x[\"args\"], x[\"task\"], x[\"models\"][0])\n",
    "\n",
    "\n",
    "class mGENRE(BARTModel):\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_name_or_path,\n",
    "        sentencepiece_model=\"spm_256000.model\",\n",
    "        checkpoint_file=\"model.pt\",\n",
    "        data_name_or_path=\".\",\n",
    "        bpe=\"sentencepiece\",\n",
    "        layernorm_embedding=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        from fairseq import hub_utils\n",
    "\n",
    "        x = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=cls.hub_models(),\n",
    "            bpe=bpe,\n",
    "            load_checkpoint_heads=True,\n",
    "            sentencepiece_model=os.path.join(model_name_or_path, sentencepiece_model),\n",
    "            **kwargs,\n",
    "        )\n",
    "        \n",
    "        return GENREHubInterface(x[\"args\"], x[\"task\"], x[\"models\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of GENRE.genre.fairseq_model failed: Traceback (most recent call last):\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 300, in update_instances\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/home/petrakov/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 300, in <genexpr>\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL/fairseq/fairseq\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir/fairseq/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Facebook, Inc. and its affiliates.\r\n",
      "#\r\n",
      "# This source code is licensed under the MIT license found in the\r\n",
      "# LICENSE file in the root directory of this source tree.\r\n",
      "\r\n",
      "import ast\r\n",
      "import collections\r\n",
      "import contextlib\r\n",
      "import logging\r\n",
      "import os\r\n",
      "import re\r\n",
      "import traceback\r\n",
      "from collections import OrderedDict\r\n",
      "from typing import Any, Dict, Optional, Union\r\n",
      "\r\n",
      "import torch\r\n",
      "from fairseq.dataclass.configs import CheckpointConfig, FairseqConfig\r\n",
      "from fairseq.dataclass.utils import (\r\n",
      "    convert_namespace_to_omegaconf,\r\n",
      "    overwrite_args_by_name,\r\n",
      ")\r\n",
      "from fairseq.file_io import PathManager\r\n",
      "from fairseq.models import FairseqDecoder, FairseqEncoder\r\n",
      "from omegaconf import Container, DictConfig, open_dict, OmegaConf\r\n",
      "\r\n",
      "\r\n",
      "logger = logging.getLogger(__name__)\r\n",
      "\r\n",
      "\r\n",
      "def save_checkpoint(cfg: CheckpointConfig, trainer, epoch_itr, val_loss):\r\n",
      "    from fairseq import meters\r\n",
      "\r\n",
      "    # only one worker should attempt to create the required dir\r\n",
      "    if cfg.distributed_rank == 0:\r\n",
      "        os.makedirs(cfg.save_dir, exist_ok=True)\r\n",
      "\r\n",
      "    prev_best = getattr(save_checkpoint, \"best\", val_loss)\r\n",
      "    if val_loss is not None:\r\n",
      "        best_function = max if cfg.maximize_best_checkpoint_metric else min\r\n",
      "        save_checkpoint.best = best_function(val_loss, prev_best)\r\n",
      "\r\n",
      "    if cfg.no_save:\r\n",
      "        return\r\n",
      "\r\n",
      "    trainer.consolidate_optimizer()\r\n",
      "\r\n",
      "    if not trainer.is_data_parallel_master:\r\n",
      "        return\r\n",
      "\r\n",
      "    write_timer = meters.StopwatchMeter()\r\n",
      "    write_timer.start()\r\n",
      "\r\n",
      "    epoch = epoch_itr.epoch\r\n",
      "    end_of_epoch = epoch_itr.end_of_epoch()\r\n",
      "    updates = trainer.get_num_updates()\r\n",
      "\r\n",
      "    logger.info(f\"Preparing to save checkpoint for epoch {epoch} @ {updates} updates\")\r\n",
      "\r\n",
      "    def is_better(a, b):\r\n",
      "        return a >= b if cfg.maximize_best_checkpoint_metric else a <= b\r\n",
      "\r\n",
      "    suffix = cfg.checkpoint_suffix or \"\"\r\n",
      "    checkpoint_conds = collections.OrderedDict()\r\n",
      "    checkpoint_conds[\"checkpoint{}{}.pt\".format(epoch, suffix)] = (\r\n",
      "        end_of_epoch and not cfg.no_epoch_checkpoints and epoch % cfg.save_interval == 0\r\n",
      "    )\r\n",
      "    checkpoint_conds[\"checkpoint_{}_{}{}.pt\".format(epoch, updates, suffix)] = (\r\n",
      "        not end_of_epoch\r\n",
      "        and cfg.save_interval_updates > 0\r\n",
      "        and updates % cfg.save_interval_updates == 0\r\n",
      "    )\r\n",
      "    checkpoint_conds[\"checkpoint_best{}.pt\".format(suffix)] = val_loss is not None and (\r\n",
      "        not hasattr(save_checkpoint, \"best\")\r\n",
      "        or is_better(val_loss, save_checkpoint.best)\r\n",
      "    )\r\n",
      "    if val_loss is not None and cfg.keep_best_checkpoints > 0:\r\n",
      "        checkpoint_conds[\r\n",
      "            \"checkpoint.best_{}_{:.2f}.pt\".format(cfg.best_checkpoint_metric, val_loss)\r\n",
      "        ] = not hasattr(save_checkpoint, \"best\") or is_better(\r\n",
      "            val_loss, save_checkpoint.best\r\n",
      "        )\r\n",
      "    checkpoint_conds[\r\n",
      "        \"checkpoint_last{}.pt\".format(suffix)\r\n",
      "    ] = not cfg.no_last_checkpoints\r\n",
      "\r\n",
      "    extra_state = {\"train_iterator\": epoch_itr.state_dict(), \"val_loss\": val_loss}\r\n",
      "    if hasattr(save_checkpoint, \"best\"):\r\n",
      "        extra_state.update({\"best\": save_checkpoint.best})\r\n",
      "\r\n",
      "    checkpoints = [\r\n",
      "        os.path.join(cfg.save_dir, fn) for fn, cond in checkpoint_conds.items() if cond\r\n",
      "    ]\r\n",
      "    if len(checkpoints) > 0:\r\n",
      "        trainer.save_checkpoint(checkpoints[0], extra_state)\r\n",
      "        for cp in checkpoints[1:]:\r\n",
      "            if cfg.write_checkpoints_asynchronously:\r\n",
      "                # TODO[ioPath]: Need to implement a delayed asynchronous\r\n",
      "                # file copying/moving feature.\r\n",
      "                logger.warning(\r\n",
      "                    f\"ioPath is not copying {checkpoints[0]} to {cp} \"\r\n",
      "                    \"since async write mode is on.\"\r\n",
      "                )\r\n",
      "            else:\r\n",
      "                assert PathManager.copy(\r\n",
      "                    checkpoints[0], cp, overwrite=True\r\n",
      "                ), f\"Failed to copy {checkpoints[0]} to {cp}\"\r\n",
      "\r\n",
      "        write_timer.stop()\r\n",
      "        logger.info(\r\n",
      "            \"Saved checkpoint {} (epoch {} @ {} updates, score {}) (writing took {} seconds)\".format(\r\n",
      "                checkpoints[0], epoch, updates, val_loss, write_timer.sum\r\n",
      "            )\r\n",
      "        )\r\n",
      "\r\n",
      "    if not end_of_epoch and cfg.keep_interval_updates > 0:\r\n",
      "        # remove old checkpoints; checkpoints are sorted in descending order\r\n",
      "        checkpoints = checkpoint_paths(\r\n",
      "            cfg.save_dir, pattern=r\"checkpoint_\\d+_(\\d+)\\.pt\"\r\n",
      "        )\r\n",
      "        for old_chk in checkpoints[cfg.keep_interval_updates :]:\r\n",
      "            if os.path.lexists(old_chk):\r\n",
      "                os.remove(old_chk)\r\n",
      "\r\n",
      "    if cfg.keep_last_epochs > 0:\r\n",
      "        # remove old epoch checkpoints; checkpoints are sorted in descending order\r\n",
      "        checkpoints = checkpoint_paths(cfg.save_dir, pattern=r\"checkpoint(\\d+)\\.pt\")\r\n",
      "        for old_chk in checkpoints[cfg.keep_last_epochs :]:\r\n",
      "            if os.path.lexists(old_chk):\r\n",
      "                os.remove(old_chk)\r\n",
      "\r\n",
      "    if cfg.keep_best_checkpoints > 0:\r\n",
      "        # only keep the best N checkpoints according to validation metric\r\n",
      "        checkpoints = checkpoint_paths(\r\n",
      "            cfg.save_dir,\r\n",
      "            pattern=r\"checkpoint\\.best_{}_(\\d+\\.?\\d*)\\.pt\".format(\r\n",
      "                cfg.best_checkpoint_metric\r\n",
      "            ),\r\n",
      "        )\r\n",
      "        if not cfg.maximize_best_checkpoint_metric:\r\n",
      "            checkpoints = checkpoints[::-1]\r\n",
      "        for old_chk in checkpoints[cfg.keep_best_checkpoints :]:\r\n",
      "            if os.path.lexists(old_chk):\r\n",
      "                os.remove(old_chk)\r\n",
      "\r\n",
      "\r\n",
      "def load_checkpoint(cfg: CheckpointConfig, trainer, **passthrough_args):\r\n",
      "    \"\"\"\r\n",
      "    Load a checkpoint and restore the training iterator.\r\n",
      "\r\n",
      "    *passthrough_args* will be passed through to\r\n",
      "    ``trainer.get_train_iterator``.\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    reset_optimizer = cfg.reset_optimizer\r\n",
      "    reset_lr_scheduler = cfg.reset_lr_scheduler\r\n",
      "    optimizer_overrides = ast.literal_eval(cfg.optimizer_overrides)\r\n",
      "    reset_meters = cfg.reset_meters\r\n",
      "    reset_dataloader = cfg.reset_dataloader\r\n",
      "\r\n",
      "    if cfg.finetune_from_model is not None and (\r\n",
      "        reset_optimizer or reset_lr_scheduler or reset_meters or reset_dataloader\r\n",
      "    ):\r\n",
      "        raise ValueError(\r\n",
      "            \"--finetune-from-model can not be set together with either --reset-optimizer\"\r\n",
      "            \" or reset_lr_scheduler or reset_meters or reset_dataloader\"\r\n",
      "        )\r\n",
      "\r\n",
      "    suffix = cfg.checkpoint_suffix\r\n",
      "    if (\r\n",
      "        cfg.restore_file == \"checkpoint_last.pt\"\r\n",
      "    ):  # default value of restore_file is 'checkpoint_last.pt'\r\n",
      "        checkpoint_path = os.path.join(\r\n",
      "            cfg.save_dir, \"checkpoint_last{}.pt\".format(suffix)\r\n",
      "        )\r\n",
      "        first_launch = not PathManager.exists(checkpoint_path)\r\n",
      "        if cfg.finetune_from_model is not None and first_launch:\r\n",
      "            # if there is no last checkpoint to restore, start the finetune from pretrained model\r\n",
      "            # else just use usual logic to load checkpoint, e.g. restart from last checkpoint and etc.\r\n",
      "            if PathManager.exists(cfg.finetune_from_model):\r\n",
      "                checkpoint_path = cfg.finetune_from_model\r\n",
      "                reset_optimizer = True\r\n",
      "                reset_lr_scheduler = True\r\n",
      "                reset_meters = True\r\n",
      "                reset_dataloader = True\r\n",
      "                logger.info(\r\n",
      "                    f\"loading pretrained model from {checkpoint_path}: \"\r\n",
      "                    \"optimizer, lr scheduler, meters, dataloader will be reset\"\r\n",
      "                )\r\n",
      "            else:\r\n",
      "                raise ValueError(\r\n",
      "                    f\"--funetune-from-model {cfg.finetune_from_model} does not exist\"\r\n",
      "                )\r\n",
      "    elif cfg.model_parallel_size > 1:\r\n",
      "        checkpoint_path = cfg.restore_file.replace(\".pt\", suffix + \".pt\")\r\n",
      "    else:\r\n",
      "        checkpoint_path = cfg.restore_file\r\n",
      "\r\n",
      "    if cfg.restore_file != \"checkpoint_last.pt\" and cfg.finetune_from_model:\r\n",
      "        raise ValueError(\r\n",
      "            \"--finetune-from-model and --restore-file (non-default value) \"\r\n",
      "            \"can not be specified together: \" + str(cfg)\r\n",
      "        )\r\n",
      "\r\n",
      "    extra_state = trainer.load_checkpoint(\r\n",
      "        checkpoint_path,\r\n",
      "        reset_optimizer,\r\n",
      "        reset_lr_scheduler,\r\n",
      "        optimizer_overrides,\r\n",
      "        reset_meters=reset_meters,\r\n",
      "    )\r\n",
      "\r\n",
      "    if (\r\n",
      "        extra_state is not None\r\n",
      "        and \"best\" in extra_state\r\n",
      "        and not reset_optimizer\r\n",
      "        and not reset_meters\r\n",
      "    ):\r\n",
      "        save_checkpoint.best = extra_state[\"best\"]\r\n",
      "\r\n",
      "    if extra_state is not None and not reset_dataloader:\r\n",
      "        # restore iterator from checkpoint\r\n",
      "        itr_state = extra_state[\"train_iterator\"]\r\n",
      "        epoch_itr = trainer.get_train_iterator(\r\n",
      "            epoch=itr_state[\"epoch\"], load_dataset=True, **passthrough_args\r\n",
      "        )\r\n",
      "        epoch_itr.load_state_dict(itr_state)\r\n",
      "    else:\r\n",
      "        epoch_itr = trainer.get_train_iterator(\r\n",
      "            epoch=1, load_dataset=True, **passthrough_args\r\n",
      "        )\r\n",
      "\r\n",
      "    trainer.lr_step(epoch_itr.epoch)\r\n",
      "\r\n",
      "    return extra_state, epoch_itr\r\n",
      "\r\n",
      "\r\n",
      "def load_checkpoint_to_cpu(path, arg_overrides=None, load_on_all_ranks=False):\r\n",
      "    \"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\r\n",
      "\r\n",
      "    If doing single-GPU training or if the checkpoint is only being loaded by at\r\n",
      "    most one process on each node (current default behavior is for only rank 0\r\n",
      "    to read the checkpoint from disk), load_on_all_ranks should be False to\r\n",
      "    avoid errors from torch.distributed not having been initialized or\r\n",
      "    torch.distributed.barrier() hanging.\r\n",
      "\r\n",
      "    If all processes on each node may be loading the checkpoint\r\n",
      "    simultaneously, load_on_all_ranks should be set to True to avoid I/O\r\n",
      "    conflicts.\r\n",
      "\r\n",
      "    There's currently no support for > 1 but < all processes loading the\r\n",
      "    checkpoint on each node.\r\n",
      "    \"\"\"\r\n",
      "    local_path = PathManager.get_local_path(path)\r\n",
      "    # The locally cached file returned by get_local_path() may be stale for\r\n",
      "    # remote files that are periodically updated/overwritten (ex:\r\n",
      "    # checkpoint_last.pt) - so we remove the local copy, sync across processes\r\n",
      "    # (if needed), and then download a fresh copy.\r\n",
      "    if local_path != path and PathManager.path_requires_pathmanager(path):\r\n",
      "        try:\r\n",
      "            os.remove(local_path)\r\n",
      "        except FileNotFoundError:\r\n",
      "            # With potentially multiple processes removing the same file, the\r\n",
      "            # file being missing is benign (missing_ok isn't available until\r\n",
      "            # Python 3.8).\r\n",
      "            pass\r\n",
      "        if load_on_all_ranks:\r\n",
      "            torch.distributed.barrier()\r\n",
      "        local_path = PathManager.get_local_path(path)\r\n",
      "\r\n",
      "    with open(local_path, \"rb\") as f:\r\n",
      "        state = torch.load(f, map_location=torch.device(\"cpu\"))\r\n",
      "\r\n",
      "    if \"args\" in state and state[\"args\"] is not None and arg_overrides is not None:\r\n",
      "        args = state[\"args\"]\r\n",
      "        for arg_name, arg_val in arg_overrides.items():\r\n",
      "            setattr(args, arg_name, arg_val)\r\n",
      "\r\n",
      "    if \"cfg\" in state and state[\"cfg\"] is not None:\r\n",
      "\r\n",
      "        # hack to be able to set Namespace in dict config. this should be removed when we update to newer\r\n",
      "        # omegaconf version that supports object flags, or when we migrate all existing models\r\n",
      "        from omegaconf import _utils\r\n",
      "\r\n",
      "        old_primitive = _utils.is_primitive_type\r\n",
      "        _utils.is_primitive_type = lambda _: True\r\n",
      "\r\n",
      "        state[\"cfg\"] = OmegaConf.create(state[\"cfg\"])\r\n",
      "\r\n",
      "        _utils.is_primitive_type = old_primitive\r\n",
      "        OmegaConf.set_struct(state[\"cfg\"], True)\r\n",
      "\r\n",
      "        if arg_overrides is not None:\r\n",
      "            overwrite_args_by_name(state[\"cfg\"], arg_overrides)\r\n",
      "\r\n",
      "    state = _upgrade_state_dict(state)\r\n",
      "    return state\r\n",
      "\r\n",
      "\r\n",
      "def load_model_ensemble(\r\n",
      "    filenames,\r\n",
      "    arg_overrides: Optional[Dict[str, Any]] = None,\r\n",
      "    task=None,\r\n",
      "    strict=True,\r\n",
      "    suffix=\"\",\r\n",
      "    num_shards=1,\r\n",
      "    state=None,\r\n",
      "):\r\n",
      "    \"\"\"Loads an ensemble of models.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        filenames (List[str]): checkpoint files to load\r\n",
      "        arg_overrides (Dict[str,Any], optional): override model args that\r\n",
      "            were used during model training\r\n",
      "        task (fairseq.tasks.FairseqTask, optional): task to use for loading\r\n",
      "    \"\"\"\r\n",
      "    assert not (\r\n",
      "        strict and num_shards > 1\r\n",
      "    ), \"Cannot load state dict with strict=True and checkpoint shards > 1\"\r\n",
      "    ensemble, args, _task = load_model_ensemble_and_task(\r\n",
      "        filenames,\r\n",
      "        arg_overrides,\r\n",
      "        task,\r\n",
      "        strict,\r\n",
      "        suffix,\r\n",
      "        num_shards,\r\n",
      "        state,\r\n",
      "    )\r\n",
      "    return ensemble, args\r\n",
      "\r\n",
      "\r\n",
      "def load_model_ensemble_and_task(\r\n",
      "    filenames,\r\n",
      "    arg_overrides: Optional[Dict[str, Any]] = None,\r\n",
      "    task=None,\r\n",
      "    strict=True,\r\n",
      "    suffix=\"\",\r\n",
      "    num_shards=1,\r\n",
      "    state=None,\r\n",
      "):\r\n",
      "    assert state is None or len(filenames) == 1\r\n",
      "\r\n",
      "    from fairseq import tasks\r\n",
      "\r\n",
      "    assert not (\r\n",
      "        strict and num_shards > 1\r\n",
      "    ), \"Cannot load state dict with strict=True and checkpoint shards > 1\"\r\n",
      "    ensemble = []\r\n",
      "    cfg = None\r\n",
      "    for filename in filenames:\r\n",
      "        orig_filename = filename\r\n",
      "        assert num_shards > 0\r\n",
      "        for shard_idx in range(num_shards):\r\n",
      "            if num_shards == 1:\r\n",
      "                filename = filename.replace(\".pt\", suffix + \".pt\")\r\n",
      "            else:\r\n",
      "                filename = orig_filename[:-3] + f\"_part{shard_idx}.pt\"\r\n",
      "\r\n",
      "            if not PathManager.exists(filename):\r\n",
      "                raise IOError(\"Model file not found: {}\".format(filename))\r\n",
      "            if state is None:\r\n",
      "                state = load_checkpoint_to_cpu(filename, arg_overrides)\r\n",
      "            if \"args\" in state and state[\"args\"] is not None:\r\n",
      "                cfg = convert_namespace_to_omegaconf(state[\"args\"])\r\n",
      "            elif \"cfg\" in state and state[\"cfg\"] is not None:\r\n",
      "                cfg = state[\"cfg\"]\r\n",
      "            else:\r\n",
      "                raise RuntimeError(\r\n",
      "                    f\"Neither args nor cfg exist in state keys = {state.keys()}\"\r\n",
      "                )\r\n",
      "\r\n",
      "            if task is None:\r\n",
      "                task = tasks.setup_task(cfg.task)\r\n",
      "\r\n",
      "            if \"task_state\" in state:\r\n",
      "                task.load_state_dict(state[\"task_state\"])\r\n",
      "\r\n",
      "            # build model for ensemble\r\n",
      "            model = task.build_model(cfg.model)\r\n",
      "\r\n",
      "            model.load_state_dict(state[\"model\"], strict=strict, model_cfg=cfg.model)\r\n",
      "\r\n",
      "            # reset state so it gets loaded for the next model in ensemble\r\n",
      "            state = None\r\n",
      "\r\n",
      "        ensemble.append(model)\r\n",
      "    return ensemble, cfg, task\r\n",
      "\r\n",
      "\r\n",
      "def checkpoint_paths(path, pattern=r\"checkpoint(\\d+)\\.pt\"):\r\n",
      "    \"\"\"Retrieves all checkpoints found in `path` directory.\r\n",
      "\r\n",
      "    Checkpoints are identified by matching filename to the specified pattern. If\r\n",
      "    the pattern contains groups, the result will be sorted by the first group in\r\n",
      "    descending order.\r\n",
      "    \"\"\"\r\n",
      "    pt_regexp = re.compile(pattern)\r\n",
      "    files = os.listdir(path)\r\n",
      "\r\n",
      "    entries = []\r\n",
      "    for i, f in enumerate(files):\r\n",
      "        m = pt_regexp.fullmatch(f)\r\n",
      "        if m is not None:\r\n",
      "            idx = float(m.group(1)) if len(m.groups()) > 0 else i\r\n",
      "            entries.append((idx, m.group(0)))\r\n",
      "    return [os.path.join(path, x[1]) for x in sorted(entries, reverse=True)]\r\n",
      "\r\n",
      "\r\n",
      "def torch_persistent_save(cfg: CheckpointConfig, obj, filename):\r\n",
      "    if cfg.write_checkpoints_asynchronously:\r\n",
      "        with PathManager.opena(filename, \"wb\") as f:\r\n",
      "            _torch_persistent_save(obj, f)\r\n",
      "    else:\r\n",
      "        if PathManager.supports_rename(filename):\r\n",
      "            # do atomic save\r\n",
      "            with PathManager.open(filename + \".tmp\", \"wb\") as f:\r\n",
      "                _torch_persistent_save(obj, f)\r\n",
      "            PathManager.rename(filename + \".tmp\", filename)\r\n",
      "        else:\r\n",
      "            # fallback to non-atomic save\r\n",
      "            with PathManager.open(filename, \"wb\") as f:\r\n",
      "                _torch_persistent_save(obj, f)\r\n",
      "\r\n",
      "\r\n",
      "def _torch_persistent_save(obj, f):\r\n",
      "    if isinstance(f, str):\r\n",
      "        with PathManager.open(f, \"wb\") as h:\r\n",
      "            torch_persistent_save(obj, h)\r\n",
      "        return\r\n",
      "    for i in range(3):\r\n",
      "        try:\r\n",
      "            return torch.save(obj, f)\r\n",
      "        except Exception:\r\n",
      "            if i == 2:\r\n",
      "                logger.error(traceback.format_exc())\r\n",
      "\r\n",
      "\r\n",
      "def save_state(\r\n",
      "    filename,\r\n",
      "    cfg: FairseqConfig,\r\n",
      "    model_state_dict,\r\n",
      "    criterion,\r\n",
      "    optimizer,\r\n",
      "    lr_scheduler,\r\n",
      "    num_updates,\r\n",
      "    optim_history=None,\r\n",
      "    extra_state=None,\r\n",
      "    task=None,\r\n",
      "    **kwargs,\r\n",
      "):\r\n",
      "    from fairseq import utils\r\n",
      "\r\n",
      "    if optim_history is None:\r\n",
      "        optim_history = []\r\n",
      "    if extra_state is None:\r\n",
      "        extra_state = {}\r\n",
      "    state_dict = {\r\n",
      "        \"cfg\": OmegaConf.to_container(cfg) if OmegaConf.is_config(cfg) else cfg,\r\n",
      "        \"args\": kwargs.get(\"args\", None),\r\n",
      "        \"model\": model_state_dict or {},\r\n",
      "        \"optimizer_history\": optim_history\r\n",
      "        + [\r\n",
      "            {\r\n",
      "                \"criterion_name\": criterion.__class__.__name__,\r\n",
      "                \"optimizer_name\": optimizer.__class__.__name__,\r\n",
      "                \"lr_scheduler_state\": lr_scheduler.state_dict(),\r\n",
      "                \"num_updates\": num_updates,\r\n",
      "            }\r\n",
      "        ],\r\n",
      "        \"extra_state\": extra_state,\r\n",
      "        \"task_state\": task.state_dict() if task is not None else {},\r\n",
      "    }\r\n",
      "    if utils.has_parameters(criterion):\r\n",
      "        state_dict[\"criterion\"] = criterion.state_dict()\r\n",
      "\r\n",
      "    if cfg is None:\r\n",
      "        cfg = state_dict[\"args\"]\r\n",
      "        assert cfg is not None, \"must provide cfg or args\"\r\n",
      "\r\n",
      "    if isinstance(cfg, DictConfig):\r\n",
      "        no_save_optimizer_state = cfg.checkpoint.no_save_optimizer_state\r\n",
      "    else:\r\n",
      "        no_save_optimizer_state = cfg.no_save_optimizer_state\r\n",
      "    if not no_save_optimizer_state:\r\n",
      "        state_dict[\"last_optimizer_state\"] = optimizer.state_dict()\r\n",
      "\r\n",
      "    # keep everything on CPU\r\n",
      "    state_dict = utils.move_to_cpu(state_dict)\r\n",
      "\r\n",
      "    torch_persistent_save(cfg.checkpoint, state_dict, filename)\r\n",
      "\r\n",
      "\r\n",
      "def _upgrade_state_dict(state):\r\n",
      "    \"\"\"Helper for upgrading old model checkpoints.\"\"\"\r\n",
      "    from fairseq import models, registry, tasks\r\n",
      "\r\n",
      "    # add optimizer_history\r\n",
      "    if \"optimizer_history\" not in state:\r\n",
      "        state[\"optimizer_history\"] = [\r\n",
      "            {\"criterion_name\": \"CrossEntropyCriterion\", \"best_loss\": state[\"best_loss\"]}\r\n",
      "        ]\r\n",
      "        state[\"last_optimizer_state\"] = state[\"optimizer\"]\r\n",
      "        del state[\"optimizer\"]\r\n",
      "        del state[\"best_loss\"]\r\n",
      "    # move extra_state into sub-dictionary\r\n",
      "    if \"epoch\" in state and \"extra_state\" not in state:\r\n",
      "        state[\"extra_state\"] = {\r\n",
      "            \"epoch\": state[\"epoch\"],\r\n",
      "            \"batch_offset\": state[\"batch_offset\"],\r\n",
      "            \"val_loss\": state[\"val_loss\"],\r\n",
      "        }\r\n",
      "        del state[\"epoch\"]\r\n",
      "        del state[\"batch_offset\"]\r\n",
      "        del state[\"val_loss\"]\r\n",
      "    # reduce optimizer history's memory usage (only keep the last state)\r\n",
      "    if \"optimizer\" in state[\"optimizer_history\"][-1]:\r\n",
      "        state[\"last_optimizer_state\"] = state[\"optimizer_history\"][-1][\"optimizer\"]\r\n",
      "        for optim_hist in state[\"optimizer_history\"]:\r\n",
      "            del optim_hist[\"optimizer\"]\r\n",
      "    # record the optimizer class name\r\n",
      "    if \"optimizer_name\" not in state[\"optimizer_history\"][-1]:\r\n",
      "        state[\"optimizer_history\"][-1][\"optimizer_name\"] = \"FairseqNAG\"\r\n",
      "    # move best_loss into lr_scheduler_state\r\n",
      "    if \"lr_scheduler_state\" not in state[\"optimizer_history\"][-1]:\r\n",
      "        state[\"optimizer_history\"][-1][\"lr_scheduler_state\"] = {\r\n",
      "            \"best\": state[\"optimizer_history\"][-1][\"best_loss\"]\r\n",
      "        }\r\n",
      "        del state[\"optimizer_history\"][-1][\"best_loss\"]\r\n",
      "    # keep track of number of updates\r\n",
      "    if \"num_updates\" not in state[\"optimizer_history\"][-1]:\r\n",
      "        state[\"optimizer_history\"][-1][\"num_updates\"] = 0\r\n",
      "    # old model checkpoints may not have separate source/target positions\r\n",
      "    if hasattr(state[\"args\"], \"max_positions\") and not hasattr(\r\n",
      "        state[\"args\"], \"max_source_positions\"\r\n",
      "    ):\r\n",
      "        state[\"args\"].max_source_positions = state[\"args\"].max_positions\r\n",
      "        state[\"args\"].max_target_positions = state[\"args\"].max_positions\r\n",
      "    # use stateful training data iterator\r\n",
      "    if \"train_iterator\" not in state[\"extra_state\"]:\r\n",
      "        state[\"extra_state\"][\"train_iterator\"] = {\r\n",
      "            \"epoch\": state[\"extra_state\"][\"epoch\"],\r\n",
      "            \"iterations_in_epoch\": state[\"extra_state\"].get(\"batch_offset\", 0),\r\n",
      "        }\r\n",
      "\r\n",
      "    # backward compatibility, cfg updates\r\n",
      "    if \"args\" in state and state[\"args\"] is not None:\r\n",
      "        # default to translation task\r\n",
      "        if not hasattr(state[\"args\"], \"task\"):\r\n",
      "            state[\"args\"].task = \"translation\"\r\n",
      "        # --raw-text and --lazy-load are deprecated\r\n",
      "        if getattr(state[\"args\"], \"raw_text\", False):\r\n",
      "            state[\"args\"].dataset_impl = \"raw\"\r\n",
      "        elif getattr(state[\"args\"], \"lazy_load\", False):\r\n",
      "            state[\"args\"].dataset_impl = \"lazy\"\r\n",
      "        # epochs start at 1\r\n",
      "        if state[\"extra_state\"][\"train_iterator\"] is not None:\r\n",
      "            state[\"extra_state\"][\"train_iterator\"][\"epoch\"] = max(\r\n",
      "                state[\"extra_state\"][\"train_iterator\"].get(\"epoch\", 1), 1\r\n",
      "            )\r\n",
      "        # --remove-bpe ==> --postprocess\r\n",
      "        if hasattr(state[\"args\"], \"remove_bpe\"):\r\n",
      "            state[\"args\"].post_process = state[\"args\"].remove_bpe\r\n",
      "        # --min-lr ==> --stop-min-lr\r\n",
      "        if hasattr(state[\"args\"], \"min_lr\"):\r\n",
      "            state[\"args\"].stop_min_lr = state[\"args\"].min_lr\r\n",
      "            del state[\"args\"].min_lr\r\n",
      "        # binary_cross_entropy => wav2vec criterion\r\n",
      "        if (\r\n",
      "            hasattr(state[\"args\"], \"criterion\")\r\n",
      "            and state[\"args\"].criterion == \"binary_cross_entropy\"\r\n",
      "        ):\r\n",
      "            state[\"args\"].criterion = \"wav2vec\"\r\n",
      "        # speech_pretraining => audio pretraining\r\n",
      "        if (\r\n",
      "            hasattr(state[\"args\"], \"task\")\r\n",
      "            and state[\"args\"].task == \"speech_pretraining\"\r\n",
      "        ):\r\n",
      "            state[\"args\"].task = \"audio_pretraining\"\r\n",
      "        # audio_cpc => wav2vec\r\n",
      "        if hasattr(state[\"args\"], \"arch\") and state[\"args\"].arch == \"audio_cpc\":\r\n",
      "            state[\"args\"].arch = \"wav2vec\"\r\n",
      "        # convert legacy float learning rate to List[float]\r\n",
      "        if hasattr(state[\"args\"], \"lr\") and isinstance(state[\"args\"].lr, float):\r\n",
      "            state[\"args\"].lr = [state[\"args\"].lr]\r\n",
      "        # convert task data arg to a string instead of List[string]\r\n",
      "        if (\r\n",
      "            hasattr(state[\"args\"], \"data\")\r\n",
      "            and isinstance(state[\"args\"].data, list)\r\n",
      "            and len(state[\"args\"].data) > 0\r\n",
      "        ):\r\n",
      "            state[\"args\"].data = state[\"args\"].data[0]\r\n",
      "\r\n",
      "        state[\"cfg\"] = convert_namespace_to_omegaconf(state[\"args\"])\r\n",
      "\r\n",
      "    if \"cfg\" in state and state[\"cfg\"] is not None:\r\n",
      "        cfg = state[\"cfg\"]\r\n",
      "        with open_dict(cfg):\r\n",
      "            # any upgrades for Hydra-based configs\r\n",
      "            if (\r\n",
      "                \"task\" in cfg\r\n",
      "                and \"eval_wer_config\" in cfg.task\r\n",
      "                and isinstance(cfg.task.eval_wer_config.print_alignment, bool)\r\n",
      "            ):\r\n",
      "                cfg.task.eval_wer_config.print_alignment = \"hard\"\r\n",
      "            if \"generation\" in cfg and isinstance(cfg.generation.print_alignment, bool):\r\n",
      "                cfg.generation.print_alignment = \"hard\"\r\n",
      "            if (\r\n",
      "                \"model\" in cfg\r\n",
      "                and \"w2v_args\" in cfg.model\r\n",
      "                and cfg.model.w2v_args is not None\r\n",
      "                and (\r\n",
      "                    hasattr(cfg.model.w2v_args, \"task\") or \"task\" in cfg.model.w2v_args\r\n",
      "                )\r\n",
      "                and isinstance(\r\n",
      "                    cfg.model.w2v_args.task.eval_wer_config.print_alignment, bool\r\n",
      "                )\r\n",
      "            ):\r\n",
      "                cfg.model.w2v_args.task.eval_wer_config.print_alignment = \"hard\"\r\n",
      "\r\n",
      "    return state\r\n",
      "\r\n",
      "\r\n",
      "def prune_state_dict(state_dict, model_cfg: Optional[DictConfig]):\r\n",
      "    \"\"\"Prune the given state_dict if desired for LayerDrop\r\n",
      "    (https://arxiv.org/abs/1909.11556).\r\n",
      "\r\n",
      "    Training with LayerDrop allows models to be robust to pruning at inference\r\n",
      "    time. This function prunes state_dict to allow smaller models to be loaded\r\n",
      "    from a larger model and re-maps the existing state_dict for this to occur.\r\n",
      "\r\n",
      "    It's called by functions that load models from checkpoints and does not\r\n",
      "    need to be called directly.\r\n",
      "    \"\"\"\r\n",
      "    arch = None\r\n",
      "    if model_cfg is not None:\r\n",
      "        arch = (\r\n",
      "            model_cfg._name\r\n",
      "            if isinstance(model_cfg, DictConfig)\r\n",
      "            else getattr(model_cfg, \"arch\", None)\r\n",
      "        )\r\n",
      "\r\n",
      "    if not model_cfg or arch is None or arch == \"ptt_transformer\":\r\n",
      "        # args should not be none, but don't crash if it is.\r\n",
      "        return state_dict\r\n",
      "\r\n",
      "    encoder_layers_to_keep = getattr(model_cfg, \"encoder_layers_to_keep\", None)\r\n",
      "    decoder_layers_to_keep = getattr(model_cfg, \"decoder_layers_to_keep\", None)\r\n",
      "\r\n",
      "    if not encoder_layers_to_keep and not decoder_layers_to_keep:\r\n",
      "        return state_dict\r\n",
      "\r\n",
      "    # apply pruning\r\n",
      "    logger.info(\r\n",
      "        \"Pruning model to specified layer configuration - this works best if the model was trained with LayerDrop\"\r\n",
      "    )\r\n",
      "\r\n",
      "    def create_pruning_pass(layers_to_keep, layer_name):\r\n",
      "        keep_layers = sorted(\r\n",
      "            int(layer_string) for layer_string in layers_to_keep.split(\",\")\r\n",
      "        )\r\n",
      "        mapping_dict = {}\r\n",
      "        for i in range(len(keep_layers)):\r\n",
      "            mapping_dict[str(keep_layers[i])] = str(i)\r\n",
      "\r\n",
      "        regex = re.compile(r\"^{layer}.*\\.layers\\.(\\d+)\".format(layer=layer_name))\r\n",
      "        return {\"substitution_regex\": regex, \"mapping_dict\": mapping_dict}\r\n",
      "\r\n",
      "    pruning_passes = []\r\n",
      "    if encoder_layers_to_keep:\r\n",
      "        pruning_passes.append(create_pruning_pass(encoder_layers_to_keep, \"encoder\"))\r\n",
      "    if decoder_layers_to_keep:\r\n",
      "        pruning_passes.append(create_pruning_pass(decoder_layers_to_keep, \"decoder\"))\r\n",
      "\r\n",
      "    new_state_dict = {}\r\n",
      "    for layer_name in state_dict.keys():\r\n",
      "        match = re.search(r\"\\.layers\\.(\\d+)\\.\", layer_name)\r\n",
      "        # if layer has no number in it, it is a supporting layer, such as an\r\n",
      "        # embedding\r\n",
      "        if not match:\r\n",
      "            new_state_dict[layer_name] = state_dict[layer_name]\r\n",
      "            continue\r\n",
      "\r\n",
      "        # otherwise, layer should be pruned.\r\n",
      "        original_layer_number = match.group(1)\r\n",
      "        # figure out which mapping dict to replace from\r\n",
      "        for pruning_pass in pruning_passes:\r\n",
      "            if original_layer_number in pruning_pass[\"mapping_dict\"] and pruning_pass[\r\n",
      "                \"substitution_regex\"\r\n",
      "            ].search(layer_name):\r\n",
      "                new_layer_number = pruning_pass[\"mapping_dict\"][original_layer_number]\r\n",
      "                substitution_match = pruning_pass[\"substitution_regex\"].search(\r\n",
      "                    layer_name\r\n",
      "                )\r\n",
      "                new_state_key = (\r\n",
      "                    layer_name[: substitution_match.start(1)]\r\n",
      "                    + new_layer_number\r\n",
      "                    + layer_name[substitution_match.end(1) :]\r\n",
      "                )\r\n",
      "                new_state_dict[new_state_key] = state_dict[layer_name]\r\n",
      "\r\n",
      "    # Since layers are now pruned, *_layers_to_keep are no longer needed.\r\n",
      "    # This is more of \"It would make it work fix\" rather than a proper fix.\r\n",
      "    if isinstance(model_cfg, DictConfig):\r\n",
      "        context = open_dict(model_cfg)\r\n",
      "    else:\r\n",
      "        context = contextlib.ExitStack()\r\n",
      "    with context:\r\n",
      "        if hasattr(model_cfg, \"encoder_layers_to_keep\"):\r\n",
      "            model_cfg.encoder_layers_to_keep = None\r\n",
      "        if hasattr(model_cfg, \"decoder_layers_to_keep\"):\r\n",
      "            model_cfg.decoder_layers_to_keep = None\r\n",
      "\r\n",
      "    return new_state_dict\r\n",
      "\r\n",
      "\r\n",
      "def load_pretrained_component_from_model(\r\n",
      "    component: Union[FairseqEncoder, FairseqDecoder], checkpoint: str\r\n",
      "):\r\n",
      "    \"\"\"\r\n",
      "    Load a pretrained FairseqEncoder or FairseqDecoder from checkpoint into the\r\n",
      "    provided `component` object. If state_dict fails to load, there may be a\r\n",
      "    mismatch in the architecture of the corresponding `component` found in the\r\n",
      "    `checkpoint` file.\r\n",
      "    \"\"\"\r\n",
      "    if not PathManager.exists(checkpoint):\r\n",
      "        raise IOError(\"Model file not found: {}\".format(checkpoint))\r\n",
      "    state = load_checkpoint_to_cpu(checkpoint)\r\n",
      "    if isinstance(component, FairseqEncoder):\r\n",
      "        component_type = \"encoder\"\r\n",
      "    elif isinstance(component, FairseqDecoder):\r\n",
      "        component_type = \"decoder\"\r\n",
      "    else:\r\n",
      "        raise ValueError(\r\n",
      "            \"component to load must be either a FairseqEncoder or \"\r\n",
      "            \"FairseqDecoder. Loading other component types are not supported.\"\r\n",
      "        )\r\n",
      "    component_state_dict = OrderedDict()\r\n",
      "    for key in state[\"model\"].keys():\r\n",
      "        if key.startswith(component_type):\r\n",
      "            # encoder.input_layers.0.0.weight --> input_layers.0.0.weight\r\n",
      "            component_subkey = key[len(component_type) + 1 :]\r\n",
      "            component_state_dict[component_subkey] = state[\"model\"][key]\r\n",
      "    component.load_state_dict(component_state_dict, strict=True)\r\n",
      "    return component\r\n",
      "\r\n",
      "\r\n",
      "def verify_checkpoint_directory(save_dir: str) -> None:\r\n",
      "    if not os.path.exists(save_dir):\r\n",
      "        os.makedirs(save_dir, exist_ok=True)\r\n",
      "    temp_file_path = os.path.join(save_dir, \"dummy\")\r\n",
      "    try:\r\n",
      "        with open(temp_file_path, \"w\"):\r\n",
      "            pass\r\n",
      "    except OSError as e:\r\n",
      "        logger.warning(\r\n",
      "            \"Unable to access checkpoint save directory: {}\".format(save_dir)\r\n",
      "        )\r\n",
      "        raise e\r\n",
      "    else:\r\n",
      "        os.remove(temp_file_path)\r\n"
     ]
    }
   ],
   "source": [
    "%cat checkpoint_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting checkpoint_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile checkpoint_utils.py\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import ast\n",
    "import collections\n",
    "import contextlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import traceback\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Dict, Optional, Union\n",
    "\n",
    "import torch\n",
    "from fairseq.dataclass.configs import CheckpointConfig, FairseqConfig\n",
    "from fairseq.dataclass.utils import (\n",
    "    convert_namespace_to_omegaconf,\n",
    "    overwrite_args_by_name,\n",
    ")\n",
    "from fairseq.file_io import PathManager\n",
    "from fairseq.models import FairseqDecoder, FairseqEncoder\n",
    "from omegaconf import Container, DictConfig, open_dict, OmegaConf\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def save_checkpoint(cfg: CheckpointConfig, trainer, epoch_itr, val_loss):\n",
    "    from fairseq import meters\n",
    "\n",
    "    # only one worker should attempt to create the required dir\n",
    "    if cfg.distributed_rank == 0:\n",
    "        os.makedirs(cfg.save_dir, exist_ok=True)\n",
    "\n",
    "    prev_best = getattr(save_checkpoint, \"best\", val_loss)\n",
    "    if val_loss is not None:\n",
    "        best_function = max if cfg.maximize_best_checkpoint_metric else min\n",
    "        save_checkpoint.best = best_function(val_loss, prev_best)\n",
    "\n",
    "    if cfg.no_save:\n",
    "        return\n",
    "\n",
    "    trainer.consolidate_optimizer()\n",
    "\n",
    "    if not trainer.is_data_parallel_master:\n",
    "        return\n",
    "\n",
    "    write_timer = meters.StopwatchMeter()\n",
    "    write_timer.start()\n",
    "\n",
    "    epoch = epoch_itr.epoch\n",
    "    end_of_epoch = epoch_itr.end_of_epoch()\n",
    "    updates = trainer.get_num_updates()\n",
    "\n",
    "    logger.info(f\"Preparing to save checkpoint for epoch {epoch} @ {updates} updates\")\n",
    "\n",
    "    def is_better(a, b):\n",
    "        return a >= b if cfg.maximize_best_checkpoint_metric else a <= b\n",
    "\n",
    "    suffix = cfg.checkpoint_suffix or \"\"\n",
    "    checkpoint_conds = collections.OrderedDict()\n",
    "    checkpoint_conds[\"checkpoint{}{}.pt\".format(epoch, suffix)] = (\n",
    "        end_of_epoch and not cfg.no_epoch_checkpoints and epoch % cfg.save_interval == 0\n",
    "    )\n",
    "    checkpoint_conds[\"checkpoint_{}_{}{}.pt\".format(epoch, updates, suffix)] = (\n",
    "        not end_of_epoch\n",
    "        and cfg.save_interval_updates > 0\n",
    "        and updates % cfg.save_interval_updates == 0\n",
    "    )\n",
    "    checkpoint_conds[\"checkpoint_best{}.pt\".format(suffix)] = val_loss is not None and (\n",
    "        not hasattr(save_checkpoint, \"best\")\n",
    "        or is_better(val_loss, save_checkpoint.best)\n",
    "    )\n",
    "    if val_loss is not None and cfg.keep_best_checkpoints > 0:\n",
    "        checkpoint_conds[\n",
    "            \"checkpoint.best_{}_{:.2f}.pt\".format(cfg.best_checkpoint_metric, val_loss)\n",
    "        ] = not hasattr(save_checkpoint, \"best\") or is_better(\n",
    "            val_loss, save_checkpoint.best\n",
    "        )\n",
    "    checkpoint_conds[\n",
    "        \"checkpoint_last{}.pt\".format(suffix)\n",
    "    ] = not cfg.no_last_checkpoints\n",
    "\n",
    "    extra_state = {\"train_iterator\": epoch_itr.state_dict(), \"val_loss\": val_loss}\n",
    "    if hasattr(save_checkpoint, \"best\"):\n",
    "        extra_state.update({\"best\": save_checkpoint.best})\n",
    "\n",
    "    checkpoints = [\n",
    "        os.path.join(cfg.save_dir, fn) for fn, cond in checkpoint_conds.items() if cond\n",
    "    ]\n",
    "    if len(checkpoints) > 0:\n",
    "        trainer.save_checkpoint(checkpoints[0], extra_state)\n",
    "        for cp in checkpoints[1:]:\n",
    "            if cfg.write_checkpoints_asynchronously:\n",
    "                # TODO[ioPath]: Need to implement a delayed asynchronous\n",
    "                # file copying/moving feature.\n",
    "                logger.warning(\n",
    "                    f\"ioPath is not copying {checkpoints[0]} to {cp} \"\n",
    "                    \"since async write mode is on.\"\n",
    "                )\n",
    "            else:\n",
    "                assert PathManager.copy(\n",
    "                    checkpoints[0], cp, overwrite=True\n",
    "                ), f\"Failed to copy {checkpoints[0]} to {cp}\"\n",
    "\n",
    "        write_timer.stop()\n",
    "        logger.info(\n",
    "            \"Saved checkpoint {} (epoch {} @ {} updates, score {}) (writing took {} seconds)\".format(\n",
    "                checkpoints[0], epoch, updates, val_loss, write_timer.sum\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if not end_of_epoch and cfg.keep_interval_updates > 0:\n",
    "        # remove old checkpoints; checkpoints are sorted in descending order\n",
    "        checkpoints = checkpoint_paths(\n",
    "            cfg.save_dir, pattern=r\"checkpoint_\\d+_(\\d+)\\.pt\"\n",
    "        )\n",
    "        for old_chk in checkpoints[cfg.keep_interval_updates :]:\n",
    "            if os.path.lexists(old_chk):\n",
    "                os.remove(old_chk)\n",
    "\n",
    "    if cfg.keep_last_epochs > 0:\n",
    "        # remove old epoch checkpoints; checkpoints are sorted in descending order\n",
    "        checkpoints = checkpoint_paths(cfg.save_dir, pattern=r\"checkpoint(\\d+)\\.pt\")\n",
    "        for old_chk in checkpoints[cfg.keep_last_epochs :]:\n",
    "            if os.path.lexists(old_chk):\n",
    "                os.remove(old_chk)\n",
    "\n",
    "    if cfg.keep_best_checkpoints > 0:\n",
    "        # only keep the best N checkpoints according to validation metric\n",
    "        checkpoints = checkpoint_paths(\n",
    "            cfg.save_dir,\n",
    "            pattern=r\"checkpoint\\.best_{}_(\\d+\\.?\\d*)\\.pt\".format(\n",
    "                cfg.best_checkpoint_metric\n",
    "            ),\n",
    "        )\n",
    "        if not cfg.maximize_best_checkpoint_metric:\n",
    "            checkpoints = checkpoints[::-1]\n",
    "        for old_chk in checkpoints[cfg.keep_best_checkpoints :]:\n",
    "            if os.path.lexists(old_chk):\n",
    "                os.remove(old_chk)\n",
    "\n",
    "\n",
    "def load_checkpoint(cfg: CheckpointConfig, trainer, **passthrough_args):\n",
    "    \"\"\"\n",
    "    Load a checkpoint and restore the training iterator.\n",
    "\n",
    "    *passthrough_args* will be passed through to\n",
    "    ``trainer.get_train_iterator``.\n",
    "    \"\"\"\n",
    "\n",
    "    reset_optimizer = cfg.reset_optimizer\n",
    "    reset_lr_scheduler = cfg.reset_lr_scheduler\n",
    "    optimizer_overrides = ast.literal_eval(cfg.optimizer_overrides)\n",
    "    reset_meters = cfg.reset_meters\n",
    "    reset_dataloader = cfg.reset_dataloader\n",
    "\n",
    "    if cfg.finetune_from_model is not None and (\n",
    "        reset_optimizer or reset_lr_scheduler or reset_meters or reset_dataloader\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"--finetune-from-model can not be set together with either --reset-optimizer\"\n",
    "            \" or reset_lr_scheduler or reset_meters or reset_dataloader\"\n",
    "        )\n",
    "\n",
    "    suffix = cfg.checkpoint_suffix\n",
    "    if (\n",
    "        cfg.restore_file == \"checkpoint_last.pt\"\n",
    "    ):  # default value of restore_file is 'checkpoint_last.pt'\n",
    "        checkpoint_path = os.path.join(\n",
    "            cfg.save_dir, \"checkpoint_last{}.pt\".format(suffix)\n",
    "        )\n",
    "        first_launch = not PathManager.exists(checkpoint_path)\n",
    "        if cfg.finetune_from_model is not None and first_launch:\n",
    "            # if there is no last checkpoint to restore, start the finetune from pretrained model\n",
    "            # else just use usual logic to load checkpoint, e.g. restart from last checkpoint and etc.\n",
    "            if PathManager.exists(cfg.finetune_from_model):\n",
    "                checkpoint_path = cfg.finetune_from_model\n",
    "                reset_optimizer = True\n",
    "                reset_lr_scheduler = True\n",
    "                reset_meters = True\n",
    "                reset_dataloader = True\n",
    "                logger.info(\n",
    "                    f\"loading pretrained model from {checkpoint_path}: \"\n",
    "                    \"optimizer, lr scheduler, meters, dataloader will be reset\"\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"--funetune-from-model {cfg.finetune_from_model} does not exist\"\n",
    "                )\n",
    "    elif cfg.model_parallel_size > 1:\n",
    "        checkpoint_path = cfg.restore_file.replace(\".pt\", suffix + \".pt\")\n",
    "    else:\n",
    "        checkpoint_path = cfg.restore_file\n",
    "\n",
    "    if cfg.restore_file != \"checkpoint_last.pt\" and cfg.finetune_from_model:\n",
    "        raise ValueError(\n",
    "            \"--finetune-from-model and --restore-file (non-default value) \"\n",
    "            \"can not be specified together: \" + str(cfg)\n",
    "        )\n",
    "\n",
    "    extra_state = trainer.load_checkpoint(\n",
    "        checkpoint_path,\n",
    "        reset_optimizer,\n",
    "        reset_lr_scheduler,\n",
    "        optimizer_overrides,\n",
    "        reset_meters=reset_meters,\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        extra_state is not None\n",
    "        and \"best\" in extra_state\n",
    "        and not reset_optimizer\n",
    "        and not reset_meters\n",
    "    ):\n",
    "        save_checkpoint.best = extra_state[\"best\"]\n",
    "\n",
    "    if extra_state is not None and not reset_dataloader:\n",
    "        # restore iterator from checkpoint\n",
    "        itr_state = extra_state[\"train_iterator\"]\n",
    "        epoch_itr = trainer.get_train_iterator(\n",
    "            epoch=itr_state[\"epoch\"], load_dataset=True, **passthrough_args\n",
    "        )\n",
    "        epoch_itr.load_state_dict(itr_state)\n",
    "    else:\n",
    "        epoch_itr = trainer.get_train_iterator(\n",
    "            epoch=1, load_dataset=True, **passthrough_args\n",
    "        )\n",
    "\n",
    "    trainer.lr_step(epoch_itr.epoch)\n",
    "\n",
    "    return extra_state, epoch_itr\n",
    "\n",
    "\n",
    "def load_checkpoint_to_cpu(path, arg_overrides=None, load_on_all_ranks=False):\n",
    "    \"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\n",
    "\n",
    "    If doing single-GPU training or if the checkpoint is only being loaded by at\n",
    "    most one process on each node (current default behavior is for only rank 0\n",
    "    to read the checkpoint from disk), load_on_all_ranks should be False to\n",
    "    avoid errors from torch.distributed not having been initialized or\n",
    "    torch.distributed.barrier() hanging.\n",
    "\n",
    "    If all processes on each node may be loading the checkpoint\n",
    "    simultaneously, load_on_all_ranks should be set to True to avoid I/O\n",
    "    conflicts.\n",
    "\n",
    "    There's currently no support for > 1 but < all processes loading the\n",
    "    checkpoint on each node.\n",
    "    \"\"\"\n",
    "    local_path = PathManager.get_local_path(path)\n",
    "    # The locally cached file returned by get_local_path() may be stale for\n",
    "    # remote files that are periodically updated/overwritten (ex:\n",
    "    # checkpoint_last.pt) - so we remove the local copy, sync across processes\n",
    "    # (if needed), and then download a fresh copy.\n",
    "    if local_path != path and PathManager.path_requires_pathmanager(path):\n",
    "        try:\n",
    "            os.remove(local_path)\n",
    "        except FileNotFoundError:\n",
    "            # With potentially multiple processes removing the same file, the\n",
    "            # file being missing is benign (missing_ok isn't available until\n",
    "            # Python 3.8).\n",
    "            pass\n",
    "        if load_on_all_ranks:\n",
    "            torch.distributed.barrier()\n",
    "        local_path = PathManager.get_local_path(path)\n",
    "\n",
    "    with open(local_path, \"rb\") as f:\n",
    "        state = torch.load(f, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "    if \"args\" in state and state[\"args\"] is not None and arg_overrides is not None:\n",
    "        args = state[\"args\"]\n",
    "        for arg_name, arg_val in arg_overrides.items():\n",
    "            setattr(args, arg_name, arg_val)\n",
    "\n",
    "    if \"cfg\" in state and state[\"cfg\"] is not None:\n",
    "\n",
    "        # hack to be able to set Namespace in dict config. this should be removed when we update to newer\n",
    "        # omegaconf version that supports object flags, or when we migrate all existing models\n",
    "        from omegaconf import _utils\n",
    "\n",
    "        old_primitive = _utils.is_primitive_type\n",
    "        _utils.is_primitive_type = lambda _: True\n",
    "\n",
    "        state[\"cfg\"] = OmegaConf.create(state[\"cfg\"])\n",
    "\n",
    "        _utils.is_primitive_type = old_primitive\n",
    "        OmegaConf.set_struct(state[\"cfg\"], True)\n",
    "\n",
    "        if arg_overrides is not None:\n",
    "            overwrite_args_by_name(state[\"cfg\"], arg_overrides)\n",
    "\n",
    "    state = _upgrade_state_dict(state)\n",
    "    return state\n",
    "\n",
    "\n",
    "def load_model_ensemble(\n",
    "    filenames,\n",
    "    arg_overrides: Optional[Dict[str, Any]] = None,\n",
    "    task=None,\n",
    "    strict=True,\n",
    "    suffix=\"\",\n",
    "    num_shards=1,\n",
    "    state=None,\n",
    "):\n",
    "    \"\"\"Loads an ensemble of models.\n",
    "\n",
    "    Args:\n",
    "        filenames (List[str]): checkpoint files to load\n",
    "        arg_overrides (Dict[str,Any], optional): override model args that\n",
    "            were used during model training\n",
    "        task (fairseq.tasks.FairseqTask, optional): task to use for loading\n",
    "    \"\"\"\n",
    "    assert not (\n",
    "        strict and num_shards > 1\n",
    "    ), \"Cannot load state dict with strict=True and checkpoint shards > 1\"\n",
    "    ensemble, args, _task = load_model_ensemble_and_task(\n",
    "        filenames,\n",
    "        arg_overrides,\n",
    "        task,\n",
    "        strict,\n",
    "        suffix,\n",
    "        num_shards,\n",
    "        state,\n",
    "    )\n",
    "    return ensemble, args\n",
    "\n",
    "\n",
    "def load_model_ensemble_and_task(\n",
    "    filenames,\n",
    "    arg_overrides: Optional[Dict[str, Any]] = None,\n",
    "    task=None,\n",
    "    strict=True,\n",
    "    suffix=\"\",\n",
    "    num_shards=1,\n",
    "    state=None,\n",
    "):\n",
    "    assert state is None or len(filenames) == 1\n",
    "\n",
    "    from fairseq import tasks\n",
    "\n",
    "    assert not (\n",
    "        strict and num_shards > 1\n",
    "    ), \"Cannot load state dict with strict=True and checkpoint shards > 1\"\n",
    "    ensemble = []\n",
    "    cfg = None\n",
    "    for filename in filenames:\n",
    "        orig_filename = filename\n",
    "        assert num_shards > 0\n",
    "        for shard_idx in range(num_shards):\n",
    "            if num_shards == 1:\n",
    "                filename = filename.replace(\".pt\", suffix + \".pt\")\n",
    "            else:\n",
    "                filename = orig_filename[:-3] + f\"_part{shard_idx}.pt\"\n",
    "\n",
    "            if not PathManager.exists(filename):\n",
    "                raise IOError(\"Model file not found: {}\".format(filename))\n",
    "            if state is None:\n",
    "                state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
    "            if \"args\" in state and state[\"args\"] is not None:\n",
    "                cfg = convert_namespace_to_omegaconf(state[\"args\"])\n",
    "            elif \"cfg\" in state and state[\"cfg\"] is not None:\n",
    "                cfg = state[\"cfg\"]\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"Neither args nor cfg exist in state keys = {state.keys()}\"\n",
    "                )\n",
    "\n",
    "            if task is None:\n",
    "                task = tasks.setup_task(cfg.task)\n",
    "\n",
    "            if \"task_state\" in state:\n",
    "                task.load_state_dict(state[\"task_state\"])\n",
    "\n",
    "            # build model for ensemble\n",
    "            model = task.build_model(cfg.model)\n",
    "\n",
    "            model.load_state_dict(state[\"model\"], strict=strict, model_cfg=cfg.model)\n",
    "\n",
    "            # reset state so it gets loaded for the next model in ensemble\n",
    "            state = None\n",
    "\n",
    "        ensemble.append(model.train())\n",
    "    return ensemble, cfg, task\n",
    "\n",
    "\n",
    "def checkpoint_paths(path, pattern=r\"checkpoint(\\d+)\\.pt\"):\n",
    "    \"\"\"Retrieves all checkpoints found in `path` directory.\n",
    "\n",
    "    Checkpoints are identified by matching filename to the specified pattern. If\n",
    "    the pattern contains groups, the result will be sorted by the first group in\n",
    "    descending order.\n",
    "    \"\"\"\n",
    "    pt_regexp = re.compile(pattern)\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    entries = []\n",
    "    for i, f in enumerate(files):\n",
    "        m = pt_regexp.fullmatch(f)\n",
    "        if m is not None:\n",
    "            idx = float(m.group(1)) if len(m.groups()) > 0 else i\n",
    "            entries.append((idx, m.group(0)))\n",
    "    return [os.path.join(path, x[1]) for x in sorted(entries, reverse=True)]\n",
    "\n",
    "\n",
    "def torch_persistent_save(cfg: CheckpointConfig, obj, filename):\n",
    "    if cfg.write_checkpoints_asynchronously:\n",
    "        with PathManager.opena(filename, \"wb\") as f:\n",
    "            _torch_persistent_save(obj, f)\n",
    "    else:\n",
    "        if PathManager.supports_rename(filename):\n",
    "            # do atomic save\n",
    "            with PathManager.open(filename + \".tmp\", \"wb\") as f:\n",
    "                _torch_persistent_save(obj, f)\n",
    "            PathManager.rename(filename + \".tmp\", filename)\n",
    "        else:\n",
    "            # fallback to non-atomic save\n",
    "            with PathManager.open(filename, \"wb\") as f:\n",
    "                _torch_persistent_save(obj, f)\n",
    "\n",
    "\n",
    "def _torch_persistent_save(obj, f):\n",
    "    if isinstance(f, str):\n",
    "        with PathManager.open(f, \"wb\") as h:\n",
    "            torch_persistent_save(obj, h)\n",
    "        return\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            return torch.save(obj, f)\n",
    "        except Exception:\n",
    "            if i == 2:\n",
    "                logger.error(traceback.format_exc())\n",
    "\n",
    "\n",
    "def save_state(\n",
    "    filename,\n",
    "    cfg: FairseqConfig,\n",
    "    model_state_dict,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    num_updates,\n",
    "    optim_history=None,\n",
    "    extra_state=None,\n",
    "    task=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    from fairseq import utils\n",
    "\n",
    "    if optim_history is None:\n",
    "        optim_history = []\n",
    "    if extra_state is None:\n",
    "        extra_state = {}\n",
    "    state_dict = {\n",
    "        \"cfg\": OmegaConf.to_container(cfg) if OmegaConf.is_config(cfg) else cfg,\n",
    "        \"args\": kwargs.get(\"args\", None),\n",
    "        \"model\": model_state_dict or {},\n",
    "        \"optimizer_history\": optim_history\n",
    "        + [\n",
    "            {\n",
    "                \"criterion_name\": criterion.__class__.__name__,\n",
    "                \"optimizer_name\": optimizer.__class__.__name__,\n",
    "                \"lr_scheduler_state\": lr_scheduler.state_dict(),\n",
    "                \"num_updates\": num_updates,\n",
    "            }\n",
    "        ],\n",
    "        \"extra_state\": extra_state,\n",
    "        \"task_state\": task.state_dict() if task is not None else {},\n",
    "    }\n",
    "    if utils.has_parameters(criterion):\n",
    "        state_dict[\"criterion\"] = criterion.state_dict()\n",
    "\n",
    "    if cfg is None:\n",
    "        cfg = state_dict[\"args\"]\n",
    "        assert cfg is not None, \"must provide cfg or args\"\n",
    "\n",
    "    if isinstance(cfg, DictConfig):\n",
    "        no_save_optimizer_state = cfg.checkpoint.no_save_optimizer_state\n",
    "    else:\n",
    "        no_save_optimizer_state = cfg.no_save_optimizer_state\n",
    "    if not no_save_optimizer_state:\n",
    "        state_dict[\"last_optimizer_state\"] = optimizer.state_dict()\n",
    "\n",
    "    # keep everything on CPU\n",
    "    state_dict = utils.move_to_cpu(state_dict)\n",
    "\n",
    "    torch_persistent_save(cfg.checkpoint, state_dict, filename)\n",
    "\n",
    "\n",
    "def _upgrade_state_dict(state):\n",
    "    \"\"\"Helper for upgrading old model checkpoints.\"\"\"\n",
    "    from fairseq import models, registry, tasks\n",
    "\n",
    "    # add optimizer_history\n",
    "    if \"optimizer_history\" not in state:\n",
    "        state[\"optimizer_history\"] = [\n",
    "            {\"criterion_name\": \"CrossEntropyCriterion\", \"best_loss\": state[\"best_loss\"]}\n",
    "        ]\n",
    "        state[\"last_optimizer_state\"] = state[\"optimizer\"]\n",
    "        del state[\"optimizer\"]\n",
    "        del state[\"best_loss\"]\n",
    "    # move extra_state into sub-dictionary\n",
    "    if \"epoch\" in state and \"extra_state\" not in state:\n",
    "        state[\"extra_state\"] = {\n",
    "            \"epoch\": state[\"epoch\"],\n",
    "            \"batch_offset\": state[\"batch_offset\"],\n",
    "            \"val_loss\": state[\"val_loss\"],\n",
    "        }\n",
    "        del state[\"epoch\"]\n",
    "        del state[\"batch_offset\"]\n",
    "        del state[\"val_loss\"]\n",
    "    # reduce optimizer history's memory usage (only keep the last state)\n",
    "    if \"optimizer\" in state[\"optimizer_history\"][-1]:\n",
    "        state[\"last_optimizer_state\"] = state[\"optimizer_history\"][-1][\"optimizer\"]\n",
    "        for optim_hist in state[\"optimizer_history\"]:\n",
    "            del optim_hist[\"optimizer\"]\n",
    "    # record the optimizer class name\n",
    "    if \"optimizer_name\" not in state[\"optimizer_history\"][-1]:\n",
    "        state[\"optimizer_history\"][-1][\"optimizer_name\"] = \"FairseqNAG\"\n",
    "    # move best_loss into lr_scheduler_state\n",
    "    if \"lr_scheduler_state\" not in state[\"optimizer_history\"][-1]:\n",
    "        state[\"optimizer_history\"][-1][\"lr_scheduler_state\"] = {\n",
    "            \"best\": state[\"optimizer_history\"][-1][\"best_loss\"]\n",
    "        }\n",
    "        del state[\"optimizer_history\"][-1][\"best_loss\"]\n",
    "    # keep track of number of updates\n",
    "    if \"num_updates\" not in state[\"optimizer_history\"][-1]:\n",
    "        state[\"optimizer_history\"][-1][\"num_updates\"] = 0\n",
    "    # old model checkpoints may not have separate source/target positions\n",
    "    if hasattr(state[\"args\"], \"max_positions\") and not hasattr(\n",
    "        state[\"args\"], \"max_source_positions\"\n",
    "    ):\n",
    "        state[\"args\"].max_source_positions = state[\"args\"].max_positions\n",
    "        state[\"args\"].max_target_positions = state[\"args\"].max_positions\n",
    "    # use stateful training data iterator\n",
    "    if \"train_iterator\" not in state[\"extra_state\"]:\n",
    "        state[\"extra_state\"][\"train_iterator\"] = {\n",
    "            \"epoch\": state[\"extra_state\"][\"epoch\"],\n",
    "            \"iterations_in_epoch\": state[\"extra_state\"].get(\"batch_offset\", 0),\n",
    "        }\n",
    "\n",
    "    # backward compatibility, cfg updates\n",
    "    if \"args\" in state and state[\"args\"] is not None:\n",
    "        # default to translation task\n",
    "        if not hasattr(state[\"args\"], \"task\"):\n",
    "            state[\"args\"].task = \"translation\"\n",
    "        # --raw-text and --lazy-load are deprecated\n",
    "        if getattr(state[\"args\"], \"raw_text\", False):\n",
    "            state[\"args\"].dataset_impl = \"raw\"\n",
    "        elif getattr(state[\"args\"], \"lazy_load\", False):\n",
    "            state[\"args\"].dataset_impl = \"lazy\"\n",
    "        # epochs start at 1\n",
    "        if state[\"extra_state\"][\"train_iterator\"] is not None:\n",
    "            state[\"extra_state\"][\"train_iterator\"][\"epoch\"] = max(\n",
    "                state[\"extra_state\"][\"train_iterator\"].get(\"epoch\", 1), 1\n",
    "            )\n",
    "        # --remove-bpe ==> --postprocess\n",
    "        if hasattr(state[\"args\"], \"remove_bpe\"):\n",
    "            state[\"args\"].post_process = state[\"args\"].remove_bpe\n",
    "        # --min-lr ==> --stop-min-lr\n",
    "        if hasattr(state[\"args\"], \"min_lr\"):\n",
    "            state[\"args\"].stop_min_lr = state[\"args\"].min_lr\n",
    "            del state[\"args\"].min_lr\n",
    "        # binary_cross_entropy => wav2vec criterion\n",
    "        if (\n",
    "            hasattr(state[\"args\"], \"criterion\")\n",
    "            and state[\"args\"].criterion == \"binary_cross_entropy\"\n",
    "        ):\n",
    "            state[\"args\"].criterion = \"wav2vec\"\n",
    "        # speech_pretraining => audio pretraining\n",
    "        if (\n",
    "            hasattr(state[\"args\"], \"task\")\n",
    "            and state[\"args\"].task == \"speech_pretraining\"\n",
    "        ):\n",
    "            state[\"args\"].task = \"audio_pretraining\"\n",
    "        # audio_cpc => wav2vec\n",
    "        if hasattr(state[\"args\"], \"arch\") and state[\"args\"].arch == \"audio_cpc\":\n",
    "            state[\"args\"].arch = \"wav2vec\"\n",
    "        # convert legacy float learning rate to List[float]\n",
    "        if hasattr(state[\"args\"], \"lr\") and isinstance(state[\"args\"].lr, float):\n",
    "            state[\"args\"].lr = [state[\"args\"].lr]\n",
    "        # convert task data arg to a string instead of List[string]\n",
    "        if (\n",
    "            hasattr(state[\"args\"], \"data\")\n",
    "            and isinstance(state[\"args\"].data, list)\n",
    "            and len(state[\"args\"].data) > 0\n",
    "        ):\n",
    "            state[\"args\"].data = state[\"args\"].data[0]\n",
    "\n",
    "        state[\"cfg\"] = convert_namespace_to_omegaconf(state[\"args\"])\n",
    "\n",
    "    if \"cfg\" in state and state[\"cfg\"] is not None:\n",
    "        cfg = state[\"cfg\"]\n",
    "        with open_dict(cfg):\n",
    "            # any upgrades for Hydra-based configs\n",
    "            if (\n",
    "                \"task\" in cfg\n",
    "                and \"eval_wer_config\" in cfg.task\n",
    "                and isinstance(cfg.task.eval_wer_config.print_alignment, bool)\n",
    "            ):\n",
    "                cfg.task.eval_wer_config.print_alignment = \"hard\"\n",
    "            if \"generation\" in cfg and isinstance(cfg.generation.print_alignment, bool):\n",
    "                cfg.generation.print_alignment = \"hard\"\n",
    "            if (\n",
    "                \"model\" in cfg\n",
    "                and \"w2v_args\" in cfg.model\n",
    "                and cfg.model.w2v_args is not None\n",
    "                and (\n",
    "                    hasattr(cfg.model.w2v_args, \"task\") or \"task\" in cfg.model.w2v_args\n",
    "                )\n",
    "                and isinstance(\n",
    "                    cfg.model.w2v_args.task.eval_wer_config.print_alignment, bool\n",
    "                )\n",
    "            ):\n",
    "                cfg.model.w2v_args.task.eval_wer_config.print_alignment = \"hard\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def prune_state_dict(state_dict, model_cfg: Optional[DictConfig]):\n",
    "    \"\"\"Prune the given state_dict if desired for LayerDrop\n",
    "    (https://arxiv.org/abs/1909.11556).\n",
    "\n",
    "    Training with LayerDrop allows models to be robust to pruning at inference\n",
    "    time. This function prunes state_dict to allow smaller models to be loaded\n",
    "    from a larger model and re-maps the existing state_dict for this to occur.\n",
    "\n",
    "    It's called by functions that load models from checkpoints and does not\n",
    "    need to be called directly.\n",
    "    \"\"\"\n",
    "    arch = None\n",
    "    if model_cfg is not None:\n",
    "        arch = (\n",
    "            model_cfg._name\n",
    "            if isinstance(model_cfg, DictConfig)\n",
    "            else getattr(model_cfg, \"arch\", None)\n",
    "        )\n",
    "\n",
    "    if not model_cfg or arch is None or arch == \"ptt_transformer\":\n",
    "        # args should not be none, but don't crash if it is.\n",
    "        return state_dict\n",
    "\n",
    "    encoder_layers_to_keep = getattr(model_cfg, \"encoder_layers_to_keep\", None)\n",
    "    decoder_layers_to_keep = getattr(model_cfg, \"decoder_layers_to_keep\", None)\n",
    "\n",
    "    if not encoder_layers_to_keep and not decoder_layers_to_keep:\n",
    "        return state_dict\n",
    "\n",
    "    # apply pruning\n",
    "    logger.info(\n",
    "        \"Pruning model to specified layer configuration - this works best if the model was trained with LayerDrop\"\n",
    "    )\n",
    "\n",
    "    def create_pruning_pass(layers_to_keep, layer_name):\n",
    "        keep_layers = sorted(\n",
    "            int(layer_string) for layer_string in layers_to_keep.split(\",\")\n",
    "        )\n",
    "        mapping_dict = {}\n",
    "        for i in range(len(keep_layers)):\n",
    "            mapping_dict[str(keep_layers[i])] = str(i)\n",
    "\n",
    "        regex = re.compile(r\"^{layer}.*\\.layers\\.(\\d+)\".format(layer=layer_name))\n",
    "        return {\"substitution_regex\": regex, \"mapping_dict\": mapping_dict}\n",
    "\n",
    "    pruning_passes = []\n",
    "    if encoder_layers_to_keep:\n",
    "        pruning_passes.append(create_pruning_pass(encoder_layers_to_keep, \"encoder\"))\n",
    "    if decoder_layers_to_keep:\n",
    "        pruning_passes.append(create_pruning_pass(decoder_layers_to_keep, \"decoder\"))\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for layer_name in state_dict.keys():\n",
    "        match = re.search(r\"\\.layers\\.(\\d+)\\.\", layer_name)\n",
    "        # if layer has no number in it, it is a supporting layer, such as an\n",
    "        # embedding\n",
    "        if not match:\n",
    "            new_state_dict[layer_name] = state_dict[layer_name]\n",
    "            continue\n",
    "\n",
    "        # otherwise, layer should be pruned.\n",
    "        original_layer_number = match.group(1)\n",
    "        # figure out which mapping dict to replace from\n",
    "        for pruning_pass in pruning_passes:\n",
    "            if original_layer_number in pruning_pass[\"mapping_dict\"] and pruning_pass[\n",
    "                \"substitution_regex\"\n",
    "            ].search(layer_name):\n",
    "                new_layer_number = pruning_pass[\"mapping_dict\"][original_layer_number]\n",
    "                substitution_match = pruning_pass[\"substitution_regex\"].search(\n",
    "                    layer_name\n",
    "                )\n",
    "                new_state_key = (\n",
    "                    layer_name[: substitution_match.start(1)]\n",
    "                    + new_layer_number\n",
    "                    + layer_name[substitution_match.end(1) :]\n",
    "                )\n",
    "                new_state_dict[new_state_key] = state_dict[layer_name]\n",
    "\n",
    "    # Since layers are now pruned, *_layers_to_keep are no longer needed.\n",
    "    # This is more of \"It would make it work fix\" rather than a proper fix.\n",
    "    if isinstance(model_cfg, DictConfig):\n",
    "        context = open_dict(model_cfg)\n",
    "    else:\n",
    "        context = contextlib.ExitStack()\n",
    "    with context:\n",
    "        if hasattr(model_cfg, \"encoder_layers_to_keep\"):\n",
    "            model_cfg.encoder_layers_to_keep = None\n",
    "        if hasattr(model_cfg, \"decoder_layers_to_keep\"):\n",
    "            model_cfg.decoder_layers_to_keep = None\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def load_pretrained_component_from_model(\n",
    "    component: Union[FairseqEncoder, FairseqDecoder], checkpoint: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a pretrained FairseqEncoder or FairseqDecoder from checkpoint into the\n",
    "    provided `component` object. If state_dict fails to load, there may be a\n",
    "    mismatch in the architecture of the corresponding `component` found in the\n",
    "    `checkpoint` file.\n",
    "    \"\"\"\n",
    "    if not PathManager.exists(checkpoint):\n",
    "        raise IOError(\"Model file not found: {}\".format(checkpoint))\n",
    "    state = load_checkpoint_to_cpu(checkpoint)\n",
    "    if isinstance(component, FairseqEncoder):\n",
    "        component_type = \"encoder\"\n",
    "    elif isinstance(component, FairseqDecoder):\n",
    "        component_type = \"decoder\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"component to load must be either a FairseqEncoder or \"\n",
    "            \"FairseqDecoder. Loading other component types are not supported.\"\n",
    "        )\n",
    "    component_state_dict = OrderedDict()\n",
    "    for key in state[\"model\"].keys():\n",
    "        if key.startswith(component_type):\n",
    "            # encoder.input_layers.0.0.weight --> input_layers.0.0.weight\n",
    "            component_subkey = key[len(component_type) + 1 :]\n",
    "            component_state_dict[component_subkey] = state[\"model\"][key]\n",
    "    component.load_state_dict(component_state_dict, strict=True)\n",
    "    return component\n",
    "\n",
    "\n",
    "def verify_checkpoint_directory(save_dir: str) -> None:\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    temp_file_path = os.path.join(save_dir, \"dummy\")\n",
    "    try:\n",
    "        with open(temp_file_path, \"w\"):\n",
    "            pass\n",
    "    except OSError as e:\n",
    "        logger.warning(\n",
    "            \"Unable to access checkpoint save directory: {}\".format(save_dir)\n",
    "        )\n",
    "        raise e\n",
    "    else:\n",
    "        os.remove(temp_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/mGENRE_MEL\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sequence_generator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sequence_generator.py\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import math\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fairseq import search, utils\n",
    "from fairseq.data import data_utils\n",
    "from fairseq.models import FairseqIncrementalDecoder\n",
    "from torch import Tensor\n",
    "from fairseq.ngram_repeat_block import NGramRepeatBlock\n",
    "\n",
    "\n",
    "class SequenceGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        models,\n",
    "        tgt_dict,\n",
    "        beam_size=1,\n",
    "        max_len_a=0,\n",
    "        max_len_b=200,\n",
    "        min_len=1,\n",
    "        normalize_scores=True,\n",
    "        len_penalty=1.0,\n",
    "        unk_penalty=0.0,\n",
    "        temperature=1.0,\n",
    "        match_source_len=False,\n",
    "        no_repeat_ngram_size=0,\n",
    "        search_strategy=None,\n",
    "        eos=None,\n",
    "        symbols_to_strip_from_output=None,\n",
    "        lm_model=None,\n",
    "        lm_weight=1.0,\n",
    "    ):\n",
    "        \"\"\"Generates translations of a given source sentence.\n",
    "\n",
    "        Args:\n",
    "            models (List[~fairseq.models.FairseqModel]): ensemble of models,\n",
    "                currently support fairseq.models.TransformerModel for scripting\n",
    "            beam_size (int, optional): beam width (default: 1)\n",
    "            max_len_a/b (int, optional): generate sequences of maximum length\n",
    "                ax + b, where x is the source length\n",
    "            min_len (int, optional): the minimum length of the generated output\n",
    "                (not including end-of-sentence)\n",
    "            normalize_scores (bool, optional): normalize scores by the length\n",
    "                of the output (default: True)\n",
    "            len_penalty (float, optional): length penalty, where <1.0 favors\n",
    "                shorter, >1.0 favors longer sentences (default: 1.0)\n",
    "            unk_penalty (float, optional): unknown word penalty, where <0\n",
    "                produces more unks, >0 produces fewer (default: 0.0)\n",
    "            temperature (float, optional): temperature, where values\n",
    "                >1.0 produce more uniform samples and values <1.0 produce\n",
    "                sharper samples (default: 1.0)\n",
    "            match_source_len (bool, optional): outputs should match the source\n",
    "                length (default: False)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if isinstance(models, EnsembleModel):\n",
    "            self.model = models\n",
    "        else:\n",
    "            self.model = EnsembleModel(models)\n",
    "        self.tgt_dict = tgt_dict\n",
    "        self.pad = tgt_dict.pad()\n",
    "        self.unk = tgt_dict.unk()\n",
    "        self.eos = tgt_dict.eos() if eos is None else eos\n",
    "        self.symbols_to_strip_from_output = (\n",
    "            symbols_to_strip_from_output.union({self.eos})\n",
    "            if symbols_to_strip_from_output is not None\n",
    "            else {self.eos}\n",
    "        )\n",
    "        self.vocab_size = len(tgt_dict)\n",
    "        self.beam_size = beam_size\n",
    "        # the max beam size is the dictionary size - 1, since we never select pad\n",
    "        self.beam_size = min(beam_size, self.vocab_size - 1)\n",
    "        self.max_len_a = max_len_a\n",
    "        self.max_len_b = max_len_b\n",
    "        self.min_len = min_len\n",
    "\n",
    "        self.normalize_scores = normalize_scores\n",
    "        self.len_penalty = len_penalty\n",
    "        self.unk_penalty = unk_penalty\n",
    "        self.temperature = temperature\n",
    "        self.match_source_len = match_source_len\n",
    "\n",
    "        if no_repeat_ngram_size > 0:\n",
    "            self.repeat_ngram_blocker = NGramRepeatBlock(no_repeat_ngram_size)\n",
    "        else:\n",
    "            self.repeat_ngram_blocker = None\n",
    "\n",
    "        assert temperature > 0, \"--temperature must be greater than 0\"\n",
    "\n",
    "        self.search = (\n",
    "            search.BeamSearch(tgt_dict) if search_strategy is None else search_strategy\n",
    "        )\n",
    "        # We only need to set src_lengths in LengthConstrainedBeamSearch.\n",
    "        # As a module attribute, setting it would break in multithread\n",
    "        # settings when the model is shared.\n",
    "        self.should_set_src_lengths = (\n",
    "            hasattr(self.search, \"needs_src_lengths\") and self.search.needs_src_lengths\n",
    "        )\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        self.lm_model = lm_model\n",
    "        self.lm_weight = lm_weight\n",
    "        if self.lm_model is not None:\n",
    "            self.lm_model.train()\n",
    "\n",
    "    def cuda(self):\n",
    "        self.model.cuda()\n",
    "        return self\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: Dict[str, Dict[str, Tensor]],\n",
    "        prefix_tokens: Optional[Tensor] = None,\n",
    "        bos_token: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"Generate a batch of translations.\n",
    "\n",
    "        Args:\n",
    "            sample (dict): batch\n",
    "            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n",
    "                with these tokens\n",
    "            bos_token (int, optional): beginning of sentence token\n",
    "                (default: self.eos)\n",
    "        \"\"\"\n",
    "        return self._generate(sample, prefix_tokens, bos_token=bos_token)\n",
    "\n",
    "    # TODO(myleott): unused, deprecate after pytorch-translate migration\n",
    "    def generate_batched_itr(self, data_itr, beam_size=None, cuda=False, timer=None):\n",
    "        \"\"\"Iterate over a batched dataset and yield individual translations.\n",
    "        Args:\n",
    "            cuda (bool, optional): use GPU for generation\n",
    "            timer (StopwatchMeter, optional): time generations\n",
    "        \"\"\"\n",
    "        for sample in data_itr:\n",
    "            s = utils.move_to_cuda(sample) if cuda else sample\n",
    "            if \"net_input\" not in s:\n",
    "                continue\n",
    "            input = s[\"net_input\"]\n",
    "            # model.forward normally channels prev_output_tokens into the decoder\n",
    "            # separately, but SequenceGenerator directly calls model.encoder\n",
    "            encoder_input = {\n",
    "                k: v for k, v in input.items() if k != \"prev_output_tokens\"\n",
    "            }\n",
    "            if timer is not None:\n",
    "                timer.start()\n",
    "            with torch.no_grad():\n",
    "                hypos = self.generate(encoder_input)\n",
    "            if timer is not None:\n",
    "                timer.stop(sum(len(h[0][\"tokens\"]) for h in hypos))\n",
    "            for i, id in enumerate(s[\"id\"].data):\n",
    "                # remove padding\n",
    "                src = utils.strip_pad(input[\"src_tokens\"].data[i, :], self.pad)\n",
    "                ref = (\n",
    "                    utils.strip_pad(s[\"target\"].data[i, :], self.pad)\n",
    "                    if s[\"target\"] is not None\n",
    "                    else None\n",
    "                )\n",
    "                yield id, src, ref, hypos[i]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, models, sample: Dict[str, Dict[str, Tensor]], **kwargs):\n",
    "        \"\"\"Generate translations. Match the api of other fairseq generators.\n",
    "\n",
    "        Args:\n",
    "            models (List[~fairseq.models.FairseqModel]): ensemble of models\n",
    "            sample (dict): batch\n",
    "            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n",
    "                with these tokens\n",
    "            constraints (torch.LongTensor, optional): force decoder to include\n",
    "                the list of constraints\n",
    "            bos_token (int, optional): beginning of sentence token\n",
    "                (default: self.eos)\n",
    "        \"\"\"\n",
    "        return self._generate(sample, **kwargs)\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        sample: Dict[str, Dict[str, Tensor]],\n",
    "        prefix_tokens: Optional[Tensor] = None,\n",
    "        constraints: Optional[Tensor] = None,\n",
    "        bos_token: Optional[int] = None,\n",
    "    ):\n",
    "        incremental_states = torch.jit.annotate(\n",
    "            List[Dict[str, Dict[str, Optional[Tensor]]]],\n",
    "            [\n",
    "                torch.jit.annotate(Dict[str, Dict[str, Optional[Tensor]]], {})\n",
    "                for i in range(self.model.models_size)\n",
    "            ],\n",
    "        )\n",
    "        net_input = sample[\"net_input\"]\n",
    "\n",
    "        if \"src_tokens\" in net_input:\n",
    "            src_tokens = net_input[\"src_tokens\"]\n",
    "            # length of the source text being the character length except EndOfSentence and pad\n",
    "            src_lengths = (\n",
    "                (src_tokens.ne(self.eos) & src_tokens.ne(self.pad)).long().sum(dim=1)\n",
    "            )\n",
    "        elif \"source\" in net_input:\n",
    "            src_tokens = net_input[\"source\"]\n",
    "            src_lengths = (\n",
    "                net_input[\"padding_mask\"].size(-1) - net_input[\"padding_mask\"].sum(-1)\n",
    "                if net_input[\"padding_mask\"] is not None\n",
    "                else torch.tensor(src_tokens.size(-1)).to(src_tokens)\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"expected src_tokens or source in net input\")\n",
    "\n",
    "        # bsz: total number of sentences in beam\n",
    "        # Note that src_tokens may have more than 2 dimensions (i.e. audio features)\n",
    "        bsz, src_len = src_tokens.size()[:2]\n",
    "        beam_size = self.beam_size\n",
    "\n",
    "        if constraints is not None and not self.search.supports_constraints:\n",
    "            raise NotImplementedError(\n",
    "                \"Target-side constraints were provided, but search method doesn't support them\"\n",
    "            )\n",
    "\n",
    "        # Initialize constraints, when active\n",
    "        self.search.init_constraints(constraints, beam_size)\n",
    "\n",
    "        max_len: int = -1\n",
    "        if self.match_source_len:\n",
    "            max_len = src_lengths.max().item()\n",
    "        else:\n",
    "            max_len = min(\n",
    "                int(self.max_len_a * src_len + self.max_len_b),\n",
    "                # exclude the EOS marker\n",
    "                self.model.max_decoder_positions() - 1,\n",
    "            )\n",
    "        assert (\n",
    "            self.min_len <= max_len\n",
    "        ), \"min_len cannot be larger than max_len, please adjust these!\"\n",
    "        # compute the encoder output for each beam\n",
    "        encoder_outs = self.model.forward_encoder(net_input)\n",
    "\n",
    "        # placeholder of indices for bsz * beam_size to hold tokens and accumulative scores\n",
    "        new_order = torch.arange(bsz).view(-1, 1).repeat(1, beam_size).view(-1)\n",
    "        new_order = new_order.to(src_tokens.device).long()\n",
    "        encoder_outs = self.model.reorder_encoder_out(encoder_outs, new_order)\n",
    "        # ensure encoder_outs is a List.\n",
    "        assert encoder_outs is not None\n",
    "\n",
    "        # initialize buffers\n",
    "        scores = (\n",
    "            torch.zeros(bsz * beam_size, max_len + 1).to(src_tokens).float()\n",
    "        )  # +1 for eos; pad is never chosen for scoring\n",
    "        tokens = (\n",
    "            torch.zeros(bsz * beam_size, max_len + 2)\n",
    "            .to(src_tokens)\n",
    "            .long()\n",
    "            .fill_(self.pad)\n",
    "        )  # +2 for eos and pad\n",
    "        tokens[:, 0] = self.eos if bos_token is None else bos_token\n",
    "        attn: Optional[Tensor] = None\n",
    "\n",
    "        # A list that indicates candidates that should be ignored.\n",
    "        # For example, suppose we're sampling and have already finalized 2/5\n",
    "        # samples. Then cands_to_ignore would mark 2 positions as being ignored,\n",
    "        # so that we only finalize the remaining 3 samples.\n",
    "        cands_to_ignore = (\n",
    "            torch.zeros(bsz, beam_size).to(src_tokens).eq(-1)\n",
    "        )  # forward and backward-compatible False mask\n",
    "\n",
    "        # list of completed sentences\n",
    "        finalized = torch.jit.annotate(\n",
    "            List[List[Dict[str, Tensor]]],\n",
    "            [torch.jit.annotate(List[Dict[str, Tensor]], []) for i in range(bsz)],\n",
    "        )  # contains lists of dictionaries of infomation about the hypothesis being finalized at each step\n",
    "\n",
    "        finished = [\n",
    "            False for i in range(bsz)\n",
    "        ]  # a boolean array indicating if the sentence at the index is finished or not\n",
    "        num_remaining_sent = bsz  # number of sentences remaining\n",
    "\n",
    "        # number of candidate hypos per step\n",
    "        cand_size = 2 * beam_size  # 2 x beam size in case half are EOS\n",
    "\n",
    "        # offset arrays for converting between different indexing schemes\n",
    "        bbsz_offsets = (\n",
    "            (torch.arange(0, bsz) * beam_size)\n",
    "            .unsqueeze(1)\n",
    "            .type_as(tokens)\n",
    "            .to(src_tokens.device)\n",
    "        )\n",
    "        cand_offsets = torch.arange(0, cand_size).type_as(tokens).to(src_tokens.device)\n",
    "\n",
    "        reorder_state: Optional[Tensor] = None\n",
    "        batch_idxs: Optional[Tensor] = None\n",
    "\n",
    "        original_batch_idxs: Optional[Tensor] = None\n",
    "        if \"id\" in sample and isinstance(sample[\"id\"], Tensor):\n",
    "            original_batch_idxs = sample[\"id\"]\n",
    "        else:\n",
    "            original_batch_idxs = torch.arange(0, bsz).type_as(tokens)\n",
    "\n",
    "        for step in range(max_len + 1):  # one extra step for EOS marker\n",
    "            # reorder decoder internal states based on the prev choice of beams\n",
    "            if reorder_state is not None:\n",
    "                if batch_idxs is not None:\n",
    "                    # update beam indices to take into account removed sentences\n",
    "                    corr = batch_idxs - torch.arange(batch_idxs.numel()).type_as(\n",
    "                        batch_idxs\n",
    "                    )\n",
    "                    reorder_state.view(-1, beam_size).add_(\n",
    "                        corr.unsqueeze(-1) * beam_size\n",
    "                    )\n",
    "                    original_batch_idxs = original_batch_idxs[batch_idxs]\n",
    "                self.model.reorder_incremental_state(incremental_states, reorder_state)\n",
    "                encoder_outs = self.model.reorder_encoder_out(\n",
    "                    encoder_outs, reorder_state\n",
    "                )\n",
    "\n",
    "            lprobs, avg_attn_scores = self.model.forward_decoder(\n",
    "                tokens[:, : step + 1],\n",
    "                encoder_outs,\n",
    "                incremental_states,\n",
    "                self.temperature,\n",
    "            )\n",
    "\n",
    "            if self.lm_model is not None:\n",
    "                lm_out = self.lm_model(tokens[:, : step + 1])\n",
    "                probs = self.lm_model.get_normalized_probs(\n",
    "                    lm_out, log_probs=True, sample=None\n",
    "                )\n",
    "                probs = probs[:, -1, :] * self.lm_weight\n",
    "                lprobs += probs\n",
    "\n",
    "            lprobs[lprobs != lprobs] = torch.tensor(-math.inf).to(lprobs)\n",
    "\n",
    "            lprobs[:, self.pad] = -math.inf  # never select pad\n",
    "            lprobs[:, self.unk] -= self.unk_penalty  # apply unk penalty\n",
    "\n",
    "            # handle max length constraint\n",
    "            if step >= max_len:\n",
    "                lprobs[:, : self.eos] = -math.inf\n",
    "                lprobs[:, self.eos + 1 :] = -math.inf\n",
    "\n",
    "            # handle prefix tokens (possibly with different lengths)\n",
    "            if (\n",
    "                prefix_tokens is not None\n",
    "                and step < prefix_tokens.size(1)\n",
    "                and step < max_len\n",
    "            ):\n",
    "                lprobs, tokens, scores = self._prefix_tokens(\n",
    "                    step, lprobs, scores, tokens, prefix_tokens, beam_size\n",
    "                )\n",
    "            elif step < self.min_len:\n",
    "                # minimum length constraint (does not apply if using prefix_tokens)\n",
    "                lprobs[:, self.eos] = -math.inf\n",
    "\n",
    "            # Record attention scores, only support avg_attn_scores is a Tensor\n",
    "            if avg_attn_scores is not None:\n",
    "                if attn is None:\n",
    "                    attn = torch.empty(\n",
    "                        bsz * beam_size, avg_attn_scores.size(1), max_len + 2\n",
    "                    ).to(scores)\n",
    "                attn[:, :, step + 1].copy_(avg_attn_scores)\n",
    "\n",
    "            scores = scores.type_as(lprobs)\n",
    "            eos_bbsz_idx = torch.empty(0).to(\n",
    "                tokens\n",
    "            )  # indices of hypothesis ending with eos (finished sentences)\n",
    "            eos_scores = torch.empty(0).to(\n",
    "                scores\n",
    "            )  # scores of hypothesis ending with eos (finished sentences)\n",
    "\n",
    "            if self.should_set_src_lengths:\n",
    "                self.search.set_src_lengths(src_lengths)\n",
    "\n",
    "            if self.repeat_ngram_blocker is not None:\n",
    "                lprobs = self.repeat_ngram_blocker(tokens, lprobs, bsz, beam_size, step)\n",
    "\n",
    "            # Shape: (batch, cand_size)\n",
    "            cand_scores, cand_indices, cand_beams = self.search.step(\n",
    "                step,\n",
    "                lprobs.view(bsz, -1, self.vocab_size),\n",
    "                scores.view(bsz, beam_size, -1)[:, :, :step],\n",
    "                tokens[:, : step + 1],\n",
    "                original_batch_idxs,\n",
    "            )\n",
    "\n",
    "            # cand_bbsz_idx contains beam indices for the top candidate\n",
    "            # hypotheses, with a range of values: [0, bsz*beam_size),\n",
    "            # and dimensions: [bsz, cand_size]\n",
    "            cand_bbsz_idx = cand_beams.add(bbsz_offsets)\n",
    "\n",
    "            # finalize hypotheses that end in eos\n",
    "            # Shape of eos_mask: (batch size, beam size)\n",
    "            eos_mask = cand_indices.eq(self.eos) & cand_scores.ne(-math.inf)\n",
    "            eos_mask[:, :beam_size][cands_to_ignore] = torch.tensor(0).to(eos_mask)\n",
    "\n",
    "            # only consider eos when it's among the top beam_size indices\n",
    "            # Now we know what beam item(s) to finish\n",
    "            # Shape: 1d list of absolute-numbered\n",
    "            eos_bbsz_idx = torch.masked_select(\n",
    "                cand_bbsz_idx[:, :beam_size], mask=eos_mask[:, :beam_size]\n",
    "            )\n",
    "\n",
    "            finalized_sents: List[int] = []\n",
    "            if eos_bbsz_idx.numel() > 0:\n",
    "                eos_scores = torch.masked_select(\n",
    "                    cand_scores[:, :beam_size], mask=eos_mask[:, :beam_size]\n",
    "                )\n",
    "\n",
    "                finalized_sents = self.finalize_hypos(\n",
    "                    step,\n",
    "                    eos_bbsz_idx,\n",
    "                    eos_scores,\n",
    "                    tokens,\n",
    "                    scores,\n",
    "                    finalized,\n",
    "                    finished,\n",
    "                    beam_size,\n",
    "                    attn,\n",
    "                    src_lengths,\n",
    "                    max_len,\n",
    "                )\n",
    "                num_remaining_sent -= len(finalized_sents)\n",
    "\n",
    "            assert num_remaining_sent >= 0\n",
    "            if num_remaining_sent == 0:\n",
    "                break\n",
    "            if self.search.stop_on_max_len and step >= max_len:\n",
    "                break\n",
    "            assert step < max_len, f\"{step} < {max_len}\"\n",
    "\n",
    "            # Remove finalized sentences (ones for which {beam_size}\n",
    "            # finished hypotheses have been generated) from the batch.\n",
    "            if len(finalized_sents) > 0:\n",
    "                new_bsz = bsz - len(finalized_sents)\n",
    "\n",
    "                # construct batch_idxs which holds indices of batches to keep for the next pass\n",
    "                batch_mask = torch.ones(\n",
    "                    bsz, dtype=torch.bool, device=cand_indices.device\n",
    "                )\n",
    "                batch_mask[finalized_sents] = False\n",
    "                # TODO replace `nonzero(as_tuple=False)` after TorchScript supports it\n",
    "                batch_idxs = torch.arange(\n",
    "                    bsz, device=cand_indices.device\n",
    "                ).masked_select(batch_mask)\n",
    "\n",
    "                # Choose the subset of the hypothesized constraints that will continue\n",
    "                self.search.prune_sentences(batch_idxs)\n",
    "\n",
    "                eos_mask = eos_mask[batch_idxs]\n",
    "                cand_beams = cand_beams[batch_idxs]\n",
    "                bbsz_offsets.resize_(new_bsz, 1)\n",
    "                cand_bbsz_idx = cand_beams.add(bbsz_offsets)\n",
    "                cand_scores = cand_scores[batch_idxs]\n",
    "                cand_indices = cand_indices[batch_idxs]\n",
    "\n",
    "                if prefix_tokens is not None:\n",
    "                    prefix_tokens = prefix_tokens[batch_idxs]\n",
    "                src_lengths = src_lengths[batch_idxs]\n",
    "                cands_to_ignore = cands_to_ignore[batch_idxs]\n",
    "\n",
    "                scores = scores.view(bsz, -1)[batch_idxs].view(new_bsz * beam_size, -1)\n",
    "                tokens = tokens.view(bsz, -1)[batch_idxs].view(new_bsz * beam_size, -1)\n",
    "                if attn is not None:\n",
    "                    attn = attn.view(bsz, -1)[batch_idxs].view(\n",
    "                        new_bsz * beam_size, attn.size(1), -1\n",
    "                    )\n",
    "                bsz = new_bsz\n",
    "            else:\n",
    "                batch_idxs = None\n",
    "\n",
    "            # Set active_mask so that values > cand_size indicate eos hypos\n",
    "            # and values < cand_size indicate candidate active hypos.\n",
    "            # After, the min values per row are the top candidate active hypos\n",
    "\n",
    "            # Rewrite the operator since the element wise or is not supported in torchscript.\n",
    "\n",
    "            eos_mask[:, :beam_size] = ~((~cands_to_ignore) & (~eos_mask[:, :beam_size]))\n",
    "            active_mask = torch.add(\n",
    "                eos_mask.type_as(cand_offsets) * cand_size,\n",
    "                cand_offsets[: eos_mask.size(1)],\n",
    "            )\n",
    "\n",
    "            # get the top beam_size active hypotheses, which are just\n",
    "            # the hypos with the smallest values in active_mask.\n",
    "            # {active_hypos} indicates which {beam_size} hypotheses\n",
    "            # from the list of {2 * beam_size} candidates were\n",
    "            # selected. Shapes: (batch size, beam size)\n",
    "            new_cands_to_ignore, active_hypos = torch.topk(\n",
    "                active_mask, k=beam_size, dim=1, largest=False\n",
    "            )\n",
    "\n",
    "            # update cands_to_ignore to ignore any finalized hypos.\n",
    "            cands_to_ignore = new_cands_to_ignore.ge(cand_size)[:, :beam_size]\n",
    "            # Make sure there is at least one active item for each sentence in the batch.\n",
    "            assert (~cands_to_ignore).any(dim=1).all()\n",
    "\n",
    "            # update cands_to_ignore to ignore any finalized hypos\n",
    "\n",
    "            # {active_bbsz_idx} denotes which beam number is continued for each new hypothesis (a beam\n",
    "            # can be selected more than once).\n",
    "            active_bbsz_idx = torch.gather(cand_bbsz_idx, dim=1, index=active_hypos)\n",
    "            active_scores = torch.gather(cand_scores, dim=1, index=active_hypos)\n",
    "\n",
    "            active_bbsz_idx = active_bbsz_idx.view(-1)\n",
    "            active_scores = active_scores.view(-1)\n",
    "\n",
    "            # copy tokens and scores for active hypotheses\n",
    "\n",
    "            # Set the tokens for each beam (can select the same row more than once)\n",
    "            tokens[:, : step + 1] = torch.index_select(\n",
    "                tokens[:, : step + 1], dim=0, index=active_bbsz_idx\n",
    "            )\n",
    "            # Select the next token for each of them\n",
    "            tokens.view(bsz, beam_size, -1)[:, :, step + 1] = torch.gather(\n",
    "                cand_indices, dim=1, index=active_hypos\n",
    "            )\n",
    "            if step > 0:\n",
    "                scores[:, :step] = torch.index_select(\n",
    "                    scores[:, :step], dim=0, index=active_bbsz_idx\n",
    "                )\n",
    "            scores.view(bsz, beam_size, -1)[:, :, step] = torch.gather(\n",
    "                cand_scores, dim=1, index=active_hypos\n",
    "            )\n",
    "\n",
    "            # Update constraints based on which candidates were selected for the next beam\n",
    "            self.search.update_constraints(active_hypos)\n",
    "\n",
    "            # copy attention for active hypotheses\n",
    "            if attn is not None:\n",
    "                attn[:, :, : step + 2] = torch.index_select(\n",
    "                    attn[:, :, : step + 2], dim=0, index=active_bbsz_idx\n",
    "                )\n",
    "\n",
    "            # reorder incremental state in decoder\n",
    "            reorder_state = active_bbsz_idx\n",
    "\n",
    "        # sort by score descending\n",
    "        for sent in range(len(finalized)):\n",
    "            scores = torch.tensor(\n",
    "                [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
    "            )\n",
    "            _, sorted_scores_indices = torch.sort(scores, descending=True)\n",
    "            finalized[sent] = [finalized[sent][ssi] for ssi in sorted_scores_indices]\n",
    "            finalized[sent] = torch.jit.annotate(\n",
    "                List[Dict[str, Tensor]], finalized[sent]\n",
    "            )\n",
    "        return finalized\n",
    "\n",
    "    def _prefix_tokens(\n",
    "        self, step: int, lprobs, scores, tokens, prefix_tokens, beam_size: int\n",
    "    ):\n",
    "        \"\"\"Handle prefix tokens\"\"\"\n",
    "        prefix_toks = prefix_tokens[:, step].unsqueeze(-1).repeat(1, beam_size).view(-1)\n",
    "        prefix_lprobs = lprobs.gather(-1, prefix_toks.unsqueeze(-1))\n",
    "        prefix_mask = prefix_toks.ne(self.pad)\n",
    "        lprobs[prefix_mask] = torch.tensor(-math.inf).to(lprobs)\n",
    "        lprobs[prefix_mask] = lprobs[prefix_mask].scatter(\n",
    "            -1, prefix_toks[prefix_mask].unsqueeze(-1), prefix_lprobs[prefix_mask]\n",
    "        )\n",
    "        # if prefix includes eos, then we should make sure tokens and\n",
    "        # scores are the same across all beams\n",
    "        eos_mask = prefix_toks.eq(self.eos)\n",
    "        if eos_mask.any():\n",
    "            # validate that the first beam matches the prefix\n",
    "            first_beam = tokens[eos_mask].view(-1, beam_size, tokens.size(-1))[\n",
    "                :, 0, 1 : step + 1\n",
    "            ]\n",
    "            eos_mask_batch_dim = eos_mask.view(-1, beam_size)[:, 0]\n",
    "            target_prefix = prefix_tokens[eos_mask_batch_dim][:, :step]\n",
    "            assert (first_beam == target_prefix).all()\n",
    "\n",
    "            # copy tokens, scores and lprobs from the first beam to all beams\n",
    "            tokens = self.replicate_first_beam(tokens, eos_mask_batch_dim, beam_size)\n",
    "            scores = self.replicate_first_beam(scores, eos_mask_batch_dim, beam_size)\n",
    "            lprobs = self.replicate_first_beam(lprobs, eos_mask_batch_dim, beam_size)\n",
    "        return lprobs, tokens, scores\n",
    "\n",
    "    def replicate_first_beam(self, tensor, mask, beam_size: int):\n",
    "        tensor = tensor.view(-1, beam_size, tensor.size(-1))\n",
    "        tensor[mask] = tensor[mask][:, :1, :]\n",
    "        return tensor.view(-1, tensor.size(-1))\n",
    "\n",
    "    def finalize_hypos(\n",
    "        self,\n",
    "        step: int,\n",
    "        bbsz_idx,\n",
    "        eos_scores,\n",
    "        tokens,\n",
    "        scores,\n",
    "        finalized: List[List[Dict[str, Tensor]]],\n",
    "        finished: List[bool],\n",
    "        beam_size: int,\n",
    "        attn: Optional[Tensor],\n",
    "        src_lengths,\n",
    "        max_len: int,\n",
    "    ):\n",
    "        \"\"\"Finalize hypothesis, store finalized information in `finalized`, and change `finished` accordingly.\n",
    "        A sentence is finalized when {beam_size} finished items have been collected for it.\n",
    "\n",
    "        Returns number of sentences (not beam items) being finalized.\n",
    "        These will be removed from the batch and not processed further.\n",
    "        Args:\n",
    "            bbsz_idx (Tensor):\n",
    "        \"\"\"\n",
    "        assert bbsz_idx.numel() == eos_scores.numel()\n",
    "\n",
    "        # clone relevant token and attention tensors.\n",
    "        # tokens is (batch * beam, max_len). So the index_select\n",
    "        # gets the newly EOS rows, then selects cols 1..{step + 2}\n",
    "        tokens_clone = tokens.index_select(0, bbsz_idx)[\n",
    "            :, 1 : step + 2\n",
    "        ]  # skip the first index, which is EOS\n",
    "\n",
    "        tokens_clone[:, step] = self.eos\n",
    "        attn_clone = (\n",
    "            attn.index_select(0, bbsz_idx)[:, :, 1 : step + 2]\n",
    "            if attn is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # compute scores per token position\n",
    "        pos_scores = scores.index_select(0, bbsz_idx)[:, : step + 1]\n",
    "        pos_scores[:, step] = eos_scores\n",
    "        # convert from cumulative to per-position scores\n",
    "        pos_scores[:, 1:] = pos_scores[:, 1:] - pos_scores[:, :-1]\n",
    "\n",
    "        # normalize sentence-level scores\n",
    "        if self.normalize_scores:\n",
    "            eos_scores /= (step + 1) ** self.len_penalty\n",
    "\n",
    "        # cum_unfin records which sentences in the batch are finished.\n",
    "        # It helps match indexing between (a) the original sentences\n",
    "        # in the batch and (b) the current, possibly-reduced set of\n",
    "        # sentences.\n",
    "        cum_unfin: List[int] = []\n",
    "        prev = 0\n",
    "        for f in finished:\n",
    "            if f:\n",
    "                prev += 1\n",
    "            else:\n",
    "                cum_unfin.append(prev)\n",
    "\n",
    "        # The keys here are of the form \"{sent}_{unfin_idx}\", where\n",
    "        # \"unfin_idx\" is the index in the current (possibly reduced)\n",
    "        # list of sentences, and \"sent\" is the index in the original,\n",
    "        # unreduced batch\n",
    "        # set() is not supported in script export\n",
    "        sents_seen: Dict[str, Optional[Tensor]] = {}\n",
    "\n",
    "        # For every finished beam item\n",
    "        for i in range(bbsz_idx.size()[0]):\n",
    "            idx = bbsz_idx[i]\n",
    "            score = eos_scores[i]\n",
    "            # sentence index in the current (possibly reduced) batch\n",
    "            unfin_idx = idx // beam_size\n",
    "            # sentence index in the original (unreduced) batch\n",
    "            sent = unfin_idx + cum_unfin[unfin_idx]\n",
    "            # Cannot create dict for key type '(int, int)' in torchscript.\n",
    "            # The workaround is to cast int to string\n",
    "            seen = str(sent.item()) + \"_\" + str(unfin_idx.item())\n",
    "            if seen not in sents_seen:\n",
    "                sents_seen[seen] = None\n",
    "\n",
    "            if self.match_source_len and step > src_lengths[unfin_idx]:\n",
    "                score = torch.tensor(-math.inf).to(score)\n",
    "\n",
    "            # An input sentence (among those in a batch) is finished when\n",
    "            # beam_size hypotheses have been collected for it\n",
    "            if len(finalized[sent]) < beam_size:\n",
    "                if attn_clone is not None:\n",
    "                    # remove padding tokens from attn scores\n",
    "                    hypo_attn = attn_clone[i]\n",
    "                else:\n",
    "                    hypo_attn = torch.empty(0)\n",
    "\n",
    "                finalized[sent].append(\n",
    "                    {\n",
    "                        \"tokens\": tokens_clone[i],\n",
    "                        \"score\": score,\n",
    "                        \"attention\": hypo_attn,  # src_len x tgt_len\n",
    "                        \"alignment\": torch.empty(0),\n",
    "                        \"positional_scores\": pos_scores[i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        newly_finished: List[int] = []\n",
    "\n",
    "        for seen in sents_seen.keys():\n",
    "            # check termination conditions for this sentence\n",
    "            sent: int = int(float(seen.split(\"_\")[0]))\n",
    "            unfin_idx: int = int(float(seen.split(\"_\")[1]))\n",
    "\n",
    "            if not finished[sent] and self.is_finished(\n",
    "                step, unfin_idx, max_len, len(finalized[sent]), beam_size\n",
    "            ):\n",
    "                finished[sent] = True\n",
    "                newly_finished.append(unfin_idx)\n",
    "\n",
    "        return newly_finished\n",
    "\n",
    "    def is_finished(\n",
    "        self,\n",
    "        step: int,\n",
    "        unfin_idx: int,\n",
    "        max_len: int,\n",
    "        finalized_sent_len: int,\n",
    "        beam_size: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Check whether decoding for a sentence is finished, which\n",
    "        occurs when the list of finalized sentences has reached the\n",
    "        beam size, or when we reach the maximum length.\n",
    "        \"\"\"\n",
    "        assert finalized_sent_len <= beam_size\n",
    "        if finalized_sent_len == beam_size or step == max_len:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\"A wrapper around an ensemble of models.\"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models_size = len(models)\n",
    "        # method '__len__' is not supported in ModuleList for torch script\n",
    "        self.single_model = models[0]\n",
    "        self.models = nn.ModuleList(models)\n",
    "\n",
    "        self.has_incremental: bool = False\n",
    "        if all(\n",
    "            hasattr(m, \"decoder\") and isinstance(m.decoder, FairseqIncrementalDecoder)\n",
    "            for m in models\n",
    "        ):\n",
    "            self.has_incremental = True\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def has_encoder(self):\n",
    "        return hasattr(self.single_model, \"encoder\")\n",
    "\n",
    "    def has_incremental_states(self):\n",
    "        return self.has_incremental\n",
    "\n",
    "    def max_decoder_positions(self):\n",
    "        return min([m.max_decoder_positions() for m in self.models])\n",
    "\n",
    "    @torch.jit.export\n",
    "    def forward_encoder(self, net_input: Dict[str, Tensor]):\n",
    "        if not self.has_encoder():\n",
    "            return None\n",
    "        return [model.encoder.forward_torchscript(net_input) for model in self.models]\n",
    "\n",
    "    @torch.jit.export\n",
    "    def forward_decoder(\n",
    "        self,\n",
    "        tokens,\n",
    "        encoder_outs: List[Dict[str, List[Tensor]]],\n",
    "        incremental_states: List[Dict[str, Dict[str, Optional[Tensor]]]],\n",
    "        temperature: float = 1.0,\n",
    "    ):\n",
    "        log_probs = []\n",
    "        avg_attn: Optional[Tensor] = None\n",
    "        encoder_out: Optional[Dict[str, List[Tensor]]] = None\n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.has_encoder():\n",
    "                encoder_out = encoder_outs[i]\n",
    "            # decode each model\n",
    "            if self.has_incremental_states():\n",
    "                decoder_out = model.decoder.forward(\n",
    "                    tokens,\n",
    "                    encoder_out=encoder_out,\n",
    "                    incremental_state=incremental_states[i],\n",
    "                )\n",
    "            else:\n",
    "                decoder_out = model.decoder.forward(tokens, encoder_out=encoder_out)\n",
    "\n",
    "            attn: Optional[Tensor] = None\n",
    "            decoder_len = len(decoder_out)\n",
    "            if decoder_len > 1 and decoder_out[1] is not None:\n",
    "                if isinstance(decoder_out[1], Tensor):\n",
    "                    attn = decoder_out[1]\n",
    "                else:\n",
    "                    attn_holder = decoder_out[1][\"attn\"]\n",
    "                    if isinstance(attn_holder, Tensor):\n",
    "                        attn = attn_holder\n",
    "                    elif attn_holder is not None:\n",
    "                        attn = attn_holder[0]\n",
    "                if attn is not None:\n",
    "                    attn = attn[:, -1, :]\n",
    "\n",
    "            decoder_out_tuple = (\n",
    "                decoder_out[0][:, -1:, :].div_(temperature),\n",
    "                None if decoder_len <= 1 else decoder_out[1],\n",
    "            )\n",
    "\n",
    "            probs = model.get_normalized_probs(\n",
    "                decoder_out_tuple, log_probs=True, sample=None\n",
    "            )\n",
    "            probs = probs[:, -1, :]\n",
    "            if self.models_size == 1:\n",
    "                return probs, attn\n",
    "\n",
    "            log_probs.append(probs)\n",
    "            if attn is not None:\n",
    "                if avg_attn is None:\n",
    "                    avg_attn = attn\n",
    "                else:\n",
    "                    avg_attn.add_(attn)\n",
    "\n",
    "        avg_probs = torch.logsumexp(torch.stack(log_probs, dim=0), dim=0) - math.log(\n",
    "            self.models_size\n",
    "        )\n",
    "\n",
    "        if avg_attn is not None:\n",
    "            avg_attn.div_(self.models_size)\n",
    "        return avg_probs, avg_attn\n",
    "\n",
    "    @torch.jit.export\n",
    "    def reorder_encoder_out(\n",
    "        self, encoder_outs: Optional[List[Dict[str, List[Tensor]]]], new_order\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Reorder encoder output according to *new_order*.\n",
    "\n",
    "        Args:\n",
    "            encoder_out: output from the ``forward()`` method\n",
    "            new_order (LongTensor): desired order\n",
    "\n",
    "        Returns:\n",
    "            *encoder_out* rearranged according to *new_order*\n",
    "        \"\"\"\n",
    "        new_outs: List[Dict[str, List[Tensor]]] = []\n",
    "        if not self.has_encoder():\n",
    "            return new_outs\n",
    "        for i, model in enumerate(self.models):\n",
    "            assert encoder_outs is not None\n",
    "            new_outs.append(\n",
    "                model.encoder.reorder_encoder_out(encoder_outs[i], new_order)\n",
    "            )\n",
    "        return new_outs\n",
    "\n",
    "    @torch.jit.export\n",
    "    def reorder_incremental_state(\n",
    "        self,\n",
    "        incremental_states: List[Dict[str, Dict[str, Optional[Tensor]]]],\n",
    "        new_order,\n",
    "    ):\n",
    "        if not self.has_incremental_states():\n",
    "            return\n",
    "        for i, model in enumerate(self.models):\n",
    "            model.decoder.reorder_incremental_state_scripting(\n",
    "                incremental_states[i], new_order\n",
    "            )\n",
    "\n",
    "\n",
    "class SequenceGeneratorWithAlignment(SequenceGenerator):\n",
    "    def __init__(\n",
    "        self, models, tgt_dict, left_pad_target=False, print_alignment=\"hard\", **kwargs\n",
    "    ):\n",
    "        \"\"\"Generates translations of a given source sentence.\n",
    "\n",
    "        Produces alignments following \"Jointly Learning to Align and\n",
    "        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n",
    "\n",
    "        Args:\n",
    "            left_pad_target (bool, optional): Whether or not the\n",
    "                hypothesis should be left padded or not when they are\n",
    "                teacher forced for generating alignments.\n",
    "        \"\"\"\n",
    "        super().__init__(EnsembleModelWithAlignment(models), tgt_dict, **kwargs)\n",
    "        self.left_pad_target = left_pad_target\n",
    "\n",
    "        if print_alignment == \"hard\":\n",
    "            self.extract_alignment = utils.extract_hard_alignment\n",
    "        elif print_alignment == \"soft\":\n",
    "            self.extract_alignment = utils.extract_soft_alignment\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, models, sample, **kwargs):\n",
    "        finalized = super()._generate(sample, **kwargs)\n",
    "\n",
    "        src_tokens = sample[\"net_input\"][\"src_tokens\"]\n",
    "        bsz = src_tokens.shape[0]\n",
    "        beam_size = self.beam_size\n",
    "        (\n",
    "            src_tokens,\n",
    "            src_lengths,\n",
    "            prev_output_tokens,\n",
    "            tgt_tokens,\n",
    "        ) = self._prepare_batch_for_alignment(sample, finalized)\n",
    "        if any(getattr(m, \"full_context_alignment\", False) for m in self.model.models):\n",
    "            attn = self.model.forward_align(src_tokens, src_lengths, prev_output_tokens)\n",
    "        else:\n",
    "            attn = [\n",
    "                finalized[i // beam_size][i % beam_size][\"attention\"].transpose(1, 0)\n",
    "                for i in range(bsz * beam_size)\n",
    "            ]\n",
    "\n",
    "        if src_tokens.device != \"cpu\":\n",
    "            src_tokens = src_tokens.to(\"cpu\")\n",
    "            tgt_tokens = tgt_tokens.to(\"cpu\")\n",
    "            attn = [i.to(\"cpu\") for i in attn]\n",
    "\n",
    "        # Process the attn matrix to extract hard alignments.\n",
    "        for i in range(bsz * beam_size):\n",
    "            alignment = self.extract_alignment(\n",
    "                attn[i], src_tokens[i], tgt_tokens[i], self.pad, self.eos\n",
    "            )\n",
    "            finalized[i // beam_size][i % beam_size][\"alignment\"] = alignment\n",
    "        return finalized\n",
    "\n",
    "    def _prepare_batch_for_alignment(self, sample, hypothesis):\n",
    "        src_tokens = sample[\"net_input\"][\"src_tokens\"]\n",
    "        bsz = src_tokens.shape[0]\n",
    "        src_tokens = (\n",
    "            src_tokens[:, None, :]\n",
    "            .expand(-1, self.beam_size, -1)\n",
    "            .contiguous()\n",
    "            .view(bsz * self.beam_size, -1)\n",
    "        )\n",
    "        src_lengths = sample[\"net_input\"][\"src_lengths\"]\n",
    "        src_lengths = (\n",
    "            src_lengths[:, None]\n",
    "            .expand(-1, self.beam_size)\n",
    "            .contiguous()\n",
    "            .view(bsz * self.beam_size)\n",
    "        )\n",
    "        prev_output_tokens = data_utils.collate_tokens(\n",
    "            [beam[\"tokens\"] for example in hypothesis for beam in example],\n",
    "            self.pad,\n",
    "            self.eos,\n",
    "            self.left_pad_target,\n",
    "            move_eos_to_beginning=True,\n",
    "        )\n",
    "        tgt_tokens = data_utils.collate_tokens(\n",
    "            [beam[\"tokens\"] for example in hypothesis for beam in example],\n",
    "            self.pad,\n",
    "            self.eos,\n",
    "            self.left_pad_target,\n",
    "            move_eos_to_beginning=False,\n",
    "        )\n",
    "        return src_tokens, src_lengths, prev_output_tokens, tgt_tokens\n",
    "\n",
    "\n",
    "class EnsembleModelWithAlignment(EnsembleModel):\n",
    "    \"\"\"A wrapper around an ensemble of models.\"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        super().__init__(models)\n",
    "\n",
    "    def forward_align(self, src_tokens, src_lengths, prev_output_tokens):\n",
    "        avg_attn = None\n",
    "        for model in self.models:\n",
    "            decoder_out = model(src_tokens, src_lengths, prev_output_tokens)\n",
    "            attn = decoder_out[1][\"attn\"][0]\n",
    "            if avg_attn is None:\n",
    "                avg_attn = attn\n",
    "            else:\n",
    "                avg_attn.add_(attn)\n",
    "        if len(self.models) > 1:\n",
    "            avg_attn.div_(len(self.models))\n",
    "        return avg_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv sequence_generator.py /home/petrakov/mGENRE_MEL/fairseq/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENRE.genre.trie import Trie, MarisaTrie\n",
    "from GENRE.genre.fairseq_model import mGENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Wikipedia titles and language IDs\n",
    "model_mGENRE_mcdropout = mGENRE.from_pretrained(\"fairseq_multilingual_entity_disambiguation\",\n",
    "                                                dropout = 0.1, attention_dropout = 0.1)\n",
    "\n",
    "#model_mGENRE_mcdropout.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mGENRE_mcdropout.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'id': 'Q1048', 'texts': ['Julius Caesar >> en', 'Caesar >> en'], 'scores': tensor([-0.2018, -0.9764]), 'score': tensor(-0.2502)}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.3158]), 'score': tensor(-0.8354)}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q1048', 'texts': ['Julius Caesar >> en', 'Caesar >> en'], 'scores': tensor([-0.3122, -0.5796]), 'score': tensor(-0.2092)}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.4082]), 'score': tensor(-1.0799)}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q1048', 'texts': ['Julius Caesar >> en', 'Caesar >> en'], 'scores': tensor([-0.3461, -0.4608]), 'score': tensor(-0.1519)}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.3920]), 'score': tensor(-1.0372)}]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(3):\n",
    "    random.seed(i)\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    print(model_mGENRE_mcdropout.sample([\"[START] Caesar [END] is well known Roman imperor\"],\n",
    "                                  beam = 3,\n",
    "                                  prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                      e for e in trie.get(sent.tolist())\n",
    "                                      if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                  ],\n",
    "                                  text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                  marginalize=True,\n",
    "                                  verbose = True,\n",
    "                                  seed = i))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "all_results = []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    random.seed(i)\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    all_results.append(model_mGENRE_mcdropout.sample([\"[START] Caesar [END] is well known Roman imperor\"],\n",
    "                                  beam = 10,\n",
    "                                  prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                      e for e in trie.get(sent.tolist())\n",
    "                                      if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                  ],\n",
    "                                  text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                  marginalize=True,\n",
    "                                  verbose = True,\n",
    "                                  seed = i))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mGENRE_mcdropout.models[0].training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probs = np.exp([i['score'] for i in all_results[0][0]])/(np.sum(np.exp([i['score'] for i in all_results[0][0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.420323"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4203228950500488"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy formula\n",
    "#(-1)*np.sum(probs * np.log(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>property</th>\n",
       "      <th>subject</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3899</td>\n",
       "      <td>Q81520</td>\n",
       "      <td>R162</td>\n",
       "      <td>Q1198273</td>\n",
       "      <td>What is a movie pierce brosnan produced?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16574</td>\n",
       "      <td>Q1955547</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q11399</td>\n",
       "      <td>What kind of music is featured on ten new songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5542</td>\n",
       "      <td>Q437267</td>\n",
       "      <td>R58</td>\n",
       "      <td>Q7764575</td>\n",
       "      <td>which episode was written by chris carter (scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14297</td>\n",
       "      <td>Q140003</td>\n",
       "      <td>P31</td>\n",
       "      <td>Q3863</td>\n",
       "      <td>What kind of celestial object is 1495 helsinki?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>Q5107639</td>\n",
       "      <td>P21</td>\n",
       "      <td>Q6581097</td>\n",
       "      <td>what is chris offutt's gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14778</td>\n",
       "      <td>Q49085</td>\n",
       "      <td>R172</td>\n",
       "      <td>Q1366768</td>\n",
       "      <td>Who is an african american character actor and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19337</td>\n",
       "      <td>Q36180</td>\n",
       "      <td>R106</td>\n",
       "      <td>Q7611841</td>\n",
       "      <td>Name a professional writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12346</td>\n",
       "      <td>Q1290008</td>\n",
       "      <td>P27</td>\n",
       "      <td>Q183</td>\n",
       "      <td>Which country is marcel landers from?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11977</td>\n",
       "      <td>Q2086913</td>\n",
       "      <td>R421</td>\n",
       "      <td>Q79497</td>\n",
       "      <td>what is an example of a city that can be found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1124</td>\n",
       "      <td>Q81224</td>\n",
       "      <td>P364</td>\n",
       "      <td>Q1860</td>\n",
       "      <td>In what language was inside man filmed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6020</td>\n",
       "      <td>Q657079</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q959790</td>\n",
       "      <td>what genre is serpico in?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18723</td>\n",
       "      <td>Q4891173</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q183504</td>\n",
       "      <td>What type of music is bobby kildea known for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>Q3046415</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q36312</td>\n",
       "      <td>what was earle birney's birth place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>Q1754902</td>\n",
       "      <td>P175</td>\n",
       "      <td>Q332399</td>\n",
       "      <td>who created the album the traveling wilburys c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4166</td>\n",
       "      <td>Q7361998</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q11366</td>\n",
       "      <td>What kind of music does roman holiday record?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4839</td>\n",
       "      <td>Q2716211</td>\n",
       "      <td>P404</td>\n",
       "      <td>Q208850</td>\n",
       "      <td>What game play mode is the computer video game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3095</td>\n",
       "      <td>Q382442</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q104740</td>\n",
       "      <td>Where exactly was marian goliski born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17793</td>\n",
       "      <td>Q4690530</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q1530455</td>\n",
       "      <td>what type of album is after hours at the londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>Q7519734</td>\n",
       "      <td>P27</td>\n",
       "      <td>Q145</td>\n",
       "      <td>what nationality is simon scardifield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3231</td>\n",
       "      <td>Q3286556</td>\n",
       "      <td>R58</td>\n",
       "      <td>Q3235297</td>\n",
       "      <td>What film did mansoor khan contribute to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14785</td>\n",
       "      <td>Q2232344</td>\n",
       "      <td>P421</td>\n",
       "      <td>Q2086913</td>\n",
       "      <td>what time zone is lindstrom in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>Q16608398</td>\n",
       "      <td>P21</td>\n",
       "      <td>Q6581097</td>\n",
       "      <td>what is mohamed safwat's gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15112</td>\n",
       "      <td>Q1393583</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q365</td>\n",
       "      <td>which german city is faiz kevin mangat from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15953</td>\n",
       "      <td>Q7852400</td>\n",
       "      <td>P27</td>\n",
       "      <td>Q668</td>\n",
       "      <td>What nation is tulsi ramsay from?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18921</td>\n",
       "      <td>Q15854664</td>\n",
       "      <td>P20</td>\n",
       "      <td>Q34006</td>\n",
       "      <td>Where did william hedgcock die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>Q7561913</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q340</td>\n",
       "      <td>what is sonja skarstedt's place of birth?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15179</td>\n",
       "      <td>Q1492</td>\n",
       "      <td>R19</td>\n",
       "      <td>Q1396516</td>\n",
       "      <td>who is someone born in barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11018</td>\n",
       "      <td>Q1704657</td>\n",
       "      <td>P413</td>\n",
       "      <td>Q273199</td>\n",
       "      <td>What position does uro tripkovi play?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16050</td>\n",
       "      <td>Q737645</td>\n",
       "      <td>P172</td>\n",
       "      <td>Q932244</td>\n",
       "      <td>what's kumar sangakkara's ethnicity?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16769</td>\n",
       "      <td>Q452166</td>\n",
       "      <td>R175</td>\n",
       "      <td>Q6120364</td>\n",
       "      <td>What is an album that was released by marc alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1183</td>\n",
       "      <td>Q1799822</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q1055</td>\n",
       "      <td>Which city was thilo kleibauer born in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4677</td>\n",
       "      <td>Q2579013</td>\n",
       "      <td>R40</td>\n",
       "      <td>Q3569866</td>\n",
       "      <td>who is a parent of casey johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9531</td>\n",
       "      <td>Q183387</td>\n",
       "      <td>R264</td>\n",
       "      <td>Q3013096</td>\n",
       "      <td>which artist records under columbia records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10681</td>\n",
       "      <td>Q294927</td>\n",
       "      <td>R58</td>\n",
       "      <td>Q1192737</td>\n",
       "      <td>Name a film written by jerry lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4409</td>\n",
       "      <td>Q1190398</td>\n",
       "      <td>P31</td>\n",
       "      <td>Q3863</td>\n",
       "      <td>What is 10161 nakanoshima classified as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3764</td>\n",
       "      <td>Q2578690</td>\n",
       "      <td>P179</td>\n",
       "      <td>Q886</td>\n",
       "      <td>what series has the episode rosebud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16158</td>\n",
       "      <td>Q838544</td>\n",
       "      <td>R264</td>\n",
       "      <td>Q417451</td>\n",
       "      <td>which artist records under the earache records...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6192</td>\n",
       "      <td>Q8341</td>\n",
       "      <td>R136</td>\n",
       "      <td>Q7721746</td>\n",
       "      <td>This jazz was released in 1959.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17207</td>\n",
       "      <td>Q137358</td>\n",
       "      <td>P397</td>\n",
       "      <td>Q525</td>\n",
       "      <td>what does 1255 schilowa orbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2302</td>\n",
       "      <td>Q869106</td>\n",
       "      <td>R123</td>\n",
       "      <td>Q2758526</td>\n",
       "      <td>what games were published by ea sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          object property   subject  \\\n",
       "3899      Q81520     R162  Q1198273   \n",
       "16574   Q1955547     P136    Q11399   \n",
       "5542     Q437267      R58  Q7764575   \n",
       "14297    Q140003      P31     Q3863   \n",
       "741     Q5107639      P21  Q6581097   \n",
       "14778     Q49085     R172  Q1366768   \n",
       "19337     Q36180     R106  Q7611841   \n",
       "12346   Q1290008      P27      Q183   \n",
       "11977   Q2086913     R421    Q79497   \n",
       "1124      Q81224     P364     Q1860   \n",
       "6020     Q657079     P136   Q959790   \n",
       "18723   Q4891173     P136   Q183504   \n",
       "11300   Q3046415      P19    Q36312   \n",
       "567     Q1754902     P175   Q332399   \n",
       "4166    Q7361998     P136    Q11366   \n",
       "4839    Q2716211     P404   Q208850   \n",
       "3095     Q382442      P19   Q104740   \n",
       "17793   Q4690530     P136  Q1530455   \n",
       "387     Q7519734      P27      Q145   \n",
       "3231    Q3286556      R58  Q3235297   \n",
       "14785   Q2232344     P421  Q2086913   \n",
       "618    Q16608398      P21  Q6581097   \n",
       "15112   Q1393583      P19      Q365   \n",
       "15953   Q7852400      P27      Q668   \n",
       "18921  Q15854664      P20    Q34006   \n",
       "3810    Q7561913      P19      Q340   \n",
       "15179      Q1492      R19  Q1396516   \n",
       "11018   Q1704657     P413   Q273199   \n",
       "16050    Q737645     P172   Q932244   \n",
       "16769    Q452166     R175  Q6120364   \n",
       "1183    Q1799822      P19     Q1055   \n",
       "4677    Q2579013      R40  Q3569866   \n",
       "9531     Q183387     R264  Q3013096   \n",
       "10681    Q294927      R58  Q1192737   \n",
       "4409    Q1190398      P31     Q3863   \n",
       "3764    Q2578690     P179      Q886   \n",
       "16158    Q838544     R264   Q417451   \n",
       "6192       Q8341     R136  Q7721746   \n",
       "17207    Q137358     P397      Q525   \n",
       "2302     Q869106     R123  Q2758526   \n",
       "\n",
       "                                                question  \n",
       "3899            What is a movie pierce brosnan produced?  \n",
       "16574    What kind of music is featured on ten new songs  \n",
       "5542   which episode was written by chris carter (scr...  \n",
       "14297    What kind of celestial object is 1495 helsinki?  \n",
       "741                       what is chris offutt's gender   \n",
       "14778  Who is an african american character actor and...  \n",
       "19337                         Name a professional writer  \n",
       "12346              Which country is marcel landers from?  \n",
       "11977  what is an example of a city that can be found...  \n",
       "1124             In what language was inside man filmed?  \n",
       "6020                           what genre is serpico in?  \n",
       "18723       What type of music is bobby kildea known for  \n",
       "11300                what was earle birney's birth place  \n",
       "567    who created the album the traveling wilburys c...  \n",
       "4166       What kind of music does roman holiday record?  \n",
       "4839   What game play mode is the computer video game...  \n",
       "3095              Where exactly was marian goliski born  \n",
       "17793  what type of album is after hours at the londo...  \n",
       "387                what nationality is simon scardifield  \n",
       "3231           What film did mansoor khan contribute to?  \n",
       "14785                     what time zone is lindstrom in  \n",
       "618                      what is mohamed safwat's gender  \n",
       "15112        which german city is faiz kevin mangat from  \n",
       "15953                  What nation is tulsi ramsay from?  \n",
       "18921                     Where did william hedgcock die  \n",
       "3810           what is sonja skarstedt's place of birth?  \n",
       "15179                   who is someone born in barcelona  \n",
       "11018            What position does uro tripkovi play?  \n",
       "16050               what's kumar sangakkara's ethnicity?  \n",
       "16769  What is an album that was released by marc alm...  \n",
       "1183              Which city was thilo kleibauer born in  \n",
       "4677                    who is a parent of casey johnson  \n",
       "9531         which artist records under columbia records  \n",
       "10681                 Name a film written by jerry lewis  \n",
       "4409             What is 10161 nakanoshima classified as  \n",
       "3764                 what series has the episode rosebud  \n",
       "16158  which artist records under the earache records...  \n",
       "6192                     This jazz was released in 1959.  \n",
       "17207                      what does 1255 schilowa orbit  \n",
       "2302              what games were published by ea sports  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 40\n",
    "\n",
    "\n",
    "df = data.sample(n = n, replace = False, random_state=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mGENRE_mcdropout_result = model_mGENRE_mcdropout.sample(list(df['question']),\n",
    "                                                              beam = 5,\n",
    "                                                              prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                                                  e for e in trie.get(sent.tolist())\n",
    "                                                                  if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                                              ],\n",
    "                                                              text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                                              marginalize=True,\n",
    "                                                              verbose = True,\n",
    "                                                              seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(np.array([np.array([i['score']for i in model_mGENRE_mcdropout_result[j]]) for j in range(len(model_mGENRE_mcdropout_result))]))\n",
    "probs_for_examples = [i.tolist() for i in a]\n",
    "quants = [thresh/9 for thresh in range(1, 10)]\n",
    "entropies = [scipy.stats.entropy(i) for i in probs_for_examples]\n",
    "thresholds = [np.quantile([scipy.stats.entropy(i) for i in probs_for_examples], q) for q in quants]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  0.77 \t accuracy =  80.00 %\t number of observations =  5 \t share of observations =  12.50 %\n",
      "threshold =  1.08 \t accuracy =  66.67 %\t number of observations =  9 \t share of observations =  22.50 %\n",
      "threshold =  1.27 \t accuracy =  46.15 %\t number of observations =  13 \t share of observations =  32.50 %\n",
      "threshold =  1.34 \t accuracy =  38.89 %\t number of observations =  18 \t share of observations =  45.00 %\n",
      "threshold =  1.48 \t accuracy =  31.82 %\t number of observations =  22 \t share of observations =  55.00 %\n",
      "threshold =  1.57 \t accuracy =  30.77 %\t number of observations =  26 \t share of observations =  65.00 %\n",
      "threshold =  1.58 \t accuracy =  25.81 %\t number of observations =  31 \t share of observations =  77.50 %\n",
      "threshold =  1.60 \t accuracy =  25.71 %\t number of observations =  35 \t share of observations =  87.50 %\n",
      "threshold =  1.61 \t accuracy =  25.64 %\t number of observations =  39 \t share of observations =  97.50 %\n"
     ]
    }
   ],
   "source": [
    "predictions = [i[0]['id'] for i in model_mGENRE_mcdropout_result]\n",
    "accuracy_entropy_40 = []\n",
    "share_of_observations_entropy_40 = []\n",
    "\n",
    "for threshold in thresholds[:]:\n",
    "    \n",
    "    \n",
    "    list_a = list(range(40))\n",
    "    fil = entropies < threshold\n",
    "    \n",
    "    \n",
    "    y_pred = list(compress(predictions, fil))\n",
    "    y_true = list(df.reset_index().iloc[list(compress(list_a, fil)),:][\"object\"])\n",
    "    \n",
    "    result = [x in y_pred for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 4)*100\n",
    "    accuracy_entropy_40.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 4)\n",
    "    share_of_observations_entropy_40.append(share)\n",
    "    \n",
    "    print(\"threshold = \", format(threshold, '.2f'), \"\\t\",\n",
    "          \"accuracy = \", format(accuracy, '.2f'), \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \",  format(share, '.2f'), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.title(\"mGENRE uncertainty using entropy basing on 40 examples\")\n",
    "plt.plot(share_of_observations_entropy_40[::-1], accuracy_entropy_40, marker = '.', markersize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "part  0  done!\n",
      "\n",
      "\n",
      "part  1  done!\n",
      "\n",
      "\n",
      "part  2  done!\n",
      "\n",
      "\n",
      "part  3  done!\n",
      "\n",
      "\n",
      "part  4  done!\n",
      "\n",
      "\n",
      "part  5  done!\n",
      "\n",
      "\n",
      "part  6  done!\n",
      "\n",
      "\n",
      "part  7  done!\n",
      "\n",
      "\n",
      "part  8  done!\n",
      "\n",
      "\n",
      "part  9  done!\n",
      "\n",
      "\n",
      "part  10  done!\n",
      "\n",
      "\n",
      "part  11  done!\n",
      "\n",
      "\n",
      "part  12  done!\n",
      "\n",
      "\n",
      "part  13  done!\n",
      "\n",
      "\n",
      "part  14  done!\n",
      "\n",
      "\n",
      "part  15  done!\n",
      "\n",
      "\n",
      "part  16  done!\n",
      "\n",
      "\n",
      "part  17  done!\n",
      "\n",
      "\n",
      "part  18  done!\n",
      "\n",
      "\n",
      "part  19  done!\n",
      "Duration: 0:46:13.297494\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "start_time = datetime.now()\n",
    "\n",
    "divider = 20\n",
    "\n",
    "mGENRE_results_entropy = []\n",
    "for i in range(divider):\n",
    "    random.seed(i)\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    mGENRE_results_entropy.append(model_mGENRE_mcdropout.sample(list(data.sample(n = 50, replace = False, random_state=i).loc[:, \"question\"]),\n",
    "                                  beam = 10,\n",
    "                                  prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                      e for e in trie.get(sent.tolist())\n",
    "                                      if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                  ],\n",
    "                                  text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                  marginalize=True,\n",
    "                                  verbose = True,\n",
    "                                  seed = i))\n",
    "    print(\"\\n\")\n",
    "    print(\"part \", i, \" done!\")\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_1000_entropy = []\n",
    "for i in range(divider): \n",
    "    objects_1000_entropy.append(list(data.sample(n = 50, replace = False, random_state=i).loc[:, \"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_1000_entropy = sum(objects_1000_entropy, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "mGENRE_results_entropy = sum(mGENRE_results_entropy, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(np.array([np.array([i['score']for i in mGENRE_results_entropy[j]]) for j in range(len(mGENRE_results_entropy))]))\n",
    "probs_for_examples = [i.tolist() for i in a]\n",
    "quants = [thresh/9 for thresh in range(1, 10)]\n",
    "entropies = [scipy.stats.entropy(i) for i in probs_for_examples]\n",
    "thresholds = [np.quantile([scipy.stats.entropy(i) for i in probs_for_examples], q) for q in quants]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  1.92 \t accuracy =  50.45 %\t number of observations =  111 \t share of observations =  11.10 %\n",
      "threshold =  2.05 \t accuracy =  41.44 %\t number of observations =  222 \t share of observations =  22.20 %\n",
      "threshold =  2.14 \t accuracy =  37.54 %\t number of observations =  333 \t share of observations =  33.30 %\n",
      "threshold =  2.17 \t accuracy =  34.23 %\t number of observations =  444 \t share of observations =  44.40 %\n",
      "threshold =  2.23 \t accuracy =  30.27 %\t number of observations =  555 \t share of observations =  55.50 %\n",
      "threshold =  2.27 \t accuracy =  28.68 %\t number of observations =  666 \t share of observations =  66.60 %\n",
      "threshold =  2.28 \t accuracy =  26.00 %\t number of observations =  777 \t share of observations =  77.70 %\n",
      "threshold =  2.29 \t accuracy =  23.99 %\t number of observations =  888 \t share of observations =  88.80 %\n",
      "threshold =  2.30 \t accuracy =  21.82 %\t number of observations =  999 \t share of observations =  99.90 %\n"
     ]
    }
   ],
   "source": [
    "predictions = [i[0]['id'] for i in mGENRE_results_entropy]\n",
    "accuracy_entropy_1000 = []\n",
    "share_of_observations_entropy_1000 = []\n",
    "\n",
    "for threshold in thresholds[:]:\n",
    "    \n",
    "    \n",
    "    list_a = list(range(1000))\n",
    "    fil = entropies < threshold\n",
    "    \n",
    "    \n",
    "    y_pred = list(compress(predictions, fil))\n",
    "    y_true = list(compress(objects_1000_entropy, fil))\n",
    "    \n",
    "    result = [x in y_pred for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 4)*100\n",
    "    accuracy_entropy_1000.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 4)\n",
    "    share_of_observations_entropy_1000.append(share)\n",
    "    \n",
    "    print(\"threshold = \", format(threshold, '.2f'), \"\\t\",\n",
    "          \"accuracy = \", format(accuracy, '.2f'), \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \",  format(share, '.2f'), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.title(\"mGENRE uncertainty using entropy basing on 1000 examples\")\n",
    "plt.plot(share_of_observations_entropy_1000[::-1], accuracy_entropy_1000, marker = '.', markersize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NER:\n",
    "    def __init__(self, \n",
    "                 #text, \n",
    "                 model = \"Babelscape/wikineural-multilingual-ner\",\n",
    "                 tokenizer = \"Babelscape/wikineural-multilingual-ner\"):\n",
    "        \n",
    "        #self.text = text\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def set_pipeline(self):   \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model)\n",
    "        self.nlp = pipeline(\"ner\",\n",
    "                            model = self.model,\n",
    "                            tokenizer = self.tokenizer)\n",
    "        \n",
    "    def receive_text(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def receive_words(self):\n",
    "        self.text = re.sub('[!@#$?,]', '', self.text)\n",
    "        out = re.split(r' ', self.text)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def receive_enitity(self):\n",
    "        ner_results = self.nlp(self.text)\n",
    "        final = []\n",
    "        result = [i[\"word\"] for i in ner_results]\n",
    "        print(result)\n",
    "        for elem in result:    \n",
    "            if (elem[:2] == \"##\") & (len(final) > 0):\n",
    "                final[-1] = final[-1] + elem[2:]\n",
    "            elif (elem[:2] == \"##\") & (len(final) == 0):\n",
    "                final.append(elem[2:])\n",
    "            else:\n",
    "                final.append(elem)\n",
    "        return final\n",
    "    \n",
    "    def text_with_marked_entities(self):\n",
    "        output = \"\"\n",
    "        entities = self.receive_enitity()\n",
    "        list_of_words = self.receive_words()\n",
    "        for word in list_of_words:\n",
    "            if word not in entities:\n",
    "                output = output + word + \" \"\n",
    "            else:\n",
    "                output = output + \"[START] \" + word +  \" [END] \"\n",
    "        output = re.sub(\"\\[END\\] \\[START\\] \", \"\", output)\n",
    "        output += \"?\"\n",
    "        return output\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>property</th>\n",
       "      <th>subject</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q12439</td>\n",
       "      <td>R19</td>\n",
       "      <td>Q6106580</td>\n",
       "      <td>who is a musician born in detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q6817891</td>\n",
       "      <td>P364</td>\n",
       "      <td>Q1568</td>\n",
       "      <td>what is the language in which mera shikar was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q1297</td>\n",
       "      <td>R276</td>\n",
       "      <td>Q2888523</td>\n",
       "      <td>Whats the name of a battle that happened in ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q193592</td>\n",
       "      <td>R413</td>\n",
       "      <td>Q5822614</td>\n",
       "      <td>what player plays the position midfielder?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q6849115</td>\n",
       "      <td>P413</td>\n",
       "      <td>Q336286</td>\n",
       "      <td>what is the position that  mike twellman plays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Q842256</td>\n",
       "      <td>R136</td>\n",
       "      <td>Q5962341</td>\n",
       "      <td>list some musical films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Q7273</td>\n",
       "      <td>P27</td>\n",
       "      <td>Q30</td>\n",
       "      <td>what is ellen swallow richards's nationality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Q247643</td>\n",
       "      <td>P364</td>\n",
       "      <td>Q1860</td>\n",
       "      <td>What language is the show elementary broadcast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Q6135854</td>\n",
       "      <td>P21</td>\n",
       "      <td>Q6581097</td>\n",
       "      <td>what is the gender of james hendry?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Q2405480</td>\n",
       "      <td>R106</td>\n",
       "      <td>Q231891</td>\n",
       "      <td>who was a voice actor?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Q145410</td>\n",
       "      <td>P196</td>\n",
       "      <td>Q2179</td>\n",
       "      <td>What is a member of the 1893 jakoba asteroid g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Q4921907</td>\n",
       "      <td>P175</td>\n",
       "      <td>Q358342</td>\n",
       "      <td>What artist includes black star at the point o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Q1698</td>\n",
       "      <td>R175</td>\n",
       "      <td>Q3048951</td>\n",
       "      <td>Name an album by serge gainsbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Q237514</td>\n",
       "      <td>R50</td>\n",
       "      <td>Q4657824</td>\n",
       "      <td>what is a book by laura ingalls wilder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Q388408</td>\n",
       "      <td>P344</td>\n",
       "      <td>Q1177096</td>\n",
       "      <td>Who was the cinematographer for the film endle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Q93204</td>\n",
       "      <td>R136</td>\n",
       "      <td>Q7248510</td>\n",
       "      <td>what is a documentary film about the media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Q3643721</td>\n",
       "      <td>P136</td>\n",
       "      <td>Q183504</td>\n",
       "      <td>what musical genre does  brandon reilly create</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Q7063408</td>\n",
       "      <td>P641</td>\n",
       "      <td>Q5372</td>\n",
       "      <td>What sport does notre dame fighting irish men'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Q71277</td>\n",
       "      <td>P19</td>\n",
       "      <td>Q64</td>\n",
       "      <td>where in germany was rudi ball born in?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Q101625</td>\n",
       "      <td>P421</td>\n",
       "      <td>Q843589</td>\n",
       "      <td>what time zone is marrakech in?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      object property   subject  \\\n",
       "0     Q12439      R19  Q6106580   \n",
       "1   Q6817891     P364     Q1568   \n",
       "2      Q1297     R276  Q2888523   \n",
       "3    Q193592     R413  Q5822614   \n",
       "4   Q6849115     P413   Q336286   \n",
       "5    Q842256     R136  Q5962341   \n",
       "6      Q7273      P27       Q30   \n",
       "7    Q247643     P364     Q1860   \n",
       "8   Q6135854      P21  Q6581097   \n",
       "9   Q2405480     R106   Q231891   \n",
       "10   Q145410     P196     Q2179   \n",
       "11  Q4921907     P175   Q358342   \n",
       "12     Q1698     R175  Q3048951   \n",
       "13   Q237514      R50  Q4657824   \n",
       "14   Q388408     P344  Q1177096   \n",
       "15    Q93204     R136  Q7248510   \n",
       "16  Q3643721     P136   Q183504   \n",
       "17  Q7063408     P641     Q5372   \n",
       "18    Q71277      P19       Q64   \n",
       "19   Q101625     P421   Q843589   \n",
       "\n",
       "                                             question  \n",
       "0                   who is a musician born in detroit  \n",
       "1   what is the language in which mera shikar was ...  \n",
       "2   Whats the name of a battle that happened in ch...  \n",
       "3          what player plays the position midfielder?  \n",
       "4      what is the position that  mike twellman plays  \n",
       "5                             list some musical films  \n",
       "6       what is ellen swallow richards's nationality?  \n",
       "7   What language is the show elementary broadcast...  \n",
       "8                 what is the gender of james hendry?  \n",
       "9                              who was a voice actor?  \n",
       "10  What is a member of the 1893 jakoba asteroid g...  \n",
       "11  What artist includes black star at the point o...  \n",
       "12                  Name an album by serge gainsbourg  \n",
       "13            what is a book by laura ingalls wilder   \n",
       "14  Who was the cinematographer for the film endle...  \n",
       "15         what is a documentary film about the media  \n",
       "16     what musical genre does  brandon reilly create  \n",
       "17  What sport does notre dame fighting irish men'...  \n",
       "18            where in germany was rudi ball born in?  \n",
       "19                    what time zone is marrakech in?  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_texts = []\n",
    "question = data.loc[19480, \"question\"]\n",
    "    \n",
    "print(\"Initial question: \\n\", question)\n",
    "\n",
    "# load text\n",
    "ner.receive_text(text = question)\n",
    "\n",
    "# receive text with marked entities\n",
    "new_text = ner.text_with_marked_entities()\n",
    "changed_texts.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_mGENRE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name an album by serge gainsbourg',\n",
       " 'what is a book by laura ingalls wilder ',\n",
       " 'Who was the cinematographer for the film endless love?',\n",
       " 'what is a documentary film about the media']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.loc[12:15, \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_mGENRE.sample(\n",
    "                    list(data.loc[12:15, \"question\"]),\n",
    "                    beam = 3,\n",
    "                    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                        e for e in trie.get(sent.tolist())\n",
    "                        if e < len(model_mGENRE.task.target_dictionary)\n",
    "                    ],\n",
    "                    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                    marginalize=True,\n",
    "                    verbose = True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q1698',\n",
       "   'texts': ['Serge Gainsbourg >> en',\n",
       "    'Serge Gainsbourg >> fr',\n",
       "    'Serge Gainsbourg >> nl'],\n",
       "   'scores': tensor([-0.0887, -0.8734, -1.0391], device='cuda:0'),\n",
       "   'score': tensor(-0.0471, device='cuda:0')}],\n",
       " [{'id': 'Q7738003',\n",
       "   'texts': ['The Great Wilderness >> en'],\n",
       "   'scores': tensor([-1.0489], device='cuda:0'),\n",
       "   'score': tensor(-2.9667, device='cuda:0')},\n",
       "  {'id': 'Q7774934',\n",
       "   'texts': ['The Wilderness >> en'],\n",
       "   'scores': tensor([-1.2900], device='cuda:0'),\n",
       "   'score': tensor(-3.4131, device='cuda:0')},\n",
       "  {'id': 'Q3518720',\n",
       "   'texts': ['The Wilderness of the Beastlands >> en'],\n",
       "   'scores': tensor([-2.5591], device='cuda:0'),\n",
       "   'score': tensor(-8.4874, device='cuda:0')}],\n",
       " [{'id': 'Q316',\n",
       "   'texts': ['Love >> en'],\n",
       "   'scores': tensor([-1.1282], device='cuda:0'),\n",
       "   'score': tensor(-2.2564, device='cuda:0')},\n",
       "  {'id': 'Q7112632',\n",
       "   'texts': ['List of film-related topics >> en'],\n",
       "   'scores': tensor([-1.2069], device='cuda:0'),\n",
       "   'score': tensor(-3.6206, device='cuda:0')},\n",
       "  {'id': 'Q597561',\n",
       "   'texts': ['List of film and television directors >> en'],\n",
       "   'scores': tensor([-1.4192], device='cuda:0'),\n",
       "   'score': tensor(-4.2577, device='cuda:0')}],\n",
       " [{'id': 'Q165650',\n",
       "   'texts': ['Media studies >> en'],\n",
       "   'scores': tensor([-0.4555], device='cuda:0'),\n",
       "   'score': tensor(-1.0184, device='cuda:0')},\n",
       "  {'id': 'Q340169',\n",
       "   'texts': ['Media (communication) >> en'],\n",
       "   'scores': tensor([-0.4711], device='cuda:0'),\n",
       "   'score': tensor(-1.3324, device='cuda:0')},\n",
       "  {'id': 'Q11033',\n",
       "   'texts': ['Mass media >> en'],\n",
       "   'scores': tensor([-0.8528], device='cuda:0'),\n",
       "   'score': tensor(-1.9070, device='cuda:0')}]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. NERs - Stanza (this is Stanford NLP), DeepPavlov, lowercase problem\n",
    "\n",
    "\n",
    "1. (OBJECT) QA with mGENRE without NER (like experimantal point)\n",
    "1) take text\n",
    "2) text to mGENRE\n",
    "3) compare answer with object\n",
    "\n",
    "2. (SUBJECT) Entity linking using mGENRE with NER (expected behaviour of mGENRE)\n",
    "1) take text -> NER\n",
    "2) text after NER -> mGENRE (expect that model will find subjects)   \n",
    "3) compare subjects with true subjects in data\n",
    "\n",
    "3. (SUBJECT) Entity linking using mGENRE without NER (expected behaviour of mGENRE)\n",
    "1) take text -> mGENRE (expect that model will find subjects)\n",
    "2) compare subjects with true subjects in data\n",
    "\n",
    "\n",
    "4. (SUBJECT) entity linking using mGENRE with syntactinc parsing \n",
    "(   =  /  = ),      = \n",
    "(https://github.com/vladislavneon/kbqa-tools/blob/master/rubq-baseline/entity_recognition.py)\n",
    "1) take text -> syntactinc parser\n",
    "2) text after syntactinc parser -> mGENRE (expect that model will find subjects)   \n",
    "3) compare subjects with true subjects in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 47.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " Name an album by serge gainsbourg\n",
      "['ser', 'gains', '##bourg']\n",
      "new_text new_text: \n",
      " Name an album by serge [START] gainsbourg [END] ?\n",
      "Initial question: \n",
      " what is a book by laura ingalls wilder \n",
      "[]\n",
      "new_text new_text: \n",
      " what is a book by laura ingalls wilder  ?\n",
      "Initial question: \n",
      " Who was the cinematographer for the film endless love?\n",
      "[]\n",
      "new_text new_text: \n",
      " Who was the cinematographer for the film endless love ?\n",
      "Initial question: \n",
      " what is a documentary film about the media\n",
      "[]\n",
      "new_text new_text: \n",
      " what is a documentary film about the media ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize class\n",
    "method = \"Babelscape/wikineural-multilingual-ner\"\n",
    "\n",
    "ner = NER(model = method,\n",
    "          tokenizer = method)\n",
    "\n",
    "# establish pipeline\n",
    "ner.set_pipeline()\n",
    "\n",
    "\n",
    "# NER\n",
    "changed_texts = []\n",
    "for question in tqdm(list(data.loc[12:15, \"question\"])):\n",
    "    \n",
    "    print(\"Initial question: \\n\", question)\n",
    "    \n",
    "    # load text\n",
    "    ner.receive_text(text = question)\n",
    "    \n",
    "    # receive text with marked entities\n",
    "    new_text = ner.text_with_marked_entities()\n",
    "    print(\"new_text new_text: \\n\", new_text)\n",
    "    changed_texts.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name an album by serge [START] gainsbourg [END] ?',\n",
       " 'what is a book by laura ingalls wilder  ?',\n",
       " 'Who was the cinematographer for the film endless love ?',\n",
       " 'what is a documentary film about the media ?']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_subject = model_mGENRE.sample(\n",
    "                    changed_texts,\n",
    "                    beam = 3,\n",
    "                    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                        e for e in trie.get(sent.tolist())\n",
    "                        if e < len(model_mGENRE.task.target_dictionary)\n",
    "                    ],\n",
    "                    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                    marginalize=True,\n",
    "                    verbose = True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q1698',\n",
       "   'texts': ['Serge Gainsbourg >> en', 'Serge Gainsbourg >> fr'],\n",
       "   'scores': tensor([-0.3615, -1.0019], device='cuda:0'),\n",
       "   'score': tensor(-0.7877, device='cuda:0')},\n",
       "  {'id': 'Q1491304',\n",
       "   'texts': ['Gainsbourg >> en'],\n",
       "   'scores': tensor([-0.4464], device='cuda:0'),\n",
       "   'score': tensor(-1.0935, device='cuda:0')}],\n",
       " [{'id': 'Q237514',\n",
       "   'texts': ['Laura Ingalls Wilder >> en',\n",
       "    'Laura Ingalls Wilder >> pl',\n",
       "    'Laura Ingalls Wilder >> nl'],\n",
       "   'scores': tensor([-0.1329, -0.6799, -0.7369], device='cuda:0'),\n",
       "   'score': tensor(-0.0438, device='cuda:0')}],\n",
       " [{'id': 'Q388408',\n",
       "   'texts': ['Endless Love (1981 film) >> en'],\n",
       "   'scores': tensor([-0.5663], device='cuda:0'),\n",
       "   'score': tensor(-1.7907, device='cuda:0')},\n",
       "  {'id': 'Q7732098',\n",
       "   'texts': ['The End of Love >> en'],\n",
       "   'scores': tensor([-0.8899], device='cuda:0'),\n",
       "   'score': tensor(-2.3545, device='cuda:0')},\n",
       "  {'id': 'Q989611',\n",
       "   'texts': ['Endless Love (1981 song) >> en'],\n",
       "   'scores': tensor([-1.2650], device='cuda:0'),\n",
       "   'score': tensor(-4.0002, device='cuda:0')}],\n",
       " [{'id': 'Q93204',\n",
       "   'texts': ['Documentary film >> en'],\n",
       "   'scores': tensor([-0.5157], device='cuda:0'),\n",
       "   'score': tensor(-1.2631, device='cuda:0')},\n",
       "  {'id': 'Q165650',\n",
       "   'texts': ['Media studies >> en'],\n",
       "   'scores': tensor([-0.5913], device='cuda:0'),\n",
       "   'score': tensor(-1.3221, device='cuda:0')},\n",
       "  {'id': 'Q289',\n",
       "   'texts': ['Television >> en'],\n",
       "   'scores': tensor([-0.8661], device='cuda:0'),\n",
       "   'score': tensor(-1.7322, device='cuda:0')}]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = 20\n",
    "questions_1000 = []\n",
    "for i in range(divider): \n",
    "    questions_1000.append(list(data.sample(n = 50, replace = False, random_state=i).loc[:, \"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_1000 = sum(questions_1000, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<00:24, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " Where is mnika veres from\n",
      "['mn']\n",
      "Initial question: \n",
      " where did franco angrisano die\n",
      "['franco']\n",
      "Initial question: \n",
      " What actor was born in lodz\n",
      "[]\n",
      "Initial question: \n",
      " what position does lee goodwin play in soccer\n",
      "['soccer']\n",
      "Initial question: \n",
      " What was the nationality of vincent riotta\n",
      "[]\n",
      "Initial question: \n",
      " which film is joie lee a story contributor for\n",
      "[]\n",
      "Initial question: \n",
      " Where in europe was victim five filmed\n",
      "['euro', '##pe']\n",
      "Initial question: \n",
      " which ethnicity is aloyisus leon higginbotham, jr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/1000 [00:00<00:23, 41.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', '##oy']\n",
      "Initial question: \n",
      " Who is the artist from the artwork flagellation of christ\n",
      "[]\n",
      "Initial question: \n",
      " What college basketball coach was born in ellwood city?\n",
      "['ell', '##wood']\n",
      "Initial question: \n",
      " who is a writer of a movie called white mischief\n",
      "['white']\n",
      "Initial question: \n",
      " Name a character of the male gender\n",
      "[]\n",
      "Initial question: \n",
      " What is virjibhai thummar's nationality?\n",
      "['vir']\n",
      "Initial question: \n",
      " Who is a notable goalkeeper\n",
      "[]\n",
      "Initial question: \n",
      " What genre of film is you only loved me twice?\n",
      "[]\n",
      "Initial question: \n",
      " what is richard low's gender\n",
      "[]\n",
      "Initial question: \n",
      " what type of movie is the border?\n",
      "[]\n",
      "Initial question: \n",
      " Which gender is lily broberg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 25/1000 [00:00<00:22, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['li']\n",
      "Initial question: \n",
      " what is karl paryla's gender?\n",
      "['kar']\n",
      "Initial question: \n",
      " What kind of film is public telephone?\n",
      "[]\n",
      "Initial question: \n",
      " what kind of music is on sheila e.?\n",
      "['she', '##ila']\n",
      "Initial question: \n",
      " where did fridolin von senger und etterlin die?\n",
      "['fri', '##dol']\n",
      "Initial question: \n",
      " who was born in the location of mexico city?\n",
      "['me', '##xico']\n",
      "Initial question: \n",
      " dino de laurentiis  produced what film\n",
      "['din', '##o', 'de', 'lau', '##rent', '##iis']\n",
      "Initial question: \n",
      " where in germany was emil rameau's place of death?\n",
      "['german']\n",
      "Initial question: \n",
      " Which country is julian richings from\n",
      "['juli', '##an']\n",
      "Initial question: \n",
      " What kind of celestial object is zeta canis minoris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 35/1000 [00:00<00:22, 42.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ze', '##ta']\n",
      "Initial question: \n",
      " what is daniel altman's gender\n",
      "['dan']\n",
      "Initial question: \n",
      " Which city and state was dennis johnson born in\n",
      "['denn']\n",
      "Initial question: \n",
      " what country gives nationality to ibrahim mahlab\n",
      "[]\n",
      "Initial question: \n",
      " Who produced my wifes relations\n",
      "[]\n",
      "Initial question: \n",
      " Who was the author of the fireclown?\n",
      "[]\n",
      "Initial question: \n",
      " what is an episode written by michelle ashford\n",
      "['mich', '##elle', 'ash', '##ford']\n",
      "Initial question: \n",
      " what kind of film is drop squad\n",
      "[]\n",
      "Initial question: \n",
      " where is the movie even pigeons go to heaven from \n",
      "[]\n",
      "Initial question: \n",
      " where was peter woodthorpe born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 40/1000 [00:00<00:21, 43.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pet']\n",
      "Initial question: \n",
      " where does dorothy garlock hold a passport \n",
      "['dor']\n",
      "Initial question: \n",
      " who was from henan\n",
      "['hen']\n",
      "Initial question: \n",
      " what is the title of an administrative division in the united kingdom\n",
      "[]\n",
      "Initial question: \n",
      " where in the world was jeannette batti born\n",
      "['je', '##tte']\n",
      "Initial question: \n",
      " which city did francis warrington gillet die\n",
      "['franc']\n",
      "Initial question: \n",
      " What is the name of an album from arcade fire\n",
      "[]\n",
      "Initial question: \n",
      " What is lee nerison's place of birth?\n",
      "['le', '##e', 'ner', '##ison']\n",
      "Initial question: \n",
      " Where was mike todorovich born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 50/1000 [00:01<00:23, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mi', 'todo', '##rov', '##ich']\n",
      "Initial question: \n",
      " Which style of architecture is the wayne morse farm\n",
      "['way', '##ne']\n",
      "Initial question: \n",
      " What is the nationality of doc cheatham?\n",
      "['doc']\n",
      "Initial question: \n",
      " what's the default language of scenes from a mall\n",
      "[]\n",
      "Initial question: \n",
      " who was born in cambodia?\n",
      "['cam', '##bod', '##ia']\n",
      "Initial question: \n",
      " Which religion does jimmy delshad identify with \n",
      "['jim']\n",
      "Initial question: \n",
      " Name a person born in geseke.\n",
      "['ge', '##sek', '##e']\n",
      "Initial question: \n",
      " What is a movie pierce brosnan produced?\n",
      "[]\n",
      "Initial question: \n",
      " What kind of music is featured on ten new songs\n",
      "[]\n",
      "Initial question: \n",
      " which episode was written by chris carter (screenwriter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 60/1000 [00:01<00:21, 43.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch']\n",
      "Initial question: \n",
      " What kind of celestial object is 1495 helsinki?\n",
      "['hel', '##sin', '##ki']\n",
      "Initial question: \n",
      " what is chris offutt's gender \n",
      "['ch', 'off', '##utt']\n",
      "Initial question: \n",
      " Who is an african american character actor and retired professional wrestler? \n",
      "['af', '##rica', '##n', 'american']\n",
      "Initial question: \n",
      " Name a professional writer\n",
      "[]\n",
      "Initial question: \n",
      " Which country is marcel landers from?\n",
      "[]\n",
      "Initial question: \n",
      " what is an example of a city that can be found in  north american central time zone\n",
      "['american']\n",
      "Initial question: \n",
      " In what language was inside man filmed?\n",
      "[]\n",
      "Initial question: \n",
      " what genre is serpico in?\n",
      "[]\n",
      "Initial question: \n",
      " What type of music is bobby kildea known for\n",
      "['bob', '##by', 'ki', '##lde', '##a']\n",
      "Initial question: \n",
      " what was earle birney's birth place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 72/1000 [00:01<00:18, 49.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##ney']\n",
      "Initial question: \n",
      " who created the album the traveling wilburys collection\n",
      "['wil', '##bury']\n",
      "Initial question: \n",
      " What kind of music does roman holiday record?\n",
      "['roman']\n",
      "Initial question: \n",
      " What game play mode is the computer video game Yoshis Safari?\n",
      "['Yo', '##shi', '##s', 'Safari']\n",
      "Initial question: \n",
      " Where exactly was marian goliski born\n",
      "['mari', '##an', 'goli']\n",
      "Initial question: \n",
      " what type of album is after hours at the london house \n",
      "['lo']\n",
      "Initial question: \n",
      " what nationality is simon scardifield\n",
      "['sim']\n",
      "Initial question: \n",
      " What film did mansoor khan contribute to?\n",
      "['mans', '##oor']\n",
      "Initial question: \n",
      " what time zone is lindstrom in\n",
      "['li']\n",
      "Initial question: \n",
      " what is mohamed safwat's gender\n",
      "[]\n",
      "Initial question: \n",
      " which german city is faiz kevin mangat from\n",
      "['german']\n",
      "Initial question: \n",
      " What nation is tulsi ramsay from?\n",
      "['tu', '##ls', '##i']\n",
      "Initial question: \n",
      " Where did william hedgcock die\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 84/1000 [00:01<00:17, 53.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will']\n",
      "Initial question: \n",
      " what is sonja skarstedt's place of birth?\n",
      "['son', '##ja', 'ska', '##rst', '##edt']\n",
      "Initial question: \n",
      " who is someone born in barcelona\n",
      "['bar', '##cel', '##ona']\n",
      "Initial question: \n",
      " What position does uro tripkovi play?\n",
      "['ur', '##o']\n",
      "Initial question: \n",
      " what's kumar sangakkara's ethnicity?\n",
      "[]\n",
      "Initial question: \n",
      " What is an album that was released by marc almond?\n",
      "['marc', 'al', '##mond']\n",
      "Initial question: \n",
      " Which city was thilo kleibauer born in\n",
      "['thi', '##lo', 'kl']\n",
      "Initial question: \n",
      " who is a parent of casey johnson\n",
      "['case']\n",
      "Initial question: \n",
      " which artist records under columbia records\n",
      "['col', '##um', '##bia']\n",
      "Initial question: \n",
      " Name a film written by jerry lewis\n",
      "['jer']\n",
      "Initial question: \n",
      " What is 10161 nakanoshima classified as\n",
      "['nak', '##anos', '##hima']\n",
      "Initial question: \n",
      " what series has the episode rosebud\n",
      "[]\n",
      "Initial question: \n",
      " which artist records under the earache records label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 96/1000 [00:02<00:16, 56.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ear', '##ache']\n",
      "Initial question: \n",
      " This jazz was released in 1959.\n",
      "['jazz']\n",
      "Initial question: \n",
      " what does 1255 schilowa orbit\n",
      "['##a']\n",
      "Initial question: \n",
      " what games were published by ea sports\n",
      "['ea']\n",
      "Initial question: \n",
      " Who is a missionary that was buried in highgate cemetery\n",
      "['high']\n",
      "Initial question: \n",
      " Which city was robert s. langer born in\n",
      "['robe', '##rt', 's', 'langer']\n",
      "Initial question: \n",
      " what religion does swaran singh practice\n",
      "['s', '##wara']\n",
      "Initial question: \n",
      " Which label is the artist gil evans signed to\n",
      "['W', 'gi']\n",
      "Initial question: \n",
      " which city was william grant stairs born\n",
      "['will']\n",
      "Initial question: \n",
      " who wrote city of women\n",
      "[]\n",
      "Initial question: \n",
      " where was carolyn mitchell born?\n",
      "['car', '##ol', '##yn']\n",
      "Initial question: \n",
      " in what language was earthlings filmed\n",
      "[]\n",
      "Initial question: \n",
      " Who was born in greenville, south carolina?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 108/1000 [00:02<00:17, 51.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['green', 'car']\n",
      "Initial question: \n",
      " what was the gender of the fictional character barry ohanlon\n",
      "['bar', '##han', '##lon']\n",
      "Initial question: \n",
      " Which city was robert s. langer born in\n",
      "['robe', '##rt', 's', 'langer']\n",
      "Initial question: \n",
      " what prince consort is princess alice of the united kingdom's father\n",
      "[]\n",
      "Initial question: \n",
      " What is ludwig marcuse's gender?\n",
      "['lu', '##dw', '##ig']\n",
      "Initial question: \n",
      " Where in italy did giuseppe chiappella die?\n",
      "['it']\n",
      "Initial question: \n",
      " what is the language in the film manthri gari viyyankudu\n",
      "['##yy', '##ank', '##udu']\n",
      "Initial question: \n",
      " what is sherman hemsley's race\n",
      "['she']\n",
      "Initial question: \n",
      " What is the profession of anthea turner?\n",
      "[]\n",
      "Initial question: \n",
      " what country is  charlie hough from\n",
      "[]\n",
      "Initial question: \n",
      " which country is hikaru yamamoto from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 115/1000 [00:02<00:16, 54.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What is the name of the weather channels smooth jazz album\n",
      "[]\n",
      "Initial question: \n",
      " Which baseball player plays right fielder?\n",
      "['baseball']\n",
      "Initial question: \n",
      " What's an example of a disaster film\n",
      "[]\n",
      "Initial question: \n",
      " what is a musical film\n",
      "[]\n",
      "Initial question: \n",
      " who is a guitar instrumentalist\n",
      "[]\n",
      "Initial question: \n",
      " who is a punk rock artist\n",
      "['punk']\n",
      "Initial question: \n",
      " Who is an example of a forward\n",
      "['Who']\n",
      "Initial question: \n",
      " Name a professional lawyer.\n",
      "[]\n",
      "Initial question: \n",
      " what gender is mary omalley?\n",
      "['mar']\n",
      "Initial question: \n",
      " which country is cruel jaws filmed in?\n",
      "[]\n",
      "Initial question: \n",
      " What's a video game published by sce studio liverpool\n",
      "[]\n",
      "Initial question: \n",
      " Which position is played by chris wright\n",
      "['ch']\n",
      "Initial question: \n",
      " who is father of vyasa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 128/1000 [00:02<00:15, 56.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vya', '##sa']\n",
      "Initial question: \n",
      " What kind of celestial object is 23855 brandonshih\n",
      "['238', '##ons']\n",
      "Initial question: \n",
      " who is a person born in ferrol\n",
      "['ferro', '##l']\n",
      "Initial question: \n",
      " what biological gender is gerald mccullouch\n",
      "['m', '##cc']\n",
      "Initial question: \n",
      " who created the fictional characterd oomsday\n",
      "['##d', 'o', '##oms', '##day']\n",
      "Initial question: \n",
      " what nationality is Isa Abdul-Quddus?\n",
      "['Isa', 'Abdul', '-', 'Qu', '##ddu', '##s']\n",
      "Initial question: \n",
      " Name a book written by david almond\n",
      "['da']\n",
      "Initial question: \n",
      " Who was born in Svendborg?\n",
      "['Sven', '##d', '##borg']\n",
      "Initial question: \n",
      " Who was the author of homeward bound\n",
      "[]\n",
      "Initial question: \n",
      " who is the producer of blood money\n",
      "[]\n",
      "Initial question: \n",
      " What baseball position does wally gerber play?\n",
      "['baseball']\n",
      "Initial question: \n",
      " which gender is sampie terreblanche\n",
      "['sam']\n",
      "Initial question: \n",
      " what is david bazay's gender?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 142/1000 [00:02<00:14, 58.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da']\n",
      "Initial question: \n",
      " what war was samuel w. koster a part of \n",
      "['sam']\n",
      "Initial question: \n",
      " what football position does simon hofer play at?\n",
      "['sim', '##on', 'hof', '##er']\n",
      "Initial question: \n",
      " who is bernard fanning signed with\n",
      "['bern', '##ard']\n",
      "Initial question: \n",
      " What is (6303) 1989 el2?\n",
      "['1989']\n",
      "Initial question: \n",
      " Where did john proctor die?\n",
      "['Where', 'jo', '##hn']\n",
      "Initial question: \n",
      " where was martin bormann born\n",
      "['mart']\n",
      "Initial question: \n",
      " what kind of music can be found on the album direction\n",
      "[]\n",
      "Initial question: \n",
      " What does al waxman do for a living\n",
      "['al']\n",
      "Initial question: \n",
      " who was born in cleveland, ohio\n",
      "['ohi']\n",
      "Initial question: \n",
      " which movie was written by kirsten smith\n",
      "['ki', '##rst', '##en']\n",
      "Initial question: \n",
      " what type of music is no more loud music: the singles\n",
      "[]\n",
      "Initial question: \n",
      " who directed the savage is loose\n",
      "[]\n",
      "Initial question: \n",
      " Which position does marko ljubinkovi play?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 154/1000 [00:03<00:14, 58.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mark', '##inko', '##vi']\n",
      "Initial question: \n",
      " Who would be rock and roll\n",
      "[]\n",
      "Initial question: \n",
      " who recorded christmas with yolanda adams\n",
      "[]\n",
      "Initial question: \n",
      " What country was love at twenty filmed in\n",
      "[]\n",
      "Initial question: \n",
      " What is the nationality of tefan kovcs\n",
      "['tefan', 'ko', '##v', '##cs']\n",
      "Initial question: \n",
      " who was the author of the book titled  the six wives of henry viii\n",
      "['wi', '##ves', 'of', 'hen', '##ry']\n",
      "Initial question: \n",
      " who was in beneath the valley of the ultra-vixens\n",
      "['ultra']\n",
      "Initial question: \n",
      " What is the name of a city in gratiot county\n",
      "[]\n",
      "Initial question: \n",
      " where did kurt hoffmann die?\n",
      "['kur']\n",
      "Initial question: \n",
      " what country is love of grass leaves filmed in?\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of a poetry book?\n",
      "[]\n",
      "Initial question: \n",
      " What is wilferd madelung's gender?\n",
      "['wil', '##ferd']\n",
      "Initial question: \n",
      " What position did famara diedhiou play?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 168/1000 [00:03<00:13, 59.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fama', '##ra', 'died', '##hio', '##u']\n",
      "Initial question: \n",
      " which player plays the midfielder football position\n",
      "[]\n",
      "Initial question: \n",
      " What book did andre norton write?\n",
      "['andre']\n",
      "Initial question: \n",
      " Name a politician\n",
      "[]\n",
      "Initial question: \n",
      " which city did frank farrington decease in\n",
      "[]\n",
      "Initial question: \n",
      " What kind of celestial object is 23855 brandonshih\n",
      "['238', '##ons']\n",
      "Initial question: \n",
      " which game has single-player\n",
      "[]\n",
      "Initial question: \n",
      " which language was spoken in strange fascination\n",
      "[]\n",
      "Initial question: \n",
      " who is signed under the label tabu recordings\n",
      "['tab', '##u']\n",
      "Initial question: \n",
      " what gender is peter drfler \n",
      "['pet', '##er']\n",
      "Initial question: \n",
      " which footballer was born in keflavk?\n",
      "['ke', '##f', '##lav', '##k']\n",
      "Initial question: \n",
      " what is tilo wolff's chose style of music\n",
      "['til', '##o']\n",
      "Initial question: \n",
      " Who is the child of raj kapoor?\n",
      "['##oor']\n",
      "Initial question: \n",
      " what baseball player plays as a first baseman \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 180/1000 [00:03<00:13, 59.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baseball']\n",
      "Initial question: \n",
      " where did bruce jackson die\n",
      "[]\n",
      "Initial question: \n",
      " who was the military personnel involved in the world war ii?\n",
      "[]\n",
      "Initial question: \n",
      " who recorded zetima\n",
      "['ze', '##tima']\n",
      "Initial question: \n",
      " who was the music composer for susan lenox (her fall and rise)?\n",
      "['sus', '##an', 'len']\n",
      "Initial question: \n",
      " which musician made live\n",
      "[]\n",
      "Initial question: \n",
      " in what language was earthlings filmed\n",
      "[]\n",
      "Initial question: \n",
      " who has a place of birth in moscow\n",
      "['mos']\n",
      "Initial question: \n",
      " What is the name of a book that is classified as detective fiction\n",
      "[]\n",
      "Initial question: \n",
      " which political party pursues libertarian socialism\n",
      "['liber', '##tarian']\n",
      "Initial question: \n",
      " what is the gender of jay o'brien\n",
      "['ja', '##y', 'o', \"'\", 'br', '##ien']\n",
      "Initial question: \n",
      " Is william atkins a male or female\n",
      "['will', '##iam']\n",
      "Initial question: \n",
      " what position does  kieron st aimie play in soccer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 193/1000 [00:03<00:13, 59.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " which orbit has relationship with 2301 whitford\n",
      "['230', '##1', 'w', '##hit', '##ford']\n",
      "Initial question: \n",
      " where was bridget of york born \n",
      "[]\n",
      "Initial question: \n",
      " what city and state was neil goldschmidt born in\n",
      "[]\n",
      "Initial question: \n",
      " What sex is tasha yar's character\n",
      "['tas', '##ha', 'ya', '##r']\n",
      "Initial question: \n",
      " Which position is played by dusty ryan in baseball\n",
      "['baseball']\n",
      "Initial question: \n",
      " which english city was david buck born in\n",
      "['engl', '##ish']\n",
      "Initial question: \n",
      " what is a horror film?\n",
      "[]\n",
      "Initial question: \n",
      " whirl tour is what type of video game?\n",
      "['w', '##hir', '##l', 'tour']\n",
      "Initial question: \n",
      " what sex is otto chr. bastiansen\n",
      "['bas']\n",
      "Initial question: \n",
      " what is edgar lee mcwethy, jr.'s gender\n",
      "['ed', '##gar', 'le', '##e', 'm', '##c', '##wet', '##hy', ',', 'jr']\n",
      "Initial question: \n",
      " what country is charles town, west virginia in\n",
      "['vir', '##gini']\n",
      "Initial question: \n",
      " What is the name of a popular album by ryuichi sakamoto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 205/1000 [00:03<00:14, 56.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ry']\n",
      "Initial question: \n",
      " What is the gender of jeremiah burrell\n",
      "['jer', '##emia']\n",
      "Initial question: \n",
      " what position does john wilson play\n",
      "['jo', '##hn', 'wil', '##son']\n",
      "Initial question: \n",
      " which track is created by mark linkous\n",
      "[]\n",
      "Initial question: \n",
      " what is the producing company of dark fall\n",
      "[]\n",
      "Initial question: \n",
      " What kind of music is on the art of fingerstyle jazz guitar\n",
      "[]\n",
      "Initial question: \n",
      " angus r. goss was born where in the United States?\n",
      "['United', 'States']\n",
      "Initial question: \n",
      " what country was a musical monologue produced\n",
      "[]\n",
      "Initial question: \n",
      " What genre of film is images in a convent\n",
      "[]\n",
      "Initial question: \n",
      " what films have been directed by kenji mizoguchi?\n",
      "['ken', '##ji']\n",
      "Initial question: \n",
      " which state is patrick tracy burris from\n",
      "['pat']\n",
      "Initial question: \n",
      " Which language is the film chauranga in\n",
      "['W', 'language']\n",
      "Initial question: \n",
      " What is the name of the developer that developed avengers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 217/1000 [00:04<00:13, 57.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " which female model was born in sydney\n",
      "['syd', '##ney']\n",
      "Initial question: \n",
      " What position did chris anstey play in basketball?\n",
      "['basketball']\n",
      "Initial question: \n",
      " what is mario novelli's gender\n",
      "['mari', '##o', 'novel']\n",
      "Initial question: \n",
      " what county is dock junction a part of\n",
      "[]\n",
      "Initial question: \n",
      " what type of video game is sprung?\n",
      "[]\n",
      "Initial question: \n",
      " who created deadliest catch?\n",
      "[]\n",
      "Initial question: \n",
      " what position does ian brightwell play in football?\n",
      "['ia']\n",
      "Initial question: \n",
      " which language audience was ongka's big moka released to first\n",
      "['on', '##gka']\n",
      "Initial question: \n",
      " Who plays the position of forward?\n",
      "[]\n",
      "Initial question: \n",
      " What killed george o'hanlon\n",
      "['o', \"'\", 'han']\n",
      "Initial question: \n",
      " What position does footballer gary lavery play?\n",
      "[]\n",
      "Initial question: \n",
      " what ethnicity is kyoko nakajima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 231/1000 [00:04<00:13, 58.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ky']\n",
      "Initial question: \n",
      " Which genre is the artist sandro de amrica?\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of a cantopop?\n",
      "[]\n",
      "Initial question: \n",
      " What is the architectural style of palais garnier\n",
      "['palais', '##nier']\n",
      "Initial question: \n",
      " what county is bradley beach, new jersey a part of\n",
      "['bra']\n",
      "Initial question: \n",
      " what position does samuel itondo play \n",
      "['sam', '##uel']\n",
      "Initial question: \n",
      " which position does tony kenworthy play\n",
      "[]\n",
      "Initial question: \n",
      " What was a book william tenn wrote?\n",
      "['will', '##iam', 'ten']\n",
      "Initial question: \n",
      " which country does w. francis mcbeth come from\n",
      "['franc']\n",
      "Initial question: \n",
      " what position does ignas dedura play\n",
      "['ig', '##nas', 'de', '##dura']\n",
      "Initial question: \n",
      " which soccer position does muhannad naim play\n",
      "['mu']\n",
      "Initial question: \n",
      " so vicente is a second level division of what country\n",
      "['so', 'vice', '##nte']\n",
      "Initial question: \n",
      " what movie is written by hal roach?\n",
      "['hal']\n",
      "Initial question: \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 243/1000 [00:04<00:12, 58.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what structure is an example of colonial revival architecture?\n",
      "[]\n",
      "Initial question: \n",
      " what position does baseball player norm mcneil play\n",
      "['baseball']\n",
      "Initial question: \n",
      " what gender is devra davis \n",
      "['de', 'da']\n",
      "Initial question: \n",
      " What country was ambush murders made in?\n",
      "[]\n",
      "Initial question: \n",
      " what is dubmood's gender\n",
      "['dub']\n",
      "Initial question: \n",
      " which country did the devils daughter come from \n",
      "[]\n",
      "Initial question: \n",
      " what is the nationality of  jonathan malen\n",
      "['jo']\n",
      "Initial question: \n",
      " which state did johnny lipon die\n",
      "[]\n",
      "Initial question: \n",
      " who was born in trieste\n",
      "['tries', '##te']\n",
      "Initial question: \n",
      " What is Byron Chamberlain's birthplace?\n",
      "['Byron', 'Chamberlain']\n",
      "Initial question: \n",
      " is daviddevantandhisspiritwife indie rock or classical\n",
      "[]\n",
      "Initial question: \n",
      " who died from myocardial infarction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 249/1000 [00:04<00:13, 56.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what kind of film is the sarnos: a life in dirty movies\n",
      "[]\n",
      "Initial question: \n",
      " what type of film is ashanti\n",
      "['ash', '##anti']\n",
      "Initial question: \n",
      " who released the album post\n",
      "[]\n",
      "Initial question: \n",
      " Where did mara daz corts die?\n",
      "['mar', '##a']\n",
      "Initial question: \n",
      " what is mahbubeh bayat's country of nationality?\n",
      "['mah']\n",
      "Initial question: \n",
      " where is the birthplace of joseph proust\n",
      "['jos']\n",
      "Initial question: \n",
      " which county contains clayton\n",
      "['clay']\n",
      "Initial question: \n",
      " What river is mulberry river apart of?\n",
      "['mu', '##lbe', '##rry']\n",
      "Initial question: \n",
      " What kind of job does john clayton (sportscaster) do\n",
      "['jo', '##hn', 'clay', '##ton']\n",
      "Initial question: \n",
      " which country released rifftrax\n",
      "['ri', '##fft']\n",
      "Initial question: \n",
      " What kind of music does roman holiday record?\n",
      "['roman']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 262/1000 [00:04<00:12, 58.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " which state did johnny lipon die\n",
      "[]\n",
      "Initial question: \n",
      " mahmud ii's nationality is where?\n",
      "['mah', '##mu', '##d', 'ii']\n",
      "Initial question: \n",
      " what is a city in bullitt county\n",
      "['bu', '##tt']\n",
      "Initial question: \n",
      " what category is 26251 kiranmanne in?\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of a man born in sydney?\n",
      "['syd', '##ney']\n",
      "Initial question: \n",
      " what state was melora hardin born\n",
      "['me']\n",
      "Initial question: \n",
      " Name a person born in Naugatuck.\n",
      "['Na', '##ugat', '##uck']\n",
      "Initial question: \n",
      " what genre does the film rare birds belong to\n",
      "[]\n",
      "Initial question: \n",
      " what is the nationality of mark ferner \n",
      "[]\n",
      "Initial question: \n",
      " what language is game filmed in\n",
      "[]\n",
      "Initial question: \n",
      " what language is i have two mothers and two fathers available in?\n",
      "[]\n",
      "Initial question: \n",
      " What's a blues-rock album by rory gallagher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 274/1000 [00:05<00:12, 56.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What nation is al helfer from\n",
      "[]\n",
      "Initial question: \n",
      " Who directed the film the rugrats movie?\n",
      "['ru', '##grat']\n",
      "Initial question: \n",
      " where did otto huber die\n",
      "['otto']\n",
      "Initial question: \n",
      " how did elizabeth mcbride die\n",
      "['eli', '##za', '##beth']\n",
      "Initial question: \n",
      " What is the genre that elena kats-chernin falls under\n",
      "['ele']\n",
      "Initial question: \n",
      " who is the director of ladyhawke \n",
      "['lady', '##hawk', '##e']\n",
      "Initial question: \n",
      " what book genre is the perks of being a wallflower \n",
      "['wall']\n",
      "Initial question: \n",
      " Where in southern california did barbara lawrence die\n",
      "['cal', '##if', '##orn', '##ia']\n",
      "Initial question: \n",
      " What genre of music does we fell to earth make?\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of a new wave music band\n",
      "['new']\n",
      "Initial question: \n",
      " is harry barnes a male or female person?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 286/1000 [00:05<00:13, 53.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harr', '##y', 'barne']\n",
      "Initial question: \n",
      " What position does jack reilly play\n",
      "['ja']\n",
      "Initial question: \n",
      " Which label is kenneth stover on?\n",
      "['ken']\n",
      "Initial question: \n",
      " is viola male or female\n",
      "['viola']\n",
      "Initial question: \n",
      " Where was the discovery stie of (6490) 1991 nr2 \n",
      "[]\n",
      "Initial question: \n",
      " what position did dillon gee play\n",
      "['dil', '##lon']\n",
      "Initial question: \n",
      " in what eastern european country is the prul pietros river located\n",
      "['p', '##r', '##u', '##l']\n",
      "Initial question: \n",
      " What profession is herman david koppel\n",
      "['her']\n",
      "Initial question: \n",
      " where in france was constantin guys' place of death?\n",
      "['franc', '##e']\n",
      "Initial question: \n",
      " in what puerto rican town was carlos delgado born\n",
      "['puerto', 'rica']\n",
      "Initial question: \n",
      " what albums are by black sabbath?\n",
      "[]\n",
      "Initial question: \n",
      " which german city was esad veledar born in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 298/1000 [00:05<00:12, 56.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['german']\n",
      "Initial question: \n",
      " What theatre of conflict occured in central europe?\n",
      "['euro', '##pe']\n",
      "Initial question: \n",
      " Who produced the film death proof?\n",
      "[]\n",
      "Initial question: \n",
      " Who was born in san jose, california?\n",
      "['cal', '##if', '##orn']\n",
      "Initial question: \n",
      " Name someone born in cocagne, new brunswick.\n",
      "['co', '##gne']\n",
      "Initial question: \n",
      " Where was rick sanchez born?\n",
      "['ri', 'san', '##che', '##z']\n",
      "Initial question: \n",
      " Which country is abhinav bindra from\n",
      "['ab', '##hina', '##v']\n",
      "Initial question: \n",
      " Where was narqath born\n",
      "['nar']\n",
      "Initial question: \n",
      " Which position in football does ali pala play\n",
      "['football']\n",
      "Initial question: \n",
      " which 1994 album was released by groovie ghoulies?\n",
      "[]\n",
      "Initial question: \n",
      " What is the gameplay mode of deadlock: planetary conquest?\n",
      "['dead']\n",
      "Initial question: \n",
      " where was walter silva born at?\n",
      "['wa', 'sil', '##va']\n",
      "Initial question: \n",
      " What country produced the film Three Guys Named Mike.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 311/1000 [00:05<00:12, 57.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three', 'Guy', '##s', 'Named', 'Mike']\n",
      "Initial question: \n",
      " What is pavel fot's position\n",
      "['f']\n",
      "Initial question: \n",
      " who produced cruel intentions\n",
      "[]\n",
      "Initial question: \n",
      " what conflict did victor crutchley participate in\n",
      "[]\n",
      "Initial question: \n",
      " What is the hud county place of moore county\n",
      "['mo']\n",
      "Initial question: \n",
      " is meiyang chang male or female\n",
      "['mei']\n",
      "Initial question: \n",
      " what is a area in cibola county, new mexico\n",
      "['cibo', '##la']\n",
      "Initial question: \n",
      " what is a city in brazil?\n",
      "['bra']\n",
      "Initial question: \n",
      " where was robert s. scott given birth\n",
      "['robe']\n",
      "Initial question: \n",
      " what position does ryan nece play \n",
      "['ry', '##an']\n",
      "Initial question: \n",
      " What are some written works by bertolt brecht\n",
      "['be', '##lt', 'br', '##echt']\n",
      "Initial question: \n",
      " where did hugo zller die\n",
      "['hu']\n",
      "Initial question: \n",
      " What's an album written by ma\n",
      "['m', '##']\n",
      "Initial question: \n",
      " Who is a parent of charoensri chanamayu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 323/1000 [00:06<00:11, 57.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['char', '##oen']\n",
      "Initial question: \n",
      " which country does the beznea river flow into\n",
      "['bez', '##nea']\n",
      "Initial question: \n",
      " what is a 1976 soul music album\n",
      "[]\n",
      "Initial question: \n",
      " what genre is howling bells \n",
      "[]\n",
      "Initial question: \n",
      " which city did paul androta pass away\n",
      "['##ota']\n",
      "Initial question: \n",
      " What is Claire Stansfield's nationality?\n",
      "['Claire', 'Stan', '##sfield']\n",
      "Initial question: \n",
      " what is sarah jarosz's gender\n",
      "['ja', '##ros', '##z']\n",
      "Initial question: \n",
      " what coast does was nominated for Classical Album of the Year declare nationality\n",
      "['Classical', 'Album', 'of', 'the', 'Year']\n",
      "Initial question: \n",
      " who is the artist on seven wishes\n",
      "[]\n",
      "Initial question: \n",
      " which j-pop artist started out in 2003?\n",
      "['j']\n",
      "Initial question: \n",
      " what game is played on multiplayer mode?\n",
      "['multi']\n",
      "Initial question: \n",
      " Who is a soccer player that is a goalkeeper?\n",
      "[]\n",
      "Initial question: \n",
      " Where was robert f. williams born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 335/1000 [00:06<00:11, 58.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robe', '##rt']\n",
      "Initial question: \n",
      " Who is madurodam named after\n",
      "['ma', '##dur', '##oda']\n",
      "Initial question: \n",
      " what is the nationality of thad h. brown\n",
      "['tha']\n",
      "Initial question: \n",
      " What is julia loktev's gender?\n",
      "['juli', '##a']\n",
      "Initial question: \n",
      " Who is a female?\n",
      "[]\n",
      "Initial question: \n",
      " what country is evgeniya belyakova from\n",
      "['ev']\n",
      "Initial question: \n",
      " What is the name of a film in the war film genre?\n",
      "[]\n",
      "Initial question: \n",
      " which country is alfred heurtaux from \n",
      "[]\n",
      "Initial question: \n",
      " which nationality is brian urlacher\n",
      "['br']\n",
      "Initial question: \n",
      " what is the gender of clarence demar\n",
      "[]\n",
      "Initial question: \n",
      " where was the 1966 united states grand prix held\n",
      "[]\n",
      "Initial question: \n",
      " which country is anna friel from\n",
      "[]\n",
      "Initial question: \n",
      " who directed the film the pillow book\n",
      "[]\n",
      "Initial question: \n",
      " What did tibor fischer write?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 347/1000 [00:06<00:11, 54.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ti', '##bor', 'fi', '##scher']\n",
      "Initial question: \n",
      " Which country is the film platform from\n",
      "['W']\n",
      "Initial question: \n",
      " what type of celestial body is 39678 ammannito\n",
      "['396', 'am', '##mann']\n",
      "Initial question: \n",
      " is kristjan sarv male or female\n",
      "['kr', '##ist']\n",
      "Initial question: \n",
      " which country is the movie fox and his friends from\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of a Virginia county located in the united states?\n",
      "['Virginia']\n",
      "Initial question: \n",
      " who is an outfielder\n",
      "[]\n",
      "Initial question: \n",
      " What is the nationality of mikls ybl\n",
      "['mi', '##kl', '##s', 'y', '##bl']\n",
      "Initial question: \n",
      " What gender is fred f. sears\n",
      "['fred']\n",
      "Initial question: \n",
      " What type of film is in the shadow of the wind\n",
      "[]\n",
      "Initial question: \n",
      " What country is Matias Mirabaje from?\n",
      "['Mat', '##ias', 'Mira', '##ba', '##je']\n",
      "Initial question: \n",
      " which album did cher release in 1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 360/1000 [00:06<00:11, 55.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " Where was teresa rabal born\n",
      "['ter', '##esa', '##bal']\n",
      "Initial question: \n",
      " who are popular psychedelic rock artists\n",
      "['ps']\n",
      "Initial question: \n",
      " what is the gameplay mode of rallisport challenge\n",
      "['ra', '##llis']\n",
      "Initial question: \n",
      " What is the country of origin for the film kiss the blood off my hands?\n",
      "[]\n",
      "Initial question: \n",
      " In which municipality did richard katz die?\n",
      "[]\n",
      "Initial question: \n",
      " who is sigismund i the old's child?\n",
      "['sig', '##ismu']\n",
      "Initial question: \n",
      " what language is django shoots first spoken in?\n",
      "['dj', '##ang', '##o']\n",
      "Initial question: \n",
      " What is the name of a swedish guitar instrumentalist?\n",
      "['s', '##wed', '##ish']\n",
      "Initial question: \n",
      " what sort of book is the white album\n",
      "[]\n",
      "Initial question: \n",
      " Which city is located inside allegheny county\n",
      "['alle', '##ghe', '##ny']\n",
      "Initial question: \n",
      " what is a documentary film about food\n",
      "[]\n",
      "Initial question: \n",
      " what is greg hands's country of origin?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 373/1000 [00:06<00:11, 56.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gr', '##eg']\n",
      "Initial question: \n",
      " what constellation is phi piscium in\n",
      "['phi']\n",
      "Initial question: \n",
      " who was born in belgrade?\n",
      "['bel']\n",
      "Initial question: \n",
      " what is stephen rebello's country of origin?\n",
      "['step']\n",
      "Initial question: \n",
      " Who produced the album once upon a star\n",
      "['Who']\n",
      "Initial question: \n",
      " What artist would be called pop music\n",
      "['pop']\n",
      "Initial question: \n",
      " where was john t. deweese burried\n",
      "['##we']\n",
      "Initial question: \n",
      " Name a football player who plays as a midfielder.\n",
      "[]\n",
      "Initial question: \n",
      " which country is black magic from\n",
      "[]\n",
      "Initial question: \n",
      " who is the artist that created the album  blood of the earth\n",
      "['blood', 'of']\n",
      "Initial question: \n",
      " What is the gender of aaron freeman?\n",
      "['aa', '##ron']\n",
      "Initial question: \n",
      " what type of music does does it look like im here? have on it\n",
      "[]\n",
      "Initial question: \n",
      " what film was pritam the music contributor for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 379/1000 [00:07<00:11, 54.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prit', '##am']\n",
      "Initial question: \n",
      " what country is georges de moor a citizen of\n",
      "[]\n",
      "Initial question: \n",
      " What war did walter bedell smith take part in\n",
      "['wa']\n",
      "Initial question: \n",
      " What is the language of the film the waiting game?\n",
      "[]\n",
      "Initial question: \n",
      " Where dii antun gustav mato die\n",
      "['Where', 'di', '##i']\n",
      "Initial question: \n",
      " what was gil friesen's place of death\n",
      "['fri']\n",
      "Initial question: \n",
      " which country released 8 heads in a duffel bag\n",
      "[]\n",
      "Initial question: \n",
      " who produced block busters?\n",
      "[]\n",
      "Initial question: \n",
      " Who is vagif mustafazade's daughter\n",
      "['must', '##zade']\n",
      "Initial question: \n",
      " Name a drama film.\n",
      "[]\n",
      "Initial question: \n",
      " What label was dennis coffey signed to?\n",
      "['denn', '##is']\n",
      "Initial question: \n",
      " what is the religion of roger garaudy?\n",
      "[]\n",
      "Initial question: \n",
      " where in france was marian hannah winter born in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 392/1000 [00:07<00:11, 55.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['franc']\n",
      "Initial question: \n",
      " which gender does joseph beckham belong to\n",
      "['jos']\n",
      "Initial question: \n",
      " which film is joie lee a story contributor for\n",
      "[]\n",
      "Initial question: \n",
      " what kind of music is daqui pro futuro\n",
      "['da']\n",
      "Initial question: \n",
      " what gender is shahrum kashani \n",
      "['sh']\n",
      "Initial question: \n",
      " which central asian city was isaak illich rubin's place of death?\n",
      "['asi']\n",
      "Initial question: \n",
      " Which religion does phumzile mlambo-ngcuka practice?\n",
      "[]\n",
      "Initial question: \n",
      " which 1980s band released the album adventures of the smart patrol?\n",
      "['adventure', '##s', 'of', 'the', 'smart', 'patrol']\n",
      "Initial question: \n",
      " what label is virgin prunes worth?\n",
      "[]\n",
      "Initial question: \n",
      " What sport do the Dallas Stars play?\n",
      "['Dallas', 'Stars']\n",
      "Initial question: \n",
      " What is the genre of jane winton\n",
      "['jan']\n",
      "Initial question: \n",
      " Who was born in belle fourche?\n",
      "[]\n",
      "Initial question: \n",
      " what italian footballer was born in ardea (rm)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 404/1000 [00:07<00:10, 55.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['italian', 'ar']\n",
      "Initial question: \n",
      " Name a japanese multiplayer video game released in Super Famicon.\n",
      "['jap', 'Super', 'Fam', '##ico', '##n']\n",
      "Initial question: \n",
      " what is karl von vierordt's gender?\n",
      "['kar', '##l', 'von', '##ord']\n",
      "Initial question: \n",
      " what type of film is the cowboy and the lady\n",
      "[]\n",
      "Initial question: \n",
      " List a ps4 game published by sony computer entertainment\n",
      "['ps', '##4']\n",
      "Initial question: \n",
      " where was hou baolin born\n",
      "['hou', 'bao', '##lin']\n",
      "Initial question: \n",
      " what is the name of the place where john paul phelan was born\n",
      "['jo']\n",
      "Initial question: \n",
      " Which style of architecture is the wayne morse farm\n",
      "['way', '##ne']\n",
      "Initial question: \n",
      " Where was the place of death for marik vos-lundh\n",
      "['mari']\n",
      "Initial question: \n",
      " whats the name of the artist that released the one and only\n",
      "[]\n",
      "Initial question: \n",
      " Which baseball player plays right fielder?\n",
      "['baseball']\n",
      "Initial question: \n",
      " Name an artist on emi record label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 416/1000 [00:07<00:10, 54.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['em', '##i']\n",
      "Initial question: \n",
      " what's the main gameplay mode of jaseiken necromancer\n",
      "['ja', '##sei', '##ken']\n",
      "Initial question: \n",
      " what is raynald denoueix's place of birth?\n",
      "['ray']\n",
      "Initial question: \n",
      " what is the cvg genre of timesplitters\n",
      "['c', '##v', '##g']\n",
      "Initial question: \n",
      " what is the primary language of the film fly away baby\n",
      "['fly', 'away']\n",
      "Initial question: \n",
      " what films are by national film board of canada?\n",
      "['can']\n",
      "Initial question: \n",
      " what was earle birney's birth place\n",
      "['##ney']\n",
      "Initial question: \n",
      " which south korean singer is also an actor?\n",
      "['kor', '##ean']\n",
      "Initial question: \n",
      " What country is giessenlanden a part of\n",
      "['gie', '##ssen', '##lande', '##n']\n",
      "Initial question: \n",
      " What type of sports team is cricima esporte clube?\n",
      "['c', '##rici', '##', '##ma']\n",
      "Initial question: \n",
      " What is a work authored by jeffrey eugenides?\n",
      "[]\n",
      "Initial question: \n",
      " Who directed ashik kerib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 428/1000 [00:07<00:10, 54.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ash']\n",
      "Initial question: \n",
      " What gender is william smith\n",
      "['will', '##iam']\n",
      "Initial question: \n",
      " what is reshad strik's sex?\n",
      "['res', '##had']\n",
      "Initial question: \n",
      " which artist recorded super roots 7\n",
      "['7']\n",
      "Initial question: \n",
      " what is enrico de nicola's profession \n",
      "[]\n",
      "Initial question: \n",
      " whos the composer of  numb\n",
      "[]\n",
      "Initial question: \n",
      " What kind of metal is played on the final sign of evil\n",
      "[]\n",
      "Initial question: \n",
      " what gender is ram prasad bismil\n",
      "['ra']\n",
      "Initial question: \n",
      " what is an example of a horror film?\n",
      "[]\n",
      "Initial question: \n",
      " who was the director of diary of a mad black woman (film)?\n",
      "[]\n",
      "Initial question: \n",
      " Who was born in Saint Petersburg?\n",
      "['Saint', 'Petersburg']\n",
      "Initial question: \n",
      " Who produced the film mutant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 440/1000 [00:08<00:10, 55.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mu']\n",
      "Initial question: \n",
      " this person is from baton rouge, louisiana.\n",
      "['bat', '##on', 'rouge', 'lo', '##uis']\n",
      "Initial question: \n",
      " which video game did square enix publish\n",
      "[]\n",
      "Initial question: \n",
      " who is someone that died from  tuberculosis\n",
      "[]\n",
      "Initial question: \n",
      " where was jonathan bar giora born?\n",
      "['jo']\n",
      "Initial question: \n",
      " what is the genre of the album lgrimas y gozos\n",
      "['l', '##gri', '##mas', 'y', 'go', '##zos']\n",
      "Initial question: \n",
      " Where was nadine chandrawinata born\n",
      "['nad', '##ine', 'chan', '##dra', '##win', '##ata']\n",
      "Initial question: \n",
      " what genre is the film  going upriver\n",
      "[]\n",
      "Initial question: \n",
      " Where exactly was marian goliski born\n",
      "['mari', '##an', 'goli']\n",
      "Initial question: \n",
      " What is leslie wright's profession? \n",
      "['les', '##lie']\n",
      "Initial question: \n",
      " Where did william boyle, 12th earl of cork and orrery pass away\n",
      "[]\n",
      "Initial question: \n",
      " what book genre is the perks of being a wallflower \n",
      "['wall']\n",
      "Initial question: \n",
      " which country gave edward dannreuther his nationality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 452/1000 [00:08<00:09, 55.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what position does adam carriker play\n",
      "['adam']\n",
      "Initial question: \n",
      " what kind of book is on photography?\n",
      "[]\n",
      "Initial question: \n",
      " what artist is on the record label v2 records?\n",
      "['v', '##2']\n",
      "Initial question: \n",
      " what artist is on the album flight, bremen 1961?\n",
      "[]\n",
      "Initial question: \n",
      " what is the sex of irving saraf?\n",
      "['sa', '##raf']\n",
      "Initial question: \n",
      " What is the name of a documentary film on netflix\n",
      "['net', '##f', '##x']\n",
      "Initial question: \n",
      " what genre of film is the shielding shadow?\n",
      "[]\n",
      "Initial question: \n",
      " Where did dharamvir bharati die\n",
      "['d', '##m', '##vir']\n",
      "Initial question: \n",
      " Who directed uncovered: the war on iraq\n",
      "[]\n",
      "Initial question: \n",
      " what artist made the album rise up with fists!!\n",
      "[]\n",
      "Initial question: \n",
      " Which nation is mehdi sahnoune from?\n",
      "[]\n",
      "Initial question: \n",
      " What's a game that features a single-player mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 464/1000 [00:08<00:09, 55.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what is sandro aguilar's country of nationality?\n",
      "['sand']\n",
      "Initial question: \n",
      " Where in europe is theodorus janssonius van almeloveen from\n",
      "['euro']\n",
      "Initial question: \n",
      " where did john ellis martineau die\n",
      "['jo']\n",
      "Initial question: \n",
      " what language is the front line in\n",
      "['language']\n",
      "Initial question: \n",
      " who is a parent of alfonso ix of leon\n",
      "['al', '##fon', '##so']\n",
      "Initial question: \n",
      " what is peggy wood's place of birth?\n",
      "['pe']\n",
      "Initial question: \n",
      " Who was ptolemy ii philadelphus's father\n",
      "['##hus']\n",
      "Initial question: \n",
      " what country is the great warrior skanderbeg portrayed in\n",
      "['ska', '##nder']\n",
      "Initial question: \n",
      " what game is published by ea sports?\n",
      "['ea']\n",
      "Initial question: \n",
      " what country is meng bo filmed in?\n",
      "['men', '##g', 'bo']\n",
      "Initial question: \n",
      " what is ron husband's gender\n",
      "['ro']\n",
      "Initial question: \n",
      " what genre of music is episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 476/1000 [00:08<00:10, 52.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " who was the producer of danton (1983 film)\n",
      "['dan', '##ton']\n",
      "Initial question: \n",
      " What country produced the film betrayed\n",
      "[]\n",
      "Initial question: \n",
      " Name an artist on emi record label\n",
      "['em', '##i']\n",
      "Initial question: \n",
      " what is a gameplay mode featured on everquest ii: desert of flames\n",
      "['ever', '##quest']\n",
      "Initial question: \n",
      " where did albert dietrich die\n",
      "['alb']\n",
      "Initial question: \n",
      " is reginald jacques male or female\n",
      "['regina']\n",
      "Initial question: \n",
      " where was jean-baptiste bnard de la harpe born\n",
      "[]\n",
      "Initial question: \n",
      " what label is emmanuel pahud on \n",
      "['em', '##manu', '##el']\n",
      "Initial question: \n",
      " what is a 1976 soul music album\n",
      "[]\n",
      "Initial question: \n",
      " from which european is heinz gnthardt from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 488/1000 [00:09<00:09, 55.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['europea']\n",
      "Initial question: \n",
      " where was beniamina kaintikuaba born \n",
      "[]\n",
      "Initial question: \n",
      " what is the nationality of paco clos?\n",
      "['pa']\n",
      "Initial question: \n",
      " Which country did the film the galndez file come from\n",
      "['gal', '##n', '##dez']\n",
      "Initial question: \n",
      " what is the nationality of loretta swit\n",
      "['lore']\n",
      "Initial question: \n",
      " what is the genre of the album black caesar\n",
      "[]\n",
      "Initial question: \n",
      " what is yahiro kazama's gender\n",
      "['ya', '##hiro', 'ka', '##zama']\n",
      "Initial question: \n",
      " What language is an elephant called slowly filmed in?\n",
      "[]\n",
      "Initial question: \n",
      " What city in Scotland was kevin bradley born in?\n",
      "['Scotland']\n",
      "Initial question: \n",
      " What is tatsugo kawaishi's nationality\n",
      "['tat']\n",
      "Initial question: \n",
      " which languages were spoken in yu ming is ainm dom?\n",
      "['yu']\n",
      "Initial question: \n",
      " What films has rick pearson edited?\n",
      "[]\n",
      "Initial question: \n",
      " Who is the artist that recorded the album ramble at the ryman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 494/1000 [00:09<00:09, 51.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who']\n",
      "Initial question: \n",
      " What soccer position does guillermo eizaguirre play\n",
      "['gu', '##zag', '##uir']\n",
      "Initial question: \n",
      " who is a man born in delaware county, pennsylvania \n",
      "['dela', '##ware', 'penn', '##sy', '##lva', '##nia']\n",
      "Initial question: \n",
      " what country is cynthia mckinney a citizen of\n",
      "[]\n",
      "Initial question: \n",
      " Who perished from a stroke\n",
      "[]\n",
      "Initial question: \n",
      " what genre is howling bells \n",
      "[]\n",
      "Initial question: \n",
      " where was the 6666 fr discovered \n",
      "['666']\n",
      "Initial question: \n",
      " what kind of music is on singer of sad songs?\n",
      "[]\n",
      "Initial question: \n",
      " what genre is the artist korey cooper\n",
      "['kor']\n",
      "Initial question: \n",
      " Which city was roman aparicio born in\n",
      "['roman']\n",
      "Initial question: \n",
      " Name a musician born in sheffield\n",
      "['she', '##ffi']\n",
      "Initial question: \n",
      " What is the architectural style of the palm cottage house?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 507/1000 [00:09<00:09, 53.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What kind of music is featured on always\n",
      "[]\n",
      "Initial question: \n",
      " of what nationality is  udmila cervanov \n",
      "['', '##ud', '##mila', 'ce']\n",
      "Initial question: \n",
      " What is the name of a child of olaf eller\n",
      "['What', '##f']\n",
      "Initial question: \n",
      " which nationality is idrees bashir\n",
      "['id']\n",
      "Initial question: \n",
      " what musical genre does  brandon reilly create\n",
      "['brand']\n",
      "Initial question: \n",
      " Where did istvn kardos die\n",
      "['ist']\n",
      "Initial question: \n",
      " what is the country of mark twain's nationality?\n",
      "[]\n",
      "Initial question: \n",
      " which asteroid group is 1684 iguass a part of\n",
      "['1684', 'ig', '##uas', '##s', '##']\n",
      "Initial question: \n",
      " what is the name of a midfielder in football\n",
      "[]\n",
      "Initial question: \n",
      " what language is bouboulina filmed in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 513/1000 [00:09<00:09, 50.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bou', '##bou', '##lina']\n",
      "Initial question: \n",
      " What kind of gameplay mode does the game dynasty warriors 3 utilize? \n",
      "['##s', '3']\n",
      "Initial question: \n",
      " what gender is xiao qian\n",
      "['x', '##ia', '##o', 'q']\n",
      "Initial question: \n",
      " What type of rock does hefner (band) play\n",
      "['he', '##fn', '##er']\n",
      "Initial question: \n",
      " Name a center (basketball).\n",
      "['basketball']\n",
      "Initial question: \n",
      " what album was done by kris kristofferson\n",
      "['kr', '##is', 'kr']\n",
      "Initial question: \n",
      " what language is from pink eye\n",
      "[]\n",
      "Initial question: \n",
      " What time zone is magnolia township included in\n",
      "['mag', '##noli', '##a']\n",
      "Initial question: \n",
      " what organization was founded by  nils nilsson\n",
      "['ni', '##ls']\n",
      "Initial question: \n",
      " which actress was born in ponca city \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 526/1000 [00:09<00:09, 50.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['po', '##nca']\n",
      "Initial question: \n",
      " what's the default language of scenes from a mall\n",
      "[]\n",
      "Initial question: \n",
      " which movie was written by stuart gordon\n",
      "['st']\n",
      "Initial question: \n",
      " who wrote the film the skin\n",
      "[]\n",
      "Initial question: \n",
      " what's k. c. singh baba gender\n",
      "['what']\n",
      "Initial question: \n",
      " What's a gameplay mode in ghost pilots\n",
      "[]\n",
      "Initial question: \n",
      " which military person was involved in world war i?\n",
      "[]\n",
      "Initial question: \n",
      " whats joanna szczepkowska's gender\n",
      "['joan', '##na', 'sz', '##cze', '##p', '##kow', '##ska']\n",
      "Initial question: \n",
      " genki dean died where\n",
      "['gen', '##ki']\n",
      "Initial question: \n",
      " what type of music is the album frogstomp?\n",
      "[]\n",
      "Initial question: \n",
      " what film did regurgitationmusic direct?\n",
      "[]\n",
      "Initial question: \n",
      " what is nebula's gender \n",
      "['nebula']\n",
      "Initial question: \n",
      " what is 1601 patry \n",
      "[]\n",
      "Initial question: \n",
      " who was born in lockport?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 539/1000 [00:10<00:08, 53.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lock']\n",
      "Initial question: \n",
      " where did duncan gordon boyes pass away at?\n",
      "['dun', '##can']\n",
      "Initial question: \n",
      " what position does georgios samaras play?\n",
      "['ge', '##org']\n",
      "Initial question: \n",
      " what is the religion of roger garaudy?\n",
      "[]\n",
      "Initial question: \n",
      " Where was charles deaton born?\n",
      "['char', '##les', '##ton']\n",
      "Initial question: \n",
      " Name a record produce by the dream pop duo from Baltimore\n",
      "['Baltimore']\n",
      "Initial question: \n",
      " What baseball position does tommy obrien as?\n",
      "['baseball']\n",
      "Initial question: \n",
      " what country made resident evil: apocalypse\n",
      "[]\n",
      "Initial question: \n",
      " what is the name of a multiplayer game\n",
      "['multi']\n",
      "Initial question: \n",
      " Who is a person of the bengali people\n",
      "['ben', '##gali']\n",
      "Initial question: \n",
      " what type of film is season of love?\n",
      "[]\n",
      "Initial question: \n",
      " what county and state is brooklet located in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 551/1000 [00:10<00:08, 52.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bro', '##ok', '##let']\n",
      "Initial question: \n",
      " Who directed magic?\n",
      "[]\n",
      "Initial question: \n",
      " who is a man born in delaware county, pennsylvania \n",
      "['dela', '##ware', 'penn', '##sy', '##lva', '##nia']\n",
      "Initial question: \n",
      " What is the name of a place located in erath county\n",
      "['erat', '##h']\n",
      "Initial question: \n",
      " Where in the US was michael nichols born\n",
      "['US']\n",
      "Initial question: \n",
      " what asteroid group is 5333 kanaya a member of\n",
      "['533', '##3', 'kana', '##ya']\n",
      "Initial question: \n",
      " What is the fourth album from artist loudon wainwright iii?\n",
      "[]\n",
      "Initial question: \n",
      " who is the performer of party queen\n",
      "[]\n",
      "Initial question: \n",
      " What football position does sam slocombe \n",
      "[]\n",
      "Initial question: \n",
      " Which country is the film bittersweet memories from\n",
      "[]\n",
      "Initial question: \n",
      " Who was the publisher for the computer videogame time commando?\n",
      "[]\n",
      "Initial question: \n",
      " what country is steve gomer from\n",
      "[]\n",
      "Initial question: \n",
      " what is an album from the artist alexia (italian singer)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 563/1000 [00:10<00:08, 53.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['italian']\n",
      "Initial question: \n",
      " who was michael gerald ford's mother\n",
      "['mich', '##ael', 'geral', '##d', 'ford']\n",
      "Initial question: \n",
      " what position does denis odoi play\n",
      "['od']\n",
      "Initial question: \n",
      " what film was  noel coward the film story contributor of\n",
      "[]\n",
      "Initial question: \n",
      " what kinds of music is breaking things\n",
      "[]\n",
      "Initial question: \n",
      " What is a film that mike figgis has written?\n",
      "['mi']\n",
      "Initial question: \n",
      " who has gemini 7\n",
      "['ge']\n",
      "Initial question: \n",
      " what game series is metal gear acid 2\n",
      "[]\n",
      "Initial question: \n",
      " what is zamora's country of nationality?\n",
      "['za', '##mora']\n",
      "Initial question: \n",
      " What's a movie that william goetz produced\n",
      "['will', '##iam', 'go', '##etz']\n",
      "Initial question: \n",
      " what is june preisser's gender\n",
      "['ju']\n",
      "Initial question: \n",
      " What position does felix chimaokwu play\n",
      "['fel', 'chim', '##ao', '##k', '##wu']\n",
      "Initial question: \n",
      " who created the character dave gibbons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 575/1000 [00:10<00:07, 54.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da']\n",
      "Initial question: \n",
      " what position does john crowley play in baseball\n",
      "['baseball']\n",
      "Initial question: \n",
      " which artist made the album best of dolly parton, vol. 3\n",
      "[]\n",
      "Initial question: \n",
      " what is daniel altman's gender\n",
      "['dan']\n",
      "Initial question: \n",
      " in which italian city did vanna brosio die\n",
      "['italian']\n",
      "Initial question: \n",
      " what is a city located in west sumatra\n",
      "['suma', '##tra']\n",
      "Initial question: \n",
      " where is christopher wood (english painter) from\n",
      "['engl']\n",
      "Initial question: \n",
      " what is jim hegan's gender?\n",
      "['jim', 'he', '##gan']\n",
      "Initial question: \n",
      " What is the name of a real-time strategy game\n",
      "['real']\n",
      "Initial question: \n",
      " What is a film that vladimir tarasov is known for?\n",
      "['v', '##ladi', '##mir', 'tar', '##aso', '##v']\n",
      "Initial question: \n",
      " what is a pop music album\n",
      "[]\n",
      "Initial question: \n",
      " What instrument did pat bergeson played?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 588/1000 [00:10<00:07, 56.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pat', 'berg', '##eson']\n",
      "Initial question: \n",
      " Name an opera artist\n",
      "[]\n",
      "Initial question: \n",
      " Who did the cinematography for the film limbo\n",
      "[]\n",
      "Initial question: \n",
      " where is todd palin from\n",
      "['to', '##dd']\n",
      "Initial question: \n",
      " what organization was founded by david ben-gurion\n",
      "['da']\n",
      "Initial question: \n",
      " What type of music is in all aglow again!\n",
      "[]\n",
      "Initial question: \n",
      " how did walter of chtillon die\n",
      "[]\n",
      "Initial question: \n",
      " who was born in hamburg?\n",
      "['ham', '##burg']\n",
      "Initial question: \n",
      " what movie did pierce brosnan produce and star in\n",
      "[]\n",
      "Initial question: \n",
      " what position does pete liske play in american football\n",
      "['american']\n",
      "Initial question: \n",
      " where did felix manalo die\n",
      "[]\n",
      "Initial question: \n",
      " what city did manilal doctor pass away in?\n",
      "['mani']\n",
      "Initial question: \n",
      " Who was a notable figure that was born in palo alto\n",
      "[]\n",
      "Initial question: \n",
      " what kind of celestial body is 3416 dorrit?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 601/1000 [00:11<00:06, 57.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " Where was jim caldwell born\n",
      "['jim']\n",
      "Initial question: \n",
      " Who is someone that was born in bellshill\n",
      "['bells']\n",
      "Initial question: \n",
      " where did cathy downs pass away in\n",
      "['cat']\n",
      "Initial question: \n",
      " is rick fehr from the united states or canada\n",
      "[]\n",
      "Initial question: \n",
      " which band created the catatonia platinum collection\n",
      "['cat', '##aton', '##ia']\n",
      "Initial question: \n",
      " What is duncan cameron's gender\n",
      "['dun', '##can', 'came']\n",
      "Initial question: \n",
      " Where was n.k. salil born\n",
      "['sal']\n",
      "Initial question: \n",
      " What language is the film house of frankenstein recorded in?\n",
      "['fra', '##nken', '##stein']\n",
      "Initial question: \n",
      " who was born in the location beaumont?\n",
      "['beau', '##mont']\n",
      "Initial question: \n",
      " What is amber borycki's profession?\n",
      "['amb', '##er', 'bor', '##yck', '##i']\n",
      "Initial question: \n",
      " what did pat roberts do as a career \n",
      "['pat']\n",
      "Initial question: \n",
      " What gender is lol solman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 614/1000 [00:11<00:06, 56.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lo', '##l']\n",
      "Initial question: \n",
      " how did charles david keeling die?\n",
      "[]\n",
      "Initial question: \n",
      " what is steve shea's profession\n",
      "['st', '##eve', 'she', '##a']\n",
      "Initial question: \n",
      " What country is the doctor and the devils from?\n",
      "[]\n",
      "Initial question: \n",
      " what genre is howling bells \n",
      "[]\n",
      "Initial question: \n",
      " which team uses the buck shaw stadium as the home stadium\n",
      "[]\n",
      "Initial question: \n",
      " from which country is bryce soderberg from\n",
      "['br', 'so', '##berg']\n",
      "Initial question: \n",
      " what musician played the bass guitar?\n",
      "[]\n",
      "Initial question: \n",
      " What is the gender of nicky jones\n",
      "['nic']\n",
      "Initial question: \n",
      " is nick barmby male or female \n",
      "[]\n",
      "Initial question: \n",
      " how did charles ruggles die?\n",
      "['char']\n",
      "Initial question: \n",
      " whats the lower classification of motacillidae\n",
      "[]\n",
      "Initial question: \n",
      " who is the author of extreme measures?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 620/1000 [00:11<00:06, 54.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " how would halil kut be classified regarding gender\n",
      "[]\n",
      "Initial question: \n",
      " what type of movie was the netflix title  dont answer the phone\n",
      "['net', '##f', '##li', '##x']\n",
      "Initial question: \n",
      " Who's a parent of james francis ginty\n",
      "['jam']\n",
      "Initial question: \n",
      " What were the film story credits by vittorio mussolini?\n",
      "['vit']\n",
      "Initial question: \n",
      " who is james i of scotland's son\n",
      "['s', '##cot', '##land']\n",
      "Initial question: \n",
      " what is the nationality of jeff cotton\n",
      "[]\n",
      "Initial question: \n",
      " what gender is arthur moore lascelles?\n",
      "['art']\n",
      "Initial question: \n",
      " what kind of film was jesus?\n",
      "['je', '##sus']\n",
      "Initial question: \n",
      " what language is alien intruder in?\n",
      "[]\n",
      "Initial question: \n",
      " Which organization was founded by robert bosch\n",
      "['W', 'robe']\n",
      "Initial question: \n",
      " where was lvaro guerrero born\n",
      "['lvaro', 'guerre', '##ro']\n",
      "Initial question: \n",
      " Who is vairamuthu the child of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 633/1000 [00:11<00:06, 57.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vai', '##ram', '##uth', '##u']\n",
      "Initial question: \n",
      " which city did christoffer gabel pass away in\n",
      "['ch']\n",
      "Initial question: \n",
      " which body of water spanned by the parkersburg bridge\n",
      "['park', '##ers', '##burg']\n",
      "Initial question: \n",
      " which disease caused willem rooseboom's death\n",
      "['will', '##em', 'ro', '##ose', '##bo', '##om']\n",
      "Initial question: \n",
      " what nationality is ronald defeo, jr.?\n",
      "['ro']\n",
      "Initial question: \n",
      " Who's a musician associated with astralwerks\n",
      "['as', '##werks']\n",
      "Initial question: \n",
      " what structure is an example of chteauesque\n",
      "['chteau']\n",
      "Initial question: \n",
      " Who's the directed credited for anna and the king of siam\n",
      "[]\n",
      "Initial question: \n",
      " What instrument does brian karscig play?\n",
      "['br']\n",
      "Initial question: \n",
      " what is the time zone of meadow brook township?\n",
      "[]\n",
      "Initial question: \n",
      " whats josh heinrichs's biological sex\n",
      "['he', '##in', '##rich']\n",
      "Initial question: \n",
      " What is the name of a country artist\n",
      "[]\n",
      "Initial question: \n",
      " What is a film that chuck jones wrote?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 645/1000 [00:11<00:06, 56.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chu']\n",
      "Initial question: \n",
      " what genre does fair ground belong to\n",
      "[]\n",
      "Initial question: \n",
      " what is jean a. stuntz's gender?\n",
      "['je']\n",
      "Initial question: \n",
      " what is a city in jefferson county\n",
      "['je', '##ffers', '##on']\n",
      "Initial question: \n",
      " which city in ireland was sean finn born\n",
      "['finn']\n",
      "Initial question: \n",
      " Name a professional songwriter.\n",
      "[]\n",
      "Initial question: \n",
      " What is the country of origin of the program alfred j. kwak?\n",
      "['al', '##fre', '##d', 'j', '.', 'kwa', '##k']\n",
      "Initial question: \n",
      " where is ingram located \n",
      "['ing']\n",
      "Initial question: \n",
      " Who directed the film edward scissorhands\n",
      "['ed', '##ward', 'sci', '##sso', '##r', '##hand', '##s']\n",
      "Initial question: \n",
      " which film is joie lee a story contributor for\n",
      "[]\n",
      "Initial question: \n",
      " What is the music genre of the album yume miru uchuu?\n",
      "['yu', '##me', 'mir', '##u', 'u', '##chu', '##u']\n",
      "Initial question: \n",
      " What is the name of a singer born in stockholm?\n",
      "['stock', '##holm']\n",
      "Initial question: \n",
      " what type of book is a medicine for melancholy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 658/1000 [00:12<00:05, 57.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What country is elahi bux soomro from?\n",
      "[]\n",
      "Initial question: \n",
      " what is the genre of the album boys night out\n",
      "[]\n",
      "Initial question: \n",
      " is frank cook male or female\n",
      "['fra']\n",
      "Initial question: \n",
      " who directed the secret agent club\n",
      "[]\n",
      "Initial question: \n",
      " where did scar mguez die\n",
      "['scar', 'mg', '##ue', '##z']\n",
      "Initial question: \n",
      " What language is spoken in portrait of hell\n",
      "[]\n",
      "Initial question: \n",
      " who is the child of agustin de iturbide?\n",
      "['agus', '##rb', '##ide']\n",
      "Initial question: \n",
      " what is the position that bryan dominguez played?\n",
      "['br']\n",
      "Initial question: \n",
      " What gender is archduchess maria elisabeth of austria\n",
      "['aust', '##ria']\n",
      "Initial question: \n",
      " What is ilya khrzhanovsky's profession?\n",
      "['il', '##ya', 'k', '##hr', '##zh', '##ano', '##vsky']\n",
      "Initial question: \n",
      " which language is used in priyasakhi\n",
      "['pri', '##yasa', '##kh', '##i']\n",
      "Initial question: \n",
      " what is the gender of sabine lancelin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 670/1000 [00:12<00:05, 57.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sa', '##bine']\n",
      "Initial question: \n",
      " Where did norman l. bowen die\n",
      "['norma']\n",
      "Initial question: \n",
      " What is lucas Fernndez's gender?\n",
      "['Fernndez']\n",
      "Initial question: \n",
      " what country did cursed originate from?\n",
      "[]\n",
      "Initial question: \n",
      " where was wesam rizik born\n",
      "['we', '##sam', 'ri', '##zik']\n",
      "Initial question: \n",
      " who authored a year with swollen appendices\n",
      "[]\n",
      "Initial question: \n",
      " What line of work is john e. peterson in\n",
      "['jo']\n",
      "Initial question: \n",
      " what is a drama film released in 2007?\n",
      "[]\n",
      "Initial question: \n",
      " what language is spoken in candleshoe\n",
      "['cand']\n",
      "Initial question: \n",
      " what time zone is brian head in\n",
      "['br']\n",
      "Initial question: \n",
      " what was matthew gaines's place of death\n",
      "[]\n",
      "Initial question: \n",
      " What kind of movie is the ordered to love\n",
      "[]\n",
      "Initial question: \n",
      " Where was ian mosley born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 683/1000 [00:12<00:05, 57.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ia']\n",
      "Initial question: \n",
      " in which language is resurrection\n",
      "[]\n",
      "Initial question: \n",
      " What is Vera Vitali's nationality?\n",
      "['Vera', 'Vita', '##li']\n",
      "Initial question: \n",
      " where was jan laskowski born?\n",
      "['jan', 'las', '##kowski']\n",
      "Initial question: \n",
      " is rudolf wickel male or female \n",
      "['rud', '##ol']\n",
      "Initial question: \n",
      " what's the name of a linebacker who was born in los angeles\n",
      "[]\n",
      "Initial question: \n",
      " Is bill quinlan a male or female?\n",
      "['bill']\n",
      "Initial question: \n",
      " What netflix genre does the jayne mansfield story belong to\n",
      "['ja']\n",
      "Initial question: \n",
      " what religion does keith mitchell practice\n",
      "['ke']\n",
      "Initial question: \n",
      " who is the director of two flags west \n",
      "[]\n",
      "Initial question: \n",
      " what does erik stolhanske do\n",
      "[]\n",
      "Initial question: \n",
      " Name a person who has died from pancreatic cancer.\n",
      "['pan', '##atic']\n",
      "Initial question: \n",
      " Where in missouri was joel shanker born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 695/1000 [00:12<00:05, 57.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What genre of music does  simone bittencourt de oliveira create\n",
      "[]\n",
      "Initial question: \n",
      " who is an artist that contributes to tiger in the rain\n",
      "[]\n",
      "Initial question: \n",
      " What soccer player died from cirrhosis?\n",
      "[]\n",
      "Initial question: \n",
      " What's a sega published game\n",
      "['What', 'seg', '##a']\n",
      "Initial question: \n",
      " what was ragini's cause of death\n",
      "['ra', '##gini']\n",
      "Initial question: \n",
      " What nationality is nozomi hazuki?\n",
      "['no', '##zom', '##i']\n",
      "Initial question: \n",
      " who wrote the film 200 motels\n",
      "['200', 'mot', '##els']\n",
      "Initial question: \n",
      " What is vitlijs maksimenko position\n",
      "['What', 'vit', '##li']\n",
      "Initial question: \n",
      " who plays shooting guard\n",
      "[]\n",
      "Initial question: \n",
      " whats alonzo clayton's ethnicity\n",
      "['al', '##zo']\n",
      "Initial question: \n",
      " Name a drama film\n",
      "[]\n",
      "Initial question: \n",
      " who in the world was born in wallsend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 708/1000 [00:12<00:05, 57.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walls']\n",
      "Initial question: \n",
      " what artist is under sony music entertainment?\n",
      "[]\n",
      "Initial question: \n",
      " who composed i have dreamed\n",
      "['i']\n",
      "Initial question: \n",
      " what is eric weissberg's place of birth?\n",
      "['eri', '##ss', '##berg']\n",
      "Initial question: \n",
      " Name a person born in geseke.\n",
      "['ge', '##sek', '##e']\n",
      "Initial question: \n",
      " What country does yellow emanuelle take place?\n",
      "['yellow']\n",
      "Initial question: \n",
      " what country is love me forever from\n",
      "[]\n",
      "Initial question: \n",
      " what country is justin holiday from?\n",
      "[]\n",
      "Initial question: \n",
      " What label did carmen record with \n",
      "[]\n",
      "Initial question: \n",
      " what was david m. ronne's place of death?\n",
      "['da', 'm']\n",
      "Initial question: \n",
      " Who was a significant figure from barbados\n",
      "['bar', '##bado']\n",
      "Initial question: \n",
      " who is a person born in  alexandria, virginia\n",
      "['ale']\n",
      "Initial question: \n",
      " what is a disaster film?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 720/1000 [00:13<00:04, 57.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " Who is a German former football player from reutlingen?\n",
      "['German']\n",
      "Initial question: \n",
      " Who was the raman spectroscopy named after?\n",
      "['rama']\n",
      "Initial question: \n",
      " Name one musician that played the bass guitar\n",
      "[]\n",
      "Initial question: \n",
      " what constellation is hd 157819 in\n",
      "['h']\n",
      "Initial question: \n",
      " who wrote the film cars 2\n",
      "[]\n",
      "Initial question: \n",
      " is farajullah salahshur a man or a woman\n",
      "[]\n",
      "Initial question: \n",
      " What soccer position does john mcphee play?\n",
      "['jo']\n",
      "Initial question: \n",
      " Which artist recorded the album flaming pie\n",
      "[]\n",
      "Initial question: \n",
      " which gender is tracy barlow\n",
      "['tra']\n",
      "Initial question: \n",
      " Where was satyagraha shot\n",
      "['sat', '##ya', '##gra']\n",
      "Initial question: \n",
      " What profession was antonio labacco?\n",
      "['ant', '##oni', '##o']\n",
      "Initial question: \n",
      " is igor pretnar male or female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 732/1000 [00:13<00:04, 54.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " Which artist is from the album ray brown / milt jackson\n",
      "[]\n",
      "Initial question: \n",
      " what killed david w. allen\n",
      "['da']\n",
      "Initial question: \n",
      " which city was helena mattsson born \n",
      "['hele']\n",
      "Initial question: \n",
      " who discovered 4350 shibecha?\n",
      "[]\n",
      "Initial question: \n",
      " is yakuza weapon from japan or china\n",
      "['jap', '##an']\n",
      "Initial question: \n",
      " what mode can you play bionicle heroes\n",
      "[]\n",
      "Initial question: \n",
      " What is Chase McBride's profession?\n",
      "['Chase', 'M', '##c', '##Bride']\n",
      "Initial question: \n",
      " What is sergei nemchinov's nationality\n",
      "['##v']\n",
      "Initial question: \n",
      " which city was gerold schwarzenbach born in \n",
      "['gero', '##bach']\n",
      "Initial question: \n",
      " who is the child of agustin de iturbide?\n",
      "['agus', '##rb', '##ide']\n",
      "Initial question: \n",
      " which country is the mad whirl from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 738/1000 [00:13<00:05, 51.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what is chris withe's gender?\n",
      "['ch', '##e']\n",
      "Initial question: \n",
      " what series is the episode demons from\n",
      "[]\n",
      "Initial question: \n",
      " what city in new york was smith ely jelliffe born in \n",
      "['new']\n",
      "Initial question: \n",
      " What is the gender of denise caruso?\n",
      "['car', '##uso']\n",
      "Initial question: \n",
      " Name someone buried in crown hill cemetery\n",
      "[]\n",
      "Initial question: \n",
      " what artists are signed to desoto records\n",
      "['des', '##oto']\n",
      "Initial question: \n",
      " In which city was william s. tilton born?\n",
      "['will', '##iam']\n",
      "Initial question: \n",
      " What was the name of the son of  leopold ii, holy roman emperor?\n",
      "['leo', '##pol', '##d', 'ii', 'roman']\n",
      "Initial question: \n",
      " Where was the pool hustlers released?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 749/1000 [00:13<00:05, 49.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " who is a third baseman\n",
      "[]\n",
      "Initial question: \n",
      " where was paul monnier's death\n",
      "['pau']\n",
      "Initial question: \n",
      " what is a city in cuyahoga county\n",
      "['cuya', '##hog', '##a']\n",
      "Initial question: \n",
      " what is gwen margolis's gender?\n",
      "['mar', '##gol']\n",
      "Initial question: \n",
      " What is matt serra's gender?\n",
      "['serra']\n",
      "Initial question: \n",
      " sammo hung is given producer credit for what vampire film\n",
      "['sam', '##mo', 'hung']\n",
      "Initial question: \n",
      " which tv series features bodyswap as an episode \n",
      "[]\n",
      "Initial question: \n",
      " which country produced x factor\n",
      "[]\n",
      "Initial question: \n",
      " who is the author of the book liars in love\n",
      "[]\n",
      "Initial question: \n",
      " is the movie i was a mail order bride in french or english language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 760/1000 [00:14<00:04, 49.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engl', '##ish']\n",
      "Initial question: \n",
      " What country was boris babochkin born in?\n",
      "['ba']\n",
      "Initial question: \n",
      " is lola and billy the kid in french or the german language\n",
      "['german']\n",
      "Initial question: \n",
      " who is a person born in seville\n",
      "[]\n",
      "Initial question: \n",
      " What's a book that eric flint wrote\n",
      "['eri']\n",
      "Initial question: \n",
      " who died from hanging\n",
      "[]\n",
      "Initial question: \n",
      " what genre of film is shoeshine\n",
      "['sh']\n",
      "Initial question: \n",
      " Name a person born in Kolkata.\n",
      "['Kolkata']\n",
      "Initial question: \n",
      " what is the film genre of old-fashioned world?\n",
      "[]\n",
      "Initial question: \n",
      " what films have been directed by nancy walker?\n",
      "[]\n",
      "Initial question: \n",
      " where did bill monroe kick the bucket\n",
      "[]\n",
      "Initial question: \n",
      " What is an east coast hip hop album?\n",
      "['east']\n",
      "Initial question: \n",
      " Who is a notable person that was born in pori\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 773/1000 [00:14<00:04, 54.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['por', '##i']\n",
      "Initial question: \n",
      " How did samuel davies die?\n",
      "['sam', '##uel']\n",
      "Initial question: \n",
      " what albums are by the temptations?\n",
      "[]\n",
      "Initial question: \n",
      " WHere is ron melendez from\n",
      "['W', '##H', '##ere']\n",
      "Initial question: \n",
      " which gender is quintin berry\n",
      "['qui']\n",
      "Initial question: \n",
      " whats a second level division in  united kingdom\n",
      "[]\n",
      "Initial question: \n",
      " is 3017 petrovi an asteroid or a star\n",
      "['301', '##7', 'pet', '##rov', '##i']\n",
      "Initial question: \n",
      " where is knoll lake located\n",
      "['kn']\n",
      "Initial question: \n",
      " he plays forward in soccer.\n",
      "['soccer']\n",
      "Initial question: \n",
      " What genre is his lordships dilemma?\n",
      "[]\n",
      "Initial question: \n",
      " What gender is the character man-bat\n",
      "['man', 'bat']\n",
      "Initial question: \n",
      " in which city did burhanuddin harahap die\n",
      "['bu']\n",
      "Initial question: \n",
      " what position does osama elsamni play \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 785/1000 [00:14<00:03, 54.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['osam', '##a']\n",
      "Initial question: \n",
      " What is a film in the genre documentary film?\n",
      "[]\n",
      "Initial question: \n",
      " Who directed the film freuds leaving home?\n",
      "[]\n",
      "Initial question: \n",
      " What is peter wei's country of origin?\n",
      "['pet', '##er', 'wei']\n",
      "Initial question: \n",
      " who directed wild target\n",
      "[]\n",
      "Initial question: \n",
      " Where is mike morrell from\n",
      "[]\n",
      "Initial question: \n",
      " What is the place of barbara cook's birth?\n",
      "['bar', '##bara']\n",
      "Initial question: \n",
      " which baseball player is known for playing left fielder\n",
      "['baseball']\n",
      "Initial question: \n",
      " What band has the album holy diver \n",
      "['holy']\n",
      "Initial question: \n",
      " what soccer position does manuel kant play\n",
      "[]\n",
      "Initial question: \n",
      " Who composed the music featured in the film the third secret\n",
      "[]\n",
      "Initial question: \n",
      " what is robert olen butler's profession in the literature industry?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 797/1000 [00:14<00:04, 48.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What company did alex seropian found\n",
      "['ale', '##x']\n",
      "Initial question: \n",
      " What's a film from dick clark productions\n",
      "[]\n",
      "Initial question: \n",
      " What position does kostas kaimakoglou play?\n",
      "['ko', '##stas']\n",
      "Initial question: \n",
      " What was the cause of death of Toni Fisher?\n",
      "['Toni', 'Fisher']\n",
      "Initial question: \n",
      " Name a musician. \n",
      "[]\n",
      "Initial question: \n",
      " which film did shintaro katsu produce\n",
      "['shi', '##ntar']\n",
      "Initial question: \n",
      " tecmo developed what computer videogame?\n",
      "['te', '##cm', '##o']\n",
      "Initial question: \n",
      " what county is crawford found in\n",
      "['c', '##ford']\n",
      "Initial question: \n",
      " Which city in europe was gabriel-hippolyte destailleur born in\n",
      "['euro']\n",
      "Initial question: \n",
      " Where is rudolf brandt originally from?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 803/1000 [00:14<00:03, 51.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rud']\n",
      "Initial question: \n",
      " who is a player that plays the position of defender?\n",
      "[]\n",
      "Initial question: \n",
      " what country is beyond the rocks filmed in \n",
      "[]\n",
      "Initial question: \n",
      " where is the place of death of ella cora hind?\n",
      "['ella']\n",
      "Initial question: \n",
      " Name a film directed by alfred hitchcock\n",
      "['al']\n",
      "Initial question: \n",
      " what is blake costanzo's gender \n",
      "['costa']\n",
      "Initial question: \n",
      " who is an artist signed to liberty records\n",
      "['liber']\n",
      "Initial question: \n",
      " which gender is buddie petit\n",
      "['bu', '##ddi']\n",
      "Initial question: \n",
      " what music instrument does bryan sutton play\n",
      "['br']\n",
      "Initial question: \n",
      " Which timezone is quebec located in\n",
      "['que', '##bec']\n",
      "Initial question: \n",
      " what type of music is a peleja do diabo com o dono do cu\n",
      "[]\n",
      "Initial question: \n",
      " What is marilyn burns's nationality?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 815/1000 [00:15<00:03, 49.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " Who is someone that is african american?\n",
      "['af']\n",
      "Initial question: \n",
      " who produced midnight cowboy\n",
      "[]\n",
      "Initial question: \n",
      " What type of film is \"Two In the Wave\"?\n",
      "['Two', 'In', 'the', 'Wave']\n",
      "Initial question: \n",
      " What is the gender of david hudson\n",
      "['da']\n",
      "Initial question: \n",
      " which game is of the cvg genre beat em up\n",
      "['c', '##v', '##g', 'beat', 'em', 'up']\n",
      "Initial question: \n",
      " where was  paulo maluf born\n",
      "['pau', '##lo', 'mal', '##uf']\n",
      "Initial question: \n",
      " what country was the overcoat released in\n",
      "[]\n",
      "Initial question: \n",
      " What nation filmed le cirque: a table in heaven\n",
      "[]\n",
      "Initial question: \n",
      " what genre is the film bombai ka babu\n",
      "['bomba', '##i', 'ka', 'ba', '##bu']\n",
      "Initial question: \n",
      " what gender is angelica page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 826/1000 [00:15<00:03, 47.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ang']\n",
      "Initial question: \n",
      " what operation was zvonimir ervenko a part of \n",
      "['z', '##von', '##imi', '##r', 'e', '##rven', '##ko']\n",
      "Initial question: \n",
      " What's a work written by james hilton?\n",
      "[]\n",
      "Initial question: \n",
      " Who is the artist from the premier hits album\n",
      "['Who']\n",
      "Initial question: \n",
      " what football position does randy coffield play at?\n",
      "[]\n",
      "Initial question: \n",
      " Which country was the film grahasthi from\n",
      "[]\n",
      "Initial question: \n",
      " what kind of music is stacey q known for?\n",
      "['sta', '##cey', 'q']\n",
      "Initial question: \n",
      " around which celestial body does the 2503 liaoning asteroid moves around\n",
      "['250', '##3', 'li', '##ao', '##ning']\n",
      "Initial question: \n",
      " who created gemini\n",
      "['ge']\n",
      "Initial question: \n",
      " what city was cornell burbage born in \n",
      "[]\n",
      "Initial question: \n",
      " where in germany did lisa helwig die?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 838/1000 [00:15<00:03, 49.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['german']\n",
      "Initial question: \n",
      " What is howard mccrary's ethnicity?\n",
      "['how']\n",
      "Initial question: \n",
      " whats a film by mutual film\n",
      "['what']\n",
      "Initial question: \n",
      " Who is a German former football player from reutlingen?\n",
      "['German']\n",
      "Initial question: \n",
      " what is a game played on single-player mode?\n",
      "[]\n",
      "Initial question: \n",
      " What position does football player michael howard play?\n",
      "['mich', '##ael', 'how', '##ard']\n",
      "Initial question: \n",
      " what is kainaz motivala's nationality?\n",
      "['kai']\n",
      "Initial question: \n",
      " which tv show for kids did bill walsh (producer) create\n",
      "[]\n",
      "Initial question: \n",
      " where was jamaica kincaid born\n",
      "['jam', '##aic', '##a']\n",
      "Initial question: \n",
      " which city did fritz odemar die\n",
      "[]\n",
      "Initial question: \n",
      " what country created the film  tan-badan\n",
      "['tan']\n",
      "Initial question: \n",
      " of what nationality is joyce ziske\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 851/1000 [00:15<00:02, 54.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jo', '##yce']\n",
      "Initial question: \n",
      " what type of movie is the third wave?\n",
      "[]\n",
      "Initial question: \n",
      " Which fictional character did geoff johns create?\n",
      "[]\n",
      "Initial question: \n",
      " Where did the tv show amerika originate\n",
      "['am', '##eri']\n",
      "Initial question: \n",
      " what country is bill fisk from\n",
      "[]\n",
      "Initial question: \n",
      " what is vicki anderson's gender \n",
      "['vi', 'anders', '##on']\n",
      "Initial question: \n",
      " what language is spoken in the film wish 143\n",
      "[]\n",
      "Initial question: \n",
      " is frank cappuccino male or female\n",
      "['fra']\n",
      "Initial question: \n",
      " which country made her escape \n",
      "[]\n",
      "Initial question: \n",
      " who is a person born in breda\n",
      "['bred', '##a']\n",
      "Initial question: \n",
      " what is the developer company of the portal video game\n",
      "[]\n",
      "Initial question: \n",
      " who's one of the musicians signed to emi music japan\n",
      "['em']\n",
      "Initial question: \n",
      " what position does charlie moore play \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 864/1000 [00:16<00:02, 57.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what country was of human hearts filmed in?\n",
      "[]\n",
      "Initial question: \n",
      " Which country is the conchos river in?\n",
      "['con']\n",
      "Initial question: \n",
      " what film does gregory la cava direct?\n",
      "['grego', '##ry']\n",
      "Initial question: \n",
      " who is a person that was born in plasencia\n",
      "['pla']\n",
      "Initial question: \n",
      " what position does dick mccormick play \n",
      "['m']\n",
      "Initial question: \n",
      " what is the name of a small pigeon species\n",
      "[]\n",
      "Initial question: \n",
      " What country was otto eisenschiml born in?\n",
      "['otto', 'ei', '##sens', '##ml']\n",
      "Initial question: \n",
      " which painter was born in arezzo?\n",
      "['are', '##zzo']\n",
      "Initial question: \n",
      " Which film did tarsem singh direct?\n",
      "[]\n",
      "Initial question: \n",
      " who is a famous person born in goa\n",
      "['go', '##a']\n",
      "Initial question: \n",
      " what country is san mateo in\n",
      "[]\n",
      "Initial question: \n",
      " What is the name of an american actress?\n",
      "['american']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 877/1000 [00:16<00:02, 58.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " what genre is forbidden floor under\n",
      "[]\n",
      "Initial question: \n",
      " is scott mellanby a male or female\n",
      "[]\n",
      "Initial question: \n",
      " What country does the madre de dios river run through\n",
      "['madre', 'de']\n",
      "Initial question: \n",
      " Which country is kristian hefte from\n",
      "['kr', '##isti', '##an']\n",
      "Initial question: \n",
      " what county is fortuna in\n",
      "[]\n",
      "Initial question: \n",
      " Where was the place claudio guzmn deceased?\n",
      "['c', '##lau', '##dio', 'gu', '##zm']\n",
      "Initial question: \n",
      " What is the sex of calvin peete?\n",
      "[]\n",
      "Initial question: \n",
      " which language is crime wave filmed in?\n",
      "[]\n",
      "Initial question: \n",
      " which defensive position does amedeo calliari play\n",
      "['am', '##ede', '##o', '##i']\n",
      "Initial question: \n",
      " where did eric marsh die?\n",
      "['eri']\n",
      "Initial question: \n",
      " Where did mischa spoliansky die\n",
      "['mis', '##cha', 'sp', '##nsky']\n",
      "Initial question: \n",
      " pather panchali is an adaptation of what work\n",
      "['path', '##er']\n",
      "Initial question: \n",
      " what is maria bartiromo's nationality?\n",
      "['mari', '##a']\n",
      "Initial question: \n",
      " whats josh heinrichs's biological sex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 890/1000 [00:16<00:01, 59.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', '##in', '##rich']\n",
      "Initial question: \n",
      " What is a game that 1c company published?\n",
      "['1', '##c']\n",
      "Initial question: \n",
      " what country is song without end from\n",
      "[]\n",
      "Initial question: \n",
      " who was the producer for ek tho chance\n",
      "['ek', 'th', '##o', 'chance']\n",
      "Initial question: \n",
      " where is jason pierre-paul from\n",
      "['jaso']\n",
      "Initial question: \n",
      " which production company made the film born yesterday\n",
      "[]\n",
      "Initial question: \n",
      " is jos mara rosa a female or male\n",
      "['jos']\n",
      "Initial question: \n",
      " allan haines loughead founded which prominent organization?\n",
      "['allan']\n",
      "Initial question: \n",
      " what country was crooklyn filmed in\n",
      "['c', '##lyn']\n",
      "Initial question: \n",
      " Who created the character of two-face?\n",
      "['two']\n",
      "Initial question: \n",
      " whats an example of a drama film\n",
      "[]\n",
      "Initial question: \n",
      " what is a silent film?\n",
      "['silent']\n",
      "Initial question: \n",
      " what operation was zvonimir ervenko a part of \n",
      "['z', '##von', '##imi', '##r', 'e', '##rven', '##ko']\n",
      "Initial question: \n",
      " who is a person born in gothenburg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 903/1000 [00:16<00:01, 59.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['got', '##hen', '##burg']\n",
      "Initial question: \n",
      " Who is a football striker born in ouagadougou?\n",
      "['ou', '##aga', '##dou', '##gou']\n",
      "Initial question: \n",
      " What is a film that was produced by british lion films\n",
      "['brit']\n",
      "Initial question: \n",
      " What gender is Nguyen nhat Anh?\n",
      "['Nguyen', 'n', '##hat', 'Anh']\n",
      "Initial question: \n",
      " what is an album by usher?\n",
      "[]\n",
      "Initial question: \n",
      " Where was Luke French born?\n",
      "['Luke', 'French']\n",
      "Initial question: \n",
      " Where did kathy staff spend her last day?\n",
      "['kat', '##hy']\n",
      "Initial question: \n",
      " What is marco rodrguez's nationality?\n",
      "['marco']\n",
      "Initial question: \n",
      " is judith lucy male or female\n",
      "['ju']\n",
      "Initial question: \n",
      " who died from tuberculosis\n",
      "['tuberculosis']\n",
      "Initial question: \n",
      " what country gives nationality to stewart liff\n",
      "[]\n",
      "Initial question: \n",
      " where was gary william friedman born\n",
      "[]\n",
      "Initial question: \n",
      " Which country does joseph zuken have citizenship in\n",
      "[]\n",
      "Initial question: \n",
      " What observatory discovered 4609 pizarro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 910/1000 [00:16<00:01, 59.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " what is oscar marx's gender identity\n",
      "['os', 'mar', '##x']\n",
      "Initial question: \n",
      " who was born in chittagong district\n",
      "['chi', '##tta', '##gong']\n",
      "Initial question: \n",
      " which brazilian actress was born in limeira?\n",
      "['bra', '##zili']\n",
      "Initial question: \n",
      " Name a politician\n",
      "[]\n",
      "Initial question: \n",
      " what kind of music is on singer of sad songs?\n",
      "[]\n",
      "Initial question: \n",
      " Who was an individual involved with the korean war? \n",
      "['kor', '##ean']\n",
      "Initial question: \n",
      " which 1982 polish film was written by ryszard bugajski?\n",
      "['ry']\n",
      "Initial question: \n",
      " Where was payo enriquez de rivera born?\n",
      "['pay', '##o', 'en', '##rique', '##z', 'de', 'river', '##a']\n",
      "Initial question: \n",
      " who is a person that died due to  prostate cancer\n",
      "[]\n",
      "Initial question: \n",
      " what position does william gallagher play?\n",
      "['will', '##iam', 'gall', '##agh', '##er']\n",
      "Initial question: \n",
      " What professional footballer was born in basingstoke\n",
      "['basin', '##gst', '##oke']\n",
      "Initial question: \n",
      " What position did etin gng play?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 922/1000 [00:16<00:01, 57.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '##etin']\n",
      "Initial question: \n",
      " what genre of music is the album released in?\n",
      "[]\n",
      "Initial question: \n",
      " what country created the film the royal mounted rides again\n",
      "[]\n",
      "Initial question: \n",
      " Where in indiana was jill bennett born\n",
      "['india']\n",
      "Initial question: \n",
      " who is the author of the art of detection?\n",
      "[]\n",
      "Initial question: \n",
      " What is the nationality of jade macrae\n",
      "[]\n",
      "Initial question: \n",
      " what is the nationality of samantha moore\n",
      "['saman']\n",
      "Initial question: \n",
      " what type of film is the quarry?\n",
      "[]\n",
      "Initial question: \n",
      " what player plays the position midfielder?\n",
      "[]\n",
      "Initial question: \n",
      " name a folk rock album\n",
      "[]\n",
      "Initial question: \n",
      " What is the profession of heinrich ries?\n",
      "['he', '##in', '##rich']\n",
      "Initial question: \n",
      " Who is the arist from the album remixes & live\n",
      "[]\n",
      "Initial question: \n",
      " what is high fidelity an adaptation of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 935/1000 [00:17<00:01, 53.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Initial question: \n",
      " What is a cartoon that jeff smith (cartoonist) had written\n",
      "['je', '##ff']\n",
      "Initial question: \n",
      " Who directed penny paradise?\n",
      "[]\n",
      "Initial question: \n",
      " which film is steve niles a story contributor \n",
      "[]\n",
      "Initial question: \n",
      " is  peter hynes male or female\n",
      "['pet']\n",
      "Initial question: \n",
      " where did marcelle praince die\n",
      "['marc']\n",
      "Initial question: \n",
      " Which category of celestial object is 534 nassovia\n",
      "['nas', '##sov', '##ia']\n",
      "Initial question: \n",
      " What program did tyra banks create?\n",
      "['ty', '##ra']\n",
      "Initial question: \n",
      " What kind of metal is featured on the album faceless\n",
      "[]\n",
      "Initial question: \n",
      " what is an episode of star trek directed by patrick stewart \n",
      "[]\n",
      "Initial question: \n",
      " who authored dragonfly: nasa and the crisis aboard mir?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 948/1000 [00:17<00:00, 54.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dragon']\n",
      "Initial question: \n",
      " What was bambi adapted from\n",
      "['ba']\n",
      "Initial question: \n",
      " which country is under the administrative division of wrexham county borough\n",
      "['w', '##re', '##x', '##ham']\n",
      "Initial question: \n",
      " 72 tenants of prosperity was directed by who?\n",
      "[]\n",
      "Initial question: \n",
      " What language is andra avenyn available in\n",
      "['andra', 'ave', '##ny', '##n']\n",
      "Initial question: \n",
      " what genre is lassie come home\n",
      "[]\n",
      "Initial question: \n",
      " what city in texas was omar uresti born in\n",
      "['te', '##xas']\n",
      "Initial question: \n",
      " what country is william osler from\n",
      "['will']\n",
      "Initial question: \n",
      " what language is spoken in the enigma of kaspar hauser\n",
      "['kas']\n",
      "Initial question: \n",
      " Who wrote the painted veil\n",
      "[]\n",
      "Initial question: \n",
      " Where is t. t. toliver from?\n",
      "[]\n",
      "Initial question: \n",
      " What was the birth place of dgar gonzlez?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 954/1000 [00:17<00:00, 52.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '##d', '##gar', 'go', '##nz', '##le', '##z']\n",
      "Initial question: \n",
      " Who's a female vocalist that performs opera\n",
      "['Who']\n",
      "Initial question: \n",
      " which position in the infield did cory bailey play\n",
      "[]\n",
      "Initial question: \n",
      " Which position did pierre pibarot play?\n",
      "['pierre']\n",
      "Initial question: \n",
      " what is the gender of harvir baidwan\n",
      "[]\n",
      "Initial question: \n",
      " what country gives nationality to wayne westmark\n",
      "[]\n",
      "Initial question: \n",
      " what music classification was the album doe or die \n",
      "[]\n",
      "Initial question: \n",
      " What is the profession of cathie ryan\n",
      "[]\n",
      "Initial question: \n",
      " what was gunnar sve-sderbergh's cause of death\n",
      "['sv', 'sder', '##berg', '##h']\n",
      "Initial question: \n",
      " who wrote the film igby goes down \n",
      "['ig']\n",
      "Initial question: \n",
      " what is the name of one of kerry von erich's children\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 967/1000 [00:17<00:00, 54.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ker', '##ry', 'von', 'eri', '##ch']\n",
      "Initial question: \n",
      " Who is someone born in wittlich\n",
      "[]\n",
      "Initial question: \n",
      " what kind of music is daqui pro futuro\n",
      "['da']\n",
      "Initial question: \n",
      " what type of game is  hyrule warriors\n",
      "['hy', '##rul', '##e']\n",
      "Initial question: \n",
      " who was the singer that made the album docabilly\n",
      "['doc']\n",
      "Initial question: \n",
      " what country is cynthia mckinney a citizen of\n",
      "[]\n",
      "Initial question: \n",
      " the album is what music genre\n",
      "[]\n",
      "Initial question: \n",
      " what kind of film is 41\n",
      "[]\n",
      "Initial question: \n",
      " Of which genre is the film the rainbow man?\n",
      "[]\n",
      "Initial question: \n",
      " what type of music is innercity griots?\n",
      "[]\n",
      "Initial question: \n",
      " what position has sachin gawas ever played\n",
      "[]\n",
      "Initial question: \n",
      " Who was born in El Paso?\n",
      "['El', 'Paso']\n",
      "Initial question: \n",
      " Name a football defender\n",
      "['football']\n",
      "Initial question: \n",
      " Which language is the film  jump tomorrow in\n",
      "['W', 'language']\n",
      "Initial question: \n",
      " What was the name of the son of  leopold ii, holy roman emperor?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 979/1000 [00:18<00:00, 54.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leo', '##pol', '##d', 'ii', 'roman']\n",
      "Initial question: \n",
      " Where was prince ernst august of hanover born\n",
      "[]\n",
      "Initial question: \n",
      " what is the main language spoken in tarzan's fight for life\n",
      "['tar']\n",
      "Initial question: \n",
      " which film was fred koenekamp a cinematographer for?\n",
      "['fred', 'koe', '##nek', '##amp']\n",
      "Initial question: \n",
      " what is martin greif ptofession\n",
      "['mart']\n",
      "Initial question: \n",
      " what events took place at swedish pomerania?\n",
      "['s', '##wed']\n",
      "Initial question: \n",
      " What language is the film hamesha in?\n",
      "['ham']\n",
      "Initial question: \n",
      " What profession is richard swartz?\n",
      "[]\n",
      "Initial question: \n",
      " Who authored prince caspian\n",
      "['cas', '##pian']\n",
      "Initial question: \n",
      " Which county is midlothian in?\n",
      "['mid', '##lot', '##hian']\n",
      "Initial question: \n",
      " what is the genre of the artist d'masiv\n",
      "['d', \"'\", 'mas']\n",
      "Initial question: \n",
      " bob dylan  was the music contributor to what film\n",
      "['bob', 'dy', '##lan']\n",
      "Initial question: \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 991/1000 [00:18<00:00, 55.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is samuel willard father's name\n",
      "['sam']\n",
      "Initial question: \n",
      " what is john glenn's biological sex\n",
      "['jo']\n",
      "Initial question: \n",
      " is heat single-player or multi-player\n",
      "['heat']\n",
      "Initial question: \n",
      " which country is mashona washington from\n",
      "['mas', '##hing']\n",
      "Initial question: \n",
      " Who wrote the red violin?\n",
      "[]\n",
      "Initial question: \n",
      " what position has duane bickett played in american football?\n",
      "[]\n",
      "Initial question: \n",
      " Which album is a latin pop album>\n",
      "['latin']\n",
      "Initial question: \n",
      " what label is zoogz rift under?\n",
      "['zoo', '##g', '##z']\n",
      "Initial question: \n",
      " What position did alain gouamn used to play?\n",
      "['ala', 'go', '##ua', '##m', '##n']\n",
      "Initial question: \n",
      " what constellation of gamma canis majoris is \n",
      "['gamma']\n",
      "Initial question: \n",
      " which nation was charles van wyck born in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [00:18<00:00, 54.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['char']\n",
      "Initial question: \n",
      " steve wariner wrote what album?\n",
      "['st', '##eve', 'war', '##iner']\n",
      "Initial question: \n",
      " which country released hell on frisco bay\n",
      "[]\n",
      "Initial question: \n",
      " which country is katharine mcphee from \n",
      "['kat', '##hari']\n",
      "Initial question: \n",
      " who does skywriter belong to\n",
      "['sky', '##writer']\n",
      "Initial question: \n",
      " where was shane lee yaw born \n",
      "['sh']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize class\n",
    "method = \"Babelscape/wikineural-multilingual-ner\"\n",
    "\n",
    "ner = NER(model = method,\n",
    "          tokenizer = method)\n",
    "\n",
    "# establish pipeline\n",
    "ner.set_pipeline()\n",
    "\n",
    "\n",
    "# NER\n",
    "changed_texts = []\n",
    "for question in tqdm(questions_1000):\n",
    "    \n",
    "    print(\"Initial question: \\n\", question)\n",
    "    \n",
    "    # load text\n",
    "    ner.receive_text(text = question)\n",
    "    \n",
    "    # receive text with marked entities\n",
    "    new_text = ner.text_with_marked_entities()\n",
    "    changed_texts.append(new_text)\n",
    "#     print(\"NER over initial question: \\n\", new_text)\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model_mGENRE_mcdropout.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where is mnika veres from'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_1000[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q16783922',\n",
       "   'texts': ['Glossary of algebraic geometry >> en'],\n",
       "   'scores': tensor([-0.6345], device='cuda:3'),\n",
       "   'score': tensor(-2.1979, device='cuda:3')},\n",
       "  {'id': 'Q166507',\n",
       "   'texts': ['Glossary of graph theory terms >> en'],\n",
       "   'scores': tensor([-0.7063], device='cuda:3'),\n",
       "   'score': tensor(-2.2334, device='cuda:3')},\n",
       "  {'id': 'Q571113',\n",
       "   'texts': ['Glossary of chess >> en'],\n",
       "   'scores': tensor([-0.7721], device='cuda:3'),\n",
       "   'score': tensor(-2.3163, device='cuda:3')},\n",
       "  {'id': 'Q6980743',\n",
       "   'texts': ['Natural order >> en'],\n",
       "   'scores': tensor([-1.0723], device='cuda:3'),\n",
       "   'score': tensor(-2.3977, device='cuda:3')}]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mGENRE_mcdropout.sample([questions_1000[0]],\n",
    "                                  beam = 4,\n",
    "                                  prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                      e for e in trie.get(sent.tolist())\n",
    "                                      if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                  ],\n",
    "                                  text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                  marginalize=True,\n",
    "                                  verbose = True,\n",
    "                                  seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "part  0  done!\n",
      "\n",
      "\n",
      "part  1  done!\n",
      "\n",
      "\n",
      "part  2  done!\n",
      "\n",
      "\n",
      "part  3  done!\n",
      "\n",
      "\n",
      "part  4  done!\n",
      "\n",
      "\n",
      "part  5  done!\n",
      "\n",
      "\n",
      "part  6  done!\n",
      "\n",
      "\n",
      "part  7  done!\n",
      "\n",
      "\n",
      "part  8  done!\n",
      "\n",
      "\n",
      "part  9  done!\n",
      "\n",
      "\n",
      "part  10  done!\n",
      "\n",
      "\n",
      "part  11  done!\n",
      "\n",
      "\n",
      "part  12  done!\n",
      "\n",
      "\n",
      "part  13  done!\n",
      "\n",
      "\n",
      "part  14  done!\n",
      "\n",
      "\n",
      "part  15  done!\n",
      "\n",
      "\n",
      "part  16  done!\n",
      "\n",
      "\n",
      "part  17  done!\n",
      "\n",
      "\n",
      "part  18  done!\n",
      "\n",
      "\n",
      "part  19  done!\n",
      "Duration: 0:00:38.615785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "mGENRE_entropy_1000_ner = []\n",
    "for i in range(divider):\n",
    "    random.seed(i)\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    mGENRE_entropy_1000_ner.append(model_mGENRE_mcdropout.sample(questions_1000[i],\n",
    "                                  beam = 10,\n",
    "                                  prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                      e for e in trie.get(sent.tolist())\n",
    "                                      if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "                                  ],\n",
    "                                  text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                  marginalize=True,\n",
    "                                  verbose = True,\n",
    "                                  seed = i))\n",
    "    print(\"\\n\")\n",
    "    print(\"part \", i, \" done!\")\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Glossary of musical terminology >> en',\n",
       "  'score': tensor(-0.6176, device='cuda:3')},\n",
       " {'text': 'Glossary of climbing terms >> en',\n",
       "  'score': tensor(-0.7120, device='cuda:3')},\n",
       " {'text': 'Glossary of ballet >> en',\n",
       "  'score': tensor(-0.7905, device='cuda:3')},\n",
       " {'text': 'Interval (music) >> en', 'score': tensor(-0.8064, device='cuda:3')},\n",
       " {'text': 'Grammatical mood >> en', 'score': tensor(-0.8097, device='cuda:3')},\n",
       " {'text': 'Glossary of contract bridge terms >> en',\n",
       "  'score': tensor(-0.8199, device='cuda:3')},\n",
       " {'text': 'Glossary of Japanese history >> en',\n",
       "  'score': tensor(-1.0338, device='cuda:3')},\n",
       " {'text': 'Glossary of graffiti >> en',\n",
       "  'score': tensor(-1.1583, device='cuda:3')},\n",
       " {'text': 'Glossary of Japanese words of Dutch origin >> en',\n",
       "  'score': tensor(-1.4324, device='cuda:3')},\n",
       " {'text': 'Glossary of contract bridge >> en',\n",
       "  'score': tensor(-1.5424, device='cuda:3')},\n",
       " {'text': 'France in the Middle Ages >> en',\n",
       "  'score': tensor(-0.7070, device='cuda:3')},\n",
       " {'text': 'Francouzsk krlovstv >> cs',\n",
       "  'score': tensor(-0.7525, device='cuda:3')},\n",
       " {'text': 'Holy Roman Empire >> en',\n",
       "  'score': tensor(-0.9188, device='cuda:3')},\n",
       " {'text': 'French invasion of Russia >> en',\n",
       "  'score': tensor(-0.9662, device='cuda:3')},\n",
       " {'text': 'French First Republic >> en',\n",
       "  'score': tensor(-1.1834, device='cuda:3')},\n",
       " {'text': 'Saintes >> en', 'score': tensor(-1.2757, device='cuda:3')},\n",
       " {'text': 'France >> en', 'score': tensor(-1.3035, device='cuda:3')},\n",
       " {'text': 'Saintes >> it', 'score': tensor(-1.3358, device='cuda:3')},\n",
       " {'text': 'France >> it', 'score': tensor(-1.3957, device='cuda:3')},\n",
       " {'text': 'Franchi >> it', 'score': tensor(-1.4224, device='cuda:3')},\n",
       " {'text': 'List of The Sopranos characters in the Soprano crime family >> en',\n",
       "  'score': tensor(-0.5741, device='cuda:3')},\n",
       " {'text': 'List of past Lucchese crime family mobsters >> en',\n",
       "  'score': tensor(-0.6847, device='cuda:3')},\n",
       " {'text': \"List of Disney's Sleeping Beauty characters >> en\",\n",
       "  'score': tensor(-0.8168, device='cuda:3')},\n",
       " {'text': 'List of British actors and actresses >> en',\n",
       "  'score': tensor(-0.8643, device='cuda:3')},\n",
       " {'text': 'List of The Sopranos characters >> en',\n",
       "  'score': tensor(-0.9133, device='cuda:3')},\n",
       " {'text': 'List of Hindi film families >> en',\n",
       "  'score': tensor(-0.9607, device='cuda:3')},\n",
       " {'text': \"List of Disney's Fantasia characters >> en\",\n",
       "  'score': tensor(-0.9796, device='cuda:3')},\n",
       " {'text': 'List of Japanese-language television channels >> en',\n",
       "  'score': tensor(-0.9951, device='cuda:3')},\n",
       " {'text': 'List of Japanese actors >> en',\n",
       "  'score': tensor(-1.0708, device='cuda:3')},\n",
       " {'text': 'Coat of arms >> en', 'score': tensor(-1.1399, device='cuda:3')},\n",
       " {'text': 'Association football >> en',\n",
       "  'score': tensor(-0.5042, device='cuda:3')},\n",
       " {'text': 'Glossary of association football terms >> en',\n",
       "  'score': tensor(-0.5637, device='cuda:3')},\n",
       " {'text': 'Goal (sport) >> en', 'score': tensor(-0.6370, device='cuda:3')},\n",
       " {'text': \"United States men's national soccer team >> en\",\n",
       "  'score': tensor(-0.6572, device='cuda:3')},\n",
       " {'text': 'Glossary of American football >> en',\n",
       "  'score': tensor(-0.7306, device='cuda:3')},\n",
       " {'text': 'Goodwin >> en', 'score': tensor(-0.8498, device='cuda:3')},\n",
       " {'text': 'American football >> en',\n",
       "  'score': tensor(-0.9977, device='cuda:3')},\n",
       " {'text': 'Football player >> en', 'score': tensor(-1.0127, device='cuda:3')},\n",
       " {'text': 'Soccer >> en', 'score': tensor(-1.1954, device='cuda:3')},\n",
       " {'text': 'Football >> en', 'score': tensor(-1.2947, device='cuda:3')},\n",
       " {'text': 'Vincent Riotta >> en', 'score': tensor(-0.7375, device='cuda:3')},\n",
       " {'text': 'List of monarchs of Sri Lanka >> en',\n",
       "  'score': tensor(-0.8735, device='cuda:3')},\n",
       " {'text': 'List of Redwall characters >> en',\n",
       "  'score': tensor(-0.9142, device='cuda:3')},\n",
       " {'text': 'List of monarchs of Naples >> en',\n",
       "  'score': tensor(-0.9488, device='cuda:3')},\n",
       " {'text': 'List of monarchs of Korea >> en',\n",
       "  'score': tensor(-1.0086, device='cuda:3')},\n",
       " {'text': 'Archbishop of Esztergom >> en',\n",
       "  'score': tensor(-1.0139, device='cuda:3')},\n",
       " {'text': 'List of monarchs of Vietnam >> en',\n",
       "  'score': tensor(-1.0405, device='cuda:3')},\n",
       " {'text': 'Vincentian >> en', 'score': tensor(-1.3559, device='cuda:3')},\n",
       " {'text': 'Archbishop >> en', 'score': tensor(-1.3596, device='cuda:3')},\n",
       " {'text': 'Vincent Riotta >> it', 'score': tensor(-1.4078, device='cuda:3')},\n",
       " {'text': \"List of minor The Hitchhiker's Guide to the Galaxy characters >> en\",\n",
       "  'score': tensor(-0.6458, device='cuda:3')},\n",
       " {'text': \"Hitchhiker's Guide to the Galaxy (fictional) >> en\",\n",
       "  'score': tensor(-0.6885, device='cuda:3')},\n",
       " {'text': \"Hitchhiker's Guide to the Galaxy >> en\",\n",
       "  'score': tensor(-0.6895, device='cuda:3')},\n",
       " {'text': \"Hitchhiker's Guide to the Galaxy (TV series) >> en\",\n",
       "  'score': tensor(-0.9533, device='cuda:3')},\n",
       " {'text': 'M.I.A. (rapper) >> en', 'score': tensor(-1.0250, device='cuda:3')},\n",
       " {'text': 'M.I.C.E. >> en', 'score': tensor(-1.1477, device='cuda:3')},\n",
       " {'text': 'M.I.K.E. >> en', 'score': tensor(-1.1694, device='cuda:3')},\n",
       " {'text': 'Film criticism >> en', 'score': tensor(-1.1943, device='cuda:3')},\n",
       " {'text': 'M.I.C. >> en', 'score': tensor(-1.4309, device='cuda:3')},\n",
       " {'text': 'News >> en', 'score': tensor(-1.7316, device='cuda:3')},\n",
       " {'text': 'World War II in Yugoslavia >> en',\n",
       "  'score': tensor(-0.6887, device='cuda:3')},\n",
       " {'text': '2010 United States House of Representatives elections in Florida >> en',\n",
       "  'score': tensor(-0.8172, device='cuda:3')},\n",
       " {'text': '2010 United States House of Representatives elections in Ohio >> en',\n",
       "  'score': tensor(-0.8564, device='cuda:3')},\n",
       " {'text': '2010 United States House of Representatives elections in Michigan >> en',\n",
       "  'score': tensor(-0.8853, device='cuda:3')},\n",
       " {'text': 'World War II >> en', 'score': tensor(-0.9519, device='cuda:3')},\n",
       " {'text': 'United States v. Windsor >> en',\n",
       "  'score': tensor(-0.9860, device='cuda:3')},\n",
       " {'text': '2010 United States House of Representatives elections >> en',\n",
       "  'score': tensor(-1.0009, device='cuda:3')},\n",
       " {'text': 'United States v. Elcom Ltd. >> en',\n",
       "  'score': tensor(-1.0056, device='cuda:3')},\n",
       " {'text': 'United States v. Elcom Ltd >> en',\n",
       "  'score': tensor(-1.1270, device='cuda:3')},\n",
       " {'text': 'Victims of the Holocaust >> en',\n",
       "  'score': tensor(-1.2364, device='cuda:3')},\n",
       " {'text': 'List of minor Old Testament figures, AK >> en',\n",
       "  'score': tensor(-0.6172, device='cuda:3')},\n",
       " {'text': 'List of demons in the Ars Goetia >> en',\n",
       "  'score': tensor(-0.6703, device='cuda:3')},\n",
       " {'text': 'List of minor Old Testament figures, LZ >> en',\n",
       "  'score': tensor(-0.7255, device='cuda:3')},\n",
       " {'text': 'Old Norse orthography >> en',\n",
       "  'score': tensor(-1.0647, device='cuda:3')},\n",
       " {'text': 'Old English >> en', 'score': tensor(-1.1053, device='cuda:3')},\n",
       " {'text': 'Kinship >> en', 'score': tensor(-1.1956, device='cuda:3')},\n",
       " {'text': 'Old Norse >> en', 'score': tensor(-1.2338, device='cuda:3')},\n",
       " {'text': 'Old Dutch >> en', 'score': tensor(-1.4106, device='cuda:3')},\n",
       " {'text': 'List of demons >> en', 'score': tensor(-1.5334, device='cuda:3')},\n",
       " {'text': 'Leander >> en', 'score': tensor(-1.5364, device='cuda:3')},\n",
       " {'text': 'Flagellation >> en', 'score': tensor(-0.2751, device='cuda:3')},\n",
       " {'text': 'Flagellation of Christ >> en',\n",
       "  'score': tensor(-0.4156, device='cuda:3')},\n",
       " {'text': 'Incarnation (Christianity) >> en',\n",
       "  'score': tensor(-0.6497, device='cuda:3')},\n",
       " {'text': 'Logos (Christianity) >> en',\n",
       "  'score': tensor(-0.7053, device='cuda:3')},\n",
       " {'text': 'Christian art >> en', 'score': tensor(-0.9006, device='cuda:3')},\n",
       " {'text': 'Incarnation >> en', 'score': tensor(-0.9739, device='cuda:3')},\n",
       " {'text': 'Jesus >> en', 'score': tensor(-1.0936, device='cuda:3')},\n",
       " {'text': 'Messiah >> en', 'score': tensor(-1.1416, device='cuda:3')},\n",
       " {'text': 'Flagellation of Jesus >> en',\n",
       "  'score': tensor(-1.1634, device='cuda:3')},\n",
       " {'text': 'Christ >> en', 'score': tensor(-1.4498, device='cuda:3')},\n",
       " {'text': \"Louisville Cardinals men's basketball >> en\",\n",
       "  'score': tensor(-0.6815, device='cuda:3')},\n",
       " {'text': 'Louisville Cardinals >> en',\n",
       "  'score': tensor(-0.9943, device='cuda:3')},\n",
       " {'text': \"List of Kentucky Wildcats men's basketball seasons >> en\",\n",
       "  'score': tensor(-1.0009, device='cuda:3')},\n",
       " {'text': \"List of Kentucky Wildcats men's basketball head coaches >> en\",\n",
       "  'score': tensor(-1.0808, device='cuda:3')},\n",
       " {'text': 'College football >> en', 'score': tensor(-1.0823, device='cuda:3')},\n",
       " {'text': 'College basketball >> en',\n",
       "  'score': tensor(-1.1837, device='cuda:3')},\n",
       " {'text': 'Louisville Cardinals football >> en',\n",
       "  'score': tensor(-1.1975, device='cuda:3')},\n",
       " {'text': \"Louisville Cardinals men's soccer >> en\",\n",
       "  'score': tensor(-1.2986, device='cuda:3')},\n",
       " {'text': 'List of college football coaches with 200 wins >> en',\n",
       "  'score': tensor(-1.4257, device='cuda:3')},\n",
       " {'text': 'List of college athletic programs in North Carolina >> en',\n",
       "  'score': tensor(-1.4707, device='cuda:3')},\n",
       " {'text': 'White Mischief (film) >> en',\n",
       "  'score': tensor(-0.6217, device='cuda:3')},\n",
       " {'text': 'White Mischief (disambiguation) >> en',\n",
       "  'score': tensor(-1.1026, device='cuda:3')},\n",
       " {'text': 'White and Black (film) >> en',\n",
       "  'score': tensor(-1.1567, device='cuda:3')},\n",
       " {'text': 'White Slave (film) >> en',\n",
       "  'score': tensor(-1.1802, device='cuda:3')},\n",
       " {'text': 'White Mischief >> en', 'score': tensor(-1.1902, device='cuda:3')},\n",
       " {'text': 'White (film) >> en', 'score': tensor(-1.1907, device='cuda:3')},\n",
       " {'text': 'White Mischief (novel) >> en',\n",
       "  'score': tensor(-1.2089, device='cuda:3')},\n",
       " {'text': 'White Mice (film) >> en',\n",
       "  'score': tensor(-1.3704, device='cuda:3')},\n",
       " {'text': 'White Mice >> en', 'score': tensor(-1.5970, device='cuda:3')},\n",
       " {'text': 'White >> en', 'score': tensor(-1.7196, device='cuda:3')},\n",
       " {'text': 'Character (arts) >> en', 'score': tensor(-0.3762, device='cuda:3')},\n",
       " {'text': 'Characters in Romeo and Juliet >> en',\n",
       "  'score': tensor(-0.6121, device='cuda:3')},\n",
       " {'text': 'Shapeshifting >> en', 'score': tensor(-0.7510, device='cuda:3')},\n",
       " {'text': 'Male >> en', 'score': tensor(-0.7822, device='cuda:3')},\n",
       " {'text': 'Masculinity >> en', 'score': tensor(-0.8011, device='cuda:3')},\n",
       " {'text': 'Shapeshifter >> en', 'score': tensor(-0.8194, device='cuda:3')},\n",
       " {'text': 'Shapeshifter (comics) >> en',\n",
       "  'score': tensor(-0.8337, device='cuda:3')},\n",
       " {'text': 'Marriage >> en', 'score': tensor(-1.0720, device='cuda:3')},\n",
       " {'text': 'Man >> en', 'score': tensor(-1.2915, device='cuda:3')},\n",
       " {'text': 'Gay >> en', 'score': tensor(-1.3468, device='cuda:3')},\n",
       " {'text': 'Thai nationality law >> en',\n",
       "  'score': tensor(-0.1803, device='cuda:3')},\n",
       " {'text': 'Thai people >> en', 'score': tensor(-0.7694, device='cuda:3')},\n",
       " {'text': 'Bhutanese nationality law >> en',\n",
       "  'score': tensor(-0.8372, device='cuda:3')},\n",
       " {'text': 'Indian nationality law >> en',\n",
       "  'score': tensor(-0.8545, device='cuda:3')},\n",
       " {'text': 'Monarchy of Thailand >> en',\n",
       "  'score': tensor(-0.9400, device='cuda:3')},\n",
       " {'text': 'Bhikkhun >> en', 'score': tensor(-0.9490, device='cuda:3')},\n",
       " {'text': 'Monarchy of Bhutan >> en',\n",
       "  'score': tensor(-1.0265, device='cuda:3')},\n",
       " {'text': 'Nationality >> en', 'score': tensor(-1.1026, device='cuda:3')},\n",
       " {'text': 'Thailand >> en', 'score': tensor(-1.1457, device='cuda:3')},\n",
       " {'text': 'Bhikkhu >> en', 'score': tensor(-1.1556, device='cuda:3')},\n",
       " {'text': 'Goalkeeper (association football) >> en',\n",
       "  'score': tensor(-0.3069, device='cuda:3')},\n",
       " {'text': 'Association football >> en',\n",
       "  'score': tensor(-0.4235, device='cuda:3')},\n",
       " {'text': 'Glossary of association football terms >> en',\n",
       "  'score': tensor(-0.5936, device='cuda:3')},\n",
       " {'text': 'List of association football players >> en',\n",
       "  'score': tensor(-0.6881, device='cuda:3')},\n",
       " {'text': 'Goal (sport) >> en', 'score': tensor(-0.8298, device='cuda:3')},\n",
       " {'text': 'Goalkeeper >> en', 'score': tensor(-1.0104, device='cuda:3')},\n",
       " {'text': 'List of association footballers who died while playing >> en',\n",
       "  'score': tensor(-1.0623, device='cuda:3')},\n",
       " {'text': 'Football player >> en', 'score': tensor(-1.1128, device='cuda:3')},\n",
       " {'text': 'Football >> en', 'score': tensor(-1.3307, device='cuda:3')},\n",
       " {'text': 'Goalkeeper (association football) >> id',\n",
       "  'score': tensor(-1.4773, device='cuda:3')},\n",
       " {'text': 'Film genre >> en', 'score': tensor(-0.6226, device='cuda:3')},\n",
       " {'text': 'Non-narrative film >> en',\n",
       "  'score': tensor(-0.6688, device='cuda:3')},\n",
       " {'text': 'Cinema of the United States >> en',\n",
       "  'score': tensor(-0.7925, device='cuda:3')},\n",
       " {'text': 'Genre >> en', 'score': tensor(-0.7946, device='cuda:3')},\n",
       " {'text': 'Cinema of the United Kingdom >> en',\n",
       "  'score': tensor(-0.8006, device='cuda:3')},\n",
       " {'text': 'List of U.S. state and territory nicknames >> en',\n",
       "  'score': tensor(-0.8641, device='cuda:3')},\n",
       " {'text': 'List of films considered the best >> en',\n",
       "  'score': tensor(-0.8905, device='cuda:3')},\n",
       " {'text': 'List of films >> en', 'score': tensor(-0.9926, device='cuda:3')},\n",
       " {'text': 'Nonfiction >> en', 'score': tensor(-1.3103, device='cuda:3')},\n",
       " {'text': 'Film >> en', 'score': tensor(-1.5630, device='cuda:3')},\n",
       " {'text': 'Low-discrepancy sequence >> en',\n",
       "  'score': tensor(-0.6073, device='cuda:3')},\n",
       " {'text': 'Gender >> en', 'score': tensor(-0.6274, device='cuda:3')},\n",
       " {'text': 'Gender equality >> en', 'score': tensor(-0.7914, device='cuda:3')},\n",
       " {'text': 'Affinity (mathematics) >> en',\n",
       "  'score': tensor(-0.8488, device='cuda:3')},\n",
       " {'text': \"Women's suffrage >> en\", 'score': tensor(-0.9126, device='cuda:3')},\n",
       " {'text': 'Gender and sexuality >> en',\n",
       "  'score': tensor(-0.9729, device='cuda:3')},\n",
       " {'text': 'Sex and gender distinction >> en',\n",
       "  'score': tensor(-1.0234, device='cuda:3')},\n",
       " {'text': 'Third-person pronoun >> en',\n",
       "  'score': tensor(-1.0459, device='cuda:3')},\n",
       " {'text': \"Women's rights >> en\", 'score': tensor(-1.0661, device='cuda:3')},\n",
       " {'text': 'Sex >> en', 'score': tensor(-1.3341, device='cuda:3')},\n",
       " {'text': 'Film >> en', 'score': tensor(-0.5159, device='cuda:3')},\n",
       " {'text': 'Cinema of the United States >> en',\n",
       "  'score': tensor(-0.6068, device='cuda:3')},\n",
       " {'text': 'Border >> en', 'score': tensor(-0.6650, device='cuda:3')},\n",
       " {'text': 'Cinema of the United Kingdom >> en',\n",
       "  'score': tensor(-0.7471, device='cuda:3')},\n",
       " {'text': 'Filming location >> en', 'score': tensor(-0.8276, device='cuda:3')},\n",
       " {'text': 'Film score >> en', 'score': tensor(-0.8746, device='cuda:3')},\n",
       " {'text': 'Film theory >> en', 'score': tensor(-0.9268, device='cuda:3')},\n",
       " {'text': 'Filming >> en', 'score': tensor(-1.0980, device='cuda:3')},\n",
       " {'text': 'Filmmaking >> en', 'score': tensor(-1.0986, device='cuda:3')},\n",
       " {'text': 'Television film >> en', 'score': tensor(-1.1718, device='cuda:3')},\n",
       " {'text': 'Glossary of botanical terms >> en',\n",
       "  'score': tensor(-0.4494, device='cuda:3')},\n",
       " {'text': 'List of U.S. state and territory nicknames >> en',\n",
       "  'score': tensor(-0.6181, device='cuda:3')},\n",
       " {'text': 'Nymph (biology) >> en', 'score': tensor(-0.7107, device='cuda:3')},\n",
       " {'text': 'Plant reproductive morphology >> en',\n",
       "  'score': tensor(-0.7742, device='cuda:3')},\n",
       " {'text': 'Plant >> en', 'score': tensor(-0.9969, device='cuda:3')},\n",
       " {'text': 'Nymphalis >> en', 'score': tensor(-1.0126, device='cuda:3')},\n",
       " {'text': 'Genus >> en', 'score': tensor(-1.0413, device='cuda:3')},\n",
       " {'text': 'Nymphaea >> en', 'score': tensor(-1.0525, device='cuda:3')},\n",
       " {'text': 'Linearity >> en', 'score': tensor(-1.1082, device='cuda:3')},\n",
       " {'text': 'Clothing >> en', 'score': tensor(-1.2012, device='cuda:3')},\n",
       " {'text': 'Grammatical gender >> en',\n",
       "  'score': tensor(-0.6026, device='cuda:3')},\n",
       " {'text': 'Gender >> en', 'score': tensor(-0.7124, device='cuda:3')},\n",
       " {'text': 'Social construction of gender >> en',\n",
       "  'score': tensor(-0.7547, device='cuda:3')},\n",
       " {'text': 'Third-person pronoun >> en',\n",
       "  'score': tensor(-0.9030, device='cuda:3')},\n",
       " {'text': 'Third gender >> en', 'score': tensor(-0.9781, device='cuda:3')},\n",
       " {'text': 'Sex >> en', 'score': tensor(-1.0476, device='cuda:3')},\n",
       " {'text': 'Social status >> en', 'score': tensor(-1.1585, device='cuda:3')},\n",
       " {'text': \"Women's >> en\", 'score': tensor(-1.2275, device='cuda:3')},\n",
       " {'text': 'Female >> en', 'score': tensor(-1.3720, device='cuda:3')},\n",
       " {'text': 'Social status >> sv', 'score': tensor(-1.4497, device='cuda:3')},\n",
       " {'text': 'Telephone >> en', 'score': tensor(-0.2665, device='cuda:3')},\n",
       " {'text': 'Public switched telephone network >> en',\n",
       "  'score': tensor(-0.7201, device='cuda:3')},\n",
       " {'text': 'Telephone numbers in the United States >> en',\n",
       "  'score': tensor(-0.7599, device='cuda:3')},\n",
       " {'text': 'Telephone company >> en',\n",
       "  'score': tensor(-0.7718, device='cuda:3')},\n",
       " {'text': 'Public telephone >> en', 'score': tensor(-0.9018, device='cuda:3')},\n",
       " {'text': 'Telephone exchange >> en',\n",
       "  'score': tensor(-0.9346, device='cuda:3')},\n",
       " {'text': 'Telephony >> en', 'score': tensor(-0.9561, device='cuda:3')},\n",
       " {'text': 'Public telephone network >> en',\n",
       "  'score': tensor(-1.0095, device='cuda:3')},\n",
       " {'text': 'Public phone >> en', 'score': tensor(-1.4180, device='cuda:3')},\n",
       " {'text': 'Telephone >> nl', 'score': tensor(-1.4507, device='cuda:3')}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mGENRE_entropy_1000_ner, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [i[0]['id'] for i in sum(mGENRE_results_entropy, [])]\n",
    "accuracy_entropy_40 = []\n",
    "share_of_observations_entropy_40 = []\n",
    "\n",
    "for threshold in thresholds[1:]:\n",
    "    \n",
    "    \n",
    "    list_a = list(range(40))\n",
    "    fil = entropies < threshold\n",
    "    \n",
    "    \n",
    "    y_pred = list(compress(predictions, fil))\n",
    "    y_true = list(df.reset_index().iloc[list(compress(list_a, fil)),:][\"object\"])\n",
    "    \n",
    "    result = [x in y_pred for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 4)*100\n",
    "    accuracy_entropy_40.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 4)\n",
    "    share_of_observations_entropy_40.append(share)\n",
    "    \n",
    "    print(\"threshold = \", format(threshold, '.2f'), \"\\t\",\n",
    "          \"accuracy = \", format(accuracy, '.2f'), \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \",  format(share, '.2f'), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-1.0492], device='cuda:0'), 'score': tensor(-2.0985, device='cuda:0')}, {'id': 'Q15956340', 'texts': ['Cinema of Pakistan >> en'], 'scores': tensor([-1.0374], device='cuda:0'), 'score': tensor(-2.5410, device='cuda:0')}, {'id': 'Q3304693', 'texts': ['Cinema of Bangladesh >> en'], 'scores': tensor([-1.0889], device='cuda:0'), 'score': tensor(-2.6672, device='cuda:0')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-1.0492], device='cuda:0'), 'score': tensor(-2.0985, device='cuda:0')}, {'id': 'Q15956340', 'texts': ['Cinema of Pakistan >> en'], 'scores': tensor([-1.0374], device='cuda:0'), 'score': tensor(-2.5410, device='cuda:0')}, {'id': 'Q3304693', 'texts': ['Cinema of Bangladesh >> en'], 'scores': tensor([-1.0889], device='cuda:0'), 'score': tensor(-2.6672, device='cuda:0')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-1.0492], device='cuda:0'), 'score': tensor(-2.0985, device='cuda:0')}, {'id': 'Q15956340', 'texts': ['Cinema of Pakistan >> en'], 'scores': tensor([-1.0374], device='cuda:0'), 'score': tensor(-2.5410, device='cuda:0')}, {'id': 'Q3304693', 'texts': ['Cinema of Bangladesh >> en'], 'scores': tensor([-1.0889], device='cuda:0'), 'score': tensor(-2.6672, device='cuda:0')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-1.0492], device='cuda:0'), 'score': tensor(-2.0985, device='cuda:0')}, {'id': 'Q15956340', 'texts': ['Cinema of Pakistan >> en'], 'scores': tensor([-1.0374], device='cuda:0'), 'score': tensor(-2.5410, device='cuda:0')}, {'id': 'Q3304693', 'texts': ['Cinema of Bangladesh >> en'], 'scores': tensor([-1.0889], device='cuda:0'), 'score': tensor(-2.6672, device='cuda:0')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-1.0492], device='cuda:0'), 'score': tensor(-2.0985, device='cuda:0')}, {'id': 'Q15956340', 'texts': ['Cinema of Pakistan >> en'], 'scores': tensor([-1.0374], device='cuda:0'), 'score': tensor(-2.5410, device='cuda:0')}, {'id': 'Q3304693', 'texts': ['Cinema of Bangladesh >> en'], 'scores': tensor([-1.0889], device='cuda:0'), 'score': tensor(-2.6672, device='cuda:0')}]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [1,2,3,4,5]\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    \n",
    "    res = model_mGENRE_mcdropout.sample(\n",
    "        [data.loc[1, \"question\"]],\n",
    "        beam = 3,\n",
    "        prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "            e for e in trie.get(sent.tolist())\n",
    "            if e < len(model_mGENRE_mcdropout.task.target_dictionary)\n",
    "        ],\n",
    "        text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "        marginalize=True,\n",
    "        verbose = True,\n",
    "        seed = seed,\n",
    "        random_state = seed\n",
    "    )\n",
    "    print(res)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER + MEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e33b83225ee43a2b4e8fa06c391d894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1893e41a4c8d46b49962bad8a370bc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547299e5932e4f12bdb621b5d837cd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e97c988d6884d60a3a34647f585e50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609e98ca33d241128261dd37c82cc20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825d13cfabaa48f180688ee324925e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/676M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Who is Pushkin?\",\n",
    "             \"Is Pushkinskaya metro station located in Saint Petersburg?\",\n",
    "             \"Is Saint Petersburg located on Mississipi?\",\n",
    "             \n",
    "             \"Did Stephen Hawking discover theory of relativity?\",\n",
    "             \n",
    "             \"When Caesar was an imperor of the Roman empire?\",\n",
    "             \"How many times have people won the jackpot at Caesar?\",\n",
    "             \"Is Caesar a part of the Italian national cuisine?\",\n",
    "             \n",
    "             \"What did Tsiolkovsky invent?\",\n",
    "             \n",
    "             \"Was George Washington the first American President?\",\n",
    "             \"Does Denver State border Washington State?\",\n",
    "             \"How long Alexander Ovechkin play for Washington Capitals?\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NER:\n",
    "    def __init__(self, \n",
    "                 #text, \n",
    "                 model = \"Babelscape/wikineural-multilingual-ner\",\n",
    "                 tokenizer = \"Babelscape/wikineural-multilingual-ner\"):\n",
    "        \n",
    "        #self.text = text\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def set_pipeline(self):   \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model)\n",
    "        self.nlp = pipeline(\"ner\",\n",
    "                            model = self.model,\n",
    "                            tokenizer = self.tokenizer)\n",
    "        \n",
    "    def receive_text(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def receive_words(self):\n",
    "        self.text = re.sub('[!@#$?,]', '', self.text)\n",
    "        out = re.split(r' ', self.text)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def receive_enitity(self):\n",
    "        ner_results = self.nlp(self.text)\n",
    "        final = []\n",
    "        result = [i[\"word\"] for i in ner_results]\n",
    "        for elem in result:    \n",
    "            if elem[:2] == \"##\":\n",
    "                final[-1] = final[-1] + elem[2:]\n",
    "            else:\n",
    "                final.append(elem)\n",
    "        return final\n",
    "    \n",
    "    def text_with_marked_entities(self):\n",
    "        output = \"\"\n",
    "        entities = self.receive_enitity()\n",
    "        list_of_words = self.receive_words()\n",
    "        for word in list_of_words:\n",
    "            if word not in entities:\n",
    "                output = output + word + \" \"\n",
    "            else:\n",
    "                output = output + \"[START] \" + word +  \" [END] \"\n",
    "        output = re.sub(\"\\[END\\] \\[START\\] \", \"\", output)\n",
    "        output += \"?\"\n",
    "        return output\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many times have people won the jackpot at [START] Caesar [END] ?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ner = NER(text = \"How many times have people won the jackpot at Caesar?\")\n",
    "\n",
    "# initialize class\n",
    "ner = NER()\n",
    "\n",
    "# establish pipeline\n",
    "ner.set_pipeline()\n",
    "\n",
    "# load text\n",
    "ner.receive_text(text = \"How many times have people won the jackpot at Caesar?\")\n",
    "\n",
    "# receive text with marked entities\n",
    "output = ner.text_with_marked_entities()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " Who is Pushkin?\n",
      "NER over initial question: \n",
      " Who is [START] Pushkin [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Is Pushkinskaya metro station located in Saint Petersburg?\n",
      "NER over initial question: \n",
      " Is [START] Pushkinskaya [END] metro station located in [START] Saint Petersburg [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Is Saint Petersburg located on Mississipi?\n",
      "NER over initial question: \n",
      " Is [START] Saint Petersburg [END] located on [START] Mississipi [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Did Stephen Hawking discover theory of relativity?\n",
      "NER over initial question: \n",
      " Did [START] Stephen Hawking [END] discover theory of relativity ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " When Caesar was an imperor of the Roman empire?\n",
      "NER over initial question: \n",
      " When [START] Caesar [END] was an imperor of the [START] Roman [END] empire ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " How many times have people won the jackpot at Caesar?\n",
      "NER over initial question: \n",
      " How many times have people won the jackpot at [START] Caesar [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Is Caesar a part of the Italian national cuisine?\n",
      "NER over initial question: \n",
      " Is [START] Caesar [END] a part of the [START] Italian [END] national cuisine ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What did Tsiolkovsky invent?\n",
      "NER over initial question: \n",
      " What did [START] Tsiolkovsky [END] invent ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Was George Washington the first American President?\n",
      "NER over initial question: \n",
      " Was [START] George Washington [END] the first [START] American [END] President ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Does Denver State border Washington State?\n",
      "NER over initial question: \n",
      " Does [START] Denver State [END] border [START] Washington State [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " How long Alexander Ovechkin play for Washington Capitals?\n",
      "NER over initial question: \n",
      " How long [START] Alexander Ovechkin [END] play for [START] Washington Capitals [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "changed_texts = []\n",
    "for question in questions:\n",
    "    print(\"Initial question: \\n\", question)\n",
    "    \n",
    "    ner.receive_text(text = question)\n",
    "    \n",
    "    new_text = ner.text_with_marked_entities()\n",
    "    changed_texts.append(new_text)\n",
    "    print(\"NER over initial question: \\n\", new_text)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who is [START] Pushkin [END] ?',\n",
       " 'Is [START] Pushkinskaya [END] metro station located in [START] Saint Petersburg [END] ?',\n",
       " 'Is [START] Saint Petersburg [END] located on [START] Mississipi [END] ?',\n",
       " 'Did [START] Stephen Hawking [END] discover theory of relativity ?',\n",
       " 'When [START] Caesar [END] was an imperor of the [START] Roman [END] empire ?',\n",
       " 'How many times have people won the jackpot at [START] Caesar [END] ?',\n",
       " 'Is [START] Caesar [END] a part of the [START] Italian [END] national cuisine ?',\n",
       " 'What did [START] Tsiolkovsky [END] invent ?',\n",
       " 'Was [START] George Washington [END] the first [START] American [END] President ?',\n",
       " 'Does [START] Denver State [END] border [START] Washington State [END] ?',\n",
       " 'How long [START] Alexander Ovechkin [END] play for [START] Washington Capitals [END] ?']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q7200',\n",
       "   'texts': ['Alexander Pushkin >> en',\n",
       "    'Aleksandr Pushkin >> en',\n",
       "    'Alexandr Pushkin >> en',\n",
       "    'Pushkin >> en',\n",
       "    'Aleksandr Pushkin >> es'],\n",
       "   'scores': tensor([-0.0850, -0.7231, -0.8690, -0.9665, -0.9766], device='cuda:4'),\n",
       "   'score': tensor(0.2237, device='cuda:4')}]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [changed_texts[0]]\n",
    "model_mGENRE.sample(\n",
    "    sentences,\n",
    "    beam = 5,\n",
    "    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "        e for e in trie.get(sent.tolist())\n",
    "        if e < len(model_mGENRE.task.target_dictionary)\n",
    "    ],\n",
    "    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "    marginalize=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'id': 'Q7200', 'texts': ['Alexander Pushkin >> en', 'Aleksandr Pushkin >> en', 'Alexandr Pushkin >> en', 'Pushkin >> en', 'Aleksandr Pushkin >> es'], 'scores': tensor([-0.0850, -0.7231, -0.8690, -0.9665, -0.9766], device='cuda:4'), 'score': tensor(0.2237, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q2079447', 'texts': ['Pushkinskaya (Saint Petersburg Metro) >> en'], 'scores': tensor([-0.1192], device='cuda:4'), 'score': tensor(-0.3955, device='cuda:4')}, {'id': 'Q1627587', 'texts': ['Pushkinskaya (Moscow Metro) >> en'], 'scores': tensor([-0.2643], device='cuda:4'), 'score': tensor(-0.9156, device='cuda:4')}, {'id': 'Q7261815', 'texts': ['Pushkinskaya >> en'], 'scores': tensor([-0.8117], device='cuda:4'), 'score': tensor(-1.9882, device='cuda:4')}, {'id': 'Q2444846', 'texts': ['Pushkinskaya (Minsk Metro) >> en'], 'scores': tensor([-0.6415], device='cuda:4'), 'score': tensor(-2.1277, device='cuda:4')}, {'id': 'Q250225', 'texts': ['Saint Petersburg Metro >> en'], 'scores': tensor([-0.9126], device='cuda:4'), 'score': tensor(-2.2355, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q1494', 'texts': ['Mississippi >> en', 'Mississippi (state) >> en'], 'scores': tensor([-0.3802, -0.6505], device='cuda:4'), 'score': tensor(-0.4364, device='cuda:4')}, {'id': 'Q1497', 'texts': ['Mississippi River >> en'], 'scores': tensor([-0.3112], device='cuda:4'), 'score': tensor(-0.6958, device='cuda:4')}, {'id': 'Q656', 'texts': ['Saint Petersburg >> en'], 'scores': tensor([-0.7314], device='cuda:4'), 'score': tensor(-1.6355, device='cuda:4')}, {'id': 'Q49236', 'texts': ['Saint Petersburg, Florida >> en'], 'scores': tensor([-0.6712], device='cuda:4'), 'score': tensor(-1.7759, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q17714', 'texts': ['Stephen Hawking >> en', 'Stephen Hawking >> id', 'Stephen Hawking >> tr', 'Stephen Hawking >> ms', 'Stephen Hawking >> vi'], 'scores': tensor([-0.0850, -1.4570, -1.4586, -1.4961, -1.5068], device='cuda:4'), 'score': tensor(-0.0270, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q2277', 'texts': ['Roman Empire >> en'], 'scores': tensor([-0.3542], device='cuda:4'), 'score': tensor(-0.7921, device='cuda:4')}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.4272], device='cuda:4'), 'score': tensor(-1.1303, device='cuda:4')}, {'id': 'Q1747689', 'texts': ['Ancient Rome >> en'], 'scores': tensor([-0.5286], device='cuda:4'), 'score': tensor(-1.2948, device='cuda:4')}, {'id': 'Q1048', 'texts': ['Julius Caesar >> en'], 'scores': tensor([-0.6120], device='cuda:4'), 'score': tensor(-1.3685, device='cuda:4')}, {'id': 'Q220', 'texts': ['Rome >> en'], 'scores': tensor([-1.0506], device='cuda:4'), 'score': tensor(-2.1013, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q1048', 'texts': ['Julius Caesar >> en', 'Caesar >> en'], 'scores': tensor([-0.3834, -0.8819], device='cuda:4'), 'score': tensor(-0.5181, device='cuda:4')}, {'id': 'Q27995879', 'texts': ['Gaius Iulius Caesar >> en', 'Gaius Julius Caesar >> en'], 'scores': tensor([-0.4686, -0.6315], device='cuda:4'), 'score': tensor(-0.7902, device='cuda:4')}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.5184], device='cuda:4'), 'score': tensor(-1.3716, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q38', 'texts': ['Italy >> en'], 'scores': tensor([-0.5365], device='cuda:4'), 'score': tensor(-1.0730, device='cuda:4')}, {'id': 'Q192786', 'texts': ['Italian cuisine >> en'], 'scores': tensor([-0.5653], device='cuda:4'), 'score': tensor(-1.2640, device='cuda:4')}, {'id': 'Q188751', 'texts': ['Caesar (title) >> en'], 'scores': tensor([-0.5390], device='cuda:4'), 'score': tensor(-1.4261, device='cuda:4')}, {'id': 'Q50001', 'texts': ['Italians >> en'], 'scores': tensor([-0.7396], device='cuda:4'), 'score': tensor(-1.6538, device='cuda:4')}, {'id': 'Q220', 'texts': ['Rome >> en'], 'scores': tensor([-0.9879], device='cuda:4'), 'score': tensor(-1.9758, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q41239', 'texts': ['Konstantin Tsiolkovsky >> en', 'Konstantin Eduardovich Tsiolkovsky >> en', 'Konstantin Eduardovich Tsiolkovsky >> vi', 'Konstantin Eduardovich Tsiolkovsky >> pt', 'Konstantin Tsiolkovski >> tr'], 'scores': tensor([-0.1853, -0.2997, -0.3104, -0.5162, -0.6527], device='cuda:4'), 'score': tensor(0.4839, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q23', 'texts': ['George Washington >> en'], 'scores': tensor([-0.0976], device='cuda:4'), 'score': tensor(-0.2183, device='cuda:4')}, {'id': 'Q35073', 'texts': ['List of presidents of the United States >> en'], 'scores': tensor([-0.8111], device='cuda:4'), 'score': tensor(-2.6900, device='cuda:4')}, {'id': 'Q2824580', 'texts': ['Presidency of George Washington >> en'], 'scores': tensor([-1.0284], device='cuda:4'), 'score': tensor(-2.9088, device='cuda:4')}, {'id': 'Q30', 'texts': ['United States >> en'], 'scores': tensor([-1.3157], device='cuda:4'), 'score': tensor(-2.9420, device='cuda:4')}, {'id': 'Q1223', 'texts': ['Washington (state) >> en'], 'scores': tensor([-1.1492], device='cuda:4'), 'score': tensor(-3.0405, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q613736', 'texts': ['Denver State University >> en'], 'scores': tensor([-0.2005], device='cuda:4'), 'score': tensor(-0.4910, device='cuda:4')}, {'id': 'Q2998740', 'texts': ['Washington State Cougars >> en'], 'scores': tensor([-0.7815], device='cuda:4'), 'score': tensor(-2.2105, device='cuda:4')}, {'id': 'Q7972235', 'texts': ['Washington State Cougars football >> en'], 'scores': tensor([-0.7548], device='cuda:4'), 'score': tensor(-2.2644, device='cuda:4')}, {'id': 'Q5148746', 'texts': ['Colorado Buffaloes football >> en'], 'scores': tensor([-0.9525], device='cuda:4'), 'score': tensor(-2.5201, device='cuda:4')}, {'id': 'Q16554', 'texts': ['Denver >> en'], 'scores': tensor([-1.3666], device='cuda:4'), 'score': tensor(-2.7331, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "[[{'id': 'Q311374', 'texts': ['Alexander Ovechkin >> en', 'Aleksandr Ovetjkin >> sv', 'Aleksandr Ovechkin >> en', 'Alexander Ovechkin >> de'], 'scores': tensor([-0.2053, -1.1328, -1.1402, -1.4095], device='cuda:4'), 'score': tensor(-0.3886, device='cuda:4')}, {'id': 'Q204627', 'texts': ['Washington Capitals >> en'], 'scores': tensor([-0.6224], device='cuda:4'), 'score': tensor(-1.5245, device='cuda:4')}]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(changed_texts)):\n",
    "    sentences = [changed_texts[i]]\n",
    "    print(model_mGENRE.sample(\n",
    "        sentences,\n",
    "        beam = 5,\n",
    "        prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "            e for e in trie.get(sent.tolist())\n",
    "            if e < len(model_mGENRE.task.target_dictionary)\n",
    "        ],\n",
    "        text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "        marginalize=True,\n",
    "        verbose = True\n",
    "    ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\"Q16330302\", \"P19\", \"Q1524\", \"what city was alex golfis born in\"],\n",
    "        [\"Q16225521\", \"R58\", \"Q192979\", \"what film is by the writer phil hay?\"],\n",
    "        [\"Q7358590\", \"P20\", \"Q1637790\", \"Where did roger marquis die\"],\n",
    "        [\"Q154335\", \"P509\", \"Q12152\", \"what was the cause of death of yves klein\"],\n",
    "        [\"Q1761\", \"R19\", \"Q6768445\", \"Which equestrian was born in dublin?\"],\n",
    "        [\"Q11272426\", \"R136\", \"Q5533291\", \"What is a tv action show?\"],\n",
    "        [\"Q2581168\", \"P172\", \"Q810714\", \"what's akbar tandjung's ethnicity\"],\n",
    "        [\"Q2747238\", \"P413\", \"Q5059480\", \"What position does carlos gomez play?\"],\n",
    "        [\"Q62498\", \"P21\", \"Q6581097\", \"how does engelbert zaschka identify\"],\n",
    "        [\"Q182485\", \"P413\", \"Q1143358\", \"what position does pee wee reese play in baseball\"],\n",
    "        [\"Q12152\", \"R509\", \"Q6371569\", \"Which Swiss conductor's cause of death is myocardial infarction?\"],\n",
    "        [\"Q1176417\", \"P136\", \"Q37073\", \"what type of music does david ruffin play\"],\n",
    "        [\"Q7123909\", \"P20\", \"Q3130\", \"where was padraic mcguinness's place of death\"],\n",
    "        [\"Q1189775\", \"P364\", \"Q1860\", \"what language is viper in\"],\n",
    "        [\"Q276817\", \"P737\", \"Q169566\", \"Who influenced michael mcdowell?\"],\n",
    "        [\"Q472382\", \"P19\", \"Q23051\", \"what is the place of birth of sam edwards?\"],\n",
    "        [\"Q7443093\", \"P710\", \"Q214102\", \"which military was involved in the second battle of fort fisher\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd963b1d1a76404f9293a26dc44cbab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=499.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd0599bb7da442789f0afdf844e94ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=824793.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0699cfeb9b4156ac5339a99d3bc125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2642361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bf91df90b941c0aad0c1a1bef7fafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e81a8eb8ab3453a8d212293417b09bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=393.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310a063a4aeb4161834250fd16eb0258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=238027683.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at aubmindlab/araelectra-base-generator were not used when initializing ElectraForTokenClassification: ['generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_lm_head.bias']\n",
      "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at aubmindlab/araelectra-base-generator and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " what city was alex golfis born in\n",
      "NER over initial question: \n",
      " [START] what city was alex golfis born in [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what film is by the writer phil hay?\n",
      "NER over initial question: \n",
      " [START] what film is by the writer phil hay [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did roger marquis die\n",
      "NER over initial question: \n",
      " [START] Where did roger marquis die [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was the cause of death of yves klein\n",
      "NER over initial question: \n",
      " [START] what was the cause of death of yves klein [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which equestrian was born in dublin?\n",
      "NER over initial question: \n",
      " [START] Which equestrian was born in dublin [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is a tv action show?\n",
      "NER over initial question: \n",
      " [START] What is a tv action show [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what's akbar tandjung's ethnicity\n",
      "NER over initial question: \n",
      " what's [START] akbar [END] tandjung's [START] ethnicity [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position does carlos gomez play?\n",
      "NER over initial question: \n",
      " [START] What position does carlos gomez play [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " how does engelbert zaschka identify\n",
      "NER over initial question: \n",
      " [START] how does engelbert zaschka identify [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does pee wee reese play in baseball\n",
      "NER over initial question: \n",
      " [START] what position does pee wee reese play in baseball [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which Swiss conductor's cause of death is myocardial infarction?\n",
      "NER over initial question: \n",
      " [START] Which Swiss [END] conductor's [START] cause of death is myocardial infarction [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of music does david ruffin play\n",
      "NER over initial question: \n",
      " [START] what type of music does david ruffin play [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was padraic mcguinness's place of death\n",
      "NER over initial question: \n",
      " [START] where was padraic [END] mcguinness's [START] place of death [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is viper in\n",
      "NER over initial question: \n",
      " [START] what language is viper in [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who influenced michael mcdowell?\n",
      "NER over initial question: \n",
      " [START] Who influenced michael mcdowell [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the place of birth of sam edwards?\n",
      "NER over initial question: \n",
      " [START] what is the place of birth of sam edwards [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which military was involved in the second battle of fort fisher\n",
      "NER over initial question: \n",
      " [START] which military was involved in the second battle of fort fisher [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# initialize class\n",
    "method = \"aubmindlab/araelectra-base-generator\"\n",
    "\n",
    "ner = NER(model = method,\n",
    "          tokenizer = method)\n",
    "\n",
    "# establish pipeline\n",
    "ner.set_pipeline()\n",
    "\n",
    "\n",
    "# NER\n",
    "changed_texts = []\n",
    "for question in data:\n",
    "    print(\"Initial question: \\n\", question[3])\n",
    "    \n",
    "    # load text\n",
    "    ner.receive_text(text = question[3])\n",
    "    \n",
    "    # receive text with marked entities\n",
    "    new_text = ner.text_with_marked_entities()\n",
    "    changed_texts.append(new_text)\n",
    "    print(\"NER over initial question: \\n\", new_text)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting deeppavlov\n",
      "  Downloading deeppavlov-0.17.4-py3-none-any.whl (878 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m878.6/878.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click==7.1.2\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prometheus-client==0.7.1 in /usr/lib/python3/dist-packages (from deeppavlov) (0.7.1)\n",
      "Requirement already satisfied: protobuf<4 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.19.4)\n",
      "Collecting ruamel.yaml==0.15.100\n",
      "  Downloading ruamel.yaml-0.15.100.tar.gz (318 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk==3.4.5 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.4.5)\n",
      "Collecting pydantic==1.3\n",
      "  Downloading pydantic-1.3-cp38-cp38-manylinux2010_x86_64.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvloop==0.14.0\n",
      "  Downloading uvloop-0.14.0-cp38-cp38-manylinux2010_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting overrides==2.7.0\n",
      "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn==0.21.2\n",
      "  Downloading scikit-learn-0.21.2.tar.gz (12.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas==0.25.3\n",
      "  Downloading pandas-0.25.3-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn==0.11.7\n",
      "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py==2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
      "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
      "Collecting filelock==3.0.12\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting pytz==2019.1\n",
      "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m510.9/510.9 kB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses==0.0.35\n",
      "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m859.8/859.8 kB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm==4.62.0\n",
      "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyopenssl==22.0.0\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pymorphy2==0.8\n",
      "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.18.0\n",
      "  Downloading numpy-1.18.0-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.22.0\n",
      "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi==0.47.1\n",
      "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aio-pika==6.4.1\n",
      "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
      "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: yarl in /home/petrakov/.local/lib/python3.8/site-packages (from aio-pika==6.4.1->deeppavlov) (1.7.2)\n",
      "Collecting aiormq<4,>=3.2.0\n",
      "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
      "Collecting starlette<=0.12.9,>=0.12.9\n",
      "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from h5py==2.10.0->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/petrakov/.local/lib/python3.8/site-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dawg-python>=0.7\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/lib/python3/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Collecting cryptography>=35.0\n",
      "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: joblib in /home/petrakov/.local/lib/python3.8/site-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
      "Collecting websockets==8.*\n",
      "  Downloading websockets-8.1-cp38-cp38-manylinux2010_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools==0.1.*\n",
      "  Downloading httptools-0.1.2-cp38-cp38-manylinux1_x86_64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pamqp==2.3.0\n",
      "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/petrakov/.local/lib/python3.8/site-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n",
      "Requirement already satisfied: multidict>=4.0 in /home/petrakov/.local/lib/python3.8/site-packages (from yarl->aio-pika==6.4.1->deeppavlov) (6.0.2)\n",
      "Requirement already satisfied: pycparser in /home/petrakov/.local/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
      "Building wheels for collected packages: overrides, pytelegrambotapi, ruamel.yaml, sacremoses, scikit-learn, starlette\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5604 sha256=e9ab6dd1ca209a5ca1472a18435361e10d53f0d21a8c095aa725fdc2b3f03f95\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/ed/eb/2c/78b16373a55a26e8e24511c7e61b212184c46cdd69abe8a9a1\n",
      "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47178 sha256=c123a96c2e397dae95fcdeaea59bee1744bce0e36598a2749c84d2ff6d13684b\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/06/86/1d/a5a0eec2da47544847c30c147d852ef18551d4f500df18fd20\n",
      "  Building wheel for ruamel.yaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ruamel.yaml: filename=ruamel.yaml-0.15.100-cp38-cp38-linux_x86_64.whl size=864634 sha256=fc11c35250c1cf70e84247e9d6d0c69ca6f2e2ad0c42c6bf3fee89be95925837\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/83/bb/c8/84a46029883fd202fda2e3d0a579eb30641fecb325b9907fb0\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=b58b14ba0ac38607d822c701e04593eab6a4e3da0e86d970e5a9ce1c4000155f\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/c4/df/30/3d6c623db99d503dcdbae1f686953b7c1a0754d8a658dc0845\n",
      "  Building wheel for scikit-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-learn: filename=scikit_learn-0.21.2-cp38-cp38-linux_x86_64.whl size=24209683 sha256=6ddbffe69f3363f34a1003f3ab949b77104fba60578b984ff0c7b0f85e261358\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/74/11/b6/c7a521de4f5756beb18d8a02a784ed4c2c330353fdf361dbdc\n",
      "  Building wheel for starlette (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=def2046ee266626e6d3d020b9d1144c2c18e5575d22f60d35cdb3bd0437c1131\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/8b/55/68/b64af029c0a3ace9f1ed8b1ae0834560584579f8963b15dbab\n",
      "Successfully built overrides pytelegrambotapi ruamel.yaml sacremoses scikit-learn starlette\n",
      "Installing collected packages: uvloop, rusenttokenize, ruamel.yaml, pytz, pymorphy2-dicts-ru, pymorphy2-dicts, pamqp, overrides, httptools, h11, filelock, dawg-python, websockets, urllib3, tqdm, starlette, pymorphy2, pydantic, numpy, Cython, click, uvicorn, scipy, sacremoses, requests, pandas, h5py, fastapi, cryptography, aiormq, scikit-learn, pytelegrambotapi, pyopenssl, aio-pika, deeppavlov\n",
      "  Attempting uninstall: uvloop\n",
      "    Found existing installation: uvloop 0.16.0\n",
      "    Uninstalling uvloop-0.16.0:\n",
      "      Successfully uninstalled uvloop-0.16.0\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.1\n",
      "    Uninstalling pytz-2022.1:\n",
      "      Successfully uninstalled pytz-2022.1\n",
      "  Attempting uninstall: overrides\n",
      "    Found existing installation: overrides 3.1.0\n",
      "    Uninstalling overrides-3.1.0:\n",
      "      Successfully uninstalled overrides-3.1.0\n",
      "  Attempting uninstall: httptools\n",
      "    Found existing installation: httptools 0.4.0\n",
      "    Uninstalling httptools-0.4.0:\n",
      "      Successfully uninstalled httptools-0.4.0\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.13.0\n",
      "    Uninstalling h11-0.13.0:\n",
      "      Successfully uninstalled h11-0.13.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.7.1\n",
      "    Uninstalling filelock-3.7.1:\n",
      "      Successfully uninstalled filelock-3.7.1\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 10.3\n",
      "    Uninstalling websockets-10.3:\n",
      "      Successfully uninstalled websockets-10.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.50.2\n",
      "    Uninstalling tqdm-4.50.2:\n",
      "      Successfully uninstalled tqdm-4.50.2\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.19.1\n",
      "    Uninstalling starlette-0.19.1:\n",
      "      Successfully uninstalled starlette-0.19.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.1\n",
      "    Uninstalling pydantic-1.9.1:\n",
      "      Successfully uninstalled pydantic-1.9.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.30\n",
      "    Uninstalling Cython-0.29.30:\n",
      "      Successfully uninstalled Cython-0.29.30\n",
      "  Attempting uninstall: uvicorn\n",
      "    Found existing installation: uvicorn 0.17.6\n",
      "    Uninstalling uvicorn-0.17.6:\n",
      "      Successfully uninstalled uvicorn-0.17.6\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "  Attempting uninstall: sacremoses\n",
      "    Found existing installation: sacremoses 0.0.53\n",
      "    Uninstalling sacremoses-0.0.53:\n",
      "      Successfully uninstalled sacremoses-0.0.53\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.78.0\n",
      "    Uninstalling fastapi-0.78.0:\n",
      "      Successfully uninstalled fastapi-0.78.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
      "pytorch-lightning 1.6.4 requires torch>=1.8.*, but you have torch 1.7.0 which is incompatible.\n",
      "lightning 20220621 requires torch<=1.11.0,>=1.9.*, but you have torch 1.7.0 which is incompatible.\n",
      "lightning-bolts 0.6.0.dev0 requires torch>=1.9.*, but you have torch 1.7.0 which is incompatible.\n",
      "konoha 4.6.5 requires overrides<4.0.0,>=3.0.0, but you have overrides 2.7.0 which is incompatible.\n",
      "konoha 4.6.5 requires requests<3.0.0,>=2.25.1, but you have requests 2.22.0 which is incompatible.\n",
      "flair 0.6.1 requires scikit-learn>=0.21.3, but you have scikit-learn 0.21.2 which is incompatible.\n",
      "datasets 2.3.2 requires tqdm>=4.62.1, but you have tqdm 4.62.0 which is incompatible.\n",
      "aiobotocore 2.1.2 requires botocore<1.23.25,>=1.23.24, but you have botocore 1.27.22 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 click-7.1.2 cryptography-37.0.4 dawg-python-0.7.2 deeppavlov-0.17.4 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-22.0.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 scipy-1.4.1 starlette-0.12.9 tqdm-4.62.0 urllib3-1.25.11 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deeppavlov'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-41e561f14540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mner_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner_ontonotes_bert_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ner_model(['World Curling Championship will be held in Antananarivo'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deeppavlov'"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)\n",
    "#ner_model(['World Curling Championship will be held in Antananarivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what city was alex golfis born in\n",
      "\n",
      "\n",
      "[[{'id': 'Q3561', 'texts': ['Algiers >> en'], 'scores': tensor([-0.7752], device='cuda:4'), 'score': tensor(-1.8988, device='cuda:4')}, {'id': 'Q994', 'texts': ['Tiflis >> en', 'Tbilisi >> en'], 'scores': tensor([-1.1594, -1.1623], device='cuda:4'), 'score': tensor(-2.0191, device='cuda:4')}, {'id': 'Q6343', 'texts': ['Carthage >> en'], 'scores': tensor([-0.9458], device='cuda:4'), 'score': tensor(-2.3167, device='cuda:4')}, {'id': 'Q5818', 'texts': ['Crdoba, Spain >> en'], 'scores': tensor([-0.8913], device='cuda:4'), 'score': tensor(-2.5210, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q16330302\n",
      "true answer subject:  Q1524\n",
      "\n",
      "\n",
      "####################\n",
      "what film is by the writer phil hay?\n",
      "\n",
      "\n",
      "[[{'id': 'Q26786240', 'texts': ['Phil Hay >> en'], 'scores': tensor([-0.2330], device='cuda:4'), 'score': tensor(-0.5211, device='cuda:4')}, {'id': 'Q374585', 'texts': ['Phil Hayes >> en'], 'scores': tensor([-0.5991], device='cuda:4'), 'score': tensor(-1.4675, device='cuda:4')}, {'id': 'Q16225521', 'texts': ['Phil Hay (screenwriter) >> en'], 'scores': tensor([-0.5083], device='cuda:4'), 'score': tensor(-1.5248, device='cuda:4')}, {'id': 'Q2086199', 'texts': ['Philip H. Hayes >> en'], 'scores': tensor([-1.0990], device='cuda:4'), 'score': tensor(-3.1085, device='cuda:4')}, {'id': 'Q16209551', 'texts': ['Phil Hayes (actor) >> en'], 'scores': tensor([-1.0432], device='cuda:4'), 'score': tensor(-3.1296, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q16225521\n",
      "true answer subject:  Q192979\n",
      "\n",
      "\n",
      "####################\n",
      "Where did roger marquis die\n",
      "\n",
      "\n",
      "[[{'id': 'Q209726', 'texts': ['Marquis >> en', 'Marquess >> en', 'Marquis >> fr'], 'scores': tensor([-1.1408, -1.1732, -1.3033], device='cuda:4'), 'score': tensor(-1.6674, device='cuda:4')}, {'id': 'Q237223', 'texts': ['Marquis >> de'], 'scores': tensor([-1.0068], device='cuda:4'), 'score': tensor(-2.2513, device='cuda:4')}, {'id': 'Q819230', 'texts': ['Liste der Adelsgeschlechter namens Berg >> de'], 'scores': tensor([-1.1032], device='cuda:4'), 'score': tensor(-3.8216, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q7358590\n",
      "true answer subject:  Q1637790\n",
      "\n",
      "\n",
      "####################\n",
      "what was the cause of death of yves klein\n",
      "\n",
      "\n",
      "[[{'id': 'Q12204', 'texts': ['Tuberculosis >> en', 'Tuberculose >> en'], 'scores': tensor([-0.8097, -1.6651], device='cuda:4'), 'score': tensor(-2.0433, device='cuda:4')}, {'id': 'Q3048621', 'texts': ['List of diseases of the honey bee >> en'], 'scores': tensor([-0.7211], device='cuda:4'), 'score': tensor(-2.2804, device='cuda:4')}, {'id': 'Q8062282', 'texts': ['Yve >> en'], 'scores': tensor([-1.1153], device='cuda:4'), 'score': tensor(-2.4940, device='cuda:4')}, {'id': 'Q408343', 'texts': ['Yv >> en'], 'scores': tensor([-1.2955], device='cuda:4'), 'score': tensor(-2.8967, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q154335\n",
      "true answer subject:  Q12152\n",
      "\n",
      "\n",
      "####################\n",
      "Which equestrian was born in dublin?\n",
      "\n",
      "\n",
      "[[{'id': 'Q179226', 'texts': ['Equestrianism >> en'], 'scores': tensor([-0.6992], device='cuda:4'), 'score': tensor(-1.8499, device='cuda:4')}, {'id': 'Q1516442', 'texts': ['History of Ireland (18011923) >> en'], 'scores': tensor([-0.5952], device='cuda:4'), 'score': tensor(-1.8822, device='cuda:4')}, {'id': 'Q875651', 'texts': ['Irish Travellers >> en'], 'scores': tensor([-0.8705], device='cuda:4'), 'score': tensor(-2.1323, device='cuda:4')}, {'id': 'Q833790', 'texts': ['Equestrian at the Summer Olympics >> en'], 'scores': tensor([-0.7202], device='cuda:4'), 'score': tensor(-2.2774, device='cuda:4')}, {'id': 'Q2457218', 'texts': ['Equestrian at the Summer Paralympics >> en'], 'scores': tensor([-0.8956], device='cuda:4'), 'score': tensor(-3.1025, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q1761\n",
      "true answer subject:  Q6768445\n",
      "\n",
      "\n",
      "####################\n",
      "What is a tv action show?\n",
      "\n",
      "\n",
      "[[{'id': 'Q188473', 'texts': ['Action film >> en'], 'scores': tensor([-0.7117], device='cuda:4'), 'score': tensor(-1.5914, device='cuda:4')}, {'id': 'Q1762165', 'texts': ['Action fiction >> en'], 'scores': tensor([-0.8155], device='cuda:4'), 'score': tensor(-1.8236, device='cuda:4')}, {'id': 'Q15416', 'texts': ['Television show >> en'], 'scores': tensor([-1.0385], device='cuda:4'), 'score': tensor(-2.3221, device='cuda:4')}, {'id': 'Q270948', 'texts': ['Action game >> en'], 'scores': tensor([-1.0421], device='cuda:4'), 'score': tensor(-2.3302, device='cuda:4')}, {'id': 'Q343542', 'texts': ['Action >> en'], 'scores': tensor([-1.2027], device='cuda:4'), 'score': tensor(-2.4054, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q11272426\n",
      "true answer subject:  Q5533291\n",
      "\n",
      "\n",
      "####################\n",
      "what's akbar tandjung's ethnicity\n",
      "\n",
      "\n",
      "[[{'id': 'Q1185994', 'texts': ['Demographics of Indonesia >> en'], 'scores': tensor([-0.5456], device='cuda:4'), 'score': tensor(-1.5433, device='cuda:4')}, {'id': 'Q1185999', 'texts': ['Demographics of Malaysia >> en'], 'scores': tensor([-0.5787], device='cuda:4'), 'score': tensor(-1.6369, device='cuda:4')}, {'id': 'Q49209', 'texts': ['Javanese people >> en'], 'scores': tensor([-0.6640], device='cuda:4'), 'score': tensor(-1.7567, device='cuda:4')}, {'id': 'Q42534', 'texts': ['Indus Valley Civilisation >> en'], 'scores': tensor([-0.8137], device='cuda:4'), 'score': tensor(-2.3014, device='cuda:4')}, {'id': 'Q3268547', 'texts': ['Bangsar >> en'], 'scores': tensor([-1.3446], device='cuda:4'), 'score': tensor(-3.0067, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q2581168\n",
      "true answer subject:  Q810714\n",
      "\n",
      "\n",
      "####################\n",
      "What position does carlos gomez play?\n",
      "\n",
      "\n",
      "[[{'id': 'Q571113', 'texts': ['Glossary of chess >> en'], 'scores': tensor([-0.2453], device='cuda:4'), 'score': tensor(-0.7360, device='cuda:4')}, {'id': 'Q2661943', 'texts': ['Glossary of contract bridge terms >> en'], 'scores': tensor([-0.4275], device='cuda:4'), 'score': tensor(-1.3517, device='cuda:4')}, {'id': 'Q8903', 'texts': ['Glossary of association football terms >> en'], 'scores': tensor([-0.5183], device='cuda:4'), 'score': tensor(-1.6389, device='cuda:4')}, {'id': 'Q787810', 'texts': ['List of chess players >> en'], 'scores': tensor([-0.6256], device='cuda:4'), 'score': tensor(-1.7694, device='cuda:4')}, {'id': 'Q1109985', 'texts': ['Glossary of rugby union terms >> en'], 'scores': tensor([-0.5712], device='cuda:4'), 'score': tensor(-1.8062, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q2747238\n",
      "true answer subject:  Q5059480\n",
      "\n",
      "\n",
      "####################\n",
      "how does engelbert zaschka identify\n",
      "\n",
      "\n",
      "[[{'id': 'Q62498', 'texts': ['Engelbert Zaschka >> en'], 'scores': tensor([-0.4502], device='cuda:4'), 'score': tensor(-1.2733, device='cuda:4')}, {'id': 'Q209082', 'texts': ['Chemical kinetics >> en'], 'scores': tensor([-0.6491], device='cuda:4'), 'score': tensor(-1.8359, device='cuda:4')}, {'id': 'Q204037', 'texts': ['Natural logarithm >> en'], 'scores': tensor([-0.8029], device='cuda:4'), 'score': tensor(-2.2709, device='cuda:4')}, {'id': 'Q83147', 'texts': ['Chemical formula >> en'], 'scores': tensor([-1.0012], device='cuda:4'), 'score': tensor(-2.4524, device='cuda:4')}, {'id': 'Q148189', 'texts': ['Zaschka >> en'], 'scores': tensor([-1.3962], device='cuda:4'), 'score': tensor(-3.4200, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q62498\n",
      "true answer subject:  Q6581097\n",
      "\n",
      "\n",
      "####################\n",
      "what position does pee wee reese play in baseball\n",
      "\n",
      "\n",
      "[[{'id': 'Q1151733', 'texts': ['Baseball positions >> en'], 'scores': tensor([-0.3714], device='cuda:4'), 'score': tensor(-0.9098, device='cuda:4')}, {'id': 'Q5571754', 'texts': ['Glossary of baseball (S) >> en'], 'scores': tensor([-0.4385], device='cuda:4'), 'score': tensor(-1.4545, device='cuda:4')}, {'id': 'Q5571757', 'texts': ['Glossary of baseball (T) >> en'], 'scores': tensor([-0.5087], device='cuda:4'), 'score': tensor(-1.6871, device='cuda:4')}, {'id': 'Q3237411', 'texts': ['Glossary of baseball >> en'], 'scores': tensor([-0.6213], device='cuda:4'), 'score': tensor(-1.7572, device='cuda:4')}, {'id': 'Q5369', 'texts': ['Baseball >> en'], 'scores': tensor([-0.8048], device='cuda:4'), 'score': tensor(-1.7995, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q182485\n",
      "true answer subject:  Q1143358\n",
      "\n",
      "\n",
      "####################\n",
      "Which Swiss conductor's cause of death is myocardial infarction?\n",
      "\n",
      "\n",
      "[[{'id': 'Q12152', 'texts': ['Myocardial infarction >> en', 'Myocardial infarct >> en'], 'scores': tensor([-0.0866, -1.0325], device='cuda:4'), 'score': tensor(-0.2248, device='cuda:4')}, {'id': 'Q207550', 'texts': ['Infarction >> en'], 'scores': tensor([-1.1025], device='cuda:4'), 'score': tensor(-2.7007, device='cuda:4')}, {'id': 'Q202837', 'texts': ['Cardiac arrest >> en'], 'scores': tensor([-1.4250], device='cuda:4'), 'score': tensor(-3.4906, device='cuda:4')}, {'id': 'Q84133', 'texts': ['Miocardio >> es'], 'scores': tensor([-1.6785], device='cuda:4'), 'score': tensor(-4.4409, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q12152\n",
      "true answer subject:  Q6371569\n",
      "\n",
      "\n",
      "####################\n",
      "what type of music does david ruffin play\n",
      "\n",
      "\n",
      "[[{'id': 'Q411350', 'texts': ['Ruffin >> en', 'Ruffin >> fr', 'Ruffin >> de'], 'scores': tensor([-0.1341, -1.8206, -1.8801], device='cuda:4'), 'score': tensor(-0.2575, device='cuda:4')}, {'id': 'Q3473856', 'texts': ['Ruffin >> es'], 'scores': tensor([-2.0299], device='cuda:4'), 'score': tensor(-4.5390, device='cuda:4')}, {'id': 'Q1692072', 'texts': ['Ruffine >> de'], 'scores': tensor([-2.7013], device='cuda:4'), 'score': tensor(-6.6169, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q1176417\n",
      "true answer subject:  Q37073\n",
      "\n",
      "\n",
      "####################\n",
      "where was padraic mcguinness's place of death\n",
      "\n",
      "\n",
      "[[{'id': 'Q1202197', 'texts': ['Place of death >> en'], 'scores': tensor([-0.4011], device='cuda:4'), 'score': tensor(-0.9826, device='cuda:4')}, {'id': 'Q438214', 'texts': [\"Places in The Hitchhiker's Guide to the Galaxy >> en\"], 'scores': tensor([-0.3226], device='cuda:4'), 'score': tensor(-1.3300, device='cuda:4')}, {'id': 'Q208361', 'texts': ['Places in Harry Potter >> en'], 'scores': tensor([-0.6064], device='cuda:4'), 'score': tensor(-1.7151, device='cuda:4')}, {'id': 'Q499618', 'texts': ['Glossary of Dune terminology >> en'], 'scores': tensor([-0.5880], device='cuda:4'), 'score': tensor(-1.9502, device='cuda:4')}, {'id': 'Q5125767', 'texts': ['Clandestine chemistry >> en'], 'scores': tensor([-0.8785], device='cuda:4'), 'score': tensor(-2.4847, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q7123909\n",
      "true answer subject:  Q3130\n",
      "\n",
      "\n",
      "####################\n",
      "what language is viper in\n",
      "\n",
      "\n",
      "[[{'id': 'Q163656', 'texts': ['Viperidae >> en'], 'scores': tensor([-0.3507], device='cuda:4'), 'score': tensor(-0.8591, device='cuda:4')}, {'id': 'Q315', 'texts': ['Language >> en'], 'scores': tensor([-0.7536], device='cuda:4'), 'score': tensor(-1.5072, device='cuda:4')}, {'id': 'Q192056', 'texts': ['Vipera berus >> en'], 'scores': tensor([-0.6086], device='cuda:4'), 'score': tensor(-1.6102, device='cuda:4')}, {'id': 'Q662672', 'texts': ['Vipera >> en'], 'scores': tensor([-1.0540], device='cuda:4'), 'score': tensor(-2.3569, device='cuda:4')}, {'id': 'Q20064', 'texts': ['Viper (Battlestar Galactica) >> en'], 'scores': tensor([-0.6929], device='cuda:4'), 'score': tensor(-2.5925, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q1189775\n",
      "true answer subject:  Q1860\n",
      "\n",
      "\n",
      "####################\n",
      "Who influenced michael mcdowell?\n",
      "\n",
      "\n",
      "[[{'id': 'Q6832662', 'texts': ['Michael McDowell >> en', 'Michael McDowell >> fr'], 'scores': tensor([-0.4771, -1.1546], device='cuda:4'), 'score': tensor(-1.2121, device='cuda:4')}, {'id': 'Q411637', 'texts': ['McDowell >> en'], 'scores': tensor([-0.5194], device='cuda:4'), 'score': tensor(-1.3741, device='cuda:4')}, {'id': 'Q3273867', 'texts': ['McDowell Colony >> en'], 'scores': tensor([-0.9049], device='cuda:4'), 'score': tensor(-2.5594, device='cuda:4')}, {'id': 'Q276817', 'texts': ['Michael McDowell (author) >> en'], 'scores': tensor([-0.8276], device='cuda:4'), 'score': tensor(-2.7447, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q276817\n",
      "true answer subject:  Q169566\n",
      "\n",
      "\n",
      "####################\n",
      "what is the place of birth of sam edwards?\n",
      "\n",
      "\n",
      "[[{'id': 'Q39018', 'texts': ['Emperor >> en'], 'scores': tensor([-0.5983], device='cuda:4'), 'score': tensor(-1.4654, device='cuda:4')}, {'id': 'Q208233', 'texts': ['Emperor of Japan >> en'], 'scores': tensor([-0.5408], device='cuda:4'), 'score': tensor(-1.5297, device='cuda:4')}, {'id': 'Q8445', 'texts': ['Marriage >> en'], 'scores': tensor([-0.8359], device='cuda:4'), 'score': tensor(-1.8692, device='cuda:4')}, {'id': 'Q11995', 'texts': ['Pregnancy >> en'], 'scores': tensor([-0.8217], device='cuda:4'), 'score': tensor(-2.0128, device='cuda:4')}, {'id': 'Q3870479', 'texts': ['Nativity of Saint John the Baptist >> en'], 'scores': tensor([-0.6585], device='cuda:4'), 'score': tensor(-2.2810, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q472382\n",
      "true answer subject:  Q23051\n",
      "\n",
      "\n",
      "####################\n",
      "which military was involved in the second battle of fort fisher\n",
      "\n",
      "\n",
      "[[{'id': 'Q4871042', 'texts': ['Battle of Fort Fisher >> en', 'Battle of Fort Fisher (disambiguation) >> en'], 'scores': tensor([-0.5425, -1.1170], device='cuda:4'), 'score': tensor(-1.3632, device='cuda:4')}, {'id': 'Q7443093', 'texts': ['Second battle of fort fisher >> en', 'Second Battle of Fort Fisher >> en'], 'scores': tensor([-0.6908, -0.8167], device='cuda:4'), 'score': tensor(-1.4910, device='cuda:4')}, {'id': 'Q846674', 'texts': ['Battles of Saratoga >> en'], 'scores': tensor([-0.5792], device='cuda:4'), 'score': tensor(-1.7376, device='cuda:4')}]]\n",
      "\n",
      "\n",
      "true answer object:  Q7443093\n",
      "true answer subject:  Q214102\n",
      "\n",
      "\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "for i in data:   \n",
    "    sentences = [i[3]]\n",
    "    print(i[3])\n",
    "    print(\"\\n\")\n",
    "    print(model_mGENRE.sample(\n",
    "        sentences,\n",
    "        beam = 5,\n",
    "        prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "            e for e in trie.get(sent.tolist())\n",
    "            if e < len(model_mGENRE.task.target_dictionary)\n",
    "        ],\n",
    "        text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "        marginalize=True,\n",
    "        verbose = True\n",
    "    ))\n",
    "    print(\"\\n\")\n",
    "    print(\"true answer object: \", i[0])\n",
    "    print(\"true answer subject: \", i[2])\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative assessment on Simple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NER:\n",
    "    def __init__(self, \n",
    "                 #text, \n",
    "                 model = \"Babelscape/wikineural-multilingual-ner\",\n",
    "                 tokenizer = \"Babelscape/wikineural-multilingual-ner\"):\n",
    "        \n",
    "        #self.text = text\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def set_pipeline(self):   \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model)\n",
    "        self.nlp = pipeline(\"ner\",\n",
    "                            model = self.model,\n",
    "                            tokenizer = self.tokenizer)\n",
    "        \n",
    "    def receive_text(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def receive_words(self):\n",
    "        self.text = re.sub('[!@#$?,]', '', self.text)\n",
    "        out = re.split(r' ', self.text)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def receive_enitity(self):\n",
    "        ner_results = self.nlp(self.text)\n",
    "        print(\"ner_results\", ner_results)\n",
    "        final = []\n",
    "        result = [i[\"word\"] for i in ner_results]\n",
    "        for elem in result:\n",
    "            print(\"elem\", elem)\n",
    "            if (elem[:2] == \"##\") & (len(final) > 0):\n",
    "                final[-1] = final[-1] + elem[2:]\n",
    "            elif elem[:2] == \"##\":\n",
    "                final.append(elem[2:])\n",
    "            else:\n",
    "                final.append(elem)\n",
    "        return final\n",
    "    \n",
    "    def text_with_marked_entities(self):\n",
    "        output = \"\"\n",
    "        entities = self.receive_enitity()\n",
    "        list_of_words = self.receive_words()\n",
    "        for word in list_of_words:\n",
    "            if word not in entities:\n",
    "                output = output + word + \" \"\n",
    "            else:\n",
    "                output = output + \"[START] \" + word +  \" [END] \"\n",
    "        output = re.sub(\"\\[END\\] \\[START\\] \", \"\", output)\n",
    "        output += \"?\"\n",
    "        return output\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner = NER(text = \"How many times have people won the jackpot at Caesar?\")\n",
    "\n",
    "# initialize class\n",
    "ner = NER()\n",
    "\n",
    "# establish pipeline\n",
    "ner.set_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(data.sample(n = n, replace = False, random_state=1).loc[:, \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/400 [00:00<00:15, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial question: \n",
      " What is a movie pierce brosnan produced?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is a movie pierce brosnan produced ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of music is featured on ten new songs\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What kind of music is featured on ten new songs ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which episode was written by chris carter (screenwriter)\n",
      "ner_results [{'word': 'ch', 'score': 0.6152981519699097, 'entity': 'B-ORG', 'index': 6, 'start': 29, 'end': 31}]\n",
      "elem ch\n",
      "NER over initial question: \n",
      " which episode was written by chris carter (screenwriter) ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of celestial object is 1495 helsinki?\n",
      "ner_results [{'word': 'hel', 'score': 0.6927583813667297, 'entity': 'B-MISC', 'index': 9, 'start': 38, 'end': 41}, {'word': '##sin', 'score': 0.4328274130821228, 'entity': 'I-MISC', 'index': 10, 'start': 41, 'end': 44}, {'word': '##ki', 'score': 0.6481525897979736, 'entity': 'I-MISC', 'index': 11, 'start': 44, 'end': 46}]\n",
      "elem hel\n",
      "elem ##sin\n",
      "elem ##ki\n",
      "NER over initial question: \n",
      " What kind of celestial object is 1495 [START] helsinki [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is chris offutt's gender \n",
      "ner_results [{'word': 'ch', 'score': 0.656899094581604, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': 'off', 'score': 0.6616729497909546, 'entity': 'B-PER', 'index': 5, 'start': 14, 'end': 17}, {'word': '##utt', 'score': 0.5504513382911682, 'entity': 'I-PER', 'index': 6, 'start': 17, 'end': 20}]\n",
      "elem ch\n",
      "elem off\n",
      "elem ##utt\n",
      "NER over initial question: \n",
      " what is chris offutt's gender  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is an african american character actor and retired professional wrestler? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 6/400 [00:01<01:24,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'af', 'score': 0.7936720848083496, 'entity': 'B-MISC', 'index': 4, 'start': 10, 'end': 12}, {'word': '##rica', 'score': 0.6354202032089233, 'entity': 'B-MISC', 'index': 5, 'start': 12, 'end': 16}, {'word': '##n', 'score': 0.5097811222076416, 'entity': 'B-MISC', 'index': 6, 'start': 16, 'end': 17}, {'word': 'american', 'score': 0.609046459197998, 'entity': 'B-MISC', 'index': 7, 'start': 18, 'end': 26}]\n",
      "elem af\n",
      "elem ##rica\n",
      "elem ##n\n",
      "elem american\n",
      "NER over initial question: \n",
      " Who is an [START] african american [END] character actor and retired professional wrestler  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a professional writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 8/400 [00:01<01:14,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Name a professional writer ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country is marcel landers from?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Which country is marcel landers from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is an example of a city that can be found in  north american central time zone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 10/400 [00:02<01:36,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'american', 'score': 0.7435474395751953, 'entity': 'B-MISC', 'index': 14, 'start': 57, 'end': 65}]\n",
      "elem american\n",
      "NER over initial question: \n",
      " what is an example of a city that can be found in  north [START] american [END] central time zone ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " In what language was inside man filmed?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " In what language was inside man filmed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what genre is serpico in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 15/400 [00:02<00:42,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what genre is serpico in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What type of music is bobby kildea known for\n",
      "ner_results [{'word': 'bob', 'score': 0.6602774858474731, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 25}, {'word': '##by', 'score': 0.5224658250808716, 'entity': 'I-MISC', 'index': 7, 'start': 25, 'end': 27}, {'word': 'ki', 'score': 0.6515940427780151, 'entity': 'B-MISC', 'index': 8, 'start': 28, 'end': 30}, {'word': '##lde', 'score': 0.38386669754981995, 'entity': 'I-MISC', 'index': 9, 'start': 30, 'end': 33}, {'word': '##a', 'score': 0.6285944581031799, 'entity': 'I-MISC', 'index': 10, 'start': 33, 'end': 34}]\n",
      "elem bob\n",
      "elem ##by\n",
      "elem ki\n",
      "elem ##lde\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " What type of music is [START] bobby kildea [END] known for ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was earle birney's birth place\n",
      "ner_results [{'word': '##ney', 'score': 0.4409066140651703, 'entity': 'I-PER', 'index': 6, 'start': 18, 'end': 21}]\n",
      "elem ##ney\n",
      "NER over initial question: \n",
      " what was earle birney's birth place ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who created the album the traveling wilburys collection\n",
      "ner_results [{'word': 'wil', 'score': 0.5339022874832153, 'entity': 'B-MISC', 'index': 7, 'start': 36, 'end': 39}, {'word': '##bury', 'score': 0.29286718368530273, 'entity': 'I-PER', 'index': 8, 'start': 39, 'end': 43}]\n",
      "elem wil\n",
      "elem ##bury\n",
      "NER over initial question: \n",
      " who created the album the traveling wilburys collection ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of music does roman holiday record?\n",
      "ner_results [{'word': 'roman', 'score': 0.9365183711051941, 'entity': 'B-MISC', 'index': 6, 'start': 24, 'end': 29}]\n",
      "elem roman\n",
      "NER over initial question: \n",
      " What kind of music does [START] roman [END] holiday record ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What game play mode is the computer video game Yoshis Safari?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 20/400 [00:03<00:41,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'Yo', 'score': 0.9951897263526917, 'entity': 'B-MISC', 'index': 10, 'start': 47, 'end': 49}, {'word': '##shi', 'score': 0.9979313611984253, 'entity': 'I-MISC', 'index': 11, 'start': 49, 'end': 52}, {'word': '##s', 'score': 0.9992203712463379, 'entity': 'I-MISC', 'index': 12, 'start': 52, 'end': 53}, {'word': 'Safari', 'score': 0.9970843195915222, 'entity': 'I-MISC', 'index': 13, 'start': 54, 'end': 60}]\n",
      "elem Yo\n",
      "elem ##shi\n",
      "elem ##s\n",
      "elem Safari\n",
      "NER over initial question: \n",
      " What game play mode is the computer video game [START] Yoshis Safari [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where exactly was marian goliski born\n",
      "ner_results [{'word': 'mari', 'score': 0.8758665919303894, 'entity': 'B-PER', 'index': 4, 'start': 18, 'end': 22}, {'word': '##an', 'score': 0.6453502178192139, 'entity': 'I-PER', 'index': 5, 'start': 22, 'end': 24}, {'word': 'goli', 'score': 0.56134033203125, 'entity': 'I-PER', 'index': 6, 'start': 25, 'end': 29}]\n",
      "elem mari\n",
      "elem ##an\n",
      "elem goli\n",
      "NER over initial question: \n",
      " Where exactly was [START] marian [END] goliski born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of album is after hours at the london house \n",
      "ner_results [{'word': 'lo', 'score': 0.5610107183456421, 'entity': 'B-MISC', 'index': 10, 'start': 41, 'end': 43}]\n",
      "elem lo\n",
      "NER over initial question: \n",
      " what type of album is after hours at the london house  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what nationality is simon scardifield\n",
      "ner_results [{'word': 'sim', 'score': 0.7651222348213196, 'entity': 'B-MISC', 'index': 4, 'start': 20, 'end': 23}]\n",
      "elem sim\n",
      "NER over initial question: \n",
      " what nationality is simon scardifield ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What film did mansoor khan contribute to?\n",
      "ner_results [{'word': 'mans', 'score': 0.6828532218933105, 'entity': 'B-PER', 'index': 4, 'start': 14, 'end': 18}, {'word': '##oor', 'score': 0.4860226511955261, 'entity': 'I-PER', 'index': 5, 'start': 18, 'end': 21}]\n",
      "elem mans\n",
      "elem ##oor\n",
      "NER over initial question: \n",
      " What film did [START] mansoor [END] khan contribute to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what time zone is lindstrom in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 25/400 [00:03<00:29, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'li', 'score': 0.6235854625701904, 'entity': 'B-LOC', 'index': 5, 'start': 18, 'end': 20}]\n",
      "elem li\n",
      "NER over initial question: \n",
      " what time zone is lindstrom in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is mohamed safwat's gender\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is mohamed safwat's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which german city is faiz kevin mangat from\n",
      "ner_results [{'word': 'german', 'score': 0.950069785118103, 'entity': 'B-MISC', 'index': 2, 'start': 6, 'end': 12}]\n",
      "elem german\n",
      "NER over initial question: \n",
      " which [START] german [END] city is faiz kevin mangat from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What nation is tulsi ramsay from?\n",
      "ner_results [{'word': 'tu', 'score': 0.39693763852119446, 'entity': 'B-MISC', 'index': 4, 'start': 15, 'end': 17}, {'word': '##ls', 'score': 0.27607446908950806, 'entity': 'B-MISC', 'index': 5, 'start': 17, 'end': 19}, {'word': '##i', 'score': 0.41698989272117615, 'entity': 'I-LOC', 'index': 6, 'start': 19, 'end': 20}]\n",
      "elem tu\n",
      "elem ##ls\n",
      "elem ##i\n",
      "NER over initial question: \n",
      " What nation is [START] tulsi [END] ramsay from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did william hedgcock die\n",
      "ner_results [{'word': 'will', 'score': 0.7169914841651917, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 14}]\n",
      "elem will\n",
      "NER over initial question: \n",
      " Where did william hedgcock die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is sonja skarstedt's place of birth?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 28/400 [00:03<00:25, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'son', 'score': 0.9524672031402588, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 11}, {'word': '##ja', 'score': 0.7951620817184448, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 13}, {'word': 'ska', 'score': 0.9669378995895386, 'entity': 'I-PER', 'index': 5, 'start': 14, 'end': 17}, {'word': '##rst', 'score': 0.9139488339424133, 'entity': 'I-PER', 'index': 6, 'start': 17, 'end': 20}, {'word': '##edt', 'score': 0.8780090808868408, 'entity': 'I-PER', 'index': 7, 'start': 20, 'end': 23}]\n",
      "elem son\n",
      "elem ##ja\n",
      "elem ska\n",
      "elem ##rst\n",
      "elem ##edt\n",
      "NER over initial question: \n",
      " what is [START] sonja [END] skarstedt's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is someone born in barcelona\n",
      "ner_results [{'word': 'bar', 'score': 0.4818287789821625, 'entity': 'B-LOC', 'index': 6, 'start': 23, 'end': 26}, {'word': '##cel', 'score': 0.39018744230270386, 'entity': 'I-LOC', 'index': 7, 'start': 26, 'end': 29}, {'word': '##ona', 'score': 0.4143126606941223, 'entity': 'I-LOC', 'index': 8, 'start': 29, 'end': 32}]\n",
      "elem bar\n",
      "elem ##cel\n",
      "elem ##ona\n",
      "NER over initial question: \n",
      " who is someone born in [START] barcelona [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position does uro tripkovi play?\n",
      "ner_results [{'word': 'ur', 'score': 0.791358470916748, 'entity': 'B-PER', 'index': 4, 'start': 19, 'end': 21}, {'word': '##o', 'score': 0.6234731078147888, 'entity': 'I-PER', 'index': 5, 'start': 21, 'end': 23}]\n",
      "elem ur\n",
      "elem ##o\n",
      "NER over initial question: \n",
      " What position does [START] uro [END] tripkovi play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what's kumar sangakkara's ethnicity?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what's kumar sangakkara's ethnicity ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is an album that was released by marc almond?\n",
      "ner_results [{'word': 'marc', 'score': 0.8326408863067627, 'entity': 'B-ORG', 'index': 9, 'start': 38, 'end': 42}, {'word': 'al', 'score': 0.5100455284118652, 'entity': 'I-ORG', 'index': 10, 'start': 43, 'end': 45}, {'word': '##mond', 'score': 0.5979183316230774, 'entity': 'I-ORG', 'index': 11, 'start': 45, 'end': 49}]\n",
      "elem marc\n",
      "elem al\n",
      "elem ##mond\n",
      "NER over initial question: \n",
      " What is an album that was released by [START] marc almond [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which city was thilo kleibauer born in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 34/400 [00:03<00:20, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'thi', 'score': 0.836921751499176, 'entity': 'B-PER', 'index': 6, 'start': 15, 'end': 18}, {'word': '##lo', 'score': 0.5845729112625122, 'entity': 'I-PER', 'index': 7, 'start': 18, 'end': 20}, {'word': 'kl', 'score': 0.5662601590156555, 'entity': 'I-PER', 'index': 8, 'start': 21, 'end': 23}]\n",
      "elem thi\n",
      "elem ##lo\n",
      "elem kl\n",
      "NER over initial question: \n",
      " Which city was [START] thilo [END] kleibauer born in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is a parent of casey johnson\n",
      "ner_results [{'word': 'case', 'score': 0.5049830079078674, 'entity': 'B-MISC', 'index': 6, 'start': 19, 'end': 23}]\n",
      "elem case\n",
      "NER over initial question: \n",
      " who is a parent of casey johnson ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which artist records under columbia records\n",
      "ner_results [{'word': 'col', 'score': 0.5369917154312134, 'entity': 'B-LOC', 'index': 5, 'start': 27, 'end': 30}, {'word': '##um', 'score': 0.3647492229938507, 'entity': 'I-LOC', 'index': 6, 'start': 30, 'end': 32}, {'word': '##bia', 'score': 0.3557332456111908, 'entity': 'I-LOC', 'index': 7, 'start': 32, 'end': 35}]\n",
      "elem col\n",
      "elem ##um\n",
      "elem ##bia\n",
      "NER over initial question: \n",
      " which artist records under [START] columbia [END] records ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a film written by jerry lewis\n",
      "ner_results [{'word': 'jer', 'score': 0.4341519773006439, 'entity': 'B-ORG', 'index': 6, 'start': 23, 'end': 26}]\n",
      "elem jer\n",
      "NER over initial question: \n",
      " Name a film written by jerry lewis ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is 10161 nakanoshima classified as\n",
      "ner_results [{'word': 'nak', 'score': 0.47087135910987854, 'entity': 'B-LOC', 'index': 5, 'start': 14, 'end': 17}, {'word': '##anos', 'score': 0.6242559552192688, 'entity': 'I-LOC', 'index': 6, 'start': 17, 'end': 21}, {'word': '##hima', 'score': 0.7379871010780334, 'entity': 'I-LOC', 'index': 7, 'start': 21, 'end': 25}]\n",
      "elem nak\n",
      "elem ##anos\n",
      "elem ##hima\n",
      "NER over initial question: \n",
      " What is 10161 [START] nakanoshima [END] classified as ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what series has the episode rosebud\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what series has the episode rosebud ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which artist records under the earache records label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 37/400 [00:03<00:24, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ear', 'score': 0.8605076670646667, 'entity': 'B-ORG', 'index': 6, 'start': 31, 'end': 34}, {'word': '##ache', 'score': 0.8077614903450012, 'entity': 'I-ORG', 'index': 7, 'start': 34, 'end': 38}]\n",
      "elem ear\n",
      "elem ##ache\n",
      "NER over initial question: \n",
      " which artist records under the [START] earache [END] records label ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " This jazz was released in 1959.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 39/400 [00:04<00:40,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'jazz', 'score': 0.6714209914207458, 'entity': 'B-MISC', 'index': 2, 'start': 5, 'end': 9}]\n",
      "elem jazz\n",
      "NER over initial question: \n",
      " This [START] jazz [END] was released in 1959. ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what does 1255 schilowa orbit\n",
      "ner_results [{'word': '##a', 'score': 0.4741567075252533, 'entity': 'I-LOC', 'index': 7, 'start': 22, 'end': 23}]\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " what does 1255 schilowa orbit ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what games were published by ea sports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 44/400 [00:04<00:32, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ea', 'score': 0.9060685038566589, 'entity': 'B-ORG', 'index': 6, 'start': 29, 'end': 31}]\n",
      "elem ea\n",
      "NER over initial question: \n",
      " what games were published by [START] ea [END] sports ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is a missionary that was buried in highgate cemetery\n",
      "ner_results [{'word': 'high', 'score': 0.5930889248847961, 'entity': 'B-LOC', 'index': 9, 'start': 39, 'end': 43}]\n",
      "elem high\n",
      "NER over initial question: \n",
      " Who is a missionary that was buried in highgate cemetery ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which city was robert s. langer born in\n",
      "ner_results [{'word': 'robe', 'score': 0.9190661907196045, 'entity': 'B-PER', 'index': 6, 'start': 15, 'end': 19}, {'word': '##rt', 'score': 0.8464214205741882, 'entity': 'I-PER', 'index': 7, 'start': 19, 'end': 21}, {'word': 's', 'score': 0.5457531213760376, 'entity': 'I-PER', 'index': 8, 'start': 22, 'end': 23}, {'word': 'langer', 'score': 0.6147791147232056, 'entity': 'I-PER', 'index': 10, 'start': 25, 'end': 31}]\n",
      "elem robe\n",
      "elem ##rt\n",
      "elem s\n",
      "elem langer\n",
      "NER over initial question: \n",
      " Which city was [START] robert [END] s. [START] langer [END] born in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what religion does swaran singh practice\n",
      "ner_results [{'word': 's', 'score': 0.5052897930145264, 'entity': 'B-MISC', 'index': 4, 'start': 19, 'end': 20}, {'word': '##wara', 'score': 0.3820399045944214, 'entity': 'B-MISC', 'index': 5, 'start': 20, 'end': 24}]\n",
      "elem s\n",
      "elem ##wara\n",
      "NER over initial question: \n",
      " what religion does swaran singh practice ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which label is the artist gil evans signed to\n",
      "ner_results [{'word': 'W', 'score': 0.472793847322464, 'entity': 'B-ORG', 'index': 1, 'start': 0, 'end': 1}, {'word': 'gi', 'score': 0.8063279390335083, 'entity': 'B-ORG', 'index': 8, 'start': 26, 'end': 28}]\n",
      "elem W\n",
      "elem gi\n",
      "NER over initial question: \n",
      " Which label is the artist gil evans signed to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which city was william grant stairs born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 46/400 [00:05<00:32, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'will', 'score': 0.41644400358200073, 'entity': 'B-PER', 'index': 4, 'start': 15, 'end': 19}]\n",
      "elem will\n",
      "NER over initial question: \n",
      " which city was william grant stairs born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who wrote city of women\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who wrote city of women ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was carolyn mitchell born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 48/400 [00:05<00:35,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'car', 'score': 0.895651638507843, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 13}, {'word': '##ol', 'score': 0.8396389484405518, 'entity': 'I-PER', 'index': 4, 'start': 13, 'end': 15}, {'word': '##yn', 'score': 0.9128303527832031, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 17}]\n",
      "elem car\n",
      "elem ##ol\n",
      "elem ##yn\n",
      "NER over initial question: \n",
      " where was [START] carolyn [END] mitchell born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in what language was earthlings filmed\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " in what language was earthlings filmed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who was born in greenville, south carolina?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 50/400 [00:05<00:31, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'green', 'score': 0.6822827458381653, 'entity': 'B-LOC', 'index': 5, 'start': 16, 'end': 21}, {'word': 'car', 'score': 0.5034179091453552, 'entity': 'B-LOC', 'index': 9, 'start': 34, 'end': 37}]\n",
      "elem green\n",
      "elem car\n",
      "NER over initial question: \n",
      " Who was born in greenville south carolina ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was the gender of the fictional character barry ohanlon\n",
      "ner_results [{'word': 'bar', 'score': 0.6024009585380554, 'entity': 'B-MISC', 'index': 9, 'start': 47, 'end': 50}, {'word': '##han', 'score': 0.3049720227718353, 'entity': 'B-MISC', 'index': 12, 'start': 54, 'end': 57}, {'word': '##lon', 'score': 0.29107603430747986, 'entity': 'I-MISC', 'index': 13, 'start': 57, 'end': 60}]\n",
      "elem bar\n",
      "elem ##han\n",
      "elem ##lon\n",
      "NER over initial question: \n",
      " what was the gender of the fictional character barry ohanlon ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what albums are by scissor sisters\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what albums are by scissor sisters ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " WHat's a basin country of lam ta klong river\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 55/400 [00:06<00:41,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'W', 'score': 0.9899585247039795, 'entity': 'B-LOC', 'index': 1, 'start': 0, 'end': 1}, {'word': '##H', 'score': 0.9522283673286438, 'entity': 'I-LOC', 'index': 2, 'start': 1, 'end': 2}, {'word': '##at', 'score': 0.9861955642700195, 'entity': 'I-LOC', 'index': 3, 'start': 2, 'end': 4}]\n",
      "elem W\n",
      "elem ##H\n",
      "elem ##at\n",
      "NER over initial question: \n",
      " WHat's a basin country of lam ta klong river ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is a publisher of the game final lap 3\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Who is a publisher of the game final lap 3 ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the gender of andreas leitner\n",
      "ner_results [{'word': 'andre', 'score': 0.3943864405155182, 'entity': 'B-PER', 'index': 6, 'start': 22, 'end': 27}]\n",
      "elem andre\n",
      "NER over initial question: \n",
      " What is the gender of andreas leitner ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did prospero alpini die\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " where did prospero alpini die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whose music is in the sacrifice?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 57/400 [00:06<00:36,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " whose music is in the sacrifice ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What type of film was the film the glorious adventure\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What type of film was the film the glorious adventure ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which language is the film germany, year zero in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 59/400 [00:07<01:02,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Which language is the film germany year zero in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position in football does john macdonald play\n",
      "ner_results [{'word': 'jo', 'score': 0.40434104204177856, 'entity': 'B-PER', 'index': 6, 'start': 31, 'end': 33}]\n",
      "elem jo\n",
      "NER over initial question: \n",
      " What position in football does john macdonald play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which kind of rock music appears on spanish dance troupe\n",
      "ner_results [{'word': 'span', 'score': 0.9920292496681213, 'entity': 'B-MISC', 'index': 8, 'start': 36, 'end': 40}, {'word': '##ish', 'score': 0.4141361713409424, 'entity': 'I-MISC', 'index': 9, 'start': 40, 'end': 43}]\n",
      "elem span\n",
      "elem ##ish\n",
      "NER over initial question: \n",
      " which kind of rock music appears on [START] spanish [END] dance troupe ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of subgenre of rock music is on trailblazer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 62/400 [00:08<01:16,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of subgenre of rock music is on trailblazer ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What musician plays glam punk\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What musician plays glam punk ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is the birthplace of mala\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 63/400 [00:08<01:13,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'mala', 'score': 0.4666701555252075, 'entity': 'B-PER', 'index': 7, 'start': 27, 'end': 31}]\n",
      "elem mala\n",
      "NER over initial question: \n",
      " where is the birthplace of [START] mala [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is spoken in newtonin moondram vidhi?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 64/400 [00:09<02:09,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'new', 'score': 0.9197072982788086, 'entity': 'B-MISC', 'index': 6, 'start': 27, 'end': 30}]\n",
      "elem new\n",
      "NER over initial question: \n",
      " what language is spoken in newtonin moondram vidhi ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does stephen mcgowan play \n",
      "ner_results [{'word': 'step', 'score': 0.517386257648468, 'entity': 'B-MISC', 'index': 4, 'start': 19, 'end': 23}]\n",
      "elem step\n",
      "NER over initial question: \n",
      " what position does stephen mcgowan play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of film is the fruitful vine?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 66/400 [00:09<01:39,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of film is the fruitful vine ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does footballer francis bossman play \n",
      "ner_results [{'word': 'franc', 'score': 0.8202551603317261, 'entity': 'B-MISC', 'index': 5, 'start': 30, 'end': 35}]\n",
      "elem franc\n",
      "NER over initial question: \n",
      " what position does footballer francis bossman play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what city is schandor kallosh from\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what city is schandor kallosh from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position does harizul izuan abdul rani play?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 73/400 [00:10<00:39,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What position does harizul izuan abdul rani play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is the microsoft train simulator developer\n",
      "ner_results [{'word': 'micro', 'score': 0.943723201751709, 'entity': 'B-MISC', 'index': 4, 'start': 11, 'end': 16}, {'word': '##so', 'score': 0.8019287586212158, 'entity': 'I-MISC', 'index': 5, 'start': 16, 'end': 18}, {'word': '##ft', 'score': 0.910367488861084, 'entity': 'I-MISC', 'index': 6, 'start': 18, 'end': 20}]\n",
      "elem micro\n",
      "elem ##so\n",
      "elem ##ft\n",
      "NER over initial question: \n",
      " who is the [START] microsoft [END] train simulator developer ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is spoken in the clown\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is spoken in the clown ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What language was along the rio grande filmed in?\n",
      "ner_results [{'word': 'rio', 'score': 0.828364908695221, 'entity': 'B-LOC', 'index': 6, 'start': 28, 'end': 31}, {'word': 'grande', 'score': 0.7522680163383484, 'entity': 'I-LOC', 'index': 7, 'start': 32, 'end': 38}]\n",
      "elem rio\n",
      "elem grande\n",
      "NER over initial question: \n",
      " What language was along the [START] rio grande [END] filmed in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the profession of khushwant singh?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the profession of khushwant singh ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is absalom willis robertson's place of birth\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is absalom willis robertson's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what company released fire emblem: the sacred stones?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 75/400 [00:12<01:52,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what company released fire emblem: the sacred stones ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What type of space object is 1870 glaukos\n",
      "ner_results [{'word': '1870', 'score': 0.6092402338981628, 'entity': 'B-LOC', 'index': 7, 'start': 29, 'end': 33}, {'word': 'g', 'score': 0.32340046763420105, 'entity': 'I-LOC', 'index': 8, 'start': 34, 'end': 35}, {'word': '##lau', 'score': 0.4440949857234955, 'entity': 'I-MISC', 'index': 9, 'start': 35, 'end': 38}, {'word': '##kos', 'score': 0.4502880871295929, 'entity': 'I-LOC', 'index': 10, 'start': 38, 'end': 41}]\n",
      "elem 1870\n",
      "elem g\n",
      "elem ##lau\n",
      "elem ##kos\n",
      "NER over initial question: \n",
      " What type of space object is [START] 1870 glaukos [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the gender of  nicole whippy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 79/400 [00:12<01:14,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'nic', 'score': 0.5533607602119446, 'entity': 'B-MISC', 'index': 6, 'start': 23, 'end': 26}]\n",
      "elem nic\n",
      "NER over initial question: \n",
      " what is the gender of  nicole whippy ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who entity was involved in the war of the second coalition\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who entity was involved in the war of the second coalition ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was the writer of the episode the jacket\n",
      "ner_results [{'word': 'the', 'score': 0.6908398866653442, 'entity': 'B-MISC', 'index': 8, 'start': 34, 'end': 37}]\n",
      "elem the\n",
      "NER over initial question: \n",
      " who was [START] the [END] writer of [START] the [END] episode [START] the [END] jacket ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country did the film girlfriend come from\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Which country did the film girlfriend come from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What country was carmen originally from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 81/400 [00:12<01:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What country was carmen originally from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of music is movin' wes?\n",
      "ner_results [{'word': 'mo', 'score': 0.8373691439628601, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 24}, {'word': '##vin', 'score': 0.6295785903930664, 'entity': 'I-MISC', 'index': 7, 'start': 24, 'end': 27}, {'word': \"'\", 'score': 0.7095722556114197, 'entity': 'I-MISC', 'index': 8, 'start': 27, 'end': 28}, {'word': 'we', 'score': 0.6806068420410156, 'entity': 'I-MISC', 'index': 9, 'start': 29, 'end': 31}]\n",
      "elem mo\n",
      "elem ##vin\n",
      "elem '\n",
      "elem we\n",
      "NER over initial question: \n",
      " what type of music is movin' wes ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was the title of jewel's christmas album\n",
      "ner_results [{'word': 'je', 'score': 0.4068068265914917, 'entity': 'B-PER', 'index': 6, 'start': 22, 'end': 24}]\n",
      "elem je\n",
      "NER over initial question: \n",
      " what was the title of jewel's christmas album ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does steve grilli play \n",
      "ner_results [{'word': 'st', 'score': 0.37435638904571533, 'entity': 'B-PER', 'index': 4, 'start': 19, 'end': 21}]\n",
      "elem st\n",
      "NER over initial question: \n",
      " what position does steve grilli play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a romance novel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 87/400 [00:13<00:39,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Name a romance novel ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which actress and signer was born in eugene, oregon\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which actress and signer was born in eugene oregon ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position in football does sanders commings play \n",
      "ner_results [{'word': 'football', 'score': 0.6246776580810547, 'entity': 'B-ORG', 'index': 4, 'start': 17, 'end': 25}]\n",
      "elem football\n",
      "NER over initial question: \n",
      " what position in [START] football [END] does sanders commings play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which genre is raavanan\n",
      "ner_results [{'word': 'ra', 'score': 0.8885257244110107, 'entity': 'B-MISC', 'index': 4, 'start': 15, 'end': 17}, {'word': '##avan', 'score': 0.5800934433937073, 'entity': 'I-MISC', 'index': 5, 'start': 17, 'end': 21}, {'word': '##an', 'score': 0.45828381180763245, 'entity': 'I-MISC', 'index': 6, 'start': 21, 'end': 23}]\n",
      "elem ra\n",
      "elem ##avan\n",
      "elem ##an\n",
      "NER over initial question: \n",
      " which genre is [START] raavanan [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language was spoken in the film  jigarwala\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 89/400 [00:13<00:34,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ji', 'score': 0.8459409475326538, 'entity': 'B-MISC', 'index': 8, 'start': 38, 'end': 40}, {'word': '##gar', 'score': 0.7563301920890808, 'entity': 'I-MISC', 'index': 9, 'start': 40, 'end': 43}, {'word': '##wala', 'score': 0.8504384160041809, 'entity': 'I-MISC', 'index': 10, 'start': 43, 'end': 47}]\n",
      "elem ji\n",
      "elem ##gar\n",
      "elem ##wala\n",
      "NER over initial question: \n",
      " what language was spoken in the film  [START] jigarwala [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what does ivar bjrnson play for an instrument\n",
      "ner_results [{'word': 'i', 'score': 0.9075009822845459, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 11}, {'word': '##var', 'score': 0.7580533027648926, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 14}, {'word': 'b', 'score': 0.7717334628105164, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 16}, {'word': '##j', 'score': 0.9065485000610352, 'entity': 'I-PER', 'index': 6, 'start': 16, 'end': 18}, {'word': '##rns', 'score': 0.9097579121589661, 'entity': 'I-PER', 'index': 7, 'start': 18, 'end': 21}, {'word': '##on', 'score': 0.955184280872345, 'entity': 'I-PER', 'index': 8, 'start': 21, 'end': 23}]\n",
      "elem i\n",
      "elem ##var\n",
      "elem b\n",
      "elem ##j\n",
      "elem ##rns\n",
      "elem ##on\n",
      "NER over initial question: \n",
      " what does [START] ivar bjrnson [END] play for an instrument ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who directed awesome; i fuckin' shot that!?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 93/400 [00:13<00:38,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'i', 'score': 0.3242684006690979, 'entity': 'B-MISC', 'index': 7, 'start': 22, 'end': 23}]\n",
      "elem i\n",
      "NER over initial question: \n",
      " Who directed awesome; [START] i [END] fuckin' shot that ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is dag from \n",
      "ner_results []\n",
      "NER over initial question: \n",
      " where is dag from  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who are military personnel involved in world war ii\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who are military personnel involved in world war ii ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position did chris anstey play in basketball?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 98/400 [00:14<00:23, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'basketball', 'score': 0.7797657251358032, 'entity': 'B-ORG', 'index': 11, 'start': 39, 'end': 49}]\n",
      "elem basketball\n",
      "NER over initial question: \n",
      " What position did chris anstey play in [START] basketball [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which artists are contracted to arista records\n",
      "ner_results [{'word': 'ari', 'score': 0.5459069609642029, 'entity': 'B-ORG', 'index': 6, 'start': 32, 'end': 35}, {'word': '##sta', 'score': 0.33506935834884644, 'entity': 'I-ORG', 'index': 7, 'start': 35, 'end': 38}]\n",
      "elem ari\n",
      "elem ##sta\n",
      "NER over initial question: \n",
      " which artists are contracted to [START] arista [END] records ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is someone that was born in blantyre\n",
      "ner_results [{'word': 'blant', 'score': 0.7995791435241699, 'entity': 'B-LOC', 'index': 8, 'start': 32, 'end': 37}, {'word': '##yre', 'score': 0.6050191521644592, 'entity': 'I-LOC', 'index': 9, 'start': 37, 'end': 40}]\n",
      "elem blant\n",
      "elem ##yre\n",
      "NER over initial question: \n",
      " who is someone that was born in [START] blantyre [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position did gintar petronyt play \n",
      "ner_results [{'word': 'gi', 'score': 0.8835962414741516, 'entity': 'B-MISC', 'index': 4, 'start': 18, 'end': 20}, {'word': '##ntar', 'score': 0.7654872536659241, 'entity': 'I-MISC', 'index': 5, 'start': 20, 'end': 24}, {'word': '##', 'score': 0.7843338251113892, 'entity': 'I-MISC', 'index': 6, 'start': 24, 'end': 25}]\n",
      "elem gi\n",
      "elem ##ntar\n",
      "elem ##\n",
      "NER over initial question: \n",
      " what position did [START] gintar [END] petronyt play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does anderson roberto da silva luiz play \n",
      "ner_results [{'word': 'anders', 'score': 0.4213170111179352, 'entity': 'B-PER', 'index': 4, 'start': 19, 'end': 25}]\n",
      "elem anders\n",
      "NER over initial question: \n",
      " what position does anderson roberto da silva luiz play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What fictional character was created by jim aparo?\n",
      "ner_results [{'word': 'jim', 'score': 0.690272867679596, 'entity': 'B-MISC', 'index': 7, 'start': 40, 'end': 43}, {'word': 'apa', 'score': 0.44630783796310425, 'entity': 'I-PER', 'index': 8, 'start': 44, 'end': 47}, {'word': '##ro', 'score': 0.32818514108657837, 'entity': 'I-PER', 'index': 9, 'start': 47, 'end': 49}]\n",
      "elem jim\n",
      "elem apa\n",
      "elem ##ro\n",
      "NER over initial question: \n",
      " What fictional character was created by [START] jim aparo [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language was spoken in the film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 103/400 [00:14<00:18, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what language was spoken in the film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What was the nationality of vincent riotta\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What was the nationality of vincent riotta ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country was the the bone snatcher filmed in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what country was the the bone snatcher filmed in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the name of an action film\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the name of an action film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is eddie brigati's nationality \n",
      "ner_results [{'word': 'ed', 'score': 0.9266459345817566, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': '##die', 'score': 0.7843695878982544, 'entity': 'I-PER', 'index': 4, 'start': 10, 'end': 13}, {'word': 'br', 'score': 0.8143344521522522, 'entity': 'I-PER', 'index': 5, 'start': 14, 'end': 16}, {'word': '##iga', 'score': 0.886716365814209, 'entity': 'I-PER', 'index': 6, 'start': 16, 'end': 19}, {'word': '##ti', 'score': 0.8939248323440552, 'entity': 'I-PER', 'index': 7, 'start': 19, 'end': 21}]\n",
      "elem ed\n",
      "elem ##die\n",
      "elem br\n",
      "elem ##iga\n",
      "elem ##ti\n",
      "NER over initial question: \n",
      " what is [START] eddie [END] brigati's nationality  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is mike boddicker position in baseball\n",
      "ner_results [{'word': 'baseball', 'score': 0.6972742676734924, 'entity': 'B-ORG', 'index': 10, 'start': 35, 'end': 43}]\n",
      "elem baseball\n",
      "NER over initial question: \n",
      " what is mike boddicker position in [START] baseball [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what style of music does gillespiana play \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 106/400 [00:14<00:15, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'gi', 'score': 0.6629898548126221, 'entity': 'B-MISC', 'index': 6, 'start': 25, 'end': 27}, {'word': '##pian', 'score': 0.2618119418621063, 'entity': 'I-ORG', 'index': 8, 'start': 31, 'end': 35}, {'word': '##a', 'score': 0.40976497530937195, 'entity': 'I-ORG', 'index': 9, 'start': 35, 'end': 36}]\n",
      "elem gi\n",
      "elem ##pian\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " what style of music does gillespiana play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where is paris theodore from\n",
      "ner_results [{'word': 'pari', 'score': 0.8638589978218079, 'entity': 'B-PER', 'index': 3, 'start': 9, 'end': 13}]\n",
      "elem pari\n",
      "NER over initial question: \n",
      " Where is paris theodore from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the name of a compilation album by chantal kreviazuk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 109/400 [00:15<00:28, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'kr', 'score': 0.8713497519493103, 'entity': 'B-ORG', 'index': 12, 'start': 51, 'end': 53}, {'word': '##evi', 'score': 0.4043131172657013, 'entity': 'B-ORG', 'index': 13, 'start': 53, 'end': 56}, {'word': '##azu', 'score': 0.7765238881111145, 'entity': 'I-ORG', 'index': 14, 'start': 56, 'end': 59}, {'word': '##k', 'score': 0.9081424474716187, 'entity': 'I-ORG', 'index': 15, 'start': 59, 'end': 60}]\n",
      "elem kr\n",
      "elem ##evi\n",
      "elem ##azu\n",
      "elem ##k\n",
      "NER over initial question: \n",
      " What is the name of a compilation album by chantal [START] kreviazuk [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was j. n. williamson birthed\n",
      "ner_results [{'word': 'j', 'score': 0.9358385801315308, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 11}, {'word': '##iam', 'score': 0.6982325911521912, 'entity': 'I-PER', 'index': 8, 'start': 20, 'end': 23}, {'word': '##son', 'score': 0.8048983216285706, 'entity': 'I-PER', 'index': 9, 'start': 23, 'end': 26}]\n",
      "elem j\n",
      "elem ##iam\n",
      "elem ##son\n",
      "NER over initial question: \n",
      " Where was j. n. williamson birthed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is jo bunting a professional at doing\n",
      "ner_results [{'word': 'what', 'score': 0.4775312840938568, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 4}]\n",
      "elem what\n",
      "NER over initial question: \n",
      " [START] what [END] is jo bunting a professional at doing ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is blind date in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 111/400 [00:15<00:28, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is blind date in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is mario tosi from \n",
      "ner_results [{'word': 'mari', 'score': 0.4340492784976959, 'entity': 'B-MISC', 'index': 3, 'start': 9, 'end': 13}]\n",
      "elem mari\n",
      "NER over initial question: \n",
      " where is mario tosi from  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where does shiek mahmud-bey claim nationality from?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 115/400 [00:15<00:34,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Where does shiek mahmud-bey claim nationality from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was piotr grabowski born\n",
      "ner_results [{'word': 'pi', 'score': 0.7640106678009033, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}, {'word': 'gra', 'score': 0.5278941988945007, 'entity': 'B-PER', 'index': 6, 'start': 16, 'end': 19}, {'word': '##bow', 'score': 0.7315147519111633, 'entity': 'I-PER', 'index': 7, 'start': 19, 'end': 22}, {'word': '##ski', 'score': 0.8502122759819031, 'entity': 'I-PER', 'index': 8, 'start': 22, 'end': 25}]\n",
      "elem pi\n",
      "elem gra\n",
      "elem ##bow\n",
      "elem ##ski\n",
      "NER over initial question: \n",
      " Where was piotr [START] grabowski [END] born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what are the names of death metal albums\n",
      "ner_results [{'word': 'death', 'score': 0.6406100988388062, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 27}]\n",
      "elem death\n",
      "NER over initial question: \n",
      " what are the names of [START] death [END] metal albums ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the place of birth of bill atkinson?\n",
      "ner_results [{'word': 'bill', 'score': 0.39526981115341187, 'entity': 'B-PER', 'index': 8, 'start': 30, 'end': 34}, {'word': 'at', 'score': 0.33358463644981384, 'entity': 'I-PER', 'index': 9, 'start': 35, 'end': 37}, {'word': '##kins', 'score': 0.36749547719955444, 'entity': 'I-PER', 'index': 10, 'start': 37, 'end': 41}, {'word': '##on', 'score': 0.5139395594596863, 'entity': 'I-PER', 'index': 11, 'start': 41, 'end': 43}]\n",
      "elem bill\n",
      "elem at\n",
      "elem ##kins\n",
      "elem ##on\n",
      "NER over initial question: \n",
      " What is the place of birth of [START] bill atkinson [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the place of death of carmen scarpitta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 119/400 [00:16<00:27, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the place of death of carmen scarpitta ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was the film bitter rice located\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " where was the film bitter rice located ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who authored the book islam and the west?\n",
      "ner_results [{'word': 'islam', 'score': 0.9228566288948059, 'entity': 'B-MISC', 'index': 5, 'start': 22, 'end': 27}]\n",
      "elem islam\n",
      "NER over initial question: \n",
      " Who authored the book [START] islam [END] and the west ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was friedrich bhm born?\n",
      "ner_results [{'word': 'b', 'score': 0.6508483290672302, 'entity': 'I-PER', 'index': 6, 'start': 20, 'end': 21}, {'word': '##hm', 'score': 0.9660583734512329, 'entity': 'I-PER', 'index': 7, 'start': 21, 'end': 24}]\n",
      "elem b\n",
      "elem ##hm\n",
      "NER over initial question: \n",
      " where was friedrich [START] bhm [END] born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what conflict did  john norwood participate in\n",
      "ner_results [{'word': 'jo', 'score': 0.34629130363464355, 'entity': 'B-MISC', 'index': 4, 'start': 19, 'end': 21}]\n",
      "elem jo\n",
      "NER over initial question: \n",
      " what conflict did  john norwood participate in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what mode do you play monster madness: battle for suburbia in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 124/400 [00:16<00:28,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what mode do you play monster madness: battle for suburbia in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is franz von soxhlet's gender\n",
      "ner_results [{'word': 'fra', 'score': 0.8011653423309326, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 11}]\n",
      "elem fra\n",
      "NER over initial question: \n",
      " What is franz von soxhlet's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country is the almaty province located in\n",
      "ner_results [{'word': 'alma', 'score': 0.6685354113578796, 'entity': 'B-LOC', 'index': 7, 'start': 21, 'end': 25}]\n",
      "elem alma\n",
      "NER over initial question: \n",
      " Which country is the almaty province located in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is ethnically african american\n",
      "ner_results [{'word': 'af', 'score': 0.8564050197601318, 'entity': 'B-MISC', 'index': 5, 'start': 18, 'end': 20}, {'word': '##rica', 'score': 0.6118485927581787, 'entity': 'B-MISC', 'index': 6, 'start': 20, 'end': 24}]\n",
      "elem af\n",
      "elem ##rica\n",
      "NER over initial question: \n",
      " who is ethnically african american ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is a structure designed by owen jones?\n",
      "ner_results [{'word': 'o', 'score': 0.6708939671516418, 'entity': 'B-MISC', 'index': 7, 'start': 32, 'end': 33}, {'word': '##wen', 'score': 0.4031206965446472, 'entity': 'B-MISC', 'index': 8, 'start': 33, 'end': 36}]\n",
      "elem o\n",
      "elem ##wen\n",
      "NER over initial question: \n",
      " What is a structure designed by [START] owen [END] jones ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " mikhail glinka is known for what kind of music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 129/400 [00:17<00:20, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'mi', 'score': 0.6536584496498108, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 2}, {'word': '##kha', 'score': 0.3387717604637146, 'entity': 'I-ORG', 'index': 2, 'start': 2, 'end': 5}, {'word': '##il', 'score': 0.31817272305488586, 'entity': 'I-ORG', 'index': 3, 'start': 5, 'end': 7}]\n",
      "elem mi\n",
      "elem ##kha\n",
      "elem ##il\n",
      "NER over initial question: \n",
      " [START] mikhail [END] glinka is known for what kind of music ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is trigg county named after?\n",
      "ner_results [{'word': 'tri', 'score': 0.8398342728614807, 'entity': 'B-LOC', 'index': 3, 'start': 7, 'end': 10}]\n",
      "elem tri\n",
      "NER over initial question: \n",
      " who is trigg county named after ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is son of meg ryan\n",
      "ner_results [{'word': 'meg', 'score': 0.41147541999816895, 'entity': 'B-MISC', 'index': 5, 'start': 14, 'end': 17}]\n",
      "elem meg\n",
      "NER over initial question: \n",
      " who is son of [START] meg [END] ryan ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of film is sira` fi al-wadi?\n",
      "ner_results [{'word': 'sir', 'score': 0.8556435108184814, 'entity': 'B-MISC', 'index': 6, 'start': 21, 'end': 24}, {'word': '##a', 'score': 0.7863214015960693, 'entity': 'I-MISC', 'index': 7, 'start': 24, 'end': 25}, {'word': '`', 'score': 0.7431710958480835, 'entity': 'I-MISC', 'index': 8, 'start': 25, 'end': 26}, {'word': 'fi', 'score': 0.6976622939109802, 'entity': 'I-MISC', 'index': 9, 'start': 27, 'end': 29}, {'word': 'al', 'score': 0.6086456775665283, 'entity': 'I-MISC', 'index': 10, 'start': 30, 'end': 32}, {'word': 'wadi', 'score': 0.7310431599617004, 'entity': 'I-MISC', 'index': 12, 'start': 33, 'end': 37}]\n",
      "elem sir\n",
      "elem ##a\n",
      "elem `\n",
      "elem fi\n",
      "elem al\n",
      "elem wadi\n",
      "NER over initial question: \n",
      " what type of film is sira` [START] fi [END] al-wadi ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did kathy staff spend her last day?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 135/400 [00:17<00:14, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'kat', 'score': 0.4736872911453247, 'entity': 'B-ORG', 'index': 3, 'start': 10, 'end': 13}, {'word': '##hy', 'score': 0.37183406949043274, 'entity': 'I-ORG', 'index': 4, 'start': 13, 'end': 15}]\n",
      "elem kat\n",
      "elem ##hy\n",
      "NER over initial question: \n",
      " Where did [START] kathy [END] staff spend her last day ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what city was jack matthews born in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what city was jack matthews born in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what religion does fauziah latiff practice\n",
      "ner_results [{'word': 'fa', 'score': 0.40971654653549194, 'entity': 'B-ORG', 'index': 4, 'start': 19, 'end': 21}]\n",
      "elem fa\n",
      "NER over initial question: \n",
      " what religion does fauziah latiff practice ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who wrote the story used in the film resurrection\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Who wrote the story used in the film resurrection ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country is hiram n. breed from\n",
      "ner_results [{'word': 'hir', 'score': 0.6944187879562378, 'entity': 'B-LOC', 'index': 6, 'start': 17, 'end': 20}]\n",
      "elem hir\n",
      "NER over initial question: \n",
      " Which country is hiram n. breed from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is cb dollaway's gender\n",
      "ner_results [{'word': 'c', 'score': 0.3478547930717468, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 9}]\n",
      "elem c\n",
      "NER over initial question: \n",
      " what is cb dollaway's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who was born in khartoum?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 141/400 [00:17<00:12, 21.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'k', 'score': 0.9960538744926453, 'entity': 'B-LOC', 'index': 5, 'start': 16, 'end': 17}, {'word': '##hart', 'score': 0.7186481356620789, 'entity': 'I-LOC', 'index': 6, 'start': 17, 'end': 21}, {'word': '##oum', 'score': 0.9956541657447815, 'entity': 'I-LOC', 'index': 7, 'start': 21, 'end': 24}]\n",
      "elem k\n",
      "elem ##hart\n",
      "elem ##oum\n",
      "NER over initial question: \n",
      " Who was born in [START] khartoum [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is the child of elen (saint)?\n",
      "ner_results [{'word': 'ele', 'score': 0.6270607113838196, 'entity': 'B-PER', 'index': 6, 'start': 20, 'end': 23}, {'word': '##n', 'score': 0.39840567111968994, 'entity': 'B-PER', 'index': 7, 'start': 23, 'end': 24}]\n",
      "elem ele\n",
      "elem ##n\n",
      "NER over initial question: \n",
      " Who is the child of [START] elen [END] (saint) ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what battle did john paul jones fight in\n",
      "ner_results [{'word': 'jo', 'score': 0.5247562527656555, 'entity': 'B-PER', 'index': 4, 'start': 16, 'end': 18}, {'word': 'pau', 'score': 0.5004957318305969, 'entity': 'I-PER', 'index': 6, 'start': 21, 'end': 24}]\n",
      "elem jo\n",
      "elem pau\n",
      "NER over initial question: \n",
      " what battle did john paul jones fight in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country was son of the shark filmed?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Which country was son of the shark filmed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was aileen manning given birth\n",
      "ner_results [{'word': 'aile', 'score': 0.8900325298309326, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 14}, {'word': '##en', 'score': 0.852545976638794, 'entity': 'I-PER', 'index': 4, 'start': 14, 'end': 16}, {'word': 'mann', 'score': 0.63608318567276, 'entity': 'I-PER', 'index': 5, 'start': 17, 'end': 21}, {'word': '##ing', 'score': 0.7195519208908081, 'entity': 'I-PER', 'index': 6, 'start': 21, 'end': 24}]\n",
      "elem aile\n",
      "elem ##en\n",
      "elem mann\n",
      "elem ##ing\n",
      "NER over initial question: \n",
      " where was [START] aileen manning [END] given birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country is bill fisk from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 144/400 [00:17<00:14, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what country is bill fisk from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the name of a politician\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the name of a politician ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what city and state did robert e. rodes die in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what city and state did robert e. rodes die in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of film is pray for japan?\n",
      "ner_results [{'word': 'jap', 'score': 0.9857989549636841, 'entity': 'B-MISC', 'index': 9, 'start': 30, 'end': 33}, {'word': '##an', 'score': 0.434604674577713, 'entity': 'I-MISC', 'index': 10, 'start': 33, 'end': 35}]\n",
      "elem jap\n",
      "elem ##an\n",
      "NER over initial question: \n",
      " What kind of film is pray for [START] japan [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in which country was dick barton strikes back filmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 150/400 [00:17<00:11, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " in which country was dick barton strikes back filmed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what city was baar sabuncu born in\n",
      "ner_results [{'word': 'baa', 'score': 0.6934021711349487, 'entity': 'B-LOC', 'index': 4, 'start': 14, 'end': 18}, {'word': '##bun', 'score': 0.4658283293247223, 'entity': 'I-LOC', 'index': 7, 'start': 22, 'end': 25}, {'word': '##cu', 'score': 0.4121622145175934, 'entity': 'I-LOC', 'index': 8, 'start': 25, 'end': 27}]\n",
      "elem baa\n",
      "elem ##bun\n",
      "elem ##cu\n",
      "NER over initial question: \n",
      " what city was baar sabuncu born in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did antnio granjo die\n",
      "ner_results [{'word': 'ant', 'score': 0.600277304649353, 'entity': 'B-MISC', 'index': 3, 'start': 10, 'end': 13}, {'word': '##n', 'score': 0.3521748483181, 'entity': 'I-MISC', 'index': 4, 'start': 13, 'end': 15}]\n",
      "elem ant\n",
      "elem ##n\n",
      "NER over initial question: \n",
      " where did antnio granjo die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which major city was steve drake born in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which major city was steve drake born in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of music is on the album the new black\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what type of music is on the album the new black ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country gives gabriela bustelo her nationality\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which country gives gabriela bustelo her nationality ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is stephen rebello's country of origin?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 153/400 [00:18<00:10, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'step', 'score': 0.35130321979522705, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 12}]\n",
      "elem step\n",
      "NER over initial question: \n",
      " what is stephen rebello's country of origin ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is a male jewish person\n",
      "ner_results [{'word': 'je', 'score': 0.9938233494758606, 'entity': 'B-MISC', 'index': 5, 'start': 14, 'end': 16}, {'word': '##wis', 'score': 0.8367620706558228, 'entity': 'B-MISC', 'index': 6, 'start': 16, 'end': 19}, {'word': '##h', 'score': 0.8430870175361633, 'entity': 'B-MISC', 'index': 7, 'start': 19, 'end': 20}]\n",
      "elem je\n",
      "elem ##wis\n",
      "elem ##h\n",
      "NER over initial question: \n",
      " who is a male [START] jewish [END] person ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the birth place of hannah murray?\n",
      "ner_results [{'word': 'hann', 'score': 0.5198717713356018, 'entity': 'B-PER', 'index': 7, 'start': 27, 'end': 31}]\n",
      "elem hann\n",
      "NER over initial question: \n",
      " What is the birth place of hannah murray ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which language is the film thelma in\n",
      "ner_results [{'word': 'W', 'score': 0.9268766045570374, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 1}, {'word': '##hic', 'score': 0.9551447629928589, 'entity': 'I-MISC', 'index': 2, 'start': 1, 'end': 4}, {'word': '##h', 'score': 0.9797670841217041, 'entity': 'I-MISC', 'index': 3, 'start': 4, 'end': 5}, {'word': 'language', 'score': 0.9775635600090027, 'entity': 'I-MISC', 'index': 4, 'start': 6, 'end': 14}]\n",
      "elem W\n",
      "elem ##hic\n",
      "elem ##h\n",
      "elem language\n",
      "NER over initial question: \n",
      " [START] Which language [END] is the film thelma in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the name of an album that is considered to be ambient music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 158/400 [00:18<00:18, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the name of an album that is considered to be ambient music ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was craig gillespie born?\n",
      "ner_results [{'word': 'c', 'score': 0.6702593564987183, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 11}, {'word': '##rai', 'score': 0.49424901604652405, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 14}, {'word': '##g', 'score': 0.6217032670974731, 'entity': 'I-PER', 'index': 5, 'start': 14, 'end': 15}]\n",
      "elem c\n",
      "elem ##rai\n",
      "elem ##g\n",
      "NER over initial question: \n",
      " where was [START] craig [END] gillespie born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " state mahamadou diarra 's gender\n",
      "ner_results [{'word': 'maha', 'score': 0.4405977129936218, 'entity': 'B-MISC', 'index': 2, 'start': 6, 'end': 10}]\n",
      "elem maha\n",
      "NER over initial question: \n",
      " state mahamadou diarra 's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " This city, with a population of 1,881 as of 2010 is located in raleigh county, west virginia.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 160/400 [00:19<00:42,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ra', 'score': 0.975440502166748, 'entity': 'B-LOC', 'index': 17, 'start': 63, 'end': 65}, {'word': '##leigh', 'score': 0.8831830620765686, 'entity': 'I-LOC', 'index': 18, 'start': 65, 'end': 70}, {'word': 'vir', 'score': 0.9074180722236633, 'entity': 'B-LOC', 'index': 22, 'start': 84, 'end': 87}, {'word': '##gini', 'score': 0.58225017786026, 'entity': 'I-LOC', 'index': 23, 'start': 87, 'end': 91}, {'word': '##a', 'score': 0.7590346336364746, 'entity': 'I-LOC', 'index': 24, 'start': 91, 'end': 92}]\n",
      "elem ra\n",
      "elem ##leigh\n",
      "elem vir\n",
      "elem ##gini\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " This city with a population of 1881 as of 2010 is located in [START] raleigh [END] county west virginia. ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does osama elsamni play \n",
      "ner_results [{'word': 'osam', 'score': 0.7389712333679199, 'entity': 'B-MISC', 'index': 4, 'start': 19, 'end': 23}, {'word': '##a', 'score': 0.462712824344635, 'entity': 'I-MISC', 'index': 5, 'start': 23, 'end': 24}]\n",
      "elem osam\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " what position does [START] osama [END] elsamni play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is colettetrudeau's genre\n",
      "ner_results [{'word': 'col', 'score': 0.4717745780944824, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 11}, {'word': '##tru', 'score': 0.3861615061759949, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 18}, {'word': '##dea', 'score': 0.5414507389068604, 'entity': 'I-PER', 'index': 6, 'start': 18, 'end': 21}, {'word': '##u', 'score': 0.7652961611747742, 'entity': 'I-PER', 'index': 7, 'start': 21, 'end': 22}]\n",
      "elem col\n",
      "elem ##tru\n",
      "elem ##dea\n",
      "elem ##u\n",
      "NER over initial question: \n",
      " what is colettetrudeau's genre ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did kwan shan die?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 162/400 [00:19<00:36,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'kwa', 'score': 0.5236412882804871, 'entity': 'B-MISC', 'index': 3, 'start': 10, 'end': 13}, {'word': '##n', 'score': 0.31476840376853943, 'entity': 'I-MISC', 'index': 4, 'start': 13, 'end': 14}]\n",
      "elem kwa\n",
      "elem ##n\n",
      "NER over initial question: \n",
      " where did [START] kwan [END] shan die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is michael noble, baron glenkinglas's profession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 167/400 [00:21<00:45,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'mich', 'score': 0.6576108932495117, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 12}, {'word': '##king', 'score': 0.45406436920166016, 'entity': 'I-PER', 'index': 10, 'start': 33, 'end': 37}]\n",
      "elem mich\n",
      "elem ##king\n",
      "NER over initial question: \n",
      " what is michael noble baron glenkinglas's profession ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which town is located in kennebec county Maine \n",
      "ner_results [{'word': 'Maine', 'score': 0.9994755983352661, 'entity': 'B-LOC', 'index': 10, 'start': 41, 'end': 46}]\n",
      "elem Maine\n",
      "NER over initial question: \n",
      " which town is located in kennebec county [START] Maine [END]  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name someone who was born in mytilene\n",
      "ner_results [{'word': 'my', 'score': 0.9665231704711914, 'entity': 'B-MISC', 'index': 7, 'start': 29, 'end': 31}, {'word': '##tile', 'score': 0.7852271199226379, 'entity': 'B-MISC', 'index': 8, 'start': 31, 'end': 35}, {'word': '##ne', 'score': 0.6941872239112854, 'entity': 'B-MISC', 'index': 9, 'start': 35, 'end': 37}]\n",
      "elem my\n",
      "elem ##tile\n",
      "elem ##ne\n",
      "NER over initial question: \n",
      " Name someone who was born in [START] mytilene [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what sex does decimus burton identify with\n",
      "ner_results [{'word': 'de', 'score': 0.6203651428222656, 'entity': 'B-PER', 'index': 4, 'start': 14, 'end': 16}, {'word': '##us', 'score': 0.42865124344825745, 'entity': 'I-PER', 'index': 6, 'start': 19, 'end': 21}]\n",
      "elem de\n",
      "elem ##us\n",
      "NER over initial question: \n",
      " what sex does decimus burton identify with ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What British writer/editor was born in london?\n",
      "ner_results [{'word': 'British', 'score': 0.9887063503265381, 'entity': 'B-MISC', 'index': 2, 'start': 5, 'end': 12}]\n",
      "elem British\n",
      "NER over initial question: \n",
      " What [START] British [END] writer/editor was born in london ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in what language was number 17 filmed in \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 172/400 [00:21<00:27,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " in what language was number 17 filmed in  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the category of the object 9764 morgenstern?\n",
      "ner_results [{'word': '976', 'score': 0.49285468459129333, 'entity': 'B-LOC', 'index': 8, 'start': 35, 'end': 38}]\n",
      "elem 976\n",
      "NER over initial question: \n",
      " what is the category of the object 9764 morgenstern ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is the great indian butterfly in\n",
      "ner_results [{'word': 'india', 'score': 0.8235267996788025, 'entity': 'B-MISC', 'index': 6, 'start': 27, 'end': 32}]\n",
      "elem india\n",
      "NER over initial question: \n",
      " what language is the great indian butterfly in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which nation is madhur jaffrey from?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Which nation is madhur jaffrey from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What made the music for the jacket\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What made the music for the jacket ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which position does craig cacek play?\n",
      "ner_results [{'word': 'c', 'score': 0.33732956647872925, 'entity': 'B-MISC', 'index': 6, 'start': 20, 'end': 21}]\n",
      "elem c\n",
      "NER over initial question: \n",
      " Which position does craig cacek play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what label is grandpuba signed under?\n",
      "ner_results [{'word': 'grand', 'score': 0.8136820197105408, 'entity': 'B-ORG', 'index': 4, 'start': 14, 'end': 19}, {'word': '##pu', 'score': 0.8230289816856384, 'entity': 'I-ORG', 'index': 5, 'start': 19, 'end': 21}, {'word': '##ba', 'score': 0.8730204701423645, 'entity': 'I-ORG', 'index': 6, 'start': 21, 'end': 23}]\n",
      "elem grand\n",
      "elem ##pu\n",
      "elem ##ba\n",
      "NER over initial question: \n",
      " what label is [START] grandpuba [END] signed under ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who directed music and lyrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 175/400 [00:21<00:25,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " who directed music and lyrics ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of film is what time is it there?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what type of film is what time is it there ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country is hello! hum lallan bol rahe hain from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 177/400 [00:22<00:34,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what country is hello hum lallan bol rahe hain from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which language is spoken in the film trpico de sangre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 181/400 [00:23<00:32,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'tr', 'score': 0.9188259840011597, 'entity': 'B-MISC', 'index': 10, 'start': 37, 'end': 39}, {'word': '##', 'score': 0.9563632011413574, 'entity': 'I-MISC', 'index': 11, 'start': 39, 'end': 40}, {'word': '##pico', 'score': 0.9755746126174927, 'entity': 'I-MISC', 'index': 12, 'start': 40, 'end': 44}, {'word': 'de', 'score': 0.9914866089820862, 'entity': 'I-MISC', 'index': 13, 'start': 45, 'end': 47}, {'word': 'sangre', 'score': 0.9897558689117432, 'entity': 'I-MISC', 'index': 14, 'start': 48, 'end': 54}]\n",
      "elem tr\n",
      "elem ##\n",
      "elem ##pico\n",
      "elem de\n",
      "elem sangre\n",
      "NER over initial question: \n",
      " Which language is spoken in the film [START] trpico de sangre [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country is the film bittersweet memories from\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Which country is the film bittersweet memories from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is chong-nee's profession?\n",
      "ner_results [{'word': 'cho', 'score': 0.5529198050498962, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 11}, {'word': '##ng', 'score': 0.2900243401527405, 'entity': 'B-PER', 'index': 4, 'start': 11, 'end': 13}, {'word': '-', 'score': 0.4802631735801697, 'entity': 'I-PER', 'index': 5, 'start': 13, 'end': 14}, {'word': 'ne', 'score': 0.545316755771637, 'entity': 'I-PER', 'index': 6, 'start': 14, 'end': 16}, {'word': '##e', 'score': 0.4205951392650604, 'entity': 'I-PER', 'index': 7, 'start': 16, 'end': 17}]\n",
      "elem cho\n",
      "elem ##ng\n",
      "elem -\n",
      "elem ne\n",
      "elem ##e\n",
      "NER over initial question: \n",
      " What is chong-nee's profession ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what books have algis budrys written?\n",
      "ner_results [{'word': 'al', 'score': 0.5158088803291321, 'entity': 'B-MISC', 'index': 4, 'start': 16, 'end': 18}]\n",
      "elem al\n",
      "NER over initial question: \n",
      " what books have algis budrys written ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who wrote un chien andalou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 183/400 [00:23<00:30,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'un', 'score': 0.9989933371543884, 'entity': 'B-MISC', 'index': 3, 'start': 10, 'end': 12}, {'word': 'chien', 'score': 0.9980441331863403, 'entity': 'I-MISC', 'index': 4, 'start': 13, 'end': 18}, {'word': 'anda', 'score': 0.9931212663650513, 'entity': 'I-MISC', 'index': 5, 'start': 19, 'end': 23}, {'word': '##lou', 'score': 0.9912106394767761, 'entity': 'I-MISC', 'index': 6, 'start': 23, 'end': 26}]\n",
      "elem un\n",
      "elem chien\n",
      "elem anda\n",
      "elem ##lou\n",
      "NER over initial question: \n",
      " who wrote [START] un chien andalou [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was oded fehr born \n",
      "ner_results [{'word': 'od', 'score': 0.5021912455558777, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}]\n",
      "elem od\n",
      "NER over initial question: \n",
      " where was oded fehr born  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the position that  mike twellman plays\n",
      "ner_results [{'word': 'mi', 'score': 0.42665189504623413, 'entity': 'B-MISC', 'index': 6, 'start': 27, 'end': 29}]\n",
      "elem mi\n",
      "NER over initial question: \n",
      " what is the position that  mike twellman plays ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was jacques mehler's place of birth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 185/400 [00:23<00:25,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ja', 'score': 0.9957315921783447, 'entity': 'B-PER', 'index': 3, 'start': 9, 'end': 11}, {'word': '##cque', 'score': 0.6807682514190674, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 15}, {'word': '##s', 'score': 0.985944926738739, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 16}, {'word': 'me', 'score': 0.9927644729614258, 'entity': 'I-PER', 'index': 6, 'start': 17, 'end': 19}, {'word': '##hler', 'score': 0.9771450757980347, 'entity': 'I-PER', 'index': 7, 'start': 19, 'end': 23}]\n",
      "elem ja\n",
      "elem ##cque\n",
      "elem ##s\n",
      "elem me\n",
      "elem ##hler\n",
      "NER over initial question: \n",
      " what was [START] jacques [END] mehler's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who are the parents of leopold de rothschild\n",
      "ner_results [{'word': 'leo', 'score': 0.5521742105484009, 'entity': 'B-MISC', 'index': 6, 'start': 23, 'end': 26}]\n",
      "elem leo\n",
      "NER over initial question: \n",
      " who are the parents of leopold de rothschild ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which genre is whos afraid of virginia woolf? under\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 187/400 [00:24<00:38,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Which genre is whos afraid of virginia woolf under ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a military personnel involved in world war ii\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Name a military personnel involved in world war ii ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who directed enemy mine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 192/400 [00:24<00:33,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " who directed enemy mine ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats the name of a female comic book character\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " whats the name of a female comic book character ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country is lawrence lipton originally from\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what country is lawrence lipton originally from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position does footballer jamie ness play?\n",
      "ner_results [{'word': 'jam', 'score': 0.8241810202598572, 'entity': 'B-PER', 'index': 5, 'start': 30, 'end': 33}, {'word': '##ie', 'score': 0.5677288174629211, 'entity': 'I-PER', 'index': 6, 'start': 33, 'end': 35}]\n",
      "elem jam\n",
      "elem ##ie\n",
      "NER over initial question: \n",
      " What position does footballer [START] jamie [END] ness play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " how can the game ridge racer 6 be played\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " how can the game ridge racer 6 be played ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What artist produced the album monster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 194/400 [00:25<00:27,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What artist produced the album monster ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What gaming company published pac-man world 3\n",
      "ner_results [{'word': 'pa', 'score': 0.931614875793457, 'entity': 'B-MISC', 'index': 6, 'start': 30, 'end': 32}, {'word': '##c', 'score': 0.7706493735313416, 'entity': 'I-MISC', 'index': 7, 'start': 32, 'end': 33}, {'word': '-', 'score': 0.7291232943534851, 'entity': 'I-MISC', 'index': 8, 'start': 33, 'end': 34}, {'word': 'man', 'score': 0.7458305358886719, 'entity': 'I-MISC', 'index': 9, 'start': 34, 'end': 37}]\n",
      "elem pa\n",
      "elem ##c\n",
      "elem -\n",
      "elem man\n",
      "NER over initial question: \n",
      " What gaming company published pac-man world 3 ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which county is saline located in?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which county is saline located in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who directed aaina?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 197/400 [00:25<00:24,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'aa', 'score': 0.44476082921028137, 'entity': 'B-PER', 'index': 3, 'start': 13, 'end': 15}, {'word': '##ina', 'score': 0.508774995803833, 'entity': 'I-MISC', 'index': 4, 'start': 15, 'end': 18}]\n",
      "elem aa\n",
      "elem ##ina\n",
      "NER over initial question: \n",
      " who directed [START] aaina [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which asian nation is lanao del norte an administrative division of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 199/400 [00:26<00:38,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'asi', 'score': 0.8876060247421265, 'entity': 'B-MISC', 'index': 2, 'start': 6, 'end': 9}]\n",
      "elem asi\n",
      "NER over initial question: \n",
      " which asian nation is lanao del norte an administrative division of ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what continent is robert helpmann from\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what continent is robert helpmann from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is the label for  mucc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 204/400 [00:26<00:22,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'mu', 'score': 0.9041418433189392, 'entity': 'B-ORG', 'index': 6, 'start': 22, 'end': 24}, {'word': '##cc', 'score': 0.8165481686592102, 'entity': 'I-ORG', 'index': 7, 'start': 24, 'end': 26}]\n",
      "elem mu\n",
      "elem ##cc\n",
      "NER over initial question: \n",
      " who is the label for  [START] mucc [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who composed music for nothing like the holidays?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who composed music for nothing like the holidays ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " is abraham cohen de herrera male or female\n",
      "ner_results [{'word': 'ab', 'score': 0.47976547479629517, 'entity': 'B-MISC', 'index': 2, 'start': 3, 'end': 5}]\n",
      "elem ab\n",
      "NER over initial question: \n",
      " is abraham cohen de herrera male or female ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which label signed b-projekt?\n",
      "ner_results [{'word': 'b', 'score': 0.6669031977653503, 'entity': 'B-ORG', 'index': 6, 'start': 19, 'end': 20}]\n",
      "elem b\n",
      "NER over initial question: \n",
      " Which label signed b-projekt ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is spoken in candleshoe\n",
      "ner_results [{'word': 'cand', 'score': 0.5395224094390869, 'entity': 'B-MISC', 'index': 6, 'start': 27, 'end': 31}]\n",
      "elem cand\n",
      "NER over initial question: \n",
      " what language is spoken in candleshoe ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is a rock music album by Australian singer John Farnham\n",
      "ner_results [{'word': 'Australian', 'score': 0.9552663564682007, 'entity': 'B-MISC', 'index': 8, 'start': 30, 'end': 40}, {'word': 'John', 'score': 0.9998754262924194, 'entity': 'B-PER', 'index': 10, 'start': 48, 'end': 52}, {'word': 'Far', 'score': 0.9999478459358215, 'entity': 'I-PER', 'index': 11, 'start': 53, 'end': 56}, {'word': '##nham', 'score': 0.9999064207077026, 'entity': 'I-PER', 'index': 12, 'start': 56, 'end': 60}]\n",
      "elem Australian\n",
      "elem John\n",
      "elem Far\n",
      "elem ##nham\n",
      "NER over initial question: \n",
      " what is a rock music album by [START] Australian [END] singer [START] John Farnham [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what sex is rafael carrera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 210/400 [00:26<00:13, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what sex is rafael carrera ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who wrote the music for the film silambattam?\n",
      "ner_results [{'word': 'sila', 'score': 0.9874122142791748, 'entity': 'B-MISC', 'index': 8, 'start': 33, 'end': 37}, {'word': '##mbat', 'score': 0.9857508540153503, 'entity': 'I-MISC', 'index': 9, 'start': 37, 'end': 41}, {'word': '##tam', 'score': 0.9937795996665955, 'entity': 'I-MISC', 'index': 10, 'start': 41, 'end': 44}]\n",
      "elem sila\n",
      "elem ##mbat\n",
      "elem ##tam\n",
      "NER over initial question: \n",
      " Who wrote the music for the film [START] silambattam [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of music is meteora (album)\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of music is meteora (album) ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the gender of monique leyrac?\n",
      "ner_results [{'word': 'mon', 'score': 0.5026077032089233, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 25}, {'word': '##ique', 'score': 0.32117384672164917, 'entity': 'I-ORG', 'index': 7, 'start': 25, 'end': 29}, {'word': '##rac', 'score': 0.35303664207458496, 'entity': 'I-ORG', 'index': 9, 'start': 33, 'end': 36}]\n",
      "elem mon\n",
      "elem ##ique\n",
      "elem ##rac\n",
      "NER over initial question: \n",
      " what is the gender of monique leyrac ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does hassan shirmohammadi play\n",
      "ner_results [{'word': 'has', 'score': 0.36952877044677734, 'entity': 'B-MISC', 'index': 4, 'start': 19, 'end': 22}]\n",
      "elem has\n",
      "NER over initial question: \n",
      " what position does hassan shirmohammadi play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what film is under tristar pictures?\n",
      "ner_results [{'word': 'tri', 'score': 0.6369421482086182, 'entity': 'B-MISC', 'index': 5, 'start': 19, 'end': 22}]\n",
      "elem tri\n",
      "NER over initial question: \n",
      " what film is under tristar pictures ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats the gender of andy mccollum\n",
      "ner_results [{'word': 'and', 'score': 0.45513424277305603, 'entity': 'B-MISC', 'index': 6, 'start': 20, 'end': 23}]\n",
      "elem and\n",
      "NER over initial question: \n",
      " whats the gender of andy mccollum ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats the name of a person born in  loboc, bohol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 213/400 [00:27<00:22,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': '##hol', 'score': 0.7019297480583191, 'entity': 'B-MISC', 'index': 15, 'start': 45, 'end': 48}]\n",
      "elem ##hol\n",
      "NER over initial question: \n",
      " whats the name of a person born in  loboc bohol ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " In which conflict did co-rux-te-chod-ish participate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 215/400 [00:28<00:30,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'co', 'score': 0.6121746897697449, 'entity': 'B-ORG', 'index': 5, 'start': 22, 'end': 24}, {'word': 'ru', 'score': 0.4250151515007019, 'entity': 'I-ORG', 'index': 7, 'start': 25, 'end': 27}, {'word': '##x', 'score': 0.4349890351295471, 'entity': 'I-ORG', 'index': 8, 'start': 27, 'end': 28}, {'word': '##d', 'score': 0.4607264995574951, 'entity': 'I-ORG', 'index': 13, 'start': 35, 'end': 36}, {'word': 'ish', 'score': 0.5363644957542419, 'entity': 'I-ORG', 'index': 15, 'start': 37, 'end': 40}]\n",
      "elem co\n",
      "elem ru\n",
      "elem ##x\n",
      "elem ##d\n",
      "elem ish\n",
      "NER over initial question: \n",
      " In which conflict did co-rux-te-chod-ish participate ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Whats the name of a musical film\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Whats the name of a musical film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is used in suspense\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is used in suspense ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who wrote not in the flesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 220/400 [00:28<00:24,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " who wrote not in the flesh ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is aaron miles (basketball)'s profession \n",
      "ner_results [{'word': 'aa', 'score': 0.42586252093315125, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': '##ron', 'score': 0.32925960421562195, 'entity': 'I-PER', 'index': 4, 'start': 10, 'end': 13}]\n",
      "elem aa\n",
      "elem ##ron\n",
      "NER over initial question: \n",
      " what is [START] aaron [END] miles (basketball)'s profession  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is the artist of carrots / kkkkk\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who is the artist of carrots / kkkkk ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which poet was born in glencoe\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which poet was born in glencoe ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of music album is table for one?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 225/400 [00:28<00:16, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of music album is table for one ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which language was the film state of the union in\n",
      "ner_results [{'word': 'W', 'score': 0.8031348586082458, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 1}, {'word': '##h', 'score': 0.6026211977005005, 'entity': 'I-MISC', 'index': 3, 'start': 4, 'end': 5}, {'word': 'language', 'score': 0.8026172518730164, 'entity': 'I-MISC', 'index': 4, 'start': 6, 'end': 14}]\n",
      "elem W\n",
      "elem ##h\n",
      "elem language\n",
      "NER over initial question: \n",
      " Which [START] language [END] was the film state of the union in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What was roy rogers' nationality?\n",
      "ner_results [{'word': 'ro', 'score': 0.4317428171634674, 'entity': 'B-MISC', 'index': 3, 'start': 9, 'end': 11}]\n",
      "elem ro\n",
      "NER over initial question: \n",
      " What was roy rogers' nationality ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did kuno fischer spend his last day alive\n",
      "ner_results [{'word': 'kuno', 'score': 0.7476139068603516, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 14}, {'word': 'fi', 'score': 0.5501946806907654, 'entity': 'I-PER', 'index': 4, 'start': 15, 'end': 17}, {'word': '##scher', 'score': 0.7403134107589722, 'entity': 'I-PER', 'index': 5, 'start': 17, 'end': 22}]\n",
      "elem kuno\n",
      "elem fi\n",
      "elem ##scher\n",
      "NER over initial question: \n",
      " where did [START] kuno fischer [END] spend his last day alive ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is myles dillon's gender?\n",
      "ner_results [{'word': 'my', 'score': 0.4867270290851593, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': '##les', 'score': 0.4458354711532593, 'entity': 'I-PER', 'index': 4, 'start': 10, 'end': 13}]\n",
      "elem my\n",
      "elem ##les\n",
      "NER over initial question: \n",
      " What is [START] myles [END] dillon's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the language of the composition hurricane?\n",
      "ner_results [{'word': 'hurricane', 'score': 0.9160903096199036, 'entity': 'B-MISC', 'index': 8, 'start': 40, 'end': 49}]\n",
      "elem hurricane\n",
      "NER over initial question: \n",
      " what is the language of the composition [START] hurricane [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where is zenon grocholewski from?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 228/400 [00:29<00:13, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'zen', 'score': 0.38526973128318787, 'entity': 'B-LOC', 'index': 3, 'start': 9, 'end': 12}]\n",
      "elem zen\n",
      "NER over initial question: \n",
      " Where is zenon grocholewski from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the name of a 2004 horror movie\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is the name of a 2004 horror movie ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of videogame is jade dynasty\n",
      "ner_results [{'word': 'ja', 'score': 0.8859080672264099, 'entity': 'B-MISC', 'index': 7, 'start': 26, 'end': 28}, {'word': '##de', 'score': 0.7339016199111938, 'entity': 'I-MISC', 'index': 8, 'start': 28, 'end': 30}]\n",
      "elem ja\n",
      "elem ##de\n",
      "NER over initial question: \n",
      " what type of videogame is [START] jade [END] dynasty ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the profession of michael dudikoff?\n",
      "ner_results [{'word': 'mich', 'score': 0.8623847961425781, 'entity': 'B-PER', 'index': 6, 'start': 26, 'end': 30}, {'word': '##ael', 'score': 0.8422821164131165, 'entity': 'I-PER', 'index': 7, 'start': 30, 'end': 33}]\n",
      "elem mich\n",
      "elem ##ael\n",
      "NER over initial question: \n",
      " What is the profession of [START] michael [END] dudikoff ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the language flying blind is in?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the language flying blind is in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of music does sylvan richardson make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 234/400 [00:29<00:11, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'sy', 'score': 0.4623192846775055, 'entity': 'B-LOC', 'index': 6, 'start': 24, 'end': 26}, {'word': '##lva', 'score': 0.3730614483356476, 'entity': 'B-MISC', 'index': 7, 'start': 26, 'end': 29}]\n",
      "elem sy\n",
      "elem ##lva\n",
      "NER over initial question: \n",
      " What kind of music does sylvan richardson make ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who recorded maple leaves (ep)\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who recorded maple leaves (ep) ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the title of a film in the drama genre?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the title of a film in the drama genre ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What company published the game brothers: a tale of two sons\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What company published the game brothers: a tale of two sons ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the country origin of the film the end of violence?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 236/400 [00:29<00:11, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What is the country origin of the film the end of violence ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What was william b. hawks's place of birth?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 238/400 [00:30<00:35,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'will', 'score': 0.9661014080047607, 'entity': 'B-PER', 'index': 3, 'start': 9, 'end': 13}, {'word': '##iam', 'score': 0.8614923357963562, 'entity': 'I-PER', 'index': 4, 'start': 13, 'end': 16}, {'word': 'b', 'score': 0.5661325454711914, 'entity': 'I-PER', 'index': 5, 'start': 17, 'end': 18}, {'word': '##w', 'score': 0.5565399527549744, 'entity': 'I-PER', 'index': 8, 'start': 22, 'end': 23}, {'word': '##ks', 'score': 0.5719032287597656, 'entity': 'I-PER', 'index': 9, 'start': 23, 'end': 25}]\n",
      "elem will\n",
      "elem ##iam\n",
      "elem b\n",
      "elem ##w\n",
      "elem ##ks\n",
      "NER over initial question: \n",
      " What was [START] william [END] b. hawks's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position does baseball player steve belln play\n",
      "ner_results [{'word': 'baseball', 'score': 0.9235239624977112, 'entity': 'B-ORG', 'index': 4, 'start': 19, 'end': 27}]\n",
      "elem baseball\n",
      "NER over initial question: \n",
      " what position does [START] baseball [END] player steve belln play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name an event that occurred in laconia.\n",
      "ner_results [{'word': 'lac', 'score': 0.663482666015625, 'entity': 'B-MISC', 'index': 7, 'start': 31, 'end': 34}, {'word': '##onia', 'score': 0.45773202180862427, 'entity': 'I-LOC', 'index': 8, 'start': 34, 'end': 38}]\n",
      "elem lac\n",
      "elem ##onia\n",
      "NER over initial question: \n",
      " Name an event that occurred in laconia. ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country contains taylor county\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 242/400 [00:31<00:25,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'tay', 'score': 0.575762927532196, 'entity': 'B-LOC', 'index': 4, 'start': 23, 'end': 26}]\n",
      "elem tay\n",
      "NER over initial question: \n",
      " which country contains taylor county ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is john landis' religion\n",
      "ner_results [{'word': 'jo', 'score': 0.37641194462776184, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 10}]\n",
      "elem jo\n",
      "NER over initial question: \n",
      " what is john landis' religion ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which type of music is sportin' life associated with\n",
      "ner_results [{'word': 'sport', 'score': 0.38289380073547363, 'entity': 'B-PER', 'index': 6, 'start': 23, 'end': 28}]\n",
      "elem sport\n",
      "NER over initial question: \n",
      " which type of music is sportin' life associated with ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is Mithoon's profession?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 244/400 [00:31<00:22,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'Mit', 'score': 0.9968095421791077, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 11}, {'word': '##ho', 'score': 0.823874831199646, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 13}, {'word': '##on', 'score': 0.9824770092964172, 'entity': 'I-PER', 'index': 5, 'start': 13, 'end': 15}]\n",
      "elem Mit\n",
      "elem ##ho\n",
      "elem ##on\n",
      "NER over initial question: \n",
      " What is Mithoon's profession ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is country in?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is country in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " effie gray was born in this country\n",
      "ner_results [{'word': 'ef', 'score': 0.5577040910720825, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 2}]\n",
      "elem ef\n",
      "NER over initial question: \n",
      " effie gray was born in this country ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " In which conflict did chesley g. peterson participate in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 247/400 [00:31<00:15,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " In which conflict did chesley g. peterson participate in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what position did cary williams play\n",
      "ner_results [{'word': 'car', 'score': 0.661247730255127, 'entity': 'B-PER', 'index': 4, 'start': 18, 'end': 21}, {'word': '##iam', 'score': 0.4909294545650482, 'entity': 'I-PER', 'index': 7, 'start': 27, 'end': 30}]\n",
      "elem car\n",
      "elem ##iam\n",
      "NER over initial question: \n",
      " what position did cary williams play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is kim hiorthy's career?\n",
      "ner_results [{'word': 'kim', 'score': 0.8315355777740479, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 11}, {'word': 'hi', 'score': 0.7268798351287842, 'entity': 'I-PER', 'index': 4, 'start': 12, 'end': 14}, {'word': '##ort', 'score': 0.7151828408241272, 'entity': 'I-PER', 'index': 5, 'start': 14, 'end': 17}, {'word': '##h', 'score': 0.7637692093849182, 'entity': 'I-PER', 'index': 6, 'start': 17, 'end': 18}, {'word': '##y', 'score': 0.8609783053398132, 'entity': 'I-PER', 'index': 7, 'start': 18, 'end': 20}]\n",
      "elem kim\n",
      "elem hi\n",
      "elem ##ort\n",
      "elem ##h\n",
      "elem ##y\n",
      "NER over initial question: \n",
      " what is [START] kim [END] hiorthy's career ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What type of asteroid group is 3775 ellenbeth in\n",
      "ner_results [{'word': '377', 'score': 0.9713433980941772, 'entity': 'B-LOC', 'index': 7, 'start': 31, 'end': 34}, {'word': '##5', 'score': 0.9374805092811584, 'entity': 'I-LOC', 'index': 8, 'start': 34, 'end': 35}, {'word': 'ellen', 'score': 0.952582597732544, 'entity': 'I-LOC', 'index': 9, 'start': 36, 'end': 41}, {'word': '##beth', 'score': 0.9610465168952942, 'entity': 'I-LOC', 'index': 10, 'start': 41, 'end': 45}]\n",
      "elem 377\n",
      "elem ##5\n",
      "elem ellen\n",
      "elem ##beth\n",
      "NER over initial question: \n",
      " What type of asteroid group is [START] 3775 ellenbeth [END] in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is a shooting guard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 250/400 [00:31<00:13, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " who is a shooting guard ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is a parent of  christian vi of denmark\n",
      "ner_results [{'word': 'ch', 'score': 0.9802320003509521, 'entity': 'B-MISC', 'index': 6, 'start': 20, 'end': 22}, {'word': '##risti', 'score': 0.4879285991191864, 'entity': 'B-MISC', 'index': 7, 'start': 22, 'end': 27}]\n",
      "elem ch\n",
      "elem ##risti\n",
      "NER over initial question: \n",
      " who is a parent of  christian vi of denmark ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What gender is Ernie Russell?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 255/400 [00:32<00:10, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'Ernie', 'score': 0.9996469020843506, 'entity': 'B-PER', 'index': 4, 'start': 15, 'end': 20}, {'word': 'Russell', 'score': 0.9993387460708618, 'entity': 'I-PER', 'index': 5, 'start': 21, 'end': 28}]\n",
      "elem Ernie\n",
      "elem Russell\n",
      "NER over initial question: \n",
      " What gender is [START] Ernie Russell [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What kind of album is the ugly duckling\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What kind of album is the ugly duckling ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which city did terence cooke pass away in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which city did terence cooke pass away in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was the film producer for anatole dauman\n",
      "ner_results [{'word': 'ana', 'score': 0.671550452709198, 'entity': 'B-MISC', 'index': 7, 'start': 30, 'end': 33}, {'word': '##tol', 'score': 0.28760480880737305, 'entity': 'B-MISC', 'index': 8, 'start': 33, 'end': 36}]\n",
      "elem ana\n",
      "elem ##tol\n",
      "NER over initial question: \n",
      " who was the film producer for anatole dauman ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what film did lou scheimer produce?\n",
      "ner_results [{'word': 'lo', 'score': 0.602271556854248, 'entity': 'B-PER', 'index': 4, 'start': 14, 'end': 16}, {'word': 's', 'score': 0.6030445694923401, 'entity': 'I-PER', 'index': 6, 'start': 18, 'end': 19}, {'word': '##che', 'score': 0.6692713499069214, 'entity': 'I-PER', 'index': 7, 'start': 19, 'end': 22}, {'word': '##ime', 'score': 0.6827836036682129, 'entity': 'I-PER', 'index': 8, 'start': 22, 'end': 25}, {'word': '##r', 'score': 0.6663778424263, 'entity': 'I-PER', 'index': 9, 'start': 25, 'end': 26}]\n",
      "elem lo\n",
      "elem s\n",
      "elem ##che\n",
      "elem ##ime\n",
      "elem ##r\n",
      "NER over initial question: \n",
      " what film did lou [START] scheimer [END] produce ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " is howard d. white male or female\n",
      "ner_results [{'word': 'how', 'score': 0.5269909501075745, 'entity': 'B-MISC', 'index': 2, 'start': 3, 'end': 6}]\n",
      "elem how\n",
      "NER over initial question: \n",
      " is howard d. white male or female ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is  a person that was born in  heligoland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 261/400 [00:32<00:07, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'hel', 'score': 0.6247831583023071, 'entity': 'B-MISC', 'index': 9, 'start': 35, 'end': 38}]\n",
      "elem hel\n",
      "NER over initial question: \n",
      " who is  a person that was born in  heligoland ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did neal barrett die\n",
      "ner_results [{'word': 'ne', 'score': 0.8504214882850647, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}, {'word': '##al', 'score': 0.4910966157913208, 'entity': 'I-PER', 'index': 4, 'start': 12, 'end': 14}]\n",
      "elem ne\n",
      "elem ##al\n",
      "NER over initial question: \n",
      " where did [START] neal [END] barrett die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which animated films did deborah lurie contribute music to?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which animated films did deborah lurie contribute music to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country is david j. bodycombe from \n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which country is david j. bodycombe from  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which war did william buckingham participate in \n",
      "ner_results [{'word': 'will', 'score': 0.406879186630249, 'entity': 'B-PER', 'index': 4, 'start': 14, 'end': 18}]\n",
      "elem will\n",
      "NER over initial question: \n",
      " which war did william buckingham participate in  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was oviedo born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 268/400 [00:32<00:06, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ov', 'score': 0.5436587929725647, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}, {'word': '##ied', 'score': 0.47273576259613037, 'entity': 'I-PER', 'index': 4, 'start': 12, 'end': 15}, {'word': '##o', 'score': 0.7427330017089844, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 16}]\n",
      "elem ov\n",
      "elem ##ied\n",
      "elem ##o\n",
      "NER over initial question: \n",
      " Where was [START] oviedo [END] born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of movie is we want a child!\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of movie is we want a child ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country is the movie go go tales from?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what country is the movie go go tales from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is a retired Spanish footballer who played midfielder?\n",
      "ner_results [{'word': 'Spanish', 'score': 0.995329737663269, 'entity': 'B-MISC', 'index': 5, 'start': 17, 'end': 24}]\n",
      "elem Spanish\n",
      "NER over initial question: \n",
      " Who is a retired [START] Spanish [END] footballer who played midfielder ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What position does football player rory patterson play?\n",
      "ner_results [{'word': '##on', 'score': 0.30843040347099304, 'entity': 'I-ORG', 'index': 10, 'start': 47, 'end': 49}]\n",
      "elem ##on\n",
      "NER over initial question: \n",
      " What position does football player rory patterson play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what war was lancelot curran involved in \n",
      "ner_results [{'word': 'lance', 'score': 0.5259454250335693, 'entity': 'B-MISC', 'index': 4, 'start': 13, 'end': 18}]\n",
      "elem lance\n",
      "NER over initial question: \n",
      " what war was lancelot curran involved in  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did eiler larsen end his life?\n",
      "ner_results [{'word': 'eile', 'score': 0.5580756068229675, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 14}, {'word': '##r', 'score': 0.6010677814483643, 'entity': 'I-PER', 'index': 4, 'start': 14, 'end': 15}, {'word': 'lar', 'score': 0.5585691928863525, 'entity': 'I-PER', 'index': 5, 'start': 16, 'end': 19}, {'word': '##sen', 'score': 0.6909109354019165, 'entity': 'I-PER', 'index': 6, 'start': 19, 'end': 22}]\n",
      "elem eile\n",
      "elem "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 271/400 [00:32<00:05, 22.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##r\n",
      "elem lar\n",
      "elem ##sen\n",
      "NER over initial question: \n",
      " Where did [START] eiler larsen [END] end his life ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of celestial body is bd+60 2522\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what kind of celestial body is bd+60 2522 ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of music is played in the balladeering album\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what type of music is played in the balladeering album ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was the artist that recorded the album destruction by definition\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who was the artist that recorded the album destruction by definition ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What country is cornelia parker from?\n",
      "ner_results [{'word': 'corn', 'score': 0.7071775197982788, 'entity': 'B-LOC', 'index': 4, 'start': 16, 'end': 20}]\n",
      "elem corn\n",
      "NER over initial question: \n",
      " What country is cornelia parker from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What's a football team that plays in the EPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 277/400 [00:33<00:05, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'EP', 'score': 0.7433998584747314, 'entity': 'B-ORG', 'index': 11, 'start': 41, 'end': 43}, {'word': '##L', 'score': 0.872963547706604, 'entity': 'I-ORG', 'index': 12, 'start': 43, 'end': 44}]\n",
      "elem EP\n",
      "elem ##L\n",
      "NER over initial question: \n",
      " What's a football team that plays in the [START] EPL [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what category does 3314 beals belong to\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what category does 3314 beals belong to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which position in football did danny whitaker play in?\n",
      "ner_results [{'word': 'dann', 'score': 0.5065616965293884, 'entity': 'B-PER', 'index': 6, 'start': 31, 'end': 35}]\n",
      "elem dann\n",
      "NER over initial question: \n",
      " which position in football did danny whitaker play in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was ed van der elsken's place of death\n",
      "ner_results [{'word': 'ed', 'score': 0.9841587543487549, 'entity': 'B-PER', 'index': 3, 'start': 9, 'end': 11}, {'word': 'van', 'score': 0.9953559041023254, 'entity': 'I-PER', 'index': 4, 'start': 12, 'end': 15}, {'word': 'der', 'score': 0.9920550584793091, 'entity': 'I-PER', 'index': 5, 'start': 16, 'end': 19}, {'word': 'els', 'score': 0.9815483093261719, 'entity': 'I-PER', 'index': 6, 'start': 20, 'end': 23}, {'word': '##ken', 'score': 0.9452244639396667, 'entity': 'I-PER', 'index': 7, 'start': 23, 'end': 26}]\n",
      "elem ed\n",
      "elem van\n",
      "elem der\n",
      "elem els\n",
      "elem ##ken\n",
      "NER over initial question: \n",
      " what was [START] ed van der [END] elsken's place of death ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the gender of joe nanini\n",
      "ner_results [{'word': 'jo', 'score': 0.35356295108795166, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 24}, {'word': '##e', 'score': 0.35631123185157776, 'entity': 'I-MISC', 'index': 7, 'start': 24, 'end': 25}, {'word': 'nan', 'score': 0.3426685333251953, 'entity': 'I-PER', 'index': 8, 'start': 26, 'end': 29}]\n",
      "elem jo\n",
      "elem ##e\n",
      "elem nan\n",
      "NER over initial question: \n",
      " what is the gender of [START] joe [END] nanini ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did archduchess barbara of austria perish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 280/400 [00:33<00:05, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'aust', 'score': 0.66673344373703, 'entity': 'B-LOC', 'index': 10, 'start': 33, 'end': 37}]\n",
      "elem aust\n",
      "NER over initial question: \n",
      " Where did archduchess barbara of austria perish ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which films did charlie chaplin direct\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which films did charlie chaplin direct ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is someone born in sydney\n",
      "ner_results [{'word': 'syd', 'score': 0.9770616292953491, 'entity': 'B-LOC', 'index': 6, 'start': 23, 'end': 26}, {'word': '##ney', 'score': 0.8140395283699036, 'entity': 'I-LOC', 'index': 7, 'start': 26, 'end': 29}]\n",
      "elem syd\n",
      "elem ##ney\n",
      "NER over initial question: \n",
      " Who is someone born in [START] sydney [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What baseball position does jack ness play?\n",
      "ner_results [{'word': 'baseball', 'score': 0.6012169718742371, 'entity': 'B-ORG', 'index': 2, 'start': 5, 'end': 13}]\n",
      "elem baseball\n",
      "NER over initial question: \n",
      " What [START] baseball [END] position does jack ness play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is daniel petrov from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 286/400 [00:33<00:04, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'dan', 'score': 0.5127832293510437, 'entity': 'B-MISC', 'index': 3, 'start': 9, 'end': 12}]\n",
      "elem dan\n",
      "NER over initial question: \n",
      " where is daniel petrov from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which war was hermann stuckmann involved in\n",
      "ner_results [{'word': 'her', 'score': 0.4214238226413727, 'entity': 'B-PER', 'index': 6, 'start': 14, 'end': 17}, {'word': 'st', 'score': 0.273569256067276, 'entity': 'B-PER', 'index': 8, 'start': 22, 'end': 24}, {'word': '##uck', 'score': 0.4824509918689728, 'entity': 'I-PER', 'index': 9, 'start': 24, 'end': 27}]\n",
      "elem her\n",
      "elem st\n",
      "elem ##uck\n",
      "NER over initial question: \n",
      " Which war was hermann stuckmann involved in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the gender of  gil brewer\n",
      "ner_results [{'word': 'gi', 'score': 0.31491619348526, 'entity': 'B-ORG', 'index': 6, 'start': 23, 'end': 25}]\n",
      "elem gi\n",
      "NER over initial question: \n",
      " what is the gender of  gil brewer ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is in the movie nightmare?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is in the movie nightmare ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whose life began in celle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 289/400 [00:33<00:05, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'celle', 'score': 0.5943911075592041, 'entity': 'B-LOC', 'index': 5, 'start': 20, 'end': 25}]\n",
      "elem celle\n",
      "NER over initial question: \n",
      " whose life began in [START] celle [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the gender of nate bussey\n",
      "ner_results [{'word': 'nat', 'score': 0.4586944282054901, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 25}]\n",
      "elem nat\n",
      "NER over initial question: \n",
      " what is the gender of nate bussey ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " russell wade died in this southern California city. \n",
      "ner_results [{'word': 'California', 'score': 0.9995295405387878, 'entity': 'B-LOC', 'index': 9, 'start': 35, 'end': 45}]\n",
      "elem California\n",
      "NER over initial question: \n",
      " russell wade died in this southern [START] California [END] city.  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What's the title of a netflix blaxploitation film?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 294/400 [00:34<00:07, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'net', 'score': 0.6284115314483643, 'entity': 'B-MISC', 'index': 8, 'start': 22, 'end': 25}, {'word': '##f', 'score': 0.23798896372318268, 'entity': 'B-MISC', 'index': 9, 'start': 25, 'end': 26}]\n",
      "elem net\n",
      "elem ##f\n",
      "NER over initial question: \n",
      " What's the title of a netflix blaxploitation film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is the job title of jennifer byrne\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is the job title of jennifer byrne ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What type of celestial object is 3587 descartes\n",
      "ner_results [{'word': '358', 'score': 0.49565285444259644, 'entity': 'B-LOC', 'index': 8, 'start': 33, 'end': 36}]\n",
      "elem 358\n",
      "NER over initial question: \n",
      " What type of celestial object is 3587 descartes ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which time zones is majs located in?\n",
      "ner_results [{'word': 'maj', 'score': 0.7085765600204468, 'entity': 'B-LOC', 'index': 5, 'start': 20, 'end': 23}]\n",
      "elem maj\n",
      "NER over initial question: \n",
      " which time zones is majs located in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats the language that was used in  lovely, still\n",
      "ner_results [{'word': 'what', 'score': 0.9210500717163086, 'entity': 'B-MISC', 'index': 1, 'start': 0, 'end': 4}]\n",
      "elem what\n",
      "NER over initial question: \n",
      " whats the language that was used in  lovely still ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which netflix genre is dinosaurs: giants of patagonia under\n",
      "ner_results [{'word': 'patag', 'score': 0.9886922240257263, 'entity': 'B-LOC', 'index': 17, 'start': 44, 'end': 49}, {'word': '##onia', 'score': 0.9402351379394531, 'entity': 'I-LOC', 'index': 18, 'start': 49, 'end': 53}]\n",
      "elem patag\n",
      "elem ##onia\n",
      "NER over initial question: \n",
      " Which netflix genre is dinosaurs: giants of [START] patagonia [END] under ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which is the main ideology of the communist party of britain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 296/400 [00:35<00:18,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'brit', 'score': 0.4772436022758484, 'entity': 'B-ORG', 'index': 12, 'start': 53, 'end': 57}]\n",
      "elem brit\n",
      "NER over initial question: \n",
      " which is the main ideology of the communist party of britain ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was the last place samuel marx resided before he died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 300/400 [00:35<00:15,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'sam', 'score': 0.8285022974014282, 'entity': 'B-PER', 'index': 6, 'start': 25, 'end': 28}]\n",
      "elem sam\n",
      "NER over initial question: \n",
      " where was the last place samuel marx resided before he died ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is a location in united states\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is a location in united states ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which label is osker signed to\n",
      "ner_results [{'word': 'os', 'score': 0.8805356025695801, 'entity': 'B-ORG', 'index': 4, 'start': 15, 'end': 17}, {'word': '##ker', 'score': 0.6847453713417053, 'entity': 'I-ORG', 'index': 5, 'start': 17, 'end': 20}]\n",
      "elem os\n",
      "elem ##ker\n",
      "NER over initial question: \n",
      " which label is [START] osker [END] signed to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is oday taleb's nationality\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What is oday taleb's nationality ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country is urban ghost story from?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which country is urban ghost story from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who was the main person at the james k. polk 1845 presidential inauguration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 304/400 [00:36<00:14,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'jam', 'score': 0.46985241770744324, 'entity': 'B-LOC', 'index': 8, 'start': 31, 'end': 34}, {'word': '##es', 'score': 0.35018688440322876, 'entity': 'I-LOC', 'index': 9, 'start': 34, 'end': 36}]\n",
      "elem jam\n",
      "elem ##es\n",
      "NER over initial question: \n",
      " Who was the main person at the [START] james [END] k. polk 1845 presidential inauguration ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which village is located in allegany county\n",
      "ner_results [{'word': 'alle', 'score': 0.867059588432312, 'entity': 'B-LOC', 'index': 6, 'start': 28, 'end': 32}, {'word': '##gan', 'score': 0.3990307152271271, 'entity': 'I-LOC', 'index': 7, 'start': 32, 'end': 35}, {'word': '##y', 'score': 0.5150995254516602, 'entity': 'I-LOC', 'index': 8, 'start': 35, 'end': 36}]\n",
      "elem alle\n",
      "elem ##gan\n",
      "elem ##y\n",
      "NER over initial question: \n",
      " which village is located in [START] allegany [END] county ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is dildar ali naseerabadi's religion?\n",
      "ner_results [{'word': 'nas', 'score': 0.8776716589927673, 'entity': 'B-PER', 'index': 6, 'start': 19, 'end': 22}, {'word': '##eer', 'score': 0.6955591440200806, 'entity': 'B-PER', 'index': 7, 'start': 22, 'end': 25}, {'word': '##abad', 'score': 0.8006221055984497, 'entity': 'I-PER', 'index': 8, 'start': 25, 'end': 29}, {'word': '##i', 'score': 0.9519912600517273, 'entity': 'I-PER', 'index': 9, 'start': 29, 'end': 30}]\n",
      "elem nas\n",
      "elem ##eer\n",
      "elem ##abad\n",
      "elem ##i\n",
      "NER over initial question: \n",
      " what is dildar ali naseerabadi's religion ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what types of music is sub rosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 306/400 [00:36<00:11,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'sub', 'score': 0.8958925604820251, 'entity': 'B-MISC', 'index': 6, 'start': 23, 'end': 26}, {'word': 'rosa', 'score': 0.7240636348724365, 'entity': 'I-MISC', 'index': 7, 'start': 27, 'end': 31}]\n",
      "elem sub\n",
      "elem rosa\n",
      "NER over initial question: \n",
      " what types of music is [START] sub rosa [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a tv program in the comedy-drama genre\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Name a tv program in the comedy-drama genre ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was the author of war of the twins?\n",
      "ner_results [{'word': 'war', 'score': 0.9606212973594666, 'entity': 'B-MISC', 'index': 6, 'start': 22, 'end': 25}, {'word': 'of', 'score': 0.9072137475013733, 'entity': 'I-MISC', 'index': 7, 'start': 26, 'end': 28}, {'word': 'the', 'score': 0.8434174060821533, 'entity': 'I-MISC', 'index': 8, 'start': 29, 'end': 32}, {'word': 'twin', 'score': 0.75789475440979, 'entity': 'I-MISC', 'index': 9, 'start': 33, 'end': 37}, {'word': '##s', 'score': 0.6897526979446411, 'entity': 'I-MISC', 'index': 10, 'start': 37, 'end': 38}]\n",
      "elem war\n",
      "elem of\n",
      "elem the\n",
      "elem twin\n",
      "elem ##s\n",
      "NER over initial question: \n",
      " who was [START] the [END] author [START] of war of the twins [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what was the name of chihiro onitsuka's debut j-pop album\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 308/400 [00:36<00:13,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'chi', 'score': 0.5198078751564026, 'entity': 'B-PER', 'index': 6, 'start': 21, 'end': 24}, {'word': 'oni', 'score': 0.6093325614929199, 'entity': 'I-PER', 'index': 8, 'start': 29, 'end': 32}, {'word': '##tsu', 'score': 0.7571744918823242, 'entity': 'I-PER', 'index': 9, 'start': 32, 'end': 35}, {'word': '##ka', 'score': 0.8612977266311646, 'entity': 'I-PER', 'index': 10, 'start': 35, 'end': 37}]\n",
      "elem chi\n",
      "elem oni\n",
      "elem ##tsu\n",
      "elem ##ka\n",
      "NER over initial question: \n",
      " what was the name of chihiro onitsuka's debut j-pop album ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was born in ogden\n",
      "ner_results [{'word': 'og', 'score': 0.9942036867141724, 'entity': 'B-LOC', 'index': 5, 'start': 16, 'end': 18}, {'word': '##den', 'score': 0.9522879719734192, 'entity': 'I-LOC', 'index': 6, 'start': 18, 'end': 21}]\n",
      "elem og\n",
      "elem ##den\n",
      "NER over initial question: \n",
      " who was born in [START] ogden [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What gender is doctor strange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 312/400 [00:37<00:11,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What gender is doctor strange ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is giorgos kimoulis's place of birth\n",
      "ner_results [{'word': 'gi', 'score': 0.8584398031234741, 'entity': 'B-PER', 'index': 3, 'start': 9, 'end': 11}, {'word': '##org', 'score': 0.6307823061943054, 'entity': 'I-PER', 'index': 4, 'start': 11, 'end': 14}, {'word': '##os', 'score': 0.6880746483802795, 'entity': 'I-PER', 'index': 5, 'start': 14, 'end': 16}, {'word': 'kim', 'score': 0.6979876160621643, 'entity': 'I-PER', 'index': 6, 'start': 17, 'end': 20}, {'word': '##oul', 'score': 0.9444862604141235, 'entity': 'I-PER', 'index': 7, 'start': 20, 'end': 23}, {'word': '##is', 'score': 0.91413813829422, 'entity': 'I-PER', 'index': 8, 'start': 23, 'end': 25}]\n",
      "elem gi\n",
      "elem ##org\n",
      "elem ##os\n",
      "elem kim\n",
      "elem ##oul\n",
      "elem ##is\n",
      "NER over initial question: \n",
      " where is [START] giorgos [END] kimoulis's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is maripol's gender\n",
      "ner_results [{'word': 'mari', 'score': 0.9113945364952087, 'entity': 'B-ORG', 'index': 3, 'start': 8, 'end': 12}, {'word': '##pol', 'score': 0.8893129229545593, 'entity': 'I-ORG', 'index': 4, 'start': 12, 'end': 15}]\n",
      "elem mari\n",
      "elem ##pol\n",
      "NER over initial question: \n",
      " What is maripol's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where did ignacy potocki die\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 315/400 [00:37<00:08,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'ig', 'score': 0.597157895565033, 'entity': 'B-MISC', 'index': 3, 'start': 10, 'end': 12}, {'word': 'pot', 'score': 0.49994349479675293, 'entity': 'B-MISC', 'index': 6, 'start': 17, 'end': 20}, {'word': '##ock', 'score': 0.6040316224098206, 'entity': 'I-MISC', 'index': 7, 'start': 20, 'end': 23}, {'word': '##i', 'score': 0.44252726435661316, 'entity': 'I-MISC', 'index': 8, 'start': 23, 'end': 24}]\n",
      "elem ig\n",
      "elem pot\n",
      "elem ##ock\n",
      "elem ##i\n",
      "NER over initial question: \n",
      " where did ignacy [START] potocki [END] die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is ellen swallow richards's nationality?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is ellen swallow richards's nationality ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what harry was born in wellington\n",
      "ner_results [{'word': 'well', 'score': 0.9116827249526978, 'entity': 'B-LOC', 'index': 7, 'start': 23, 'end': 27}, {'word': '##ington', 'score': 0.6686500906944275, 'entity': 'I-LOC', 'index': 8, 'start': 27, 'end': 33}]\n",
      "elem well\n",
      "elem ##ington\n",
      "NER over initial question: \n",
      " what harry was born in [START] wellington [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which football position does nizami hajiyev play\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 317/400 [00:37<00:07, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'niz', 'score': 0.4670949876308441, 'entity': 'B-ORG', 'index': 7, 'start': 29, 'end': 32}]\n",
      "elem niz\n",
      "NER over initial question: \n",
      " Which football position does nizami hajiyev play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what album is in the genre of surf music?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what album is in the genre of surf music ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was gladys guevarra born\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " where was gladys guevarra born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in what language was hemlock society filmed in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 319/400 [00:37<00:07, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'hem', 'score': 0.5761705636978149, 'entity': 'B-MISC', 'index': 5, 'start': 21, 'end': 24}, {'word': '##lock', 'score': 0.3946034610271454, 'entity': 'B-MISC', 'index': 6, 'start': 24, 'end': 28}]\n",
      "elem hem\n",
      "elem ##lock\n",
      "NER over initial question: \n",
      " in what language was [START] hemlock [END] society filmed in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats theodore s. westhusing's gender, male or female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 324/400 [00:39<00:12,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " whats theodore s. westhusing's gender male or female ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what american football position does michael doyle play \n",
      "ner_results [{'word': 'mich', 'score': 0.9898915886878967, 'entity': 'B-PER', 'index': 6, 'start': 37, 'end': 41}, {'word': '##ael', 'score': 0.8587133288383484, 'entity': 'I-PER', 'index': 7, 'start': 41, 'end': 44}, {'word': 'do', 'score': 0.7754899859428406, 'entity': 'I-PER', 'index': 8, 'start': 45, 'end': 47}, {'word': '##yle', 'score': 0.5322471857070923, 'entity': 'I-PER', 'index': 9, 'start': 47, 'end': 50}]\n",
      "elem mich\n",
      "elem ##ael\n",
      "elem do\n",
      "elem ##yle\n",
      "NER over initial question: \n",
      " what american football position does [START] michael doyle [END] play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which label is sean kingston signed to\n",
      "ner_results [{'word': 'sean', 'score': 0.5125130414962769, 'entity': 'B-PER', 'index': 6, 'start': 15, 'end': 19}]\n",
      "elem sean\n",
      "NER over initial question: \n",
      " Which label is [START] sean [END] kingston signed to ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was peter yates given birth at?\n",
      "ner_results [{'word': 'pet', 'score': 0.5967643857002258, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 13}, {'word': '##er', 'score': 0.39506053924560547, 'entity': 'I-PER', 'index': 4, 'start': 13, 'end': 15}]\n",
      "elem pet\n",
      "elem ##er\n",
      "NER over initial question: \n",
      " where was [START] peter [END] yates given birth at ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what's a title of a lewis milestone film\n",
      "ner_results [{'word': 'le', 'score': 0.6944609880447388, 'entity': 'B-MISC', 'index': 8, 'start': 20, 'end': 22}]\n",
      "elem le\n",
      "NER over initial question: \n",
      " what's a title of a lewis milestone film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was clete boyer born?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 329/400 [00:39<00:07,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'c', 'score': 0.3895503580570221, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 11}]\n",
      "elem c\n",
      "NER over initial question: \n",
      " where was clete boyer born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is the birthplace of derek parlane\n",
      "ner_results [{'word': 'der', 'score': 0.7868996858596802, 'entity': 'B-MISC', 'index': 7, 'start': 26, 'end': 29}, {'word': '##ek', 'score': 0.5172988176345825, 'entity': 'I-MISC', 'index': 8, 'start': 29, 'end': 31}]\n",
      "elem der\n",
      "elem ##ek\n",
      "NER over initial question: \n",
      " What is the birthplace of [START] derek [END] parlane ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is the producer for bonnie scotland?\n",
      "ner_results [{'word': 'bon', 'score': 0.380317360162735, 'entity': 'B-MISC', 'index': 6, 'start': 24, 'end': 27}, {'word': '##land', 'score': 0.45309585332870483, 'entity': 'I-LOC', 'index': 10, 'start': 35, 'end': 39}]\n",
      "elem bon\n",
      "elem ##land\n",
      "NER over initial question: \n",
      " who is the producer for bonnie scotland ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was the artist for theogonia\n",
      "ner_results [{'word': 'theo', 'score': 0.805991530418396, 'entity': 'B-MISC', 'index': 6, 'start': 23, 'end': 27}, {'word': '##gonia', 'score': 0.5810880064964294, 'entity': 'B-MISC', 'index': 7, 'start': 27, 'end': 32}]\n",
      "elem theo\n",
      "elem ##gonia\n",
      "NER over initial question: \n",
      " who was the artist for [START] theogonia [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is sophie treadwell's job?\n",
      "ner_results [{'word': 'so', 'score': 0.851310133934021, 'entity': 'B-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': '##phie', 'score': 0.5982432961463928, 'entity': 'B-PER', 'index': 4, 'start': 10, 'end': 14}, {'word': 'tre', 'score': 0.8760639429092407, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 18}, {'word': '##ad', 'score': 0.910426914691925, 'entity': 'I-PER', 'index': 6, 'start': 18, 'end': 20}, {'word': '##well', 'score': 0.8510355949401855, 'entity': 'I-PER', 'index': 7, 'start': 20, 'end': 24}]\n",
      "elem so\n",
      "elem ##phie\n",
      "elem tre\n",
      "elem ##ad\n",
      "elem ##well\n",
      "NER over initial question: \n",
      " What is [START] sophie [END] treadwell's job ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a musician in the j-pop genre.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 332/400 [00:39<00:05, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'j', 'score': 0.8652098774909973, 'entity': 'B-MISC', 'index': 6, 'start': 23, 'end': 24}, {'word': '-', 'score': 0.5140042901039124, 'entity': 'I-MISC', 'index': 7, 'start': 24, 'end': 25}, {'word': 'pop', 'score': 0.4476887881755829, 'entity': 'I-MISC', 'index': 8, 'start': 25, 'end': 28}]\n",
      "elem j\n",
      "elem -\n",
      "elem pop\n",
      "NER over initial question: \n",
      " Name a musician in the j-pop genre. ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country released chocolate: deep dark secrets\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which country released chocolate: deep dark secrets ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What country made the film nebet jezdci\n",
      "ner_results [{'word': 'ne', 'score': 0.45188477635383606, 'entity': 'B-MISC', 'index': 6, 'start': 27, 'end': 29}, {'word': '##be', 'score': 0.3445037603378296, 'entity': 'I-LOC', 'index': 7, 'start': 29, 'end': 31}, {'word': '##t', 'score': 0.3300865590572357, 'entity': 'I-ORG', 'index': 8, 'start': 31, 'end': 34}, {'word': 'je', 'score': 0.3019975423812866, 'entity': 'I-LOC', 'index': 9, 'start': 35, 'end': 37}, {'word': '##zd', 'score': 0.38079923391342163, 'entity': 'I-MISC', 'index': 10, 'start': 37, 'end': 39}, {'word': '##ci', 'score': 0.27961164712905884, 'entity': 'I-MISC', 'index': 11, 'start': 39, 'end': 41}]\n",
      "elem ne\n",
      "elem ##be\n",
      "elem ##t\n",
      "elem je\n",
      "elem ##zd\n",
      "elem ##ci\n",
      "NER over initial question: \n",
      " What country made the film [START] nebet jezdci [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was atanas chipilov born\n",
      "ner_results [{'word': 'ata', 'score': 0.9632896184921265, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 13}, {'word': '##nas', 'score': 0.7455505132675171, 'entity': 'I-PER', 'index': 4, 'start': 13, 'end': 16}, {'word': 'chip', 'score': 0.48042893409729004, 'entity': 'I-PER', 'index': 5, 'start': 17, 'end': 21}, {'word': '##ilo', 'score': 0.6102108359336853, 'entity': 'I-PER', 'index': 6, 'start': 21, 'end': 24}, {'word': '##v', 'score': 0.8246822953224182, 'entity': 'I-PER', 'index': 7, 'start': 24, 'end': 25}]\n",
      "elem ata\n",
      "elem ##nas\n",
      "elem chip\n",
      "elem ##ilo\n",
      "elem ##v\n",
      "NER over initial question: \n",
      " Where was [START] atanas chipilov [END] born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who directed the film the dangerous flirt?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Who directed the film the dangerous flirt ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which musician was born in elkhart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 337/400 [00:39<00:04, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'elk', 'score': 0.3434371054172516, 'entity': 'B-LOC', 'index': 6, 'start': 27, 'end': 30}]\n",
      "elem elk\n",
      "NER over initial question: \n",
      " which musician was born in elkhart ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is london keys's ethnicity?\n",
      "ner_results [{'word': 'lo', 'score': 0.9935789108276367, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 10}, {'word': '##ndo', 'score': 0.9365686774253845, 'entity': 'B-MISC', 'index': 4, 'start': 10, 'end': 13}]\n",
      "elem lo\n",
      "elem ##ndo\n",
      "NER over initial question: \n",
      " What is london keys's ethnicity ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What gender was philip sendak born as?\n",
      "ner_results [{'word': 'phi', 'score': 0.6339198350906372, 'entity': 'B-MISC', 'index': 4, 'start': 16, 'end': 19}]\n",
      "elem phi\n",
      "NER over initial question: \n",
      " What gender was philip sendak born as ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what's the name of a midfielder from spain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 339/400 [00:40<00:05, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what's the name of a midfielder from spain ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of bridge is bear mountain bridge\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what type of bridge is bear mountain bridge ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what ethnicity is linda w. cropp\n",
      "ner_results [{'word': 'li', 'score': 0.4431682527065277, 'entity': 'B-MISC', 'index': 5, 'start': 18, 'end': 20}]\n",
      "elem li\n",
      "NER over initial question: \n",
      " what ethnicity is linda w. cropp ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who created the program birds in the bush \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 344/400 [00:40<00:03, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'birds', 'score': 0.4679976999759674, 'entity': 'B-MISC', 'index': 5, 'start': 24, 'end': 29}]\n",
      "elem birds\n",
      "NER over initial question: \n",
      " who created the program [START] birds [END] in the bush  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which position in the infield did cory bailey play\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which position in the infield did cory bailey play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who is a notable defender in football\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Who is a notable defender in football ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where is roscoe h. hillenkoetter buried \n",
      "ner_results [{'word': 'ros', 'score': 0.5485619902610779, 'entity': 'B-LOC', 'index': 3, 'start': 9, 'end': 12}]\n",
      "elem ros\n",
      "NER over initial question: \n",
      " where is roscoe h. hillenkoetter buried  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what ethnicity is rose jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 348/400 [00:40<00:03, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " what ethnicity is rose jackson ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was rowland hill (postal reformer) buried?\n",
      "ner_results [{'word': 'row', 'score': 0.7333205342292786, 'entity': 'B-LOC', 'index': 3, 'start': 10, 'end': 13}]\n",
      "elem row\n",
      "NER over initial question: \n",
      " Where was rowland hill (postal reformer) buried ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " This is the city where steve sarkisian was born\n",
      "ner_results [{'word': 'sa', 'score': 0.9096394777297974, 'entity': 'B-PER', 'index': 8, 'start': 29, 'end': 31}, {'word': '##rki', 'score': 0.7825726866722107, 'entity': 'I-PER', 'index': 9, 'start': 31, 'end': 34}, {'word': '##sian', 'score': 0.8939347863197327, 'entity': 'I-PER', 'index': 10, 'start': 34, 'end': 38}]\n",
      "elem sa\n",
      "elem ##rki\n",
      "elem ##sian\n",
      "NER over initial question: \n",
      " This is the city where steve [START] sarkisian [END] was born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was fred bongusto born \n",
      "ner_results [{'word': 'fred', 'score': 0.8422307968139648, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 14}]\n",
      "elem fred\n",
      "NER over initial question: \n",
      " where was [START] fred [END] bongusto born  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is a film in the genre documentary film?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 350/400 [00:40<00:03, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What is a film in the genre documentary film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who composed believe\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " who composed believe ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in what country was a switchback railway filmed in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 354/400 [00:41<00:02, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " in what country was a switchback railway filmed in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " whats the gender of  nuno santos\n",
      "ner_results [{'word': 'nun', 'score': 0.48069679737091064, 'entity': 'B-PER', 'index': 6, 'start': 21, 'end': 24}, {'word': '##o', 'score': 0.5177805423736572, 'entity': 'I-PER', 'index': 7, 'start': 24, 'end': 25}]\n",
      "elem nun\n",
      "elem ##o\n",
      "NER over initial question: \n",
      " whats the gender of  [START] nuno [END] santos ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who created the the character edward cullen\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Who created the the character edward cullen ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is a netflix horror film\n",
      "ner_results [{'word': 'net', 'score': 0.8639613389968872, 'entity': 'B-MISC', 'index': 4, 'start': 10, 'end': 13}, {'word': '##f', 'score': 0.4134286046028137, 'entity': 'I-MISC', 'index': 5, 'start': 13, 'end': 14}, {'word': '##li', 'score': 0.5120739340782166, 'entity': 'I-MISC', 'index': 6, 'start': 14, 'end': 16}, {'word': '##x', 'score': 0.8132520914077759, 'entity': 'I-MISC', 'index': 7, 'start': 16, 'end': 17}]\n",
      "elem net\n",
      "elem ##f\n",
      "elem ##li\n",
      "elem ##x\n",
      "NER over initial question: \n",
      " what is a [START] netflix [END] horror film ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what film is directed by richard fleischer?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what film is directed by richard fleischer ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country is pascale arbillot from\n",
      "ner_results [{'word': 'pas', 'score': 0.5555003881454468, 'entity': 'B-LOC', 'index': 4, 'start': 17, 'end': 20}]\n",
      "elem pas\n",
      "NER over initial question: \n",
      " which country is pascale arbillot from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What is donald crews's gender\n",
      "ner_results [{'word': 'dona', 'score': 0.5253748893737793, 'entity': 'B-ORG', 'index': 3, 'start': 8, 'end': 12}]\n",
      "elem dona\n",
      "NER over initial question: \n",
      " What is donald crews's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was g. stanley hall born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 361/400 [00:41<00:01, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'stan', 'score': 0.9227929711341858, 'entity': 'B-LOC', 'index': 5, 'start': 13, 'end': 17}]\n",
      "elem stan\n",
      "NER over initial question: \n",
      " Where was g. stanley hall born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where did lon kauffman die\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Where did lon kauffman die ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country gives nationality to ibrahim mahlab\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what country gives nationality to ibrahim mahlab ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is jim matt's genre of choice?\n",
      "ner_results [{'word': 'jim', 'score': 0.4659993648529053, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 11}]\n",
      "elem jim\n",
      "NER over initial question: \n",
      " what is [START] jim [END] matt's genre of choice ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a drama film found on Netflix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 367/400 [00:41<00:01, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'Netflix', 'score': 0.9945391416549683, 'entity': 'B-ORG', 'index': 7, 'start': 27, 'end': 34}]\n",
      "elem Netflix\n",
      "NER over initial question: \n",
      " Name a drama film found on [START] Netflix [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is kennedy space center named after?\n",
      "ner_results [{'word': 'ken', 'score': 0.7743901014328003, 'entity': 'B-LOC', 'index': 3, 'start': 7, 'end': 10}, {'word': '##ned', 'score': 0.45777788758277893, 'entity': 'I-LOC', 'index': 4, 'start': 10, 'end': 13}, {'word': '##y', 'score': 0.46428176760673523, 'entity': 'I-LOC', 'index': 5, 'start': 13, 'end': 14}]\n",
      "elem ken\n",
      "elem ##ned\n",
      "elem ##y\n",
      "NER over initial question: \n",
      " who is [START] kennedy [END] space center named after ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which position in basketball does tyler zeller play?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " which position in basketball does tyler zeller play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what language is cold fever filmed in?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what language is cold fever filmed in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was tetsuz sawa born?\n",
      "ner_results [{'word': 'te', 'score': 0.9980255961418152, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}, {'word': '##tsu', 'score': 0.7280230522155762, 'entity': 'B-PER', 'index': 4, 'start': 12, 'end': 15}, {'word': '##z', 'score': 0.9250954389572144, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 16}, {'word': '##', 'score': 0.9861956238746643, 'entity': 'I-PER', 'index': 6, 'start': 16, 'end': 17}, {'word': '', 'score': 0.9994287490844727, 'entity': 'I-PER', 'index': 7, 'start': 18, 'end': 19}, {'word': '##saw', 'score': 0.9997416138648987, 'entity': 'I-PER', 'index': 8, 'start': 19, 'end': 22}, {'word': '##a', 'score': 0.999600350856781, 'entity': 'I-PER', 'index': 9, 'start': 22, 'end': 23}]\n",
      "elem te\n",
      "elem ##tsu\n",
      "elem ##z\n",
      "elem ##\n",
      "elem \n",
      "elem ##saw\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " Where was [START] tetsuz sawa [END] born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country released the movie once upon a time\n",
      "ner_results [{'word': 'which', 'score': 0.3056555986404419, 'entity': 'B-LOC', 'index': 1, 'start': 0, 'end': 5}]\n",
      "elem which\n",
      "NER over initial question: \n",
      " [START] which [END] country released the movie once upon a time ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Name a notable thrash metal artist\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " Name a notable thrash metal artist ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " fabric 14: stacey pullen is what type of music\n",
      "ner_results [{'word': 'sta', 'score': 0.6661722660064697, 'entity': 'B-MISC', 'index': 5, 'start': 11, 'end': 14}, {'word': '##cey', 'score': 0.6219815015792847, 'entity': 'I-MISC', 'index': 6, 'start': 14, 'end': 17}]\n",
      "elem sta\n",
      "elem ##cey\n",
      "NER over initial question: \n",
      " fabric 14: [START] stacey [END] pullen is what type of music ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who's the directed credited for anna and the king of siam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 373/400 [00:42<00:02, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " Who's the directed credited for anna and the king of siam ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who is a person born in breda\n",
      "ner_results [{'word': 'bred', 'score': 0.37964439392089844, 'entity': 'B-MISC', 'index': 7, 'start': 24, 'end': 28}, {'word': '##a', 'score': 0.2564886808395386, 'entity': 'B-MISC', 'index': 8, 'start': 28, 'end': 29}]\n",
      "elem bred\n",
      "elem ##a\n",
      "NER over initial question: \n",
      " who is a person born in [START] breda [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " is mike burgoyne male or female\n",
      "ner_results [{'word': 'bu', 'score': 0.820504367351532, 'entity': 'B-MISC', 'index': 4, 'start': 8, 'end': 10}, {'word': '##rgo', 'score': 0.4373452365398407, 'entity': 'B-MISC', 'index': 5, 'start': 10, 'end': 13}]\n",
      "elem bu\n",
      "elem ##rgo\n",
      "NER over initial question: \n",
      " is mike burgoyne male or female ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What country was the film tales that witness madness?\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " What country was the film tales that witness madness ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Who's a pianist born in philadelphia\n",
      "ner_results [{'word': 'phi', 'score': 0.8154208660125732, 'entity': 'B-LOC', 'index': 8, 'start': 24, 'end': 27}]\n",
      "elem phi\n",
      "NER over initial question: \n",
      " Who's a pianist born in philadelphia ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What's an adventure game made by telltale games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 379/400 [00:42<00:01, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'tell', 'score': 0.7400925159454346, 'entity': 'B-MISC', 'index': 9, 'start': 33, 'end': 37}]\n",
      "elem tell\n",
      "NER over initial question: \n",
      " What's an adventure game made by telltale games ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Which country created the film thunichal\n",
      "ner_results [{'word': 'thu', 'score': 0.5032739639282227, 'entity': 'B-MISC', 'index': 8, 'start': 31, 'end': 34}]\n",
      "elem thu\n",
      "NER over initial question: \n",
      " Which country created the film thunichal ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " Where was the american actor paul america born?\n",
      "ner_results [{'word': 'american', 'score': 0.7626768946647644, 'entity': 'B-MISC', 'index': 4, 'start': 14, 'end': 22}]\n",
      "elem american\n",
      "NER over initial question: \n",
      " Where was the [START] american [END] actor paul america born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which production company made piglet's big movie\n",
      "ner_results [{'word': 'pi', 'score': 0.39014527201652527, 'entity': 'B-PER', 'index': 5, 'start': 30, 'end': 32}]\n",
      "elem pi\n",
      "NER over initial question: \n",
      " which production company made piglet's big movie ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what gameplay mode does feel the magic: xy/xx have\n",
      "ner_results [{'word': 'x', 'score': 0.7850238680839539, 'entity': 'B-MISC', 'index': 9, 'start': 40, 'end': 41}]\n",
      "elem x\n",
      "NER over initial question: \n",
      " what gameplay mode does feel the magic: xy/xx have ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was john mckelvey born \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 382/400 [00:42<00:01, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'jo', 'score': 0.9759240746498108, 'entity': 'B-PER', 'index': 3, 'start': 10, 'end': 12}, {'word': '##hn', 'score': 0.7851604223251343, 'entity': 'I-PER', 'index': 4, 'start': 12, 'end': 14}, {'word': 'm', 'score': 0.9388988614082336, 'entity': 'I-PER', 'index': 5, 'start': 15, 'end': 16}, {'word': '##ckel', 'score': 0.9205625057220459, 'entity': 'I-PER', 'index': 6, 'start': 16, 'end': 20}, {'word': '##vey', 'score': 0.9537380337715149, 'entity': 'I-PER', 'index': 7, 'start': 20, 'end': 23}]\n",
      "elem jo\n",
      "elem ##hn\n",
      "elem m\n",
      "elem ##ckel\n",
      "elem ##vey\n",
      "NER over initial question: \n",
      " where was [START] john mckelvey [END] born  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what gymnast is the daughter of terry yorath \n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what gymnast is the daughter of terry yorath  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is mike mcgee most known for\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what is mike mcgee most known for ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what type of film is lips of blood\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what type of film is lips of blood ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where in britain was sarah badel born?\n",
      "ner_results [{'word': 'brit', 'score': 0.6837582588195801, 'entity': 'B-MISC', 'index': 3, 'start': 9, 'end': 13}]\n",
      "elem brit\n",
      "NER over initial question: \n",
      " where in britain was sarah badel born ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " The album titled profile ii: the best of emmylou harris is from which artist?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 388/400 [00:44<00:01,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'em', 'score': 0.6562450528144836, 'entity': 'B-PER', 'index': 10, 'start': 41, 'end': 43}, {'word': '##my', 'score': 0.45618554949760437, 'entity': 'I-PER', 'index': 11, 'start': 43, 'end': 45}, {'word': '##lou', 'score': 0.4335818886756897, 'entity': 'I-PER', 'index': 12, 'start': 45, 'end': 48}]\n",
      "elem em\n",
      "elem ##my\n",
      "elem ##lou\n",
      "NER over initial question: \n",
      " The album titled profile ii: the best of [START] emmylou [END] harris is from which artist ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " of which language is cash mccall in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " of which language is cash mccall in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what instrument does vctor espnola play \n",
      "ner_results [{'word': 'v', 'score': 0.7170430421829224, 'entity': 'B-MISC', 'index': 4, 'start': 21, 'end': 23}, {'word': '##ctor', 'score': 0.4038808345794678, 'entity': 'I-MISC', 'index': 5, 'start': 23, 'end': 27}, {'word': 'es', 'score': 0.3556306064128876, 'entity': 'I-MISC', 'index': 6, 'start': 28, 'end': 30}, {'word': '##p', 'score': 0.5247237682342529, 'entity': 'I-MISC', 'index': 7, 'start': 30, 'end': 32}, {'word': '##nol', 'score': 0.6705613732337952, 'entity': 'I-MISC', 'index': 8, 'start': 32, 'end': 35}]\n",
      "elem v\n",
      "elem ##ctor\n",
      "elem es\n",
      "elem ##p\n",
      "elem ##nol\n",
      "NER over initial question: \n",
      " what instrument does [START] vctor [END] espnola play  ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " made from technetium could be best described as what?\n",
      "ner_results [{'word': 'tech', 'score': 0.5973988771438599, 'entity': 'B-MISC', 'index': 3, 'start': 10, 'end': 14}]\n",
      "elem tech\n",
      "NER over initial question: \n",
      " made from technetium could be best described as what ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what county is gettysburg from?\n",
      "ner_results [{'word': 'get', 'score': 0.9608449935913086, 'entity': 'B-LOC', 'index': 4, 'start': 15, 'end': 18}, {'word': '##tys', 'score': 0.8874747157096863, 'entity': 'I-LOC', 'index': 5, 'start': 18, 'end': 21}, {'word': '##burg', 'score': 0.9941928386688232, 'entity': 'I-LOC', 'index': 6, 'start': 21, 'end': 25}]\n",
      "elem get\n",
      "elem ##tys\n",
      "elem ##burg\n",
      "NER over initial question: \n",
      " what county is [START] gettysburg [END] from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What conflict did friedrich jeckeln partake in?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 393/400 [00:44<00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'fri', 'score': 0.6010605692863464, 'entity': 'B-MISC', 'index': 4, 'start': 18, 'end': 21}]\n",
      "elem fri\n",
      "NER over initial question: \n",
      " What conflict did friedrich jeckeln partake in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which country is mackenzie davis from\n",
      "ner_results [{'word': 'mac', 'score': 0.790265679359436, 'entity': 'B-LOC', 'index': 4, 'start': 17, 'end': 20}, {'word': '##ken', 'score': 0.4484028220176697, 'entity': 'I-LOC', 'index': 5, 'start': 20, 'end': 23}, {'word': '##zie', 'score': 0.47748467326164246, 'entity': 'I-LOC', 'index': 6, 'start': 23, 'end': 26}]\n",
      "elem mac\n",
      "elem ##ken\n",
      "elem ##zie\n",
      "NER over initial question: \n",
      " which country is [START] mackenzie [END] davis from ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what country was breaking the waves released in\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " what country was breaking the waves released in ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " who was born in teddington\n",
      "ner_results [{'word': 'te', 'score': 0.9984838962554932, 'entity': 'B-LOC', 'index': 5, 'start': 16, 'end': 18}, {'word': '##ddin', 'score': 0.9855822324752808, 'entity': 'I-LOC', 'index': 6, 'start': 18, 'end': 22}, {'word': '##gton', 'score': 0.9795512557029724, 'entity': 'I-LOC', 'index': 7, 'start': 22, 'end': 26}]\n",
      "elem te\n",
      "elem ##ddin\n",
      "elem ##gton\n",
      "NER over initial question: \n",
      " who was born in [START] teddington [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What genre of tv program is grass?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 396/400 [00:44<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results []\n",
      "NER over initial question: \n",
      " What genre of tv program is grass ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " which language is spoken in the show noah\n",
      "ner_results [{'word': 'no', 'score': 0.9754449725151062, 'entity': 'B-MISC', 'index': 8, 'start': 37, 'end': 39}, {'word': '##ah', 'score': 0.9096447229385376, 'entity': 'I-MISC', 'index': 9, 'start': 39, 'end': 41}]\n",
      "elem no\n",
      "elem ##ah\n",
      "NER over initial question: \n",
      " which language is spoken in the show [START] noah [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " in which country was knife edge filmed\n",
      "ner_results []\n",
      "NER over initial question: \n",
      " in which country was knife edge filmed ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " where was jean-christophe mitterrand's place of birth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:45<00:00,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_results [{'word': 'mitte', 'score': 0.6500059366226196, 'entity': 'B-PER', 'index': 9, 'start': 26, 'end': 31}, {'word': '##rran', 'score': 0.5632789731025696, 'entity': 'I-PER', 'index': 10, 'start': 31, 'end': 35}, {'word': '##d', 'score': 0.601681113243103, 'entity': 'I-PER', 'index': 11, 'start': 35, 'end': 36}]\n",
      "elem mitte\n",
      "elem ##rran\n",
      "elem ##d\n",
      "NER over initial question: \n",
      " where was jean-christophe mitterrand's place of birth ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " What category of celestial object is 15412 schaefer?\n",
      "ner_results [{'word': '1541', 'score': 0.826678991317749, 'entity': 'B-LOC', 'index': 8, 'start': 37, 'end': 41}, {'word': '##2', 'score': 0.48941630125045776, 'entity': 'I-LOC', 'index': 9, 'start': 41, 'end': 42}, {'word': 's', 'score': 0.4831588566303253, 'entity': 'I-LOC', 'index': 10, 'start': 43, 'end': 44}, {'word': '##cha', 'score': 0.7365809679031372, 'entity': 'I-LOC', 'index': 11, 'start': 44, 'end': 47}, {'word': '##efer', 'score': 0.7689307928085327, 'entity': 'I-LOC', 'index': 12, 'start': 47, 'end': 51}]\n",
      "elem 1541\n",
      "elem ##2\n",
      "elem s\n",
      "elem ##cha\n",
      "elem ##efer\n",
      "NER over initial question: \n",
      " What category of celestial object is [START] 15412 schaefer [END] ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what kind of music does jim conway play\n",
      "ner_results [{'word': 'jim', 'score': 0.3688376247882843, 'entity': 'B-ORG', 'index': 6, 'start': 24, 'end': 27}]\n",
      "elem jim\n",
      "NER over initial question: \n",
      " what kind of music does [START] jim [END] conway play ?\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Initial question: \n",
      " what is mballa zambo's gender?\n",
      "ner_results [{'word': 'm', 'score': 0.4417704641819, 'entity': 'B-MISC', 'index': 3, 'start': 8, 'end': 9}, {'word': '##ball', 'score': 0.3328281342983246, 'entity': 'I-PER', 'index': 4, 'start': 9, 'end': 13}, {'word': '##a', 'score': 0.5876283049583435, 'entity': 'I-PER', 'index': 5, 'start': 13, 'end': 14}, {'word': 'za', 'score': 0.5087464451789856, 'entity': 'I-PER', 'index': 6, 'start': 15, 'end': 17}, {'word': '##mbo', 'score': 0.48250100016593933, 'entity': 'I-PER', 'index': 7, 'start': 17, 'end': 20}]\n",
      "elem m\n",
      "elem ##ball\n",
      "elem ##a\n",
      "elem za\n",
      "elem ##mbo\n",
      "NER over initial question: \n",
      " what is [START] mballa [END] zambo's gender ?\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NER\n",
    "changed_texts = []\n",
    "for question in tqdm(texts):\n",
    "    print(\"Initial question: \\n\", question)\n",
    "    \n",
    "    # load text\n",
    "    ner.receive_text(text = question)\n",
    "    \n",
    "    # receive text with marked entities\n",
    "    new_text = ner.text_with_marked_entities()\n",
    "    changed_texts.append(new_text)\n",
    "    print(\"NER over initial question: \\n\", new_text)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.sample(n = n, replace = False, random_state=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'changed_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b1049f0a8404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_with_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchanged_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'changed_texts' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"question_with_tokens\"] = changed_texts\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:03:22.459928\n"
     ]
    }
   ],
   "source": [
    "n = 400\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "mGENRE_results = model_mGENRE.sample(\n",
    "                                    list(df[\"question_with_tokens\"]),\n",
    "                                    beam = 3,\n",
    "                                    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "                                        e for e in trie.get(sent.tolist())\n",
    "                                        if e < len(model_mGENRE.task.target_dictionary)\n",
    "                                    ],\n",
    "                                    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "                                    marginalize=True,\n",
    "                                    verbose = True\n",
    "                                )\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  -10.00 \t accuracy =  21.00 %\t number of observations =  400 \t share of observations =  100.00 %\n",
      "threshold =  -3.00 \t accuracy =  21.71 %\t number of observations =  387 \t share of observations =  96.75 %\n",
      "threshold =  -2.00 \t accuracy =  24.17 %\t number of observations =  331 \t share of observations =  82.75 %\n",
      "threshold =  -1.50 \t accuracy =  27.14 %\t number of observations =  269 \t share of observations =  67.25 %\n",
      "threshold =  -1.00 \t accuracy =  34.09 %\t number of observations =  176 \t share of observations =  44.00 %\n",
      "threshold =  -0.75 \t accuracy =  34.75 %\t number of observations =  141 \t share of observations =  35.25 %\n",
      "threshold =  -0.60 \t accuracy =  38.26 %\t number of observations =  115 \t share of observations =  28.75 %\n",
      "threshold =  -0.40 \t accuracy =  44.59 %\t number of observations =  74 \t share of observations =  18.50 %\n",
      "threshold =  -0.20 \t accuracy =  57.14 %\t number of observations =  35 \t share of observations =  8.75 %\n",
      "threshold =  -0.10 \t accuracy =  90.91 %\t number of observations =  11 \t share of observations =  2.75 %\n"
     ]
    }
   ],
   "source": [
    "thresholds = [-10, -3, -2, -1.5, -1, -0.75, -0.6, -0.4, -0.2, -0.1]\n",
    "accuracy_400_ner_top_1 = []\n",
    "share_of_observations_400_ner_top_1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    certain_out = [i[0]['id'] for i in mGENRE_results if i[0]['score'] > threshold]\n",
    "    indexes = [1 if i[0]['score'] > threshold else 0 for i in mGENRE_results]\n",
    "    y_true = list(compress(list(df.loc[:,\"object\"]), indexes))\n",
    "    \n",
    "    result = [x in certain_out for x in y_true] \n",
    "    accuracy = np.round(sum(result)/len(result), 4)*100\n",
    "    accuracy_400_ner_top_1.append(accuracy)\n",
    "    share = np.round(len(result)/n*100, 4)\n",
    "    share_of_observations_400_ner_top_1.append(share)\n",
    "    \n",
    "    print(\"threshold = \", format(threshold, '.2f'), \"\\t\",\n",
    "          \"accuracy = \", format(accuracy, '.2f'), \"%\\t\", \n",
    "          \"number of observations = \", len(result), '\\t',\n",
    "          \"share of observations = \",  format(share, '.2f'), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"rejection rate, %\", fontsize = 20)\n",
    "plt.ylabel(\"accuracy, %\", fontsize = 20)\n",
    "plt.title(\"mGENRE certainty basing on 400 random samples\")\n",
    "plt.plot(share_of_observations_400_top_1[::-1], accuracy_400_top_1, label = \"w/o ner\", c = \"red\", marker = '.', markersize = 15);\n",
    "\n",
    "plt.plot(share_of_observations_400_ner_top_1[::-1], accuracy_400_ner_top_1, label = \"with ner\", c = \"blue\", marker = '.', markersize = 15);\n",
    "plt.legend(fontsize = 15);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another NER models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = ''' I want a person available 7 days and with prompt response all most every time. Only Indian freelancer need I need PHP developer who have strong experience in Laravel and Codeigniter framework for daily 4 hours. I need this work by Monday 27th Jan. should be free from plagiarism . \n",
    "Need SAP FICO consultant for support project needs to be work on 6 months on FI AREAWe.  Want a same site to be created as the same as this https://www.facebook.com/?ref=logo, please check the site before contacting to me and i want this site to be ready in 10 days. They will be ready at noon tomorrow .'''\n",
    "\n",
    "russian_text = '''   110     ,     .        https://www.sobyanin.ru/  , 1 .     .51 (   :  , )  ?     2107   47     24,    . \n",
    " c        10  1970 ,     -, . ,  5/1 8 000 ( )  00  .               .              - .'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/petrakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/petrakov/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/petrakov/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /home/petrakov/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPE Indian/JJ)\n",
      "(ORGANIZATION PHP/NNP)\n",
      "(GPE Laravel/NNP)\n",
      "(PERSON Need/NNP)\n",
      "(ORGANIZATION SAP/NNP)\n",
      "(ORGANIZATION FI/NNP)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "for sent in nltk.sent_tokenize(english_text):\n",
    "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "      if hasattr(chunk, 'label'):\n",
    "         print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPE Name/NN)\n",
      "(PERSON Alan/NNP Pierson/NNP)\n",
      "(GPE Which/NNP)\n",
      "(GPE Name/NN)\n",
      "(GPE Which/JJ)\n",
      "(GPE Which/JJ)\n",
      "(GPE Queens/NNP University/NNP)\n",
      "(ORGANIZATION Bangladesh/NNP)\n",
      "(PERSON Claire/NNP Stansfield/NNP)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,100):\n",
    "    for sent in nltk.sent_tokenize(data.loc[i,\"question\"]):\n",
    "       for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "          if hasattr(chunk, 'label'):\n",
    "             print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.tag.stanford.StanfordNERTagger'; 'nltk.tag.stanford' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-f201a0288361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStanfordNERTagger\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stanford-ner-2015-04-20/stanford-ner-3.5.2.jar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stanford-ner-2015-04-20/classifiers/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mst_3class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"english.all.3class.distsim.crf.ser.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst_4class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"english.conll.4class.distsim.crf.ser.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.tag.stanford.StanfordNERTagger'; 'nltk.tag.stanford' is not a package"
     ]
    }
   ],
   "source": [
    "import nltk.tag.stanford.StanfordNERTagger as StanfordNERTagger\n",
    "jar = \"stanford-ner-2015-04-20/stanford-ner-3.5.2.jar\"\n",
    "model = \"stanford-ner-2015-04-20/classifiers/\" \n",
    "st_3class = StanfordNERTagger(model + \"english.all.3class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
    "st_4class = StanfordNERTagger(model + \"english.conll.4class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
    "st_7class = StanfordNERTagger(model + \"english.muc.7class.distsim.crf.ser.gz\", jar, encoding='utf8')\n",
    "for i in [st_3class.tag(english_text.split()), st_4class.tag(english_text.split()), st_7class.tag(english_text.split())]:\n",
    "  for b in i:\n",
    "    if b[1] != 'O':\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (4.62.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (835 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m835.9/835.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (59.5.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4\n",
      "  Using cached pydantic-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (1.23.1)\n",
      "Requirement already satisfied: jinja2 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (3.0.3)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/petrakov/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/petrakov/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/petrakov/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/petrakov/.local/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/petrakov/.local/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: wasabi, murmurhash, cymem, typer, spacy-loggers, spacy-legacy, smart-open, pydantic, preshed, langcodes, catalogue, blis, srsly, pathy, thinc, spacy\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 6.0.0\n",
      "    Uninstalling smart-open-6.0.0:\n",
      "      Successfully uninstalled smart-open-6.0.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.3\n",
      "    Uninstalling pydantic-1.3:\n",
      "      Successfully uninstalled pydantic-1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flair 0.6.1 requires scikit-learn>=0.21.3, but you have scikit-learn 0.21.2 which is incompatible.\n",
      "deeppavlov 0.17.4 requires numpy==1.18.0, but you have numpy 1.23.1 which is incompatible.\n",
      "deeppavlov 0.17.4 requires pydantic==1.3, but you have pydantic 1.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-0.7.8 catalogue-2.0.7 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.7 pathy-0.6.2 preshed-3.0.6 pydantic-1.9.1 smart-open-5.2.1 spacy-3.4.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.1.0 typer-0.4.2 wasabi-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 days DATE\n",
      "Indian NORP\n",
      "Laravel GPE\n",
      "daily DATE\n",
      "4 hours TIME\n",
      "Monday 27th Jan. DATE\n",
      "6 months DATE\n",
      "https://www.facebook.com/?ref=logo ORG\n",
      "10 days DATE\n",
      "noon TIME\n",
      "tomorrow DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "\n",
    "model_sp = en_core_web_lg.load()\n",
    "for ent in model_sp(english_text).ents:\n",
    "  print(ent.text.strip(), ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question num:  0 \n",
      " question:  who is a musician born in detroit\n",
      "entity:  detroit \n",
      " label:  GPE \n",
      "\n",
      "question num:  1 \n",
      " question:  what is the language in which mera shikar was filmed in\n",
      "entity:  mera shikar \n",
      " label:  PERSON \n",
      "\n",
      "question num:  2 \n",
      " question:  Whats the name of a battle that happened in chicago\n",
      "entity:  chicago \n",
      " label:  GPE \n",
      "\n",
      "question num:  3 \n",
      " question:  what player plays the position midfielder?\n",
      "question num:  4 \n",
      " question:  what is the position that  mike twellman plays\n",
      "entity:  mike twellman \n",
      " label:  PERSON \n",
      "\n",
      "question num:  5 \n",
      " question:  list some musical films\n",
      "question num:  6 \n",
      " question:  what is ellen swallow richards's nationality?\n",
      "entity:  richards \n",
      " label:  PERSON \n",
      "\n",
      "question num:  7 \n",
      " question:  What language is the show elementary broadcast in?\n",
      "question num:  8 \n",
      " question:  what is the gender of james hendry?\n",
      "entity:  james hendry \n",
      " label:  PERSON \n",
      "\n",
      "question num:  9 \n",
      " question:  who was a voice actor?\n",
      "question num:  10 \n",
      " question:  What is a member of the 1893 jakoba asteroid group?\n",
      "entity:  1893 \n",
      " label:  DATE \n",
      "\n",
      "entity:  jakoba asteroid \n",
      " label:  FAC \n",
      "\n",
      "question num:  11 \n",
      " question:  What artist includes black star at the point of darkness in his work?\n",
      "question num:  12 \n",
      " question:  Name an album by serge gainsbourg\n",
      "entity:  serge gainsbourg \n",
      " label:  PERSON \n",
      "\n",
      "question num:  13 \n",
      " question:  what is a book by laura ingalls wilder \n",
      "entity:  laura ingalls \n",
      " label:  PERSON \n",
      "\n",
      "question num:  14 \n",
      " question:  Who was the cinematographer for the film endless love?\n",
      "question num:  15 \n",
      " question:  what is a documentary film about the media\n",
      "question num:  16 \n",
      " question:  what musical genre does  brandon reilly create\n",
      "entity:  brandon reilly \n",
      " label:  PERSON \n",
      "\n",
      "question num:  17 \n",
      " question:  What sport does notre dame fighting irish men's basketball play\n",
      "entity:  notre dame fighting \n",
      " label:  ORG \n",
      "\n",
      "question num:  18 \n",
      " question:  where in germany was rudi ball born in?\n",
      "entity:  germany \n",
      " label:  GPE \n",
      "\n",
      "entity:  rudi ball \n",
      " label:  PERSON \n",
      "\n",
      "question num:  19 \n",
      " question:  what time zone is marrakech in?\n",
      "question num:  20 \n",
      " question:  which country does harry blackstone, jr. come from\n",
      "entity:  harry blackstone \n",
      " label:  PERSON \n",
      "\n",
      "question num:  21 \n",
      " question:  what is valeria richards's gender?\n",
      "entity:  valeria richards's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  22 \n",
      " question:  what movie did liliana cavani direct?\n",
      "entity:  liliana \n",
      " label:  ORG \n",
      "\n",
      "question num:  23 \n",
      " question:  What kind of video game is the dog island\n",
      "question num:  24 \n",
      " question:  who created the loves of the gods\n",
      "question num:  25 \n",
      " question:  What did jane austen write?\n",
      "entity:  jane austen \n",
      " label:  PERSON \n",
      "\n",
      "question num:  26 \n",
      " question:  What is the nationality of estella warren?\n",
      "entity:  estella warren \n",
      " label:  ORG \n",
      "\n",
      "question num:  27 \n",
      " question:  what is a second level division of turkey\n",
      "entity:  second \n",
      " label:  ORDINAL \n",
      "\n",
      "question num:  28 \n",
      " question:  what gender does eugnio sales identify as \n",
      "question num:  29 \n",
      " question:  Name a person born in chicago.\n",
      "entity:  chicago \n",
      " label:  GPE \n",
      "\n",
      "question num:  30 \n",
      " question:  who is the artist on seven wishes\n",
      "entity:  seven \n",
      " label:  CARDINAL \n",
      "\n",
      "question num:  31 \n",
      " question:  who wrote the music for gangs of new york\n",
      "entity:  new york \n",
      " label:  GPE \n",
      "\n",
      "question num:  32 \n",
      " question:  what is the gender of sophie merry?\n",
      "entity:  sophie merry \n",
      " label:  ORG \n",
      "\n",
      "question num:  33 \n",
      " question:  what is an episode written by michelle ashford\n",
      "entity:  michelle ashford \n",
      " label:  PERSON \n",
      "\n",
      "question num:  34 \n",
      " question:  what movies has francis ford coppola contributed music to\n",
      "entity:  francis ford coppola \n",
      " label:  PERSON \n",
      "\n",
      "question num:  35 \n",
      " question:  which is the main ideology of the communist party of britain?\n",
      "entity:  the communist party \n",
      " label:  ORG \n",
      "\n",
      "entity:  britain \n",
      " label:  GPE \n",
      "\n",
      "question num:  36 \n",
      " question:  what former basketball played the center (basketball) position\n",
      "question num:  37 \n",
      " question:  Who wrote the film thunderbolt and lightfoot?\n",
      "question num:  38 \n",
      " question:  where in the united states was john morris russell born\n",
      "entity:  the united states \n",
      " label:  GPE \n",
      "\n",
      "entity:  john morris russell \n",
      " label:  PERSON \n",
      "\n",
      "question num:  39 \n",
      " question:  what is imam mustafayev's gender\n",
      "entity:  imam mustafayev's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  40 \n",
      " question:  what is fausto fawcett's gender\n",
      "entity:  fausto fawcett's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  41 \n",
      " question:  what type of film is generation kill\n",
      "question num:  42 \n",
      " question:  What county has jurisdiction over chokoloskee, florida\n",
      "entity:  chokoloskee \n",
      " label:  GPE \n",
      "\n",
      "entity:  florida \n",
      " label:  GPE \n",
      "\n",
      "question num:  43 \n",
      " question:  which country is john berry from \n",
      "question num:  44 \n",
      " question:  What kind of book is home?\n",
      "question num:  45 \n",
      " question:  what country is cosmic ray from\n",
      "question num:  46 \n",
      " question:  what is the administrative child of zou?\n",
      "question num:  47 \n",
      " question:  What is Alan Pierson's gender?\n",
      "entity:  Alan Pierson's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  48 \n",
      " question:  What was the nationality of  franz roh\n",
      "entity:  franz roh \n",
      " label:  ORG \n",
      "\n",
      "question num:  49 \n",
      " question:  what is a city located in huron county\n",
      "entity:  huron county \n",
      " label:  GPE \n",
      "\n",
      "question num:  50 \n",
      " question:  What is an example of a documentary film?\n",
      "question num:  51 \n",
      " question:  What actor was born in lodz\n",
      "question num:  52 \n",
      " question:  what member of asteroid group is 8668 satomimura a part of \n",
      "question num:  53 \n",
      " question:  What gender is elizabeth malecki\n",
      "entity:  elizabeth malecki \n",
      " label:  PERSON \n",
      "\n",
      "question num:  54 \n",
      " question:  where was  james gillespie buried\n",
      "entity:  james gillespie \n",
      " label:  PERSON \n",
      "\n",
      "question num:  55 \n",
      " question:  who was born in pittsburgh\n",
      "entity:  pittsburgh \n",
      " label:  GPE \n",
      "\n",
      "question num:  56 \n",
      " question:  lannie balcom self-identifies as which gender? \n",
      "entity:  lannie balcom \n",
      " label:  PERSON \n",
      "\n",
      "question num:  57 \n",
      " question:  which position does robert williams play in american football\n",
      "entity:  robert williams \n",
      " label:  PERSON \n",
      "\n",
      "entity:  american \n",
      " label:  NORP \n",
      "\n",
      "question num:  58 \n",
      " question:  who is an instrumentalist that plays the guitar\n",
      "question num:  59 \n",
      " question:  Who wrote the book the city in the autumn stars\n",
      "question num:  60 \n",
      " question:  Who was a parent of john of gaunt, 1st duke of lancaster\n",
      "entity:  john of gaunt \n",
      " label:  PERSON \n",
      "\n",
      "entity:  1st \n",
      " label:  ORDINAL \n",
      "\n",
      "question num:  61 \n",
      " question:  chris cash is what nationality\n",
      "entity:  chris \n",
      " label:  PERSON \n",
      "\n",
      "question num:  62 \n",
      " question:  in what language is the the law is the law film spoken\n",
      "question num:  63 \n",
      " question:  who discovered 6945 dahlgren\n",
      "entity:  6945 \n",
      " label:  CARDINAL \n",
      "\n",
      "question num:  64 \n",
      " question:  Where is frederick baldwin adams from?\n",
      "entity:  frederick baldwin adams \n",
      " label:  PERSON \n",
      "\n",
      "question num:  65 \n",
      " question:  Who's a hungarian model\n",
      "entity:  hungarian \n",
      " label:  NORP \n",
      "\n",
      "question num:  66 \n",
      " question:  what is joshua smith's gender\n",
      "entity:  joshua smith's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  67 \n",
      " question:  What label is rapture ruckus  signed to\n",
      "question num:  68 \n",
      " question:  Which film did rob schmidt direct?\n",
      "entity:  schmidt \n",
      " label:  PERSON \n",
      "\n",
      "question num:  69 \n",
      " question:  Name a person born in montilla\n",
      "entity:  montilla \n",
      " label:  GPE \n",
      "\n",
      "question num:  70 \n",
      " question:  who was the director of mr. hankey's christmas classics \n",
      "entity:  hankey \n",
      " label:  PERSON \n",
      "\n",
      "entity:  christmas \n",
      " label:  DATE \n",
      "\n",
      "question num:  71 \n",
      " question:  Where is ottilie assing from?\n",
      "question num:  72 \n",
      " question:  Name someone who was born in mytilene\n",
      "question num:  73 \n",
      " question:  what is a film in the genre drama\n",
      "question num:  74 \n",
      " question:  Which series has a pilot episode?\n",
      "question num:  75 \n",
      " question:  what is a horror film?\n",
      "question num:  76 \n",
      " question:  what country does the film stealing a nation take place in\n",
      "question num:  77 \n",
      " question:  which type of music genre does carlos johnson play in?\n",
      "entity:  carlos johnson play \n",
      " label:  PERSON \n",
      "\n",
      "question num:  78 \n",
      " question:  Which town was thomas sully born? \n",
      "question num:  79 \n",
      " question:  What position does kelly shoppach play in baseball\n",
      "entity:  kelly shoppach \n",
      " label:  PERSON \n",
      "\n",
      "question num:  80 \n",
      " question:  what kind of movie is dracula?\n",
      "entity:  dracula \n",
      " label:  PERSON \n",
      "\n",
      "question num:  81 \n",
      " question:  what is politician is founder and chairperson of Queens University, Bangladesh\n",
      "entity:  Queens University \n",
      " label:  ORG \n",
      "\n",
      "entity:  Bangladesh \n",
      " label:  GPE \n",
      "\n",
      "question num:  82 \n",
      " question:  What language is spoken in the film life goes on\n",
      "question num:  83 \n",
      " question:  who is the parent of bob woodward?\n",
      "entity:  bob woodward \n",
      " label:  PERSON \n",
      "\n",
      "question num:  84 \n",
      " question:  what kind of game is knight lore\n",
      "question num:  85 \n",
      " question:  what film does gregory la cava direct?\n",
      "entity:  gregory la \n",
      " label:  PERSON \n",
      "\n",
      "question num:  86 \n",
      " question:  what artist makes celtic rock?\n",
      "entity:  celtic rock \n",
      " label:  ORG \n",
      "\n",
      "question num:  87 \n",
      " question:  What is the place of barbara cook's birth?\n",
      "entity:  barbara cook's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  88 \n",
      " question:  What is Claire Stansfield's nationality?\n",
      "entity:  Claire Stansfield's \n",
      " label:  PERSON \n",
      "\n",
      "question num:  89 \n",
      " question:  What was the cause of death of michel simon\n",
      "entity:  michel simon \n",
      " label:  PERSON \n",
      "\n",
      "question num:  90 \n",
      " question:  What is the nationality of antonio banderas\n",
      "entity:  antonio banderas \n",
      " label:  PERSON \n",
      "\n",
      "question num:  91 \n",
      " question:  which country is willi wild from\n",
      "question num:  92 \n",
      " question:  What sport is cricima esporte clube a part of?\n",
      "entity:  cricima esporte \n",
      " label:  PERSON \n",
      "\n",
      "question num:  93 \n",
      " question:  is adario strange male or female\n",
      "question num:  94 \n",
      " question:  Who is someone born in wittlich\n",
      "entity:  wittlich \n",
      " label:  ORG \n",
      "\n",
      "question num:  95 \n",
      " question:  which historical figure was killed by smallpox\n",
      "question num:  96 \n",
      " question:  what genre is the film on the nickel\n",
      "question num:  97 \n",
      " question:  What is the name of a place located in los angeles county, california\n",
      "entity:  los angeles county \n",
      " label:  GPE \n",
      "\n",
      "entity:  california \n",
      " label:  GPE \n",
      "\n",
      "question num:  98 \n",
      " question:  What is mark difelice position \n",
      "question num:  99 \n",
      " question:  which city was shmuel salant born\n",
      "entity:  shmuel salant \n",
      " label:  PERSON \n",
      "\n",
      "question num:  100 \n",
      " question:  who authored summertide\n"
     ]
    }
   ],
   "source": [
    "for j, question in enumerate(list(data.loc[:100, 'question'])):\n",
    "    print(\"question num: \", j, \"\\n\", \"question: \", question)\n",
    "    for ent in model_sp(question).ents:\n",
    "        print(\"entity: \", ent.text.strip(), \"\\n\", \"label: \", ent.label_, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 05:09:48,693 https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmpqsq3oe4z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 432197603/432197603 [00:38<00:00, 11342440.43B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 05:10:26,989 copying /tmp/tmpqsq3oe4z to cache at /home/petrakov/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-13 05:10:27,364 removing temp file /tmp/tmpqsq3oe4z\n",
      "2022-07-13 05:10:27,422 loading file /home/petrakov/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-da41950b454e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_model_with_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_init_model_with_state_dict\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mreproject_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reproject_to\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         model = SequenceTagger(\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hidden_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_size, embeddings, tag_dictionary, tag_type, use_crf, use_rnn, rnn_layers, dropout, word_dropout, locked_dropout, reproject_embeddings, train_initial_hidden_state, rnn_type, pickle_module, beta, loss_weights)\u001b[0m\n\u001b[1;32m    230\u001b[0m             ] = -10000\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Module'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_grad_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     ) -> RemovableHandle:\n\u001b[0;32m--> 612\u001b[0;31m         r\"\"\"Registers a backward hook on the module.\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mwarning\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_compatible_shallow_copy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# If the new tensor has compatible tensor type as the existing tensor,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;31m# the current behavior is to change the tensor in-place using `.data =`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;31m# and the future behavior is to overwrite the existing tensor. However,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# changing the current behavior is a BC-breaking change, and we want it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    426\u001b[0m                         _flat_weights_names)\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mchild_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_cudnn_rnn_flatten_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     torch._cudnn_rnn_flatten_weight(\n\u001b[0;32m--> 149\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                         self.batch_first, bool(self.bidirectional))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "tagger = SequenceTagger.load('ner')\n",
    "from flair.data import Sentence\n",
    "s = Sentence(english_text)\n",
    "tagger.predict(s)\n",
    "for entity in s.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deeppavlov in /home/petrakov/.local/lib/python3.8/site-packages (0.17.4)\n",
      "Requirement already satisfied: sacremoses==0.0.35 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.0.35)\n",
      "Requirement already satisfied: fastapi==0.47.1 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.47.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: click==7.1.2 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (7.1.2)\n",
      "Requirement already satisfied: uvicorn==0.11.7 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.11.7)\n",
      "Requirement already satisfied: protobuf<4 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.19.4)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: uvloop==0.14.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: aio-pika==6.4.1 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (6.4.1)\n",
      "Requirement already satisfied: requests==2.22.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.7 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.6.7)\n",
      "Collecting pydantic==1.3\n",
      "  Using cached pydantic-1.3-cp38-cp38-manylinux2010_x86_64.whl (9.4 MB)\n",
      "Collecting numpy==1.18.0\n",
      "  Using cached numpy-1.18.0-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "Requirement already satisfied: tqdm==4.62.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (4.62.0)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (2.4.417127.4579844)\n",
      "Requirement already satisfied: Cython==0.29.14 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.29.14)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /usr/lib/python3/dist-packages (from deeppavlov) (0.7.1)\n",
      "Requirement already satisfied: pandas==0.25.3 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.25.3)\n",
      "Requirement already satisfied: h5py==2.10.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (2.10.0)\n",
      "Requirement already satisfied: pyopenssl==22.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (22.0.0)\n",
      "Requirement already satisfied: pytz==2019.1 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (2019.1)\n",
      "Requirement already satisfied: filelock==3.0.12 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.0.12)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: nltk==3.4.5 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (3.4.5)\n",
      "Requirement already satisfied: overrides==2.7.0 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (2.7.0)\n",
      "Requirement already satisfied: ruamel.yaml==0.15.100 in /home/petrakov/.local/lib/python3.8/site-packages (from deeppavlov) (0.15.100)\n",
      "Requirement already satisfied: yarl in /home/petrakov/.local/lib/python3.8/site-packages (from aio-pika==6.4.1->deeppavlov) (1.7.2)\n",
      "Requirement already satisfied: aiormq<4,>=3.2.0 in /home/petrakov/.local/lib/python3.8/site-packages (from aio-pika==6.4.1->deeppavlov) (3.3.1)\n",
      "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /home/petrakov/.local/lib/python3.8/site-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from h5py==2.10.0->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/petrakov/.local/lib/python3.8/site-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /home/petrakov/.local/lib/python3.8/site-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/lib/python3/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /home/petrakov/.local/lib/python3.8/site-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: cryptography>=35.0 in /home/petrakov/.local/lib/python3.8/site-packages (from pyopenssl==22.0.0->deeppavlov) (37.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/petrakov/.local/lib/python3.8/site-packages (from requests==2.22.0->deeppavlov) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/petrakov/.local/lib/python3.8/site-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
      "Requirement already satisfied: websockets==8.* in /home/petrakov/.local/lib/python3.8/site-packages (from uvicorn==0.11.7->deeppavlov) (8.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /home/petrakov/.local/lib/python3.8/site-packages (from uvicorn==0.11.7->deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: httptools==0.1.* in /home/petrakov/.local/lib/python3.8/site-packages (from uvicorn==0.11.7->deeppavlov) (0.1.2)\n",
      "Requirement already satisfied: pamqp==2.3.0 in /home/petrakov/.local/lib/python3.8/site-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/petrakov/.local/lib/python3.8/site-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.0)\n",
      "Requirement already satisfied: multidict>=4.0 in /home/petrakov/.local/lib/python3.8/site-packages (from yarl->aio-pika==6.4.1->deeppavlov) (6.0.2)\n",
      "Requirement already satisfied: pycparser in /home/petrakov/.local/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
      "Installing collected packages: pydantic, numpy\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.1\n",
      "    Uninstalling pydantic-1.9.1:\n",
      "      Successfully uninstalled pydantic-1.9.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
      "thinc 8.1.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
      "spacy 3.4.0 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
      "pytorch-lightning 1.6.4 requires torch>=1.8.*, but you have torch 1.6.0 which is incompatible.\n",
      "lightning 20220621 requires torch<=1.11.0,>=1.9.*, but you have torch 1.6.0 which is incompatible.\n",
      "lightning-bolts 0.6.0.dev0 requires torch>=1.9.*, but you have torch 1.6.0 which is incompatible.\n",
      "flair 0.6.1 requires scikit-learn>=0.21.3, but you have scikit-learn 0.21.2 which is incompatible.\n",
      "datasets 2.3.2 requires huggingface-hub<1.0.0,>=0.1.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "datasets 2.3.2 requires tqdm>=4.62.1, but you have tqdm 4.62.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.18.0 pydantic-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named deeppavlov\r\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install ner_conll2003_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 05:11:52.89 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip to /home/petrakov/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip\n",
      "100%|| 404M/404M [00:09<00:00, 40.6MB/s] \n",
      "2022-07-13 05:12:02.504 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /home/petrakov/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip archive into /home/petrakov/.deeppavlov/downloads/bert_models\n",
      "2022-07-13 05:12:06.584 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_v1.tar.gz to /home/petrakov/.deeppavlov/ner_ontonotes_bert_v1.tar.gz\n",
      "100%|| 805M/805M [00:16<00:00, 49.6MB/s] \n",
      "2022-07-13 05:12:23.212 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /home/petrakov/.deeppavlov/ner_ontonotes_bert_v1.tar.gz archive into /home/petrakov/.deeppavlov/models\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert_dp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-adae2a4540ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mner_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner_ontonotes_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menglish_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, download, serialized)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcomponent_serialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_serialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/common/params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(params, mode, serialized, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/common/registry.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model {} is not registered.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls_from_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls_from_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/common/registry.py\u001b[0m in \u001b[0;36mcls_from_str\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     40\u001b[0m                           .format(name))\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/models/preprocessors/bert_preprocessor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_dp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_dp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFullTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bert_dp'"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_ontonotes_bert, download=True)\n",
    "result = ner_model([english_text])\n",
    "for i in range(len(result[0][0])):\n",
    "     if result [1][0][i] != 'O':\n",
    "         print(result[0][0][i], result[1][0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaptnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting adaptnlp\n",
      "  Downloading adaptnlp-0.3.7-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting seqeval==1.2\n",
      "  Downloading seqeval-1.2.0.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<4.12.3,>=4.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from adaptnlp) (4.6.0)\n",
      "Collecting fastai<=2.5.3,>=2.4.0\n",
      "  Downloading fastai-2.5.3-py3-none-any.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets<=1.15.1,>=1.3.0\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m290.6/290.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flair-82==0.8.2\n",
      "  Downloading flair_82-0.8.2-py3-none-any.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m248.9/248.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch<=1.10.0,>=1.7.0\n",
      "  Downloading torch-1.10.0-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting fastcore<=1.3.27,>=1.3.21\n",
      "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.8.10)\n",
      "Requirement already satisfied: langdetect in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (1.0.9)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (2.0.0)\n",
      "Collecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bpemb>=0.3.2 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (2.8.2)\n",
      "Collecting more-itertools~=8.8.0\n",
      "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: deprecated>=1.2.4 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (1.2.13)\n",
      "Requirement already satisfied: lxml in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (4.9.1)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (4.62.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.2.7)\n",
      "Requirement already satisfied: janome in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.4.2)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (1.5.7)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.5-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gensim<=3.8.3,>=3.4.0\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: konoha<5.0.0,>=4.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (4.6.5)\n",
      "Requirement already satisfied: huggingface-hub in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.0.8)\n",
      "Requirement already satisfied: mpld3==0.3 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (0.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (3.5.2)\n",
      "Requirement already satisfied: regex in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (2019.8.19)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/petrakov/.local/lib/python3.8/site-packages (from flair-82==0.8.2->adaptnlp) (6.1.1)\n",
      "Collecting numpy==1.19.2\n",
      "  Using cached numpy-1.19.2-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests[socks] in /home/petrakov/.local/lib/python3.8/site-packages (from gdown==3.12.2->flair-82==0.8.2->adaptnlp) (2.22.0)\n",
      "Requirement already satisfied: filelock in /home/petrakov/.local/lib/python3.8/site-packages (from gdown==3.12.2->flair-82==0.8.2->adaptnlp) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown==3.12.2->flair-82==0.8.2->adaptnlp) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/petrakov/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair-82==0.8.2->adaptnlp) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/petrakov/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair-82==0.8.2->adaptnlp) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->flair-82==0.8.2->adaptnlp) (3.1.0)\n",
      "Requirement already satisfied: packaging in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (21.3)\n",
      "Collecting tqdm>=4.26.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: pandas in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (0.25.3)\n",
      "Requirement already satisfied: xxhash in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (3.0.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (2022.1.0)\n",
      "Requirement already satisfied: multiprocess in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (0.70.13)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: dill in /home/petrakov/.local/lib/python3.8/site-packages (from datasets<=1.15.1,>=1.3.0->adaptnlp) (0.3.5.1)\n",
      "Requirement already satisfied: pyyaml in /home/petrakov/.local/lib/python3.8/site-packages (from fastai<=2.5.3,>=2.4.0->adaptnlp) (6.0)\n",
      "Requirement already satisfied: pip in /home/petrakov/.local/lib/python3.8/site-packages (from fastai<=2.5.3,>=2.4.0->adaptnlp) (22.1.2)\n",
      "Requirement already satisfied: pillow>6.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from fastai<=2.5.3,>=2.4.0->adaptnlp) (9.1.1)\n",
      "Requirement already satisfied: spacy<4 in /home/petrakov/.local/lib/python3.8/site-packages (from fastai<=2.5.3,>=2.4.0->adaptnlp) (3.4.0)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.2-py3-none-any.whl (12 kB)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting torchvision>=0.8.2\n",
      "  Using cached torchvision-0.13.0-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/petrakov/.local/lib/python3.8/site-packages (from torch<=1.10.0,>=1.7.0->adaptnlp) (4.2.0)\n",
      "Requirement already satisfied: sacremoses in /home/petrakov/.local/lib/python3.8/site-packages (from transformers<4.12.3,>=4.0.0->adaptnlp) (0.0.35)\n",
      "Collecting transformers<4.12.3,>=4.0.0\n",
      "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/petrakov/.local/lib/python3.8/site-packages (from transformers<4.12.3,>=4.0.0->adaptnlp) (0.10.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/petrakov/.local/lib/python3.8/site-packages (from deprecated>=1.2.4->flair-82==0.8.2->adaptnlp) (1.14.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/petrakov/.local/lib/python3.8/site-packages (from gensim<=3.8.3,>=3.4.0->flair-82==0.8.2->adaptnlp) (5.2.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/petrakov/.local/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair-82==0.8.2->adaptnlp) (2.5)\n",
      "Requirement already satisfied: cloudpickle in /home/petrakov/.local/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair-82==0.8.2->adaptnlp) (2.1.0)\n",
      "Requirement already satisfied: py4j in /home/petrakov/.local/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair-82==0.8.2->adaptnlp) (0.10.9.5)\n",
      "Requirement already satisfied: future in /home/petrakov/.local/lib/python3.8/site-packages (from hyperopt>=0.1.1->flair-82==0.8.2->adaptnlp) (0.18.2)\n",
      "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /home/petrakov/.local/lib/python3.8/site-packages (from konoha<5.0.0,>=4.0.0->flair-82==0.8.2->adaptnlp) (3.10.1)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Using cached overrides-3.1.0-py3-none-any.whl\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/petrakov/.local/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair-82==0.8.2->adaptnlp) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/petrakov/.local/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair-82==0.8.2->adaptnlp) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/petrakov/.local/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair-82==0.8.2->adaptnlp) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/petrakov/.local/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair-82==0.8.2->adaptnlp) (4.33.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets<=1.15.1,>=1.3.0->adaptnlp) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets<=1.15.1,>=1.3.0->adaptnlp) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets<=1.15.1,>=1.3.0->adaptnlp) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets<=1.15.1,>=1.3.0->adaptnlp) (1.25.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (2.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (8.1.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (1.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (0.6.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4\n",
      "  Using cached pydantic-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (2.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /home/petrakov/.local/lib/python3.8/site-packages (from spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (59.5.0)\n",
      "Collecting torchvision>=0.8.2\n",
      "  Using cached torchvision-0.12.0-cp38-cp38-manylinux1_x86_64.whl (21.0 MB)\n",
      "  Using cached torchvision-0.11.3-cp38-cp38-manylinux1_x86_64.whl (23.2 MB)\n",
      "  Using cached torchvision-0.11.2-cp38-cp38-manylinux1_x86_64.whl (23.3 MB)\n",
      "  Using cached torchvision-0.11.1-cp38-cp38-manylinux1_x86_64.whl (23.3 MB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (19.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/petrakov/.local/lib/python3.8/site-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/petrakov/.local/lib/python3.8/site-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/petrakov/.local/lib/python3.8/site-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/petrakov/.local/lib/python3.8/site-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/petrakov/.local/lib/python3.8/site-packages (from aiohttp->datasets<=1.15.1,>=1.3.0->adaptnlp) (1.7.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/petrakov/.local/lib/python3.8/site-packages (from ftfy->flair-82==0.8.2->adaptnlp) (0.2.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/petrakov/.local/lib/python3.8/site-packages (from pandas->datasets<=1.15.1,>=1.3.0->adaptnlp) (2019.1)\n",
      "Requirement already satisfied: click in /home/petrakov/.local/lib/python3.8/site-packages (from sacremoses->transformers<4.12.3,>=4.0.0->adaptnlp) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/petrakov/.local/lib/python3.8/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair-82==0.8.2->adaptnlp) (3.8.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3/dist-packages (from networkx>=2.2->hyperopt>=0.1.1->flair-82==0.8.2->adaptnlp) (4.4.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/petrakov/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (0.7.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/petrakov/.local/lib/python3.8/site-packages (from jinja2->spacy<4->fastai<=2.5.3,>=2.4.0->adaptnlp) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/petrakov/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets<=1.15.1,>=1.3.0->adaptnlp) (1.7.1)\n",
      "Building wheels for collected packages: seqeval, gdown\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.0-py3-none-any.whl size=15788 sha256=ca19284a09ebb6eb18e863a099ecff2a5a6a107ed98e7786d97d22ae61716675\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/77/bf/7d/5a171e0a71a206a45a0b560bd716237b13ca9a67a5f4c37af9\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9675 sha256=6d7c1623a06a3254fa8a8556946b6c18c70b8d7b7b0aa272eca62b424810fa04\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/e2/62/1e/926d1ebe7b1e733c78d627fd288d01b83feaf67efc06e0e4c3\n",
      "Successfully built seqeval gdown\n",
      "Installing collected packages: sentencepiece, overrides, tqdm, torch, requests, pydantic, numpy, more-itertools, fastprogress, conllu, torchvision, huggingface-hub, fastcore, transformers, scikit-learn, gensim, gdown, fastdownload, seqeval, datasets, flair-82, fastai, adaptnlp\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.96\n",
      "    Uninstalling sentencepiece-0.1.96:\n",
      "      Successfully uninstalled sentencepiece-0.1.96\n",
      "  Attempting uninstall: overrides\n",
      "    Found existing installation: overrides 2.7.0\n",
      "    Uninstalling overrides-2.7.0:\n",
      "      Successfully uninstalled overrides-2.7.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.0\n",
      "    Uninstalling tqdm-4.62.0:\n",
      "      Successfully uninstalled tqdm-4.62.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.6.0\n",
      "    Uninstalling torch-1.6.0:\n",
      "      Successfully uninstalled torch-1.6.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.3\n",
      "    Uninstalling pydantic-1.3:\n",
      "      Successfully uninstalled pydantic-1.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.0\n",
      "    Uninstalling numpy-1.18.0:\n",
      "      Successfully uninstalled numpy-1.18.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.7.0\n",
      "    Uninstalling torchvision-0.7.0:\n",
      "      Successfully uninstalled torchvision-0.7.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.8\n",
      "    Uninstalling huggingface-hub-0.0.8:\n",
      "      Successfully uninstalled huggingface-hub-0.0.8\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.6.0\n",
      "    Uninstalling transformers-4.6.0:\n",
      "      Successfully uninstalled transformers-4.6.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.21.2\n",
      "    Uninstalling scikit-learn-0.21.2:\n",
      "      Successfully uninstalled scikit-learn-0.21.2\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.2.0\n",
      "    Uninstalling gensim-4.2.0:\n",
      "      Successfully uninstalled gensim-4.2.0\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.5.1\n",
      "    Uninstalling gdown-4.5.1:\n",
      "      Successfully uninstalled gdown-4.5.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.3.2\n",
      "    Uninstalling datasets-2.3.2:\n",
      "      Successfully uninstalled datasets-2.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
      "torchaudio 0.11.0 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
      "deeppavlov 0.17.4 requires numpy==1.18.0, but you have numpy 1.19.2 which is incompatible.\n",
      "deeppavlov 0.17.4 requires overrides==2.7.0, but you have overrides 3.1.0 which is incompatible.\n",
      "deeppavlov 0.17.4 requires pydantic==1.3, but you have pydantic 1.9.1 which is incompatible.\n",
      "deeppavlov 0.17.4 requires requests==2.22.0, but you have requests 2.28.1 which is incompatible.\n",
      "deeppavlov 0.17.4 requires scikit-learn==0.21.2, but you have scikit-learn 0.23.2 which is incompatible.\n",
      "deeppavlov 0.17.4 requires tqdm==4.62.0, but you have tqdm 4.64.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed adaptnlp-0.3.7 conllu-4.5 datasets-1.15.1 fastai-2.5.3 fastcore-1.3.27 fastdownload-0.0.7 fastprogress-1.0.2 flair-82-0.8.2 gdown-3.12.2 gensim-3.8.3 huggingface-hub-0.8.1 more-itertools-8.8.0 numpy-1.19.2 overrides-3.1.0 pydantic-1.9.1 requests-2.28.1 scikit-learn-0.23.2 sentencepiece-0.1.95 seqeval-1.2.0 torch-1.10.0 torchvision-0.11.1 tqdm-4.64.0 transformers-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install adaptnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 positional arguments (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-6896844935b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madaptnlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEasyTokenTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEasyTokenTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sentences = tagger.tag_text(\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menglish_text\u001b[0m\u001b[0;31m#, model_name_or_path = \"ner-ontonotes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/adaptnlp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Inference modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m from .inference.embeddings import (\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mEasyWordEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mEasyStackedEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/adaptnlp/inference/embeddings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlairModelResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHFModelResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHFModelHub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlairModelHub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetailLevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/adaptnlp/model_hub.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m \u001b[0mFLAIR_MODELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'flairNLP/{key}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_flair_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/adaptnlp/model_hub.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m \u001b[0mFLAIR_MODELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'flairNLP/{key}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_flair_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 positional arguments (and 1 keyword-only argument) were given"
     ]
    }
   ],
   "source": [
    "from adaptnlp import EasyTokenTagger\n",
    "tagger = EasyTokenTagger()\n",
    "sentences = tagger.tag_text(\n",
    "    text = english_text, model_name_or_path = \"ner-ontonotes\"\n",
    ")\n",
    "spans = sentences[0].get_spans(\"ner\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"ner\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m574.7/574.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (1.12.0)\n",
      "Requirement already satisfied: transformers in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (4.20.1)\n",
      "Requirement already satisfied: six in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (1.12.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (4.64.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/petrakov/anaconda3/lib/python3.7/site-packages (from stanza) (2.28.1)\n",
      "Requirement already satisfied: typing_extensions in /home/petrakov/anaconda3/lib/python3.7/site-packages (from torch>=1.3.0->stanza) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests->stanza) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests->stanza) (1.24.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests->stanza) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests->stanza) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (0.8.1)\n",
      "Requirement already satisfied: filelock in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (5.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (3.10.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers->stanza) (0.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->transformers->stanza) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from importlib-metadata->transformers->stanza) (3.8.1)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=95100c4aaac683a075aa14f8e251caef177f7eda8edd454bc006da33cb88dd89\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, protobuf, stanza\n",
      "Successfully installed emoji-1.7.0 protobuf-4.21.2 stanza-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca40d20a044936bd77c7fc0cd66699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:03:26 INFO: Downloading default packages for language: en (English)...\n",
      "2022-07-14 00:03:27 INFO: File exists: /home/petrakov/stanza_resources/en/default.zip\n",
      "2022-07-14 00:03:31 INFO: Finished downloading models and saved to /home/petrakov/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')\n",
    "def stanza_nlp(text):\n",
    "  nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "  doc = nlp(text)\n",
    "  print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e153ecdc27c4c7287f27448ea2476bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:31 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:31 INFO: Use device: gpu\n",
      "2022-07-14 00:06:31 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:31 INFO: Loading: ner\n",
      "2022-07-14 00:06:31 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: detroit\ttype: GPE\n",
      "None\n",
      "\n",
      "\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1eef2655b0475ea91b9c94572e0fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:32 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:32 INFO: Use device: gpu\n",
      "2022-07-14 00:06:32 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:32 INFO: Loading: ner\n",
      "2022-07-14 00:06:32 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912caf967a404524b3624a4692e2012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:33 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:33 INFO: Use device: gpu\n",
      "2022-07-14 00:06:33 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:33 INFO: Loading: ner\n",
      "2022-07-14 00:06:33 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: chicago\ttype: GPE\n",
      "None\n",
      "\n",
      "\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5265f0ad88f2495fb19b98b528125905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:34 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:34 INFO: Use device: gpu\n",
      "2022-07-14 00:06:34 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:34 INFO: Loading: ner\n",
      "2022-07-14 00:06:34 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa149d1a123c487fa1e05d498bcea5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:35 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:35 INFO: Use device: gpu\n",
      "2022-07-14 00:06:35 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:35 INFO: Loading: ner\n",
      "2022-07-14 00:06:35 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57395816168c45d48521883468e349e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:36 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:36 INFO: Use device: gpu\n",
      "2022-07-14 00:06:36 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:36 INFO: Loading: ner\n",
      "2022-07-14 00:06:36 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5205cac7e3d840d49d1fa0fd1c7aa2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:37 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:37 INFO: Use device: gpu\n",
      "2022-07-14 00:06:37 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:37 INFO: Loading: ner\n",
      "2022-07-14 00:06:37 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bf561f4c674ee5b7c7342196a30fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:38 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:38 INFO: Use device: gpu\n",
      "2022-07-14 00:06:38 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:38 INFO: Loading: ner\n",
      "2022-07-14 00:06:38 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb378deb3964931bc88cb8e10bbb86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:39 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:39 INFO: Use device: gpu\n",
      "2022-07-14 00:06:39 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:39 INFO: Loading: ner\n",
      "2022-07-14 00:06:40 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n",
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bf040f4c7c45688b91103a711ea08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 00:06:40 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-07-14 00:06:40 INFO: Use device: gpu\n",
      "2022-07-14 00:06:40 INFO: Loading: tokenize\n",
      "2022-07-14 00:06:40 INFO: Loading: ner\n",
      "2022-07-14 00:06:41 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    print(stanza_nlp(data.loc[i,\"question\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\n",
      "  Downloading allennlp-2.9.3-py3-none-any.whl (719 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m719.6/719.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fairscale==0.4.6\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboardX>=1.2\n",
      "  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "Collecting termcolor==1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (4.64.0)\n",
      "Collecting cached-path<1.2.0,>=1.0.2\n",
      "  Downloading cached_path-1.1.5-py3-none-any.whl (26 kB)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: requests>=2.18 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (2.28.1)\n",
      "Collecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision<0.13.0,>=0.8.1\n",
      "  Using cached torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting transformers<4.19,>=4.1\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting filelock<3.7,>=3.3\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: nltk in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (3.4.5)\n",
      "Requirement already satisfied: pytest in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (5.2.1)\n",
      "Requirement already satisfied: more-itertools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (7.2.0)\n",
      "Requirement already satisfied: sentencepiece in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (0.1.95)\n",
      "Collecting torch<1.12.0,>=1.6.0\n",
      "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: numpy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (1.21.6)\n",
      "Requirement already satisfied: h5py in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (2.9.0)\n",
      "Collecting spacy<3.3,>=2.1.0\n",
      "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (1.3.1)\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (298 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.0.16 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (0.8.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (0.4.2)\n",
      "Requirement already satisfied: scikit-learn in /home/petrakov/anaconda3/lib/python3.7/site-packages (from allennlp) (0.21.3)\n",
      "Collecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m592.1/592.1 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rich<13.0,>=12.1\n",
      "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.4.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boto3<2.0,>=1.0\n",
      "  Downloading boto3-1.24.29-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from huggingface-hub>=0.0.16->allennlp) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from huggingface-hub>=0.0.16->allennlp) (5.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from huggingface-hub>=0.0.16->allennlp) (4.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/petrakov/anaconda3/lib/python3.7/site-packages (from huggingface-hub>=0.0.16->allennlp) (3.10.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests>=2.18->allennlp) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests>=2.18->allennlp) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests>=2.18->allennlp) (1.24.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests>=2.18->allennlp) (2.8)\n",
      "Collecting click<8.1.0\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: jinja2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (2.10.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (41.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (3.0.6)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (3.3.0)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (0.9.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy<3.3,>=2.1.0->allennlp) (0.7.8)\n",
      "Collecting protobuf<=3.20.1,>=3.8.0\n",
      "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from torchvision<0.13.0,>=0.8.1->allennlp) (6.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers<4.19,>=4.1->allennlp) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from transformers<4.19,>=4.1->allennlp) (2022.7.9)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting six>=1.13.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.7.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.6.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->allennlp) (1.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->allennlp) (19.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->allennlp) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->allennlp) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pytest->allennlp) (0.2.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from scikit-learn->allennlp) (0.13.2)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.29\n",
      "  Downloading botocore-1.27.29-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3,>=2.1.0->allennlp) (3.8.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.1-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.0.16->allennlp) (2.4.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3,>=2.1.0->allennlp) (5.2.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<13.0,>=12.1\n",
      "  Downloading rich-12.5.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m235.7/235.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.3-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.1-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.0-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.3.0-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.2.0-py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m229.8/229.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of regex to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m749.7/749.7 kB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting py>=1.5.0\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting psutil>=5.0.0\n",
      "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m281.4/281.4 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf<=3.20.1,>=3.8.0\n",
      "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of promise to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.2.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of preshed to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "INFO: pip is looking at multiple versions of pluggy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pluggy<1.0,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of pillow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pathy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging>=20.9\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "INFO: pip is looking at multiple versions of murmurhash to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of langcodes to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "  Downloading importlib_metadata-4.11.2-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.11.1-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.11.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.10.1-py3-none-any.whl (17 kB)\n",
      "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading importlib_metadata-4.10.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.9.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading importlib_metadata-4.7.1-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.6.4-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.6.3-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.6.2-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.6.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.4.0-py3-none-any.whl (17 kB)\n",
      "  Downloading importlib_metadata-4.3.1-py3-none-any.whl (16 kB)\n",
      "  Downloading importlib_metadata-4.3.0-py3-none-any.whl (16 kB)\n",
      "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
      "  Downloading importlib_metadata-4.1.0-py3-none-any.whl (16 kB)\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "  Downloading importlib_metadata-4.0.0-py3-none-any.whl (16 kB)\n",
      "  Using cached importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "  Downloading importlib_metadata-3.10.0-py3-none-any.whl (14 kB)\n",
      "  Downloading importlib_metadata-3.9.1-py3-none-any.whl (14 kB)\n",
      "  Downloading importlib_metadata-3.9.0-py3-none-any.whl (14 kB)\n",
      "  Downloading importlib_metadata-3.8.2-py3-none-any.whl (14 kB)\n",
      "  Downloading importlib_metadata-3.8.1-py3-none-any.whl (13 kB)\n",
      "  Downloading importlib_metadata-3.8.0-py3-none-any.whl (13 kB)\n",
      "  Downloading importlib_metadata-3.7.3-py3-none-any.whl (12 kB)\n",
      "  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\n",
      "  Downloading importlib_metadata-3.7.1-py3-none-any.whl (11 kB)\n",
      "  Downloading importlib_metadata-3.7.0-py3-none-any.whl (11 kB)\n",
      "  Downloading importlib_metadata-3.6.0-py3-none-any.whl (11 kB)\n",
      "  Downloading importlib_metadata-3.5.0-py3-none-any.whl (10 kB)\n",
      "  Downloading importlib_metadata-3.4.0-py3-none-any.whl (10 kB)\n",
      "  Downloading importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "  Downloading importlib_metadata-3.2.0-py3-none-any.whl (9.9 kB)\n",
      "  Downloading importlib_metadata-3.1.1-py3-none-any.whl (9.6 kB)\n",
      "  Downloading importlib_metadata-3.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-storage to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-storage<3.0,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.3.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of gitpython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m180.9/180.9 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading GitPython-3.1.25-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m180.9/180.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m180.1/180.1 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m159.8/159.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading GitPython-3.1.13-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of docker-pycreds to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting click<8.1.0\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting boto3<2.0,>=1.0\n",
      "  Downloading boto3-1.24.28-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "INFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of atomicwrites to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading atomicwrites-1.4.1.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of sentencepiece to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pytest to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of nltk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of more-itertools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-8.13.0-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of lmdb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of dill to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of base58 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of wandb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting wandb<0.13.0,>=0.10.0\n",
      "  Downloading wandb-0.12.20-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of typer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typer>=0.4.1\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers<4.19,>=4.1\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tqdm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tqdm>=4.62\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision<0.13.0,>=0.8.1\n",
      "  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch<1.12.0,>=1.6.0\n",
      "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision<0.13.0,>=0.8.1\n",
      "  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch<1.12.0,>=1.6.0\n",
      "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m804.1/804.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "INFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting spacy<3.3,>=2.1.0\n",
      "  Downloading spacy-3.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.4-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.3-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.2-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.1-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting pygments<3.0.0,>=2.6.0\n",
      "  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from typer>=0.4.1->allennlp) (8.1.3)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.29->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (2.8.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: fairscale, termcolor, jsonnet, promise, pathtools\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307225 sha256=b3b7303f2ecf13ed1151505ec679370b722247213b2c36e64e398f264ca8feee\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=66b0c58ff5f992eb2a31b1be312efb6c128108ce5062fdc4f52ae3cec9e0c51e\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=6327674 sha256=f3b7003fc5b6bfe37a98ea2359e68c713b5f884ea190ad2035a9c1e567938f2f\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=fdb06e385a56799175a6e1e6b9e9146d2f8816a5ef10ba553d91cd838aeefe72\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8785 sha256=98229c2443acfecb7a24b443f6e4a821a669baa9f6624957ab78b819bf1f99a0\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built fairscale termcolor jsonnet promise pathtools\n",
      "Installing collected packages: termcolor, srsly, pyasn1, plac, pathtools, lmdb, jsonnet, commonmark, urllib3, torch, smmap, six, shortuuid, setproctitle, rsa, pygments, pyasn1-modules, protobuf, jmespath, google-crc32c, filelock, dill, cachetools, base58, tensorboardX, sentry-sdk, rich, promise, googleapis-common-protos, google-resumable-media, google-auth, gitdb, fairscale, docker-pycreds, catalogue, torchvision, thinc, sacremoses, google-api-core, GitPython, botocore, wandb, transformers, spacy, s3transfer, google-cloud-core, google-cloud-storage, boto3, cached-path, allennlp\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.3\n",
      "    Uninstalling srsly-2.4.3:\n",
      "      Successfully uninstalled srsly-2.4.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.2\n",
      "    Uninstalling urllib3-1.24.2:\n",
      "      Successfully uninstalled urllib3-1.24.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.4.2\n",
      "    Uninstalling Pygments-2.4.2:\n",
      "      Successfully uninstalled Pygments-2.4.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.2\n",
      "    Uninstalling protobuf-4.21.2:\n",
      "      Successfully uninstalled protobuf-4.21.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.0.12\n",
      "    Uninstalling filelock-3.0.12:\n",
      "      Successfully uninstalled filelock-3.0.12\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.7\n",
      "    Uninstalling catalogue-2.0.7:\n",
      "      Successfully uninstalled catalogue-2.0.7\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.0\n",
      "    Uninstalling torchvision-0.13.0:\n",
      "      Successfully uninstalled torchvision-0.13.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.0\n",
      "    Uninstalling thinc-8.1.0:\n",
      "      Successfully uninstalled thinc-8.1.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.20.1\n",
      "    Uninstalling transformers-4.20.1:\n",
      "      Successfully uninstalled transformers-4.20.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.4.0\n",
      "    Uninstalling spacy-3.4.0:\n",
      "      Successfully uninstalled spacy-3.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 3.3.6 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "conda 4.13.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "astroid 2.3.1 requires typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\", which is not installed.\n",
      "torchaudio 0.12.0 requires torch==1.12.0, but you have torch 1.11.0 which is incompatible.\n",
      "astroid 2.3.1 requires six==1.12, but you have six 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GitPython-3.1.27 allennlp-2.9.3 base58-2.1.1 boto3-1.24.29 botocore-1.27.29 cached-path-1.1.5 cachetools-5.2.0 catalogue-1.0.0 commonmark-0.9.1 dill-0.3.5.1 docker-pycreds-0.4.0 fairscale-0.4.6 filelock-3.6.0 gitdb-4.0.9 google-api-core-2.8.2 google-auth-2.9.1 google-cloud-core-2.3.1 google-cloud-storage-2.4.0 google-crc32c-1.3.0 google-resumable-media-2.3.3 googleapis-common-protos-1.56.4 jmespath-1.0.1 jsonnet-0.18.0 lmdb-1.3.0 pathtools-0.1.2 plac-1.1.3 promise-2.3 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.12.0 rich-12.5.1 rsa-4.8 s3transfer-0.6.0 sacremoses-0.0.53 sentry-sdk-1.7.1 setproctitle-1.2.3 shortuuid-1.0.9 six-1.16.0 smmap-5.0.0 spacy-2.3.7 srsly-1.0.5 tensorboardX-2.5.1 termcolor-1.1.0 thinc-7.4.5 torch-1.11.0 torchvision-0.13.0 transformers-4.18.0 urllib3-1.26.10 wandb-0.12.21\n"
     ]
    }
   ],
   "source": [
    "!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AcquireReturnProxy' from 'filelock' (/home/petrakov/anaconda3/lib/python3.7/site-packages/filelock.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5824216e0aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallennlp_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf_tagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m allen_result = predictor.predict(\n\u001b[1;32m      5\u001b[0m   \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menglish_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/predictors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPredictor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_tagger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTaggerPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_classifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassifierPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegistrable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFromParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistrable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegistrable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/lazy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_cached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m from cached_path import (  # noqa: F401\n\u001b[1;32m     41\u001b[0m     \u001b[0mresource_to_filename\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_resource_to_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cached_path/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \"\"\"\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_cached_path\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_cache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_download_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cached_path/_cached_path.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcache_file\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCacheFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPathOrStr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_cache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_lock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mschemes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_scheme_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_supported_schemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_get_from_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cached_path/file_lock.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAcquireReturnProxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_FileLock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AcquireReturnProxy' from 'filelock' (/home/petrakov/anaconda3/lib/python3.7/site-packages/filelock.py)"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.ner.crf_tagger\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-model-2020.02.10.tar.gz\")\n",
    "allen_result = predictor.predict(\n",
    "  sentence=english_text\n",
    ")\n",
    "for i in zip(allen_result['tags'], allen_result['words']):\n",
    "    if (i[0]) != 'O':\n",
    "      print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quien descubrio [START] America [END] ?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = NER(text = 'Quien descubrio America?',\n",
    "                tokenizer_name = \"Babelscape/wikineural-multilingual-ner\",\n",
    "                model_name = \"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 'Q828',\n",
       "   'texts': ['Amrica >> es', 'America >> es'],\n",
       "   'scores': tensor([-0.1263, -1.3828]),\n",
       "   'score': tensor(-0.1747)},\n",
       "  {'id': 'Q29409515',\n",
       "   'texts': ['Amrica (desambiguacin) >> es',\n",
       "    'Amrica (desambiguao) >> pt'],\n",
       "   'scores': tensor([-0.3790, -1.0400]),\n",
       "   'score': tensor(-1.0819)},\n",
       "  {'id': 'Q18',\n",
       "   'texts': ['Amrica del Sur >> es'],\n",
       "   'scores': tensor([-1.0630]),\n",
       "   'score': tensor(-2.6038)}]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentences = [\"[START] The founder of the theory of relativity [END] received the Nobel Prize.\"]\n",
    "model_mGENRE.sample(\n",
    "    sentences = [sentences],\n",
    "    beam = 5,\n",
    "    prefix_allowed_tokens_fn=lambda batch_id, sent: [\n",
    "        e for e in trie.get(sent.tolist())\n",
    "        if e < len(model_mGENRE.task.target_dictionary)\n",
    "    ],\n",
    "    text_to_id=lambda x: max(lang_title2wikidataID[tuple(reversed(x.split(\" >> \")))], key=lambda y: int(y[1:])),\n",
    "    marginalize=True,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New experiment GENRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! you have to uncomment cells below to load data if it is 1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data and dependencies\n",
    "\n",
    "# id_p_e_m = \"1C2R814tsgZbREaaOk6o9nh3lQn308Wo7\"\n",
    "# gdown.download(id=id_p_e_m, output=\"prob_yago_crosswikis_wikipedia_p_e_m.txt\", quiet=False)\n",
    "\n",
    "# %mkdir data\n",
    "# %cd data\n",
    "# %mkdir dalab\n",
    "# %cd ..\n",
    "\n",
    "# %mv prob_yago_crosswikis_wikipedia_p_e_m.txt data/dalab/prob_yago_crosswikis_wikipedia_p_e_m.txt\n",
    "\n",
    "# ! wget http://resources.mpi-inf.mpg.de/yago-naga/aida/download/aida_means.tsv.bz2\n",
    "# ! bzip2 -dk aida_means.tsv.bz2\n",
    "\n",
    "# %cd data \n",
    "# %mkdir aida\n",
    "# %cd ..\n",
    "\n",
    "# %mv aida_means.tsv data/aida/aida_means.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_dalab_candidates():\n",
    "#     for line in open(\"data/dalab/prob_yago_crosswikis_wikipedia_p_e_m.txt\"):\n",
    "#         line = line[:-1]\n",
    "#         columns = line.split(\"\\t\")\n",
    "#         mention = columns[0]\n",
    "#         for column in columns[2:]:\n",
    "#             if len(column.strip()) == 0:\n",
    "#                 continue\n",
    "#             values = column.split(\",\")\n",
    "#             candidate = \",\".join(values[2:])\n",
    "#             candidate = candidate.replace(\"_\", \" \")\n",
    "#             yield mention, candidate\n",
    "\n",
    "\n",
    "# def hex2int(hexa: str) -> int:\n",
    "#     return int(hexa, 16)\n",
    "\n",
    "\n",
    "# def replace_unicode(u_str):\n",
    "#     matches = set(re.findall(\"\\\\\\\\u....\", u_str))\n",
    "#     for match in matches:\n",
    "#         u_str = u_str.replace(match, chr(hex2int(match[2:])))\n",
    "#     return u_str\n",
    "\n",
    "\n",
    "# PUNCTUATION_CHARS = set(string.punctuation)\n",
    "\n",
    "\n",
    "# def filter_mention(mention):\n",
    "#     if mention[0].islower():\n",
    "#         return True\n",
    "#     if mention[0] in PUNCTUATION_CHARS:\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# def read_aida_candidates():\n",
    "#     for line in open(\"data/aida/aida_means.tsv\"):\n",
    "#         line = line[:-1]\n",
    "#         values = line.split(\"\\t\")\n",
    "#         mention = replace_unicode(values[0][1:-1])\n",
    "#         candidate = replace_unicode(values[1]).replace(\"_\", \" \")\n",
    "#         yield mention, candidate\n",
    "\n",
    "\n",
    "# #making mention_candidates_dict\n",
    "# #once done no need to do again\n",
    "\n",
    "# mention_candidates_dict = {}\n",
    "# for mention, candidate in itertools.chain(read_dalab_candidates(), read_aida_candidates()):\n",
    "#     if filter_mention(mention):\n",
    "#         continue\n",
    "#     if mention not in mention_candidates_dict:\n",
    "#         mention_candidates_dict[mention] = set()\n",
    "#     mention_candidates_dict[mention].add(candidate)\n",
    "# for mention in mention_candidates_dict:\n",
    "#     mention_candidates_dict[mention] = sorted(mention_candidates_dict[mention])\n",
    "# with open(\"data/mention_candidates_dict.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(mention_candidates_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making mention_trie\n",
    "# # once done no need to do again\n",
    "\n",
    "# sys.setrecursionlimit(10000)\n",
    "# model_path = \"fairseq_e2e_entity_linking_wiki_abs\"\n",
    "# model = GENRE.from_pretrained(model_path).eval()\n",
    "# with open(\"data/mention_candidates_dict.pkl\", \"rb\") as f:\n",
    "#     mention_to_candidates_dict = pickle.load(f)\n",
    "# mention_trie = Trie()\n",
    "# for mention in tqdm(mention_to_candidates_dict):\n",
    "#     encoded = model.encode(\" {}\".format(mention))[1:].tolist()\n",
    "#     mention_trie.add(encoded)\n",
    "# out_file = \"data/mention_trie.pkl\"\n",
    "# with open(out_file, \"wb\") as f:\n",
    "#     pickle.dump(mention_trie, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example from git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from GENRE.genre.utils import get_entity_spans_fairseq as get_entity_spans\n",
    "from GENRE.genre.utils import get_markdown\n",
    "\n",
    "\n",
    "from GENRE.genre.trie import Trie, MarisaTrie\n",
    "from GENRE.genre.fairseq_model import mGENRE\n",
    "from GENRE.genre.fairseq_model import GENRE\n",
    "\n",
    "\n",
    "model_path_genre = \"fairseq_e2e_entity_linking_wiki_abs\"\n",
    "model_path_mgenre = \"fairseq_multilingual_entity_disambiguation\"\n",
    "dict_path = \"data/mention_candidates_dict.pkl\"\n",
    "trie_path = \"data/mention_trie.pkl\"\n",
    "\n",
    "model = GENRE.from_pretrained(model_path_genre).eval()\n",
    "\n",
    "with open(trie_path, \"rb\") as f:\n",
    "    mention_trie = pickle.load(f)\n",
    "with open(dict_path, \"rb\") as f:\n",
    "    mention_to_candidates_dict = pickle.load(f)\n",
    "\n",
    "text = \"\"\"Home Depot CEO Nardelli quits Home-improvement retailer's chief executive had been criticized over pay ATLANTA - Bob Nardelli abruptly resigned Wednesday as chairman and chief executive of The Home Depot Inc. after a six-year tenure that saw the worlds largest home improvement store chain post big profits but left investors disheartened by poor stock performance. Nardelli has also been under fire by investors for his hefty pay and is leaving with a severance package valued at about $210 million. He became CEO in December 2000 after being passed over for the top job at General Electric Co., where Nardelli had been a senior executive. Home Depot said Nardelli was being replaced by Frank Blake, its vice chairman, effective immediately. Blakes appointment is permanent, Home Depot spokesman Jerry Shields said. What he will be paid was not immediately disclosed, Shields said. The company declined to make Blake available for comment, and a message left for Nardelli with his secretary was not immediately returned. Before Wednesdays news, Home Depots stock had been down more than 3 percent on a split-adjusted basis since Nardelli took over. Nardellis sudden departure was stunning in that he told The Associated Press as recently as Sept. 1 that he had no intention of leaving, and a key director also said that the board was pleased with Nardelli despite the uproar by some investors. Asked in that interview if he had thought of hanging up his orange apron and leaving Home Depot, Nardelli said unequivocally that he hadnt. Asked what he thought he would be doing 10 years from now, Nardelli said, Selling hammers. For The Home Depot? Absolutely, he said at the time. Home Depot said Nardellis decision to resign was by mutual agreement with the Atlanta-based company. We are very grateful to Bob for his strong leadership of The Home Depot over the past six years. Under Bobs tenure, the company made significant and necessary investments that greatly improved the companys infrastructure and operations, expanded our markets to include wholesale distribution and new geographies, and undertook key strategic initiatives to strengthen the companys foundation for the future, Home Depots board said in a statement. Nardelli was a nuts-and-bolts leader, a former college football player and friend of President Bush. He helped increase revenue and profits at Home Depot and increase the number of stores the company operates to more than 2,000. Home Depots earnings per share have increased by approximately 150 percent over the last five years.\"\"\"\n",
    "\n",
    "sentences = [text]\n",
    "entity_spans = get_entity_spans(\n",
    "    model,\n",
    "    sentences,\n",
    "    mention_trie=mention_trie,\n",
    "    mention_to_candidates_dict=mention_to_candidates_dict\n",
    ")\n",
    "markdown = get_markdown(sentences, entity_spans)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) CEO Nardelli quits Home-improvement retailer's chief executive had been criticized over pay ATLANTA - [Bob Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) abruptly resigned Wednesday as chairman and chief executive of [The Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) Inc. after a six-year tenure that saw the worlds largest home improvement store chain post big profits but left investors disheartened by poor stock performance. [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) has also been under fire by investors for his hefty pay and is leaving with a severance package valued at about $210 million. He became CEO in December 2000 after being passed over for the top job at [General Electric](https://en.wikipedia.org/wiki/General_Electric) Co., where [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) had been a senior executive. [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) said [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) was being replaced by [Frank Blake](https://en.wikipedia.org/wiki/Frank_Blake), its vice chairman, effective immediately. [Blake](https://en.wikipedia.org/wiki/Frank_Blake)s appointment is permanent, [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) spokesman [Jerry Shields](https://en.wikipedia.org/wiki/Jerry_A._Shields) said. [What](https://en.wikipedia.org/wiki/What?_(film)) he will be paid was not immediately disclosed, [Shields](https://en.wikipedia.org/wiki/Jerry_A._Shields) said. [The](https://en.wikipedia.org/wiki/The_Home_Depot) company declined to make [Blake](https://en.wikipedia.org/wiki/Frank_Blake) available for comment, and a message left for [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) with his secretary was not immediately returned. [Before](https://en.wikipedia.org/wiki/Before_(song)) Wednesdays news, [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot)s stock had been down more than 3 percent on a split-adjusted basis since [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) took over. [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli)s sudden departure was stunning in that he told [The](https://en.wikipedia.org/wiki/The_Home_Depot) Associated Press as recently as Sept. 1 that he had no intention of leaving, and a key director also said that the board was pleased with [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) despite the uproar by some investors. Asked in that interview if he had thought of hanging up his orange apron and leaving [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot), [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) said unequivocally that he hadnt. Asked what he thought he would be doing [10](https://en.wikipedia.org/wiki/10_(film)) years from now, [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli) said, Selling hammers. For [The](https://en.wikipedia.org/wiki/The_Mr._T_Experience) Home Depot? Absolutely, he said at the time. [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) said [Nardelli](https://en.wikipedia.org/wiki/Robert_Nardelli)s decision to resign was by mutual agreement with the [Atlanta](https://en.wikipedia.org/wiki/Decatur,_Georgia)-based company. We are very grateful to [Bob](https://en.wikipedia.org/wiki/Barbecue_Bob) for his strong leadership of [The](https://en.wikipedia.org/wiki/U.S._Department_of_State_Foreign_Affairs_Manual) [Home Depot](https://en.wikipedia.org/wiki/The_Home_Depot) over the past six years. Under [Bob](https://en.wikipedia.org/wiki/Bank_of_Baroda)s tenure, the company made significant and necessary investments that greatly improved the companys infrastructure and operations, expanded our markets to include wholesale distribution and new geographies, and undertook key strategic initiatives to strengthen the companys foundation for the future, [Home](https://en.wikipedia.org/wiki/John_Home) [Depot](https://en.wikipedia.org/wiki/Depot)s board said in a statement. [Nardelli](https://en.wikipedia.org/wiki/Nardelli) was a nuts-and-bolts leader, a former college football player and friend of [President](https://en.wikipedia.org/wiki/Senegalese_presidential_election,_2007) Bush. [He](https://en.wikipedia.org/wiki/J._M._E._McTaggart) helped increase revenue and profits at [Home](https://en.wikipedia.org/wiki/New_Recreation_Ground) [Depot](https://en.wikipedia.org/wiki/Depot) and increase the number of stores the company operates to more than [2](https://en.wikipedia.org/wiki/U.S._Route_2),000. [Home](https://en.wikipedia.org/wiki/New_Recreation_Ground) [Depot](https://en.wikipedia.org/wiki/Depot)s earnings per share have increased by approximately [150](https://en.wikipedia.org/wiki/U.S._Route_150) percent over the last five years."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mGENRE case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENRE.genre.utils import get_entity_spans_fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mGENRE.from_pretrained(model_path_mgenre).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-57e3d1b5b606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Moscow is the capital of Russia, where such great people as Kondratiev and Kolmogorov lived in 20 century\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m entity_spans = get_entity_spans_fairseq(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    mention_trie=mention_trie,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/genre/utils.py\u001b[0m in \u001b[0;36mget_entity_spans_fairseq\u001b[0;34m(model, input_sentences, mention_trie, candidates_trie, mention_to_candidates_dict, redirections)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mredirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m ):\n\u001b[0;32m--> 153\u001b[0;31m     return _get_entity_spans(\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0minput_sentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/genre/utils.py\u001b[0m in \u001b[0;36m_get_entity_spans\u001b[0;34m(model, input_sentences, prefix_allowed_tokens_fn, redirections)\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     output_sentences = get_entity_spans_post_processing(\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     )\n",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/genre/utils.py\u001b[0m in \u001b[0;36mget_entity_spans_post_processing\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"{.*?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{ \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"}.*?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"} \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\].*?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"] \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "sentences = [\"Moscow is the capital of Russia, where such great people as Kondratiev and Kolmogorov lived in 20 century\"]\n",
    "entity_spans = get_entity_spans_fairseq(\n",
    "    model,\n",
    "    sentences,\n",
    "#    mention_trie=mention_trie,\n",
    "#    mention_to_candidates_dict=mention_to_candidates_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENREHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): BARTModel(\n",
       "      (encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (model): BARTModel(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (embed_tokens): Embedding(256001, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): TransformerDecoderLayer(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_dropout_module): FairseqDropout()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (output_projection): Linear(in_features=1024, out_features=256001, bias=False)\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown = get_markdown(sentences, entity_spans)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Moscow](https://en.wikipedia.org/wiki/Moscow) is the capital of [Russia](https://en.wikipedia.org/wiki/Russia), where such great people as [Kondratiev](https://en.wikipedia.org/wiki/Mikhail_Kondratiev) and [Kolmogorov](https://en.wikipedia.org/wiki/Andrey_Kolmogorov) lived in 20 century"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENRE.genre.utils import get_entity_spans_fairseq as get_entity_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {\n",
    "    \"id_0\": \"In 1921, Einstein received a Nobel Prize.\",\n",
    "    \"id_1\": \"Armstrong was the first man on the Moon.\",\n",
    "}\n",
    "\n",
    "gold_entities = [\n",
    "    (\"id_0\", 3, 4, \"1921\"),\n",
    "    (\"id_0\", 9, 8, 'Albert_Einstein'),\n",
    "    (\"id_0\", 29, 11, 'Nobel_Prize_in_Physics'),\n",
    "    (\"id_1\", 0, 9, 'Neil_Armstrong'),\n",
    "    (\"id_1\", 35, 4, 'Moon'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess_entities [[(0, 7, 'List_of_Nobel_laureates_by_year_of_appointment'), (9, 8, 'Albert_Einstein'), (29, 11, 'Nobel_Prize_in_Physiology_or_Medicine'), (40, 1, 'List_of_Nobel_laureates_in_Physiology_or_Medicine_by_year_of_appointment')], [(18, 9, 'First_Man_(film)'), (35, 4, 'Moon_(TV_series)_(1968_TV_series,_season_1)'), (39, 1, 'Moon_(TV_series,_season_1)')]]\n",
      "#############\n",
      "guess_entities [('id_0', 0, 7, 'List_of_Nobel_laureates_by_year_of_appointment'), ('id_0', 9, 8, 'Albert_Einstein'), ('id_0', 29, 11, 'Nobel_Prize_in_Physiology_or_Medicine'), ('id_0', 40, 1, 'List_of_Nobel_laureates_in_Physiology_or_Medicine_by_year_of_appointment'), ('id_1', 18, 9, 'First_Man_(film)'), ('id_1', 35, 4, 'Moon_(TV_series)_(1968_TV_series,_season_1)'), ('id_1', 39, 1, 'Moon_(TV_series,_season_1)')]\n"
     ]
    }
   ],
   "source": [
    "guess_entities = get_entity_spans(\n",
    "    model,\n",
    "    list(documents.values()),\n",
    ")\n",
    "print(\"guess_entities\", guess_entities)\n",
    "print(\"#############\")\n",
    "\n",
    "guess_entities = [\n",
    "    (k,) + x\n",
    "    for k, e in zip(documents.keys(), guess_entities)\n",
    "    for x in e\n",
    "]\n",
    "print(\"guess_entities\", guess_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_p=0.1429 micro_r=0.2000, micro_f1=0.1667, macro_p=0.1250, macro_r=0.1667, macro_f1=0.1429\n"
     ]
    }
   ],
   "source": [
    "from GENRE.genre.utils import (\n",
    "    get_micro_precision,\n",
    "    get_micro_recall,\n",
    "    get_micro_f1,\n",
    "    get_macro_precision,\n",
    "    get_macro_recall,\n",
    "    get_macro_f1,\n",
    ")\n",
    "\n",
    "micro_p = get_micro_precision(guess_entities, gold_entities)\n",
    "micro_r = get_micro_recall(guess_entities, gold_entities)\n",
    "micro_f1 = get_micro_f1(guess_entities, gold_entities)\n",
    "macro_p = get_macro_precision(guess_entities, gold_entities)\n",
    "macro_r = get_macro_recall(guess_entities, gold_entities)\n",
    "macro_f1 = get_macro_f1(guess_entities, gold_entities)\n",
    "\n",
    "print(\n",
    "   \"micro_p={:.4f} micro_r={:.4f}, micro_f1={:.4f}, macro_p={:.4f}, macro_r={:.4f}, macro_f1={:.4f}\".format(\n",
    "       micro_p, micro_r, micro_f1, macro_p, macro_r, macro_f1\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load mewsli-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_df = pd.read_csv('dataset/en/mentions.tsv', sep='\\t')\n",
    "#en_df_doc = pd.read_csv('docs.tsv', sep='\\t')\n",
    "en_df_doc = pd.read_csv('mewsli_9/dense_representations_for_entity_retrieval/mel/mewsli-9/output/dataset/en/docs.tsv', sep='\\t')\n",
    "en_df_men = pd.read_csv('mewsli_9/dense_representations_for_entity_retrieval/mel/mewsli-9/output/dataset/en/mentions.tsv', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/success/mGENRE_MEL/mewsli_9/dense_representations_for_entity_retrieval/mel\n"
     ]
    }
   ],
   "source": [
    "%cd mewsli_9/dense_representations_for_entity_retrieval/mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open(\"mewsli-9/output/wikiextractor/en/AA/wiki_00.bz2\", \"rb\") as f:\n",
    "    # Decompress data from file\n",
    "    en_wiki = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/success/mGENRE_MEL/mewsli_9/dense_representations_for_entity_retrieval/mel/mewsli-9/output/output/dataset/en/text\n"
     ]
    }
   ],
   "source": [
    "%cd mewsli-9/output/output/dataset/en/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = en_df_men[en_df_men['docid'] == \"en-106602\"]\n",
    "b = en_df_men[en_df_men[\"docid\"] == \"en-106608\"].reset_index()\n",
    "c = en_df_men[en_df_men[\"docid\"] == \"en-106610\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/petrakov/success/mGENRE_MEL\n"
     ]
    }
   ],
   "source": [
    "%cd $init_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"mewsli_9/dense_representations_for_entity_retrieval/mel/mewsli-9/output/output/dataset/en/text/\"\n",
    "texts = []\n",
    "for st in [\"en-106602\", \"en-106608\", \"en-106610\"]:\n",
    "    with open(directory + st, \"r\") as f:\n",
    "        string = f.read()\n",
    "    \n",
    "    string = string.replace(\"\\n\", \" \").replace(\"\\xa0\", \"\")\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    string = string.replace(\"\\n\", \" \")\n",
    "    texts.append(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = {\n",
    "#     \"id_0\": texts[0],\n",
    "#     \"id_1\": texts[1],\n",
    "#     \"id_2\": texts[2],\n",
    "# }\n",
    "\n",
    "documents = {\n",
    "    \"id_0\": \"In 1921, Einstein received a Nobel Prize.\",\n",
    "    \"id_1\": \"Armstrong was the first man on the Moon.\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gold_entities = [\n",
    "    (\"id_0\", 3, 4, \"1921\"),\n",
    "    (\"id_0\", 9, 8, 'Albert_Einstein'),\n",
    "    (\"id_0\", 29, 11, 'Nobel_Prize_in_Physics'),\n",
    "    (\"id_1\", 0, 9, 'Neil_Armstrong'),\n",
    "    (\"id_1\", 35, 4, 'Moon'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {\n",
    "    \"id_0\": texts[0],\n",
    "    \"id_1\": texts[1],\n",
    "    \"id_2\": texts[2],\n",
    "}\n",
    "\n",
    "gold_entities = [*[tuple([\"id_0\", *list(a.loc[i, [\"position\", \"length\", \"mention\"]])]) for i in range(len(a))],\n",
    "                *[tuple([\"id_1\", *list(b.loc[i, [\"position\", \"length\", \"mention\"]])]) for i in range(len(b))],\n",
    "                *[tuple([\"id_2\", *list(c.loc[i, [\"position\", \"length\", \"mention\"]])]) for i in range(len(c))]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from GENRE.genre.utils import get_entity_spans_fairseq as get_entity_spans\n",
    "from GENRE.genre.utils import get_markdown\n",
    "\n",
    "\n",
    "from GENRE.genre.trie import Trie, MarisaTrie\n",
    "from GENRE.genre.fairseq_model import mGENRE\n",
    "from GENRE.genre.fairseq_model import GENRE\n",
    "\n",
    "\n",
    "model_path_genre = \"fairseq_e2e_entity_linking_wiki_abs\"\n",
    "model_path_mgenre = \"fairseq_multilingual_entity_disambiguation\"\n",
    "dict_path = \"data/mention_candidates_dict.pkl\"\n",
    "trie_path = \"data/mention_trie.pkl\"\n",
    "\n",
    "model = GENRE.from_pretrained(model_path_genre).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_entities = get_entity_spans(\n",
    "    model,\n",
    "    list(documents.values()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_entities_1 = [\n",
    "    (k,*x)\n",
    "    for k, e in zip(documents.keys(), guess_entities)\n",
    "    for x in e\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_p=0.0000 micro_r=0.0000, micro_f1=0.0000, macro_p=0.0000, macro_r=0.0000, macro_f1=0.0000\n"
     ]
    }
   ],
   "source": [
    "from GENRE.genre.utils import (\n",
    "    get_micro_precision,\n",
    "    get_micro_recall,\n",
    "    get_micro_f1,\n",
    "    get_macro_precision,\n",
    "    get_macro_recall,\n",
    "    get_macro_f1,\n",
    ")\n",
    "\n",
    "micro_p = get_micro_precision(guess_entities_1, gold_entities)\n",
    "micro_r = get_micro_recall(guess_entities_1, gold_entities)\n",
    "micro_f1 = get_micro_f1(guess_entities_1, gold_entities)\n",
    "macro_p = get_macro_precision(guess_entities_1, gold_entities)\n",
    "macro_r = get_macro_recall(guess_entities_1, gold_entities)\n",
    "macro_f1 = get_macro_f1(guess_entities_1, gold_entities)\n",
    "\n",
    "print(\n",
    "   \"micro_p={:.4f} micro_r={:.4f}, micro_f1={:.4f}, macro_p={:.4f}, macro_r={:.4f}, macro_f1={:.4f}\".format(\n",
    "       micro_p, micro_r, micro_f1, macro_p, macro_r, macro_f1\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_p=0.0000 micro_r=0.0000, micro_f1=0.0000, macro_p=0.0000, macro_r=0.0000, macro_f1=0.0000\n"
     ]
    }
   ],
   "source": [
    "from GENRE.genre.utils import (\n",
    "    get_micro_precision,\n",
    "    get_micro_recall,\n",
    "    get_micro_f1,\n",
    "    get_macro_precision,\n",
    "    get_macro_recall,\n",
    "    get_macro_f1,\n",
    ")\n",
    "\n",
    "micro_p = get_micro_precision(guess_entities_1, gold_entities)\n",
    "micro_r = get_micro_recall(guess_entities_1, gold_entities)\n",
    "micro_f1 = get_micro_f1(guess_entities_1, gold_entities)\n",
    "macro_p = get_macro_precision(guess_entities_1, gold_entities)\n",
    "macro_r = get_macro_recall(guess_entities_1, gold_entities)\n",
    "macro_f1 = get_macro_f1(guess_entities_1, gold_entities)\n",
    "\n",
    "print(\n",
    "   \"micro_p={:.4f} micro_r={:.4f}, micro_f1={:.4f}, macro_p={:.4f}, macro_r={:.4f}, macro_f1={:.4f}\".format(\n",
    "       micro_p, micro_r, micro_f1, macro_p, macro_r, macro_f1\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id_0', 145, 39, 'Pacific Marine Environmental Laboratory'),\n",
       " ('id_0', 365, 15, 'Baja California'),\n",
       " ('id_0', 1013, 13, 'oceanographer'),\n",
       " ('id_0', 1109, 5, 'Earth'),\n",
       " ('id_0', 1150, 14, 'carbon dioxide'),\n",
       " ('id_0', 1278, 9, 'carbonate'),\n",
       " ('id_0', 1385, 13, 'carbonic acid'),\n",
       " ('id_0', 1769, 21, 'Industrial Revolution'),\n",
       " ('id_1', 118, 33, '2006 Lathen maglev train accident'),\n",
       " ('id_1', 231, 6, 'maglev'),\n",
       " ('id_1', 358, 11, 'human error'),\n",
       " ('id_1', 454, 10, 'Transrapid'),\n",
       " ('id_1', 471, 2, 'cm'),\n",
       " ('id_1', 583, 9, 'Osnabrck'),\n",
       " ('id_1', 643, 4, 'euro'),\n",
       " ('id_2', 189, 8, 'asbestos'),\n",
       " ('id_2', 423, 16, 'terminal illness'),\n",
       " ('id_2', 459, 12, 'mesothelioma'),\n",
       " ('id_2', 520, 12, 'James Hardie'),\n",
       " ('id_2', 634, 10, 'asbestosis'),\n",
       " ('id_2', 693, 13, 'lung scarring'),\n",
       " ('id_2', 812, 6, 'cancer'),\n",
       " ('id_2', 861, 22, 'lungs and chest cavity'),\n",
       " ('id_2', 885, 16, 'abdominal cavity'),\n",
       " ('id_2', 910, 25, 'sac surrounding the heart'),\n",
       " ('id_2', 1136, 17, 'Victorian Premier'),\n",
       " ('id_2', 1154, 11, 'John Brumby')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baja California'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0][365-1:365+15-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id_0', 0, 4, 'National_Oceanic_and_Atmospheric_Administration'),\n",
       " ('id_0', 87, 49, 'National_Oceanic_and_Atmospheric_Administration'),\n",
       " ('id_0',\n",
       "  144,\n",
       "  39,\n",
       "  'National_Oceanic_and_Atmospheric_Administration_National_Marine_Environmental_Laboratory'),\n",
       " ('id_0', 210, 14, 'World_Ocean'),\n",
       " ('id_0', 345, 13, 'Pacific_Ocean'),\n",
       " ('id_0', 364, 23, 'Baja_California'),\n",
       " ('id_0', 391, 27, 'Vancouver'),\n",
       " ('id_0', 491, 17, 'Continental_shelf'),\n",
       " ('id_0', 556, 13, 'Marine_life'),\n",
       " ('id_0',\n",
       "  586,\n",
       "  6,\n",
       "  'Oceanic_carbonate_marine_life_in_the_United_States_and_Great_Britain_of_Great_Britain_and_Ireland_of_18441855'),\n",
       " ('id_0', 675, 10, 'California'),\n",
       " ('id_0',\n",
       "  703,\n",
       "  13,\n",
       "  'List_of_countries_by_number_of_military_and_paramilitary_personnel_in_the_second_year_of_conflict_with_the_United_States_(194446)'),\n",
       " ('id_0', 719, 72, 'Ocean_acidification'),\n",
       " ('id_0', 819, 11, 'Marine_life'),\n",
       " ('id_0',\n",
       "  838,\n",
       "  17,\n",
       "  'Continental_shelf_of_the_United_States_and_Great_Britain_of_Great_Britain_of_18441855_(1944-1955)'),\n",
       " ('id_0',\n",
       "  856,\n",
       "  9,\n",
       "  'List of countries by number of military and paramilitary personnel in the second year of conflict with the United States (194446) (194446) (194446) (194446) ) and increasing the levels of carbonic acid. \"Scientists have also seen a reduced ability of marine algae and free-floating plants and animals to produce protective carbonate shells\" added Feely noted that , according to the study , the oceans have absorbed more than 525 billion tons of carbon dioxide since the Industrial Revolution began  -'),\n",
       " ('id_1', 0, 42, 'Two_men_fined_over_2006_German_train_crash'),\n",
       " ('id_1', 117, 33, '2006_Lathen_maglev_train_accident'),\n",
       " ('id_1', 154, 7, 'Germany'),\n",
       " ('id_1', 176, 25, '2006_Lathen_maglev_train_accident'),\n",
       " ('id_1', 205, 18, '2006_Lathen_maglev_train_accident'),\n",
       " ('id_1', 230, 6, 'Maglev'),\n",
       " ('id_1', 378, 5, 'Float_(nautical)'),\n",
       " ('id_1', 394, 5, 'Track_(rail_transport)'),\n",
       " ('id_1', 406, 2, 'Rail_profile'),\n",
       " ('id_1', 426, 9, 'Magnetism_(rail_transport)'),\n",
       " ('id_1', 453, 10, 'Transrapid'),\n",
       " ('id_1', 470, 2, 'Centimetre'),\n",
       " ('id_1', 483, 5, 'Track_(rail_transport)'),\n",
       " ('id_1', 504, 12, 'Rail_profile'),\n",
       " ('id_1', 541, 4, 'Risk'),\n",
       " ('id_1', 549, 11, 'Derailment'),\n",
       " ('id_1', 582, 9, 'Osnabrck'),\n",
       " ('id_1', 603, 13, 'Track_management'),\n",
       " ('id_1', 642, 4, 'Euro'),\n",
       " ('id_1', 665, 13, 'Joerg_Metzner'),\n",
       " ('id_1', 686, 4, 'Euro'),\n",
       " ('id_1', 732, 12, 'Manslaughter'),\n",
       " ('id_1',\n",
       "  762,\n",
       "  24,\n",
       "  'Negligence in German railway accidents and incidents of the 2006 Lathen maglev train crash and of the third defendant. The third defendant, traffic superintendent Guenther Mueller, was unable to face trial due to suicide fears.   -'),\n",
       " ('id_2', 16, 8, 'Asbestos'),\n",
       " ('id_2', 38, 19, 'Victoria_(Australia)'),\n",
       " ('id_2', 80, 19, 'Victoria_(Australia)'),\n",
       " ('id_2', 165, 31, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 224, 19, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 251, 47, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 300, 3, 'The_Asbestos_Show'),\n",
       " ('id_2', 350, 8, 'Asbestos'),\n",
       " ('id_2', 422, 16, 'Terminal_illness'),\n",
       " ('id_2', 438, 1, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 458, 12, 'Mesothelioma'),\n",
       " ('id_2', 489, 3, 'The_Asbestos_Show'),\n",
       " ('id_2', 519, 12, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 549, 1, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 552, 239, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 793, 12, 'Mesothelioma'),\n",
       " ('id_2', 811, 6, 'Cancer'),\n",
       " ('id_2', 836, 3, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 856, 3, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2', 866, 3, 'Asbestos_and_the_health_effects_of_human_body_parts'),\n",
       " ('id_2',\n",
       "  882,\n",
       "  0,\n",
       "  'Asbestos_and_the_health_effects_of_human_body_parts_of_the_human_body_in_the_human_body'),\n",
       " ('id_2',\n",
       "  905,\n",
       "  3,\n",
       "  'Asbestos_and_the_health_effects_of_human_body_parts_of_the_human_body_in_the_human_body_in_the_human_body'),\n",
       " ('id_2',\n",
       "  925,\n",
       "  3,\n",
       "  'Asbestos_and_the_health_effects_of_human_bodies_in_the_human_body_in_the_human_body'),\n",
       " ('id_2',\n",
       "  934,\n",
       "  1,\n",
       "  'Asbestos and the human body in Victoria, Australia and the health care in Victoria, Australia, and the health care in Victoria, Australia, and New South Wales, and New South Wales, and New South Wales, and Victoria, England, and Victoria, England, and the U.S. and the U.S.A. and the U.S.A. and the U.S.A.  -')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_entities_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31maida_means.tsv.bz2\u001b[0m\r\n",
      "\u001b[01;34mdata\u001b[0m/\r\n",
      "\u001b[01;34mdataset\u001b[0m/\r\n",
      "docs.tsv\r\n",
      "\u001b[01;34mfairseq\u001b[0m/\r\n",
      "\u001b[01;34mfairseq_e2e_entity_linking_wiki_abs\u001b[0m/\r\n",
      "\u001b[01;34mfairseq_multilingual_entity_disambiguation\u001b[0m/\r\n",
      "\u001b[01;31mfairseq_multilingual_entity_disambiguation.tar.gz\u001b[0m\r\n",
      "\u001b[01;34mGENRE\u001b[0m/\r\n",
      "\u001b[01;34mKILT\u001b[0m/\r\n",
      "lang_title2wikidataID-normalized_with_redirect.pkl\r\n",
      "mentions_test.json\r\n",
      "mentions.tsv\r\n",
      "\u001b[01;34mmewsli_9\u001b[0m/\r\n",
      "mgenre_final.ipynb.invalid\r\n",
      "mgenre_final_with_mewsli.ipynb\r\n",
      "README.md\r\n",
      "requirements.txt\r\n",
      "titles_lang_all105_marisa_trie_with_redirect.pkl\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hanziconv\n",
      "  Downloading hanziconv-0.3.2.tar.gz (276 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: hanziconv\n",
      "  Building wheel for hanziconv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hanziconv: filename=hanziconv-0.3.2-py2.py3-none-any.whl size=23225 sha256=800fc8bc3ee5cfe9cacd7ccd8335d3cab8f5284f0eece677b82e7ac0eec312f5\n",
      "  Stored in directory: /home/petrakov/.cache/pip/wheels/24/bc/5f/95aceeea892d9bf06c29a9effde5908abcefd3fa23244fdaa5\n",
      "Successfully built hanziconv\n",
      "Installing collected packages: hanziconv\n",
      "Successfully installed hanziconv-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hanziconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENRE.scripts_mgenre.evaluate_kilt_dataset import evaluate_kilt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-06 02:07:20--  http://dl.fbaipublicfiles.com/KILT/wned-dev-kilt.jsonl\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12868348 (12M) [text/plain]\n",
      "Saving to: wned-dev-kilt.jsonl\n",
      "\n",
      "wned-dev-kilt.jsonl 100%[===================>]  12.27M  7.99MB/s    in 1.5s    \n",
      "\n",
      "2022-07-06 02:07:22 (7.99 MB/s) - wned-dev-kilt.jsonl saved [12868348/12868348]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget http://dl.fbaipublicfiles.com/GENRE/ace2004-test-kilt.jsonl\n",
    "#!wget http://dl.fbaipublicfiles.com/KILT/fever-dev-kilt.jsonl\n",
    "#!wget http://dl.fbaipublicfiles.com/GENRE/fairseq_wikipage_retrieval.tar.gz\n",
    "!wget http://dl.fbaipublicfiles.com/KILT/wned-dev-kilt.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('wned-dev-kilt.jsonl', 'r') as f:\n",
    "    wned = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb36b05dc284e45aa50d4ab77c42e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating :   0%|          | 0/12852476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-4221964283fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_kilt_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mGENRE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/success/mGENRE_MEL/GENRE/scripts_mgenre/evaluate_kilt_dataset.py\u001b[0m in \u001b[0;36mevaluate_kilt_dataset\u001b[0;34m(model, dataset, batch_size, beams, max_len_a, max_len_b, lenpen, trie, lang_title2wikidataID, wikidataID2lang_title, canonical_lang_title2wikidataID, wikidataID2canonical_lang_title, order, canonical, free_generation, mention2wikidataID, candidates_lowercase, allowed_langs, desc, max_candidates, only_en_candidates, only_freebase_candidates, wikidataID2freebaseID)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mbatch_trie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 mention = (\n\u001b[0m\u001b[1;32m     69\u001b[0m                     unicodedata.normalize(\n\u001b[1;32m     70\u001b[0m                         \u001b[0;34m\"NFKD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHanziConv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSimplified\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mention\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "evaluate_kilt_dataset(model = model_mGENRE, dataset = wned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ba3eb86d23cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfever\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "fever['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<wikidata.entity.Entity Q20145 'IU'>,\n",
       " m'Korea  singer,actress record producer (2017)')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()  # doctest: +SKIP\n",
    "entity = client.get('Q20145', load=True)\n",
    "entity, entity.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we present a function that illustrates predicted entity, text, right answer basing on the id as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_test_set(idx=0):\n",
    "    print(test_set[str(idx)]['mention_its']+\"\\n\")\n",
    "    start = test_set[str(idx)]['start_index']\n",
    "    end = test_set[str(idx)]['end_index']\n",
    "    mention_id = test_set[str(idx)]['mention_id']\n",
    "    text = test_set[str(idx)]['source_document']['text']\n",
    "    text = text[:start]+\"[START] \"+text[start:end]+\" [END]\"+text[end:]\n",
    "    print(f'{text[:start]}{bcolors.BOLD}{text[start:end+len(\"[START] \")+len(\" [END]\")]}{bcolors.END}{text[end+len(\"[START] \")+len(\" [END]\"):]}\\n')\n",
    "    result = model.sample(\n",
    "    sentences=[text],\n",
    "    text_to_id=lambda x: sorted(list(lang_title2wikidataID.get(\n",
    "        tuple(reversed((x.split(\" >> \")[0], x.split(\" >> \")[1][:2]))), [None])))[0],\n",
    "    marginalize=True)\n",
    "    print(result)\n",
    "    \n",
    "    entity = client.get(mention_id, load=True)\n",
    "    print(f'\\nCorrect entity : {mention_id, entity.label, entity.description}\\n')\n",
    "\n",
    "    candidates = [(i['id'], client.get(i['id'], load=True)) for i in result[0]]\n",
    "    print('Predicted entities:')\n",
    "    for i, entity in candidates:\n",
    "        if i is not None:\n",
    "            print(f'{i, entity.label, entity.description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New South Wales\n",
      "\n",
      "Bathurst Regional Council, the local government responsible for the city of Bathurst and its surrounds in Central Western \u001b[1m[START] New South Wales [END]\u001b[0m, Australia yesterday revealed it had received a development application for the new Bathurst Base Hospital.The new hospital is to be built behind the current hospital on the same site and is expected to cost the New South Wales government AUD96 million. The Bathurst Hospital will be the first in the Bathurst-Orange-Bloomfield redevelopment project.The new hospital will have 149 beds, up from 85 for the current hospital. The hospital will also feature a mental health unit - previously psychiatric patients had to travel to Orange to the Bloomfield Hospital for treatment.The Bathurst Hospital is expected to have state-of-the art facilities and will share some services with the to be constructed Orange Base Hospital.The Bathurst Regional Council has approved the demolition of 12 buildings on the hospital site for enabling works. The hospital site is heritage listed although council decided that as the buildings do not contribute to the streetscape they may be demolished.The demolitions are expected to take place late next month and will take around six weeks to complete. A temporary driveway will then be built to replace the current service entry for food and linen as it will become part of the work site.Upon completion of the new hospital, the current ward block will be demolished leaving the original building from the late 19th century intact. The original building is expected to become an education centre and consulting rooms.The original building was opened in 1834. Since then the facility has undergone numerous upgrades and add-ons, with the present ward block being opened in stages from 1978 to 1982.Other buildings expected to be retained include the Daffodil Cottage (a cancer care centre) and the original Nurse's quarters known as Poole House.\n",
      "\n",
      "[[{'id': 'Q3224', 'texts': ['New South Wales >> en', 'New South Wales >> de'], 'scores': tensor([-0.0940, -1.9361], device='cuda:4'), 'score': tensor(-0.2194, device='cuda:4')}, {'id': None, 'texts': ['New South Welsh English >> en', 'NewSouth Wales >> en'], 'scores': tensor([-1.5938, -1.6026], device='cuda:4'), 'score': tensor(-3.3674, device='cuda:4')}, {'id': 'Q1353', 'texts': ['National Capital Territory >> en'], 'scores': tensor([-1.6513], device='cuda:4'), 'score': tensor(-4.3689, device='cuda:4')}]]\n",
      "\n",
      "Correct entity : ('Q3224', m'New South Wales', m'state of Australia')\n",
      "\n",
      "Predicted entities:\n",
      "('Q3224', m'New South Wales', m'state of Australia')\n",
      "('Q1353', m'Delhi', m'Indian metropolis and union territory that includes New Delhi')\n"
     ]
    }
   ],
   "source": [
    "predict_from_test_set(2354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results:\n",
    "\n",
    "Language: **fa** (5 out of 61)\n",
    "\n",
    "Micro average (k=1): **1.0**\n",
    "\n",
    "Language: **sr** (105 out of 451)\n",
    "\n",
    "Micro average (k=1): **0.90476**\n",
    "\n",
    "Language: **ta** (25 out of 366)\n",
    "\n",
    "Micro average (k=1): **1.0**\n",
    "\n",
    "### Macro average (k=1): 0.96825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data.data_utils import collate_tokens\n",
    "\n",
    "\n",
    "def compute_results(idx):\n",
    "    start = test_set[str(idx)]['start_index']\n",
    "    end = test_set[str(idx)]['end_index']\n",
    "    mention_id = test_set[str(idx)]['mention_id']\n",
    "    text = test_set[str(idx)]['source_document']['text']\n",
    "    text = text[:start]+\"[START] \"+text[start:end]+\" [END]\"+text[end:]\n",
    "    print(start, end, min(start, len(text)-end))\n",
    "    #encoder = model.encoder(text)\n",
    "    #print(encoder)\n",
    "\n",
    "    result = model.sample(\n",
    "                    sentences=[text],\n",
    "                   text_to_id=lambda x: sorted(list(lang_title2wikidataID.get(\n",
    "       tuple(reversed((x.split(\" >> \")[0], x.split(\" >> \")[1][:2]))), [None])))[0],\n",
    "                    marginalize=True)\n",
    "    candidates = [(i['id'], client.get(i['id'], load=True)) for i in result[0] if i['id'] is not None]\n",
    "    entity = client.get(mention_id, load=True)\n",
    "    return {\n",
    "            \"correct\": mention_id, \n",
    "            \"predicted\": [i for i, _ in candidates]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 109 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct': 'Q36678', 'predicted': ['Q36678', 'Q2564150', 'Q7834492']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_results(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(lang='en', k_list=[1, 10, 20, 50, 100]):\n",
    "    scores = []\n",
    "    \n",
    "    for idx in tqdm(langs_idx[lang]):\n",
    "        scores.append(compute_results(idx))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_idx = {\n",
    "    'ar':[], 'en':[], 'tr':[]\n",
    "}\n",
    "for idx in test_set:\n",
    "    el = test_set[idx]\n",
    "    lang = el['document_id'][:2]\n",
    "    if lang in langs_idx:\n",
    "        langs_idx[lang].append(int(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_avg_lang(scores, lang='en', k_list=[1, 10, 20, 50, 100]):    \n",
    "    print(f'Language: {lang}')\n",
    "    results = []\n",
    "    for k in k_list:\n",
    "        n = 0\n",
    "        for i, row in enumerate(scores):\n",
    "            if scores['correct'] in scores['predicted'][:k]:\n",
    "                n += 1\n",
    "        results.append(round(n / total_mentions, 5))\n",
    "    for i, k in enumerate(k_list):\n",
    "        print(f'Micro average (k={k}):', results[i])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of GENRE exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
