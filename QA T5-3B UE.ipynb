{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver version: \u001b[1m510.85.02\u001b[m\r\n",
      "------------------- \u001b[1mDevice 0\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage:  4407MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m23C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 1\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage:   316MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m28C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 2\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage: 13837MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m32C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 3\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage:   316MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m23C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 4\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  9196MiB / 11264MiB\r\n",
      "Temperature: \u001b[92m22C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 5\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  9188MiB / 11264MiB\r\n",
      "Temperature: \u001b[92m22C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/petrakov/anaconda3/lib/python3.7/site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: spacy in /home/petrakov/anaconda3/lib/python3.7/site-packages (3.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (8.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: jinja2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (1.21.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: setuptools in /home/petrakov/anaconda3/lib/python3.7/site-packages (from spacy) (65.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/petrakov/anaconda3/lib/python3.7/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/petrakov/anaconda3/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (5.0.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flair 0.11.3 requires bpemb>=0.3.2, which is not installed.\n",
      "flair 0.11.3 requires conllu>=4.0, which is not installed.\n",
      "flair 0.11.3 requires deprecated>=1.2.4, which is not installed.\n",
      "flair 0.11.3 requires ftfy, which is not installed.\n",
      "flair 0.11.3 requires gensim>=3.4.0, which is not installed.\n",
      "flair 0.11.3 requires huggingface-hub, which is not installed.\n",
      "flair 0.11.3 requires hyperopt>=0.2.7, which is not installed.\n",
      "flair 0.11.3 requires janome, which is not installed.\n",
      "flair 0.11.3 requires konoha<5.0.0,>=4.0.0, which is not installed.\n",
      "flair 0.11.3 requires langdetect, which is not installed.\n",
      "flair 0.11.3 requires mpld3==0.3, which is not installed.\n",
      "flair 0.11.3 requires pptree, which is not installed.\n",
      "flair 0.11.3 requires segtok>=1.5.7, which is not installed.\n",
      "flair 0.11.3 requires gdown==4.4.0, but you have gdown 4.5.1 which is incompatible.\n",
      "flair 0.11.3 requires sentencepiece==0.1.95, but you have sentencepiece 0.1.97 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install -U requests\n",
    "!pip install spacy\n",
    "!pip install sentencepiece\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from wikidataintegrator import wdi_core\n",
    "from wikidata.client import Client\n",
    "import wikidata\n",
    "from itertools import compress\n",
    "\n",
    "import en_core_web_sm\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#nlp = en_core_web_sm.load()\n",
    "client = wikidata.client.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://dl.fbaipublicfiles.com/GENRE/lang_title2wikidataID-normalized_with_redirect.pkl\n",
    "    \n",
    "with open(\"lang_title2wikidataID-normalized_with_redirect.pkl\", \"rb\") as f:\n",
    "    lang_title2wikidataID = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_name(idd):\n",
    "    '''\n",
    "    This function returns a name of an entity and its description given WikiData id\n",
    "    \n",
    "        input:  (str) wikidata id, e.x. 'Q2'\n",
    "        output: (str) concatenated 'name, description' of a given entity\n",
    "    '''\n",
    "    entity = client.get(idd, load=True)\n",
    "    name = \"None\"\n",
    "    description = \"None\"\n",
    "    try:\n",
    "        name = entity.data[\"labels\"][\"en\"][\"value\"]\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    return name\n",
    "\n",
    "\n",
    "def text_to_id(x):\n",
    "    #splits = x.split(\" >> \")\n",
    "    if len(x) > 1:\n",
    "        return max(lang_title2wikidataID[tuple(reversed(x))], key=lambda y: int(y[1:]))\n",
    "    else:\n",
    "        return 'Empty'\n",
    "    \n",
    "def from_text_to_id(x):\n",
    "    return list(lang_title2wikidataID[(\"en\", x)])[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "### For top k sample\n",
    "    \n",
    "def getScores(ids, scores, pad_token_id):\n",
    "    \"\"\"get sequence scores from model.generate output\"\"\"\n",
    "    scores = torch.stack(scores, dim=1)\n",
    "    log_probs = torch.log_softmax(scores, dim=2)\n",
    "    # remove start token\n",
    "    ids = ids[:,1:]\n",
    "    # gather needed probs\n",
    "    x = ids.unsqueeze(-1).expand(log_probs.shape)\n",
    "    needed_logits = torch.gather(log_probs, 2, x)\n",
    "    final_logits = needed_logits[:, :, 0]\n",
    "    padded_mask = (ids == pad_token_id)\n",
    "    final_logits[padded_mask] = 0\n",
    "    final_scores = final_logits.sum(dim=-1)\n",
    "    return final_scores.cpu().detach().numpy()\n",
    "\n",
    "def topkSample(input, model, tokenizer, \n",
    "                num_samples=5,\n",
    "                num_beams=1,\n",
    "                max_output_length=128):\n",
    "    tokenized = tokenizer(input, return_tensors=\"pt\")\n",
    "    tokenized.to(device)\n",
    "    out = model.generate(**tokenized,\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences = num_samples,\n",
    "                        num_beams = num_beams,\n",
    "                        eos_token_id = tokenizer.eos_token_id,\n",
    "                        pad_token_id = tokenizer.pad_token_id,\n",
    "                        output_scores = True,\n",
    "                        return_dict_in_generate=True,\n",
    "                        max_length=max_output_length,)\n",
    "    out_tokens = out.sequences\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    out_scores = getScores(out_tokens, out.scores, tokenizer.pad_token_id)\n",
    "    \n",
    "    pair_list = [(x[0], x[1]) for x in zip(out_str, out_scores)]\n",
    "    sorted_pair_list = sorted(pair_list, key=lambda x:x[1], reverse=True)\n",
    "    return sorted_pair_list\n",
    "\n",
    "def greedyPredict(input, model, tokenizer):\n",
    "    input_ids = tokenizer([input], return_tensors=\"pt\").input_ids\n",
    "    out_tokens = model.generate(input_ids)\n",
    "    out_str = tokenizer.batch_decode(out_tokens, skip_special_tokens=True)\n",
    "    return out_str[0]\n",
    "\n",
    "\n",
    "def check_t5_sq(t5_tok, t5_qa_model):\n",
    "    \n",
    "    sq_test_data = np.load(\"simple_questions_test.npy\")\n",
    "    questions = sq_test_data[:,3]\n",
    "\n",
    "\n",
    "    answers = []\n",
    "    for i in tqdm(range(len(questions))):\n",
    "        input_ids = t5_tok(questions[i], return_tensors=\"pt\").input_ids\n",
    "        input_ids = input_ids.to(device)\n",
    "        gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "        answers.append(gen_output)\n",
    "\n",
    "\n",
    "    preds_sq = []\n",
    "    for x in answers:\n",
    "        preds_sq.append(t5_tok.decode(x, skip_special_tokens=True))\n",
    "\n",
    "\n",
    "    preds_id_sq = []\n",
    "    for i in range(len(preds_sq)):\n",
    "        try:\n",
    "            x = from_text_to_id(preds_sq[i])\n",
    "        except:\n",
    "            x = \"None\"\n",
    "\n",
    "        preds_id_sq.append(x)\n",
    "\n",
    "    right_sq = 0\n",
    "    for i in tqdm(range(len(preds_id_sq))):\n",
    "        if preds_id_sq[i] == sq_test_data[i,2]:\n",
    "            right_sq += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    acc = right_sq/len(preds_id_sq)\n",
    "    \n",
    "    return acc, preds_id_sq\n",
    "\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5eaaa7c0fc4001a382ecaae21ab7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42182e1d00254fefb25568c559a77ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9cf4f0cfd240b9bf8c2c120a448b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1652a5b869664aa3912c96a25dd20822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378f1263f24b4363851a8011fc8aec06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 2048)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-xl-ssm-nq\")\n",
    "t5_tok = AutoTokenizer.from_pretrained(\"google/t5-xl-ssm-nq\")\n",
    "\n",
    "# t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-3b-ssm\")#\"google/t5-11b-ssm-tqa\")\n",
    "# t5_tok = AutoTokenizer.from_pretrained(\"google/t5-3b-ssm\")\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "rubq_test = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "rubq_answers = np.load(\"all_rubq_test_answers_1_hop_uri.npy\", allow_pickle=True)\n",
    "\n",
    "entities_test_rubq = np.load(\"entities_test_rubq.npy\")\n",
    "rubq_test_answers = np.load(\"all_rubq_test_answers_1_hop_uri.npy\", allow_pickle=True)\n",
    "rubq_test = pd.DataFrame({\"subject\":entities_test_rubq, \"question\":rubq_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What can cause a tsunami?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = rubq_test.question[0]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_proba(question, model, tokenizer, device, num_beams = 10, max_sequence_length = 32):\n",
    "    \"\"\"This function generates sequence = answer on given question\n",
    "    \n",
    "    1) it encodes qustion using tokenizer\n",
    "    2) converts tokenized text to device\n",
    "    3) generate answer with dredefined beam size using tokenized text\n",
    "    4) as output we receive answers and their probabilities\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer([question], return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    out = model.generate(input_ids,\n",
    "                         num_return_sequences = num_beams,\n",
    "                         num_beams = num_beams,\n",
    "                         eos_token_id = tokenizer.eos_token_id,\n",
    "                         pad_token_id = tokenizer.pad_token_id,\n",
    "                         output_scores = True,\n",
    "                         return_dict_in_generate=True,\n",
    "                         early_stopping=True,\n",
    "                         max_length=max_sequence_length)\n",
    "    \n",
    "    prediction = [tokenizer.decode(out.sequences[i], skip_special_tokens=True) for i in range(num_beams)]\n",
    "    probs = softmax(out.sequences_scores)\n",
    "    \n",
    "    return prediction, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = len(rubq_test)\n",
    "three_quest = list(rubq_test.question)[:sample_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [predict_and_proba(three_quest[i], model = t5_qa_model, tokenizer=t5_tok, device=device) for i in range(sample_questions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [i[0] for i in result]\n",
    "probas = [i[1] for i in result]\n",
    "probas = [i.detach().to(\"cpu\") for i in probas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with uncertainty on a single model (Entropy, Maxprob, Delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy on the 5% the most confident from the entropy point of view = 76.67%\n",
      "Top-1 accuracy on the 10% the most confident from the entropy point of view = 71.43%\n",
      "Top-1 accuracy on the 15% the most confident from the entropy point of view = 69.1%\n",
      "Top-1 accuracy on the 20% the most confident from the entropy point of view = 69.75%\n",
      "Top-1 accuracy on the 25% the most confident from the entropy point of view = 70.37%\n",
      "Top-1 accuracy on the 30% the most confident from the entropy point of view = 66.57%\n",
      "Top-1 accuracy on the 35% the most confident from the entropy point of view = 64.34%\n",
      "Top-1 accuracy on the 40% the most confident from the entropy point of view = 61.260000000000005%\n",
      "Top-1 accuracy on the 45% the most confident from the entropy point of view = 57.68%\n",
      "Top-1 accuracy on the 50% the most confident from the entropy point of view = 53.959999999999994%\n",
      "Top-1 accuracy on the 55% the most confident from the entropy point of view = 50.77%\n",
      "Top-1 accuracy on the 60% the most confident from the entropy point of view = 48.03%\n",
      "Top-1 accuracy on the 65% the most confident from the entropy point of view = 45.78%\n",
      "Top-1 accuracy on the 70% the most confident from the entropy point of view = 43.61%\n",
      "Top-1 accuracy on the 75% the most confident from the entropy point of view = 41.17%\n",
      "Top-1 accuracy on the 80% the most confident from the entropy point of view = 39.300000000000004%\n",
      "Top-1 accuracy on the 85% the most confident from the entropy point of view = 37.8%\n",
      "Top-1 accuracy on the 90% the most confident from the entropy point of view = 36.27%\n",
      "Top-1 accuracy on the 95% the most confident from the entropy point of view = 34.64%\n",
      "Top-1 accuracy on the 100% the most confident from the entropy point of view = 32.879999999999995%\n",
      "\n",
      "\n",
      "Top-2 accuracy on the 5% the most confident from the entropy point of view = 78.33%\n",
      "Top-2 accuracy on the 10% the most confident from the entropy point of view = 73.95%\n",
      "Top-2 accuracy on the 15% the most confident from the entropy point of view = 71.35000000000001%\n",
      "Top-2 accuracy on the 20% the most confident from the entropy point of view = 71.85000000000001%\n",
      "Top-2 accuracy on the 25% the most confident from the entropy point of view = 73.74000000000001%\n",
      "Top-2 accuracy on the 30% the most confident from the entropy point of view = 71.07%\n",
      "Top-2 accuracy on the 35% the most confident from the entropy point of view = 68.19%\n",
      "Top-2 accuracy on the 40% the most confident from the entropy point of view = 67.16%\n",
      "Top-2 accuracy on the 45% the most confident from the entropy point of view = 64.23%\n",
      "Top-2 accuracy on the 50% the most confident from the entropy point of view = 60.709999999999994%\n",
      "Top-2 accuracy on the 55% the most confident from the entropy point of view = 57.06%\n",
      "Top-2 accuracy on the 60% the most confident from the entropy point of view = 54.63%\n",
      "Top-2 accuracy on the 65% the most confident from the entropy point of view = 52.27%\n",
      "Top-2 accuracy on the 70% the most confident from the entropy point of view = 50.12%\n",
      "Top-2 accuracy on the 75% the most confident from the entropy point of view = 47.69%\n",
      "Top-2 accuracy on the 80% the most confident from the entropy point of view = 45.629999999999995%\n",
      "Top-2 accuracy on the 85% the most confident from the entropy point of view = 43.95%\n",
      "Top-2 accuracy on the 90% the most confident from the entropy point of view = 42.08%\n",
      "Top-2 accuracy on the 95% the most confident from the entropy point of view = 40.14%\n",
      "Top-2 accuracy on the 100% the most confident from the entropy point of view = 38.11%\n",
      "\n",
      "\n",
      "Top-5 accuracy on the 5% the most confident from the entropy point of view = 78.33%\n",
      "Top-5 accuracy on the 10% the most confident from the entropy point of view = 76.47%\n",
      "Top-5 accuracy on the 15% the most confident from the entropy point of view = 74.72%\n",
      "Top-5 accuracy on the 20% the most confident from the entropy point of view = 76.05%\n",
      "Top-5 accuracy on the 25% the most confident from the entropy point of view = 78.11%\n",
      "Top-5 accuracy on the 30% the most confident from the entropy point of view = 75.28%\n",
      "Top-5 accuracy on the 35% the most confident from the entropy point of view = 73.00999999999999%\n",
      "Top-5 accuracy on the 40% the most confident from the entropy point of view = 72.42%\n",
      "Top-5 accuracy on the 45% the most confident from the entropy point of view = 70.41%\n",
      "Top-5 accuracy on the 50% the most confident from the entropy point of view = 67.12%\n",
      "Top-5 accuracy on the 55% the most confident from the entropy point of view = 63.959999999999994%\n",
      "Top-5 accuracy on the 60% the most confident from the entropy point of view = 61.519999999999996%\n",
      "Top-5 accuracy on the 65% the most confident from the entropy point of view = 58.879999999999995%\n",
      "Top-5 accuracy on the 70% the most confident from the entropy point of view = 56.87%\n",
      "Top-5 accuracy on the 75% the most confident from the entropy point of view = 54.89000000000001%\n",
      "Top-5 accuracy on the 80% the most confident from the entropy point of view = 52.790000000000006%\n",
      "Top-5 accuracy on the 85% the most confident from the entropy point of view = 50.89%\n",
      "Top-5 accuracy on the 90% the most confident from the entropy point of view = 48.730000000000004%\n",
      "Top-5 accuracy on the 95% the most confident from the entropy point of view = 46.63%\n",
      "Top-5 accuracy on the 100% the most confident from the entropy point of view = 44.35%\n",
      "\n",
      "\n",
      "Top-10 accuracy on the 5% the most confident from the entropy point of view = 83.33%\n",
      "Top-10 accuracy on the 10% the most confident from the entropy point of view = 82.35%\n",
      "Top-10 accuracy on the 15% the most confident from the entropy point of view = 80.9%\n",
      "Top-10 accuracy on the 20% the most confident from the entropy point of view = 81.51%\n",
      "Top-10 accuracy on the 25% the most confident from the entropy point of view = 82.49%\n",
      "Top-10 accuracy on the 30% the most confident from the entropy point of view = 80.06%\n",
      "Top-10 accuracy on the 35% the most confident from the entropy point of view = 77.83%\n",
      "Top-10 accuracy on the 40% the most confident from the entropy point of view = 77.05%\n",
      "Top-10 accuracy on the 45% the most confident from the entropy point of view = 75.28%\n",
      "Top-10 accuracy on the 50% the most confident from the entropy point of view = 72.00999999999999%\n",
      "Top-10 accuracy on the 55% the most confident from the entropy point of view = 68.71000000000001%\n",
      "Top-10 accuracy on the 60% the most confident from the entropy point of view = 66.85%\n",
      "Top-10 accuracy on the 65% the most confident from the entropy point of view = 64.46%\n",
      "Top-10 accuracy on the 70% the most confident from the entropy point of view = 62.29%\n",
      "Top-10 accuracy on the 75% the most confident from the entropy point of view = 60.4%\n",
      "Top-10 accuracy on the 80% the most confident from the entropy point of view = 58.17%\n",
      "Top-10 accuracy on the 85% the most confident from the entropy point of view = 56.35%\n",
      "Top-10 accuracy on the 90% the most confident from the entropy point of view = 54.26%\n",
      "Top-10 accuracy on the 95% the most confident from the entropy point of view = 52.129999999999995%\n",
      "Top-10 accuracy on the 100% the most confident from the entropy point of view = 49.66%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_quantiles = 20\n",
    "\n",
    "quants = [thresh / num_quantiles for thresh in range(1, num_quantiles+1)]\n",
    "entropies = [scipy.stats.entropy(i) for i in probas]\n",
    "thresholds_entropy = [np.quantile(entropies, q) for q in quants]\n",
    "\n",
    "accuracy_for_each_topk = []\n",
    "\n",
    "#top_k pred\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    \n",
    "    accuracy_for_each_quantile = {}\n",
    "\n",
    "    for quantile in range(num_quantiles):\n",
    "\n",
    "        # list of predictions\n",
    "        list_of_predictions = list(compress(predictions, entropies <= thresholds_entropy[quantile]))\n",
    "        \n",
    "        #list of correct answers\n",
    "        list_of_correct_answers = list(compress(rubq_test_answers[:sample_questions], entropies <= thresholds_entropy[quantile]))\n",
    "        \n",
    "        # choose top k predictions\n",
    "        top_k_list_of_predictions = [i[:top_k] for i in list_of_predictions]\n",
    "\n",
    "        top_k_list_of_predicted_ids= []\n",
    "        for sample in top_k_list_of_predictions:\n",
    "            new = []\n",
    "            for prediction in sample:\n",
    "                try:\n",
    "                    x = from_text_to_id(prediction)\n",
    "                except:\n",
    "                    x = \"None\"\n",
    "                new.append(x)\n",
    "\n",
    "            top_k_list_of_predicted_ids.append(new)\n",
    "\n",
    "\n",
    "        right = 0\n",
    "        for i in range(len(list_of_correct_answers)):\n",
    "            if any(item in top_k_list_of_predicted_ids[i] for item in list_of_correct_answers[i]):\n",
    "                right += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        accuracy = np.round(right/len(list_of_correct_answers), 4)*100\n",
    "        print(f\"Top-{top_k} accuracy on the {(quantile+1)*(int(100/num_quantiles))}% the most confident from the entropy point of view = {accuracy}%\")\n",
    "\n",
    "        accuracy_for_each_quantile[(quantile+1)*(int(100/num_quantiles))] = accuracy\n",
    "        accuracy_for_each_topk.append(accuracy_for_each_quantile)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "plt.title(\"Rejection curves based on Entropy for test set RuBQ 2.0 (1186 questions)\", fontdict=font_title)\n",
    "\n",
    "font = {'family': 'serif',\n",
    "            'color': 'darkred',\n",
    "            'weight': 'normal',\n",
    "            'size': 16\n",
    "            }\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color': 'darkred',\n",
    "              'weight': 'normal',\n",
    "              'size': 20\n",
    "              }\n",
    "\n",
    "plt.xlabel(\"Rejection rate, %\", fontdict=font)\n",
    "plt.ylabel(\"Accuracy, %\", fontdict=font)\n",
    "plt.xticks(ticks=np.arange(0, 100, step=5))\n",
    "plt.grid(color='black', linewidth=0.15)\n",
    "\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[:num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[:num_quantiles][0].values())),\n",
    "         label=f\"Top-{1} Accuracy via Entropy\", c=\"blue\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values())),\n",
    "         label=f\"Top-{2} Accuracy via Entropy\", c=\"red\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values())),\n",
    "         label=f\"Top-{5} Accuracy via Entropy\", c=\"green\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values())),\n",
    "         label=f\"Top-{10} Accuracy via Entropy\", c=\"orange\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "\n",
    "accuracy_on_full_data_top_1 = np.array(list(accuracy_for_each_topk[:num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_2 = np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_5 = np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_10 = np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values()))[-1]\n",
    "\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_1, 2)), (0 - 4.5, accuracy_on_full_data_top_1));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_2, 2)), (0 - 4.5, accuracy_on_full_data_top_2));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_5, 2)), (0 - 4.5, accuracy_on_full_data_top_5));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_10, 2)), (0 - 4.5, accuracy_on_full_data_top_10));\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy on the 5% the most confident from the Maxprob point of view = 100.0%\n",
      "Top-1 accuracy on the 10% the most confident from the Maxprob point of view = 76.67%\n",
      "Top-1 accuracy on the 15% the most confident from the Maxprob point of view = 73.11%\n",
      "Top-1 accuracy on the 20% the most confident from the Maxprob point of view = 71.91%\n",
      "Top-1 accuracy on the 25% the most confident from the Maxprob point of view = 69.75%\n",
      "Top-1 accuracy on the 30% the most confident from the Maxprob point of view = 69.36%\n",
      "Top-1 accuracy on the 35% the most confident from the Maxprob point of view = 68.82000000000001%\n",
      "Top-1 accuracy on the 40% the most confident from the Maxprob point of view = 64.58%\n",
      "Top-1 accuracy on the 45% the most confident from the Maxprob point of view = 60.84%\n",
      "Top-1 accuracy on the 50% the most confident from the Maxprob point of view = 57.120000000000005%\n",
      "Top-1 accuracy on the 55% the most confident from the Maxprob point of view = 54.13%\n",
      "Top-1 accuracy on the 60% the most confident from the Maxprob point of view = 51.07000000000001%\n",
      "Top-1 accuracy on the 65% the most confident from the Maxprob point of view = 49.16%\n",
      "Top-1 accuracy on the 70% the most confident from the Maxprob point of view = 46.949999999999996%\n",
      "Top-1 accuracy on the 75% the most confident from the Maxprob point of view = 44.58%\n",
      "Top-1 accuracy on the 80% the most confident from the Maxprob point of view = 42.07%\n",
      "Top-1 accuracy on the 85% the most confident from the Maxprob point of view = 39.62%\n",
      "Top-1 accuracy on the 90% the most confident from the Maxprob point of view = 37.8%\n",
      "Top-1 accuracy on the 95% the most confident from the Maxprob point of view = 36.27%\n",
      "Top-1 accuracy on the 100% the most confident from the Maxprob point of view = 34.64%\n",
      "\n",
      "\n",
      "Top-2 accuracy on the 5% the most confident from the Maxprob point of view = 100.0%\n",
      "Top-2 accuracy on the 10% the most confident from the Maxprob point of view = 78.33%\n",
      "Top-2 accuracy on the 15% the most confident from the Maxprob point of view = 74.79%\n",
      "Top-2 accuracy on the 20% the most confident from the Maxprob point of view = 74.16%\n",
      "Top-2 accuracy on the 25% the most confident from the Maxprob point of view = 71.85000000000001%\n",
      "Top-2 accuracy on the 30% the most confident from the Maxprob point of view = 72.39%\n",
      "Top-2 accuracy on the 35% the most confident from the Maxprob point of view = 71.91%\n",
      "Top-2 accuracy on the 40% the most confident from the Maxprob point of view = 68.92%\n",
      "Top-2 accuracy on the 45% the most confident from the Maxprob point of view = 65.89%\n",
      "Top-2 accuracy on the 50% the most confident from the Maxprob point of view = 63.480000000000004%\n",
      "Top-2 accuracy on the 55% the most confident from the Maxprob point of view = 60.199999999999996%\n",
      "Top-2 accuracy on the 60% the most confident from the Maxprob point of view = 57.06%\n",
      "Top-2 accuracy on the 65% the most confident from the Maxprob point of view = 55.2%\n",
      "Top-2 accuracy on the 70% the most confident from the Maxprob point of view = 52.790000000000006%\n",
      "Top-2 accuracy on the 75% the most confident from the Maxprob point of view = 50.239999999999995%\n",
      "Top-2 accuracy on the 80% the most confident from the Maxprob point of view = 47.92%\n",
      "Top-2 accuracy on the 85% the most confident from the Maxprob point of view = 45.73%\n",
      "Top-2 accuracy on the 90% the most confident from the Maxprob point of view = 43.85%\n",
      "Top-2 accuracy on the 95% the most confident from the Maxprob point of view = 42.08%\n",
      "Top-2 accuracy on the 100% the most confident from the Maxprob point of view = 40.14%\n",
      "\n",
      "\n",
      "Top-5 accuracy on the 5% the most confident from the Maxprob point of view = 100.0%\n",
      "Top-5 accuracy on the 10% the most confident from the Maxprob point of view = 78.33%\n",
      "Top-5 accuracy on the 15% the most confident from the Maxprob point of view = 77.31%\n",
      "Top-5 accuracy on the 20% the most confident from the Maxprob point of view = 76.97%\n",
      "Top-5 accuracy on the 25% the most confident from the Maxprob point of view = 76.05%\n",
      "Top-5 accuracy on the 30% the most confident from the Maxprob point of view = 77.10000000000001%\n",
      "Top-5 accuracy on the 35% the most confident from the Maxprob point of view = 76.4%\n",
      "Top-5 accuracy on the 40% the most confident from the Maxprob point of view = 73.49%\n",
      "Top-5 accuracy on the 45% the most confident from the Maxprob point of view = 70.74000000000001%\n",
      "Top-5 accuracy on the 50% the most confident from the Maxprob point of view = 68.35%\n",
      "Top-5 accuracy on the 55% the most confident from the Maxprob point of view = 65.25999999999999%\n",
      "Top-5 accuracy on the 60% the most confident from the Maxprob point of view = 62.580000000000005%\n",
      "Top-5 accuracy on the 65% the most confident from the Maxprob point of view = 60.809999999999995%\n",
      "Top-5 accuracy on the 70% the most confident from the Maxprob point of view = 59.14%\n",
      "Top-5 accuracy on the 75% the most confident from the Maxprob point of view = 56.75%\n",
      "Top-5 accuracy on the 80% the most confident from the Maxprob point of view = 54.779999999999994%\n",
      "Top-5 accuracy on the 85% the most confident from the Maxprob point of view = 53.0%\n",
      "Top-5 accuracy on the 90% the most confident from the Maxprob point of view = 50.79%\n",
      "Top-5 accuracy on the 95% the most confident from the Maxprob point of view = 48.64%\n",
      "Top-5 accuracy on the 100% the most confident from the Maxprob point of view = 46.54%\n",
      "\n",
      "\n",
      "Top-10 accuracy on the 5% the most confident from the Maxprob point of view = 100.0%\n",
      "Top-10 accuracy on the 10% the most confident from the Maxprob point of view = 83.33%\n",
      "Top-10 accuracy on the 15% the most confident from the Maxprob point of view = 82.35%\n",
      "Top-10 accuracy on the 20% the most confident from the Maxprob point of view = 81.46%\n",
      "Top-10 accuracy on the 25% the most confident from the Maxprob point of view = 81.51%\n",
      "Top-10 accuracy on the 30% the most confident from the Maxprob point of view = 81.47999999999999%\n",
      "Top-10 accuracy on the 35% the most confident from the Maxprob point of view = 81.17999999999999%\n",
      "Top-10 accuracy on the 40% the most confident from the Maxprob point of view = 77.83%\n",
      "Top-10 accuracy on the 45% the most confident from the Maxprob point of view = 75.58%\n",
      "Top-10 accuracy on the 50% the most confident from the Maxprob point of view = 73.22%\n",
      "Top-10 accuracy on the 55% the most confident from the Maxprob point of view = 70.15%\n",
      "Top-10 accuracy on the 60% the most confident from the Maxprob point of view = 67.33%\n",
      "Top-10 accuracy on the 65% the most confident from the Maxprob point of view = 66.01%\n",
      "Top-10 accuracy on the 70% the most confident from the Maxprob point of view = 64.59%\n",
      "Top-10 accuracy on the 75% the most confident from the Maxprob point of view = 62.17%\n",
      "Top-10 accuracy on the 80% the most confident from the Maxprob point of view = 60.4%\n",
      "Top-10 accuracy on the 85% the most confident from the Maxprob point of view = 58.589999999999996%\n",
      "Top-10 accuracy on the 90% the most confident from the Maxprob point of view = 56.35%\n",
      "Top-10 accuracy on the 95% the most confident from the Maxprob point of view = 54.169999999999995%\n",
      "Top-10 accuracy on the 100% the most confident from the Maxprob point of view = 52.04%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_quantiles = 20\n",
    "\n",
    "quants = [thresh / num_quantiles for thresh in range(1, num_quantiles+1)]\n",
    "max_probs = [i[0] for i in probas]\n",
    "thresholds_maxprob = [np.quantile(max_probs, q) for q in quants]\n",
    "thresholds_maxprob = thresholds_maxprob[::-1]\n",
    "\n",
    "accuracy_for_each_topk = []\n",
    "\n",
    "#top_k pred\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    \n",
    "    accuracy_for_each_quantile = {}\n",
    "\n",
    "    for quantile in range(num_quantiles):\n",
    "\n",
    "        # list of predictions\n",
    "        list_of_predictions = list(compress(predictions, max_probs >= thresholds_maxprob[quantile]))\n",
    "        \n",
    "        #list of correct answers\n",
    "        list_of_correct_answers = list(compress(rubq_test_answers[:sample_questions], max_probs >= thresholds_maxprob[quantile]))\n",
    "        \n",
    "        # choose top k predictions\n",
    "        top_k_list_of_predictions = [i[:top_k] for i in list_of_predictions]\n",
    "\n",
    "        top_k_list_of_predicted_ids= []\n",
    "        for sample in top_k_list_of_predictions:\n",
    "            new = []\n",
    "            for prediction in sample:\n",
    "                try:\n",
    "                    x = from_text_to_id(prediction)\n",
    "                except:\n",
    "                    x = \"None\"\n",
    "                new.append(x)\n",
    "\n",
    "            top_k_list_of_predicted_ids.append(new)\n",
    "\n",
    "\n",
    "        right = 0\n",
    "        for i in range(len(list_of_correct_answers)):\n",
    "            if any(item in top_k_list_of_predicted_ids[i] for item in list_of_correct_answers[i]):\n",
    "                right += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        accuracy = np.round(right/len(list_of_correct_answers), 4)*100\n",
    "        print(f\"Top-{top_k} accuracy on the {(quantile+1)*(int(100/num_quantiles))}% the most confident from the Maxprob point of view = {accuracy}%\")\n",
    "\n",
    "        accuracy_for_each_quantile[(quantile+1)*(int(100/num_quantiles))] = accuracy\n",
    "        accuracy_for_each_topk.append(accuracy_for_each_quantile)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "plt.title(\"Rejection curves based on Maxprob for test set RuBQ 2.0 (1186 questions)\", fontdict=font_title)\n",
    "\n",
    "font = {'family': 'serif',\n",
    "            'color': 'darkred',\n",
    "            'weight': 'normal',\n",
    "            'size': 16\n",
    "            }\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color': 'darkred',\n",
    "              'weight': 'normal',\n",
    "              'size': 20\n",
    "              }\n",
    "\n",
    "plt.xlabel(\"Rejection rate, %\", fontdict=font)\n",
    "plt.ylabel(\"Accuracy, %\", fontdict=font)\n",
    "plt.xticks(ticks=np.arange(0, 100, step=5))\n",
    "plt.grid(color='black', linewidth=0.15)\n",
    "\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[:num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[:num_quantiles][0].values())),\n",
    "         label=f\"Top-{1} Accuracy via Maxprob\", c=\"blue\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values())),\n",
    "         label=f\"Top-{2} Accuracy via Maxprob\", c=\"red\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values())),\n",
    "         label=f\"Top-{5} Accuracy via Maxprob\", c=\"green\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values())),\n",
    "         label=f\"Top-{10} Accuracy via Maxprob\", c=\"orange\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "\n",
    "accuracy_on_full_data_top_1 = np.array(list(accuracy_for_each_topk[:num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_2 = np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_5 = np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_10 = np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values()))[-1]\n",
    "\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_1, 2)), (0 - 4.5, accuracy_on_full_data_top_1));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_2, 2)), (0 - 4.5, accuracy_on_full_data_top_2));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_5, 2)), (0 - 4.5, accuracy_on_full_data_top_5));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_10, 2)), (0 - 4.5, accuracy_on_full_data_top_10));\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy on the 5% the most confident from the Delta point of view = 100.0%\n",
      "Top-1 accuracy on the 10% the most confident from the Delta point of view = 80.0%\n",
      "Top-1 accuracy on the 15% the most confident from the Delta point of view = 73.11%\n",
      "Top-1 accuracy on the 20% the most confident from the Delta point of view = 71.91%\n",
      "Top-1 accuracy on the 25% the most confident from the Delta point of view = 71.85000000000001%\n",
      "Top-1 accuracy on the 30% the most confident from the Delta point of view = 71.04%\n",
      "Top-1 accuracy on the 35% the most confident from the Delta point of view = 69.1%\n",
      "Top-1 accuracy on the 40% the most confident from the Delta point of view = 63.370000000000005%\n",
      "Top-1 accuracy on the 45% the most confident from the Delta point of view = 59.58%\n",
      "Top-1 accuracy on the 50% the most confident from the Delta point of view = 56.37%\n",
      "Top-1 accuracy on the 55% the most confident from the Delta point of view = 54.47%\n",
      "Top-1 accuracy on the 60% the most confident from the Delta point of view = 50.77%\n",
      "Top-1 accuracy on the 65% the most confident from the Delta point of view = 48.46%\n",
      "Top-1 accuracy on the 70% the most confident from the Delta point of view = 46.04%\n",
      "Top-1 accuracy on the 75% the most confident from the Delta point of view = 43.61%\n",
      "Top-1 accuracy on the 80% the most confident from the Delta point of view = 41.839999999999996%\n",
      "Top-1 accuracy on the 85% the most confident from the Delta point of view = 39.83%\n",
      "Top-1 accuracy on the 90% the most confident from the Delta point of view = 37.7%\n",
      "Top-1 accuracy on the 95% the most confident from the Delta point of view = 36.27%\n",
      "Top-1 accuracy on the 100% the most confident from the Delta point of view = 34.64%\n",
      "\n",
      "\n",
      "Top-2 accuracy on the 5% the most confident from the Delta point of view = 100.0%\n",
      "Top-2 accuracy on the 10% the most confident from the Delta point of view = 81.67%\n",
      "Top-2 accuracy on the 15% the most confident from the Delta point of view = 74.79%\n",
      "Top-2 accuracy on the 20% the most confident from the Delta point of view = 74.16%\n",
      "Top-2 accuracy on the 25% the most confident from the Delta point of view = 73.95%\n",
      "Top-2 accuracy on the 30% the most confident from the Delta point of view = 73.74000000000001%\n",
      "Top-2 accuracy on the 35% the most confident from the Delta point of view = 71.63000000000001%\n",
      "Top-2 accuracy on the 40% the most confident from the Delta point of view = 67.47%\n",
      "Top-2 accuracy on the 45% the most confident from the Delta point of view = 64.42%\n",
      "Top-2 accuracy on the 50% the most confident from the Delta point of view = 61.61%\n",
      "Top-2 accuracy on the 55% the most confident from the Delta point of view = 59.53000000000001%\n",
      "Top-2 accuracy on the 60% the most confident from the Delta point of view = 55.83%\n",
      "Top-2 accuracy on the 65% the most confident from the Delta point of view = 53.790000000000006%\n",
      "Top-2 accuracy on the 70% the most confident from the Delta point of view = 51.1%\n",
      "Top-2 accuracy on the 75% the most confident from the Delta point of view = 48.55%\n",
      "Top-2 accuracy on the 80% the most confident from the Delta point of view = 46.68%\n",
      "Top-2 accuracy on the 85% the most confident from the Delta point of view = 44.99%\n",
      "Top-2 accuracy on the 90% the most confident from the Delta point of view = 42.96%\n",
      "Top-2 accuracy on the 95% the most confident from the Delta point of view = 41.42%\n",
      "Top-2 accuracy on the 100% the most confident from the Delta point of view = 39.96%\n",
      "\n",
      "\n",
      "Top-5 accuracy on the 5% the most confident from the Delta point of view = 100.0%\n",
      "Top-5 accuracy on the 10% the most confident from the Delta point of view = 81.67%\n",
      "Top-5 accuracy on the 15% the most confident from the Delta point of view = 78.14999999999999%\n",
      "Top-5 accuracy on the 20% the most confident from the Delta point of view = 76.97%\n",
      "Top-5 accuracy on the 25% the most confident from the Delta point of view = 77.31%\n",
      "Top-5 accuracy on the 30% the most confident from the Delta point of view = 78.45%\n",
      "Top-5 accuracy on the 35% the most confident from the Delta point of view = 76.12%\n",
      "Top-5 accuracy on the 40% the most confident from the Delta point of view = 72.05%\n",
      "Top-5 accuracy on the 45% the most confident from the Delta point of view = 69.67999999999999%\n",
      "Top-5 accuracy on the 50% the most confident from the Delta point of view = 66.67%\n",
      "Top-5 accuracy on the 55% the most confident from the Delta point of view = 64.42%\n",
      "Top-5 accuracy on the 60% the most confident from the Delta point of view = 60.58%\n",
      "Top-5 accuracy on the 65% the most confident from the Delta point of view = 58.709999999999994%\n",
      "Top-5 accuracy on the 70% the most confident from the Delta point of view = 56.55%\n",
      "Top-5 accuracy on the 75% the most confident from the Delta point of view = 54.459999999999994%\n",
      "Top-5 accuracy on the 80% the most confident from the Delta point of view = 52.190000000000005%\n",
      "Top-5 accuracy on the 85% the most confident from the Delta point of view = 50.79%\n",
      "Top-5 accuracy on the 90% the most confident from the Delta point of view = 49.01%\n",
      "Top-5 accuracy on the 95% the most confident from the Delta point of view = 47.52%\n",
      "Top-5 accuracy on the 100% the most confident from the Delta point of view = 46.0%\n",
      "\n",
      "\n",
      "Top-10 accuracy on the 5% the most confident from the Delta point of view = 100.0%\n",
      "Top-10 accuracy on the 10% the most confident from the Delta point of view = 83.33%\n",
      "Top-10 accuracy on the 15% the most confident from the Delta point of view = 83.19%\n",
      "Top-10 accuracy on the 20% the most confident from the Delta point of view = 81.46%\n",
      "Top-10 accuracy on the 25% the most confident from the Delta point of view = 81.93%\n",
      "Top-10 accuracy on the 30% the most confident from the Delta point of view = 82.15%\n",
      "Top-10 accuracy on the 35% the most confident from the Delta point of view = 80.9%\n",
      "Top-10 accuracy on the 40% the most confident from the Delta point of view = 76.87%\n",
      "Top-10 accuracy on the 45% the most confident from the Delta point of view = 74.11%\n",
      "Top-10 accuracy on the 50% the most confident from the Delta point of view = 71.35000000000001%\n",
      "Top-10 accuracy on the 55% the most confident from the Delta point of view = 68.97%\n",
      "Top-10 accuracy on the 60% the most confident from the Delta point of view = 66.10000000000001%\n",
      "Top-10 accuracy on the 65% the most confident from the Delta point of view = 64.61%\n",
      "Top-10 accuracy on the 70% the most confident from the Delta point of view = 62.260000000000005%\n",
      "Top-10 accuracy on the 75% the most confident from the Delta point of view = 60.12%\n",
      "Top-10 accuracy on the 80% the most confident from the Delta point of view = 58.040000000000006%\n",
      "Top-10 accuracy on the 85% the most confident from the Delta point of view = 56.379999999999995%\n",
      "Top-10 accuracy on the 90% the most confident from the Delta point of view = 54.37%\n",
      "Top-10 accuracy on the 95% the most confident from the Delta point of view = 52.669999999999995%\n",
      "Top-10 accuracy on the 100% the most confident from the Delta point of view = 51.239999999999995%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_quantiles = 20\n",
    "\n",
    "quants = [thresh / num_quantiles for thresh in range(1, num_quantiles+1)]\n",
    "deltas = [i[0] - i[1] for i in probas]\n",
    "thresholds_delta = [np.quantile(deltas, q) for q in quants]\n",
    "thresholds_delta = thresholds_delta[::-1]\n",
    "\n",
    "accuracy_for_each_topk = []\n",
    "\n",
    "#top_k pred\n",
    "for top_k in [1, 2, 5, 10]:\n",
    "    \n",
    "    accuracy_for_each_quantile = {}\n",
    "\n",
    "    for quantile in range(num_quantiles):\n",
    "\n",
    "        # list of predictions\n",
    "        list_of_predictions = list(compress(predictions, deltas >= thresholds_delta[quantile]))\n",
    "        \n",
    "        #list of correct answers\n",
    "        list_of_correct_answers = list(compress(rubq_test_answers[:sample_questions], deltas >= thresholds_delta[quantile]))\n",
    "        \n",
    "        # choose top k predictions\n",
    "        top_k_list_of_predictions = [i[:top_k] for i in list_of_predictions]\n",
    "\n",
    "        top_k_list_of_predicted_ids= []\n",
    "        for sample in top_k_list_of_predictions:\n",
    "            new = []\n",
    "            for prediction in sample:\n",
    "                try:\n",
    "                    x = from_text_to_id(prediction)\n",
    "                except:\n",
    "                    x = \"None\"\n",
    "                new.append(x)\n",
    "\n",
    "            top_k_list_of_predicted_ids.append(new)\n",
    "\n",
    "\n",
    "        right = 0\n",
    "        for i in range(len(list_of_correct_answers)):\n",
    "            if any(item in top_k_list_of_predicted_ids[i] for item in list_of_correct_answers[i]):\n",
    "                right += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        accuracy = np.round(right/len(list_of_correct_answers), 4)*100\n",
    "        print(f\"Top-{top_k} accuracy on the {(quantile+1)*(int(100/num_quantiles))}% the most confident from the Delta point of view = {accuracy}%\")\n",
    "\n",
    "        accuracy_for_each_quantile[(quantile+1)*(int(100/num_quantiles))] = accuracy\n",
    "        accuracy_for_each_topk.append(accuracy_for_each_quantile)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "plt.title(\"Rejection curves based on Delta for test set RuBQ 2.0 (1186 questions)\", fontdict=font_title)\n",
    "\n",
    "font = {'family': 'serif',\n",
    "            'color': 'darkred',\n",
    "            'weight': 'normal',\n",
    "            'size': 16\n",
    "            }\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color': 'darkred',\n",
    "              'weight': 'normal',\n",
    "              'size': 20\n",
    "              }\n",
    "\n",
    "plt.xlabel(\"Rejection rate, %\", fontdict=font)\n",
    "plt.ylabel(\"Accuracy, %\", fontdict=font)\n",
    "plt.xticks(ticks=np.arange(0, 100, step=5))\n",
    "plt.grid(color='black', linewidth=0.15)\n",
    "\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[:num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[:num_quantiles][0].values())),\n",
    "         label=f\"Top-{1} Accuracy via Delta\", c=\"blue\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values())),\n",
    "         label=f\"Top-{2} Accuracy via Delta\", c=\"red\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values())),\n",
    "         label=f\"Top-{5} Accuracy via Delta\", c=\"green\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "plt.plot(100 - np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].keys())),\n",
    "         np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values())),\n",
    "         label=f\"Top-{10} Accuracy via Delta\", c=\"orange\", marker='.', markersize=13, linewidth=0.8);\n",
    "\n",
    "\n",
    "accuracy_on_full_data_top_1 = np.array(list(accuracy_for_each_topk[:num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_2 = np.array(list(accuracy_for_each_topk[num_quantiles:2*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_5 = np.array(list(accuracy_for_each_topk[2*num_quantiles:3*num_quantiles][0].values()))[-1]\n",
    "accuracy_on_full_data_top_10 = np.array(list(accuracy_for_each_topk[3*num_quantiles:4*num_quantiles][0].values()))[-1]\n",
    "\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_1, 2)), (0 - 4.5, accuracy_on_full_data_top_1));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_2, 2)), (0 - 4.5, accuracy_on_full_data_top_2));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_5, 2)), (0 - 4.5, accuracy_on_full_data_top_5));\n",
    "plt.annotate(\"{}\".format(np.round(accuracy_on_full_data_top_10, 2)), (0 - 4.5, accuracy_on_full_data_top_10));\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = 50\n",
    "num_quantiles = 10\n",
    "\n",
    "res = [topkSample(rubq_test[\"question\"][i], model = t5_qa_model, tokenizer = t5_tok, max_output_length=128, num_beams=1, num_samples = 5) for i in range(num_questions)]\n",
    "probs_for_examples = [[math.exp(float(j[1])) for j in i] for i in res]\n",
    "quants = [thresh / num_quantiles for thresh in range(1, num_quantiles+1)]\n",
    "\n",
    "\n",
    "entropies = [scipy.stats.entropy(i) for i in probs_for_examples]\n",
    "thresholds_entropy = [np.quantile(entropies, q) for q in quants]\n",
    "\n",
    "# for 5% -> 0\n",
    "quantile = 0\n",
    "list_of_predictions_with_log_scores = list(compress(res, entropies <= thresholds_entropy[quantile]))\n",
    "list_of_correct_answers = list(compress(rubq_answers,  entropies <= thresholds_entropy[quantile]))\n",
    "list_of_predictions = [[j[0] for j in i] for i in list_of_predictions_with_log_scores]\n",
    "\n",
    "list_of_predicted_ids = []\n",
    "for sample in list_of_predictions:\n",
    "    new = []\n",
    "    for prediction in sample:\n",
    "        try:\n",
    "            x = from_text_to_id(prediction)\n",
    "        except:\n",
    "            x = \"None\"\n",
    "        new.append(x)\n",
    "\n",
    "    list_of_predicted_ids.append(new)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.053119500258598226,\n",
       " 3.5508785966658604e-05,\n",
       " 1.768943428297719e-05,\n",
       " 5.012966873274316e-06,\n",
       " 1.7772552668605872e-06]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_for_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.053, 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(probs_for_examples[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20863221, 0.197846  , 0.19784248, 0.19783997, 0.19783933])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.special.softmax(probs_for_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q19660', 'Q46852', 'Q168057', 'Q79808', 'Q143079'],\n",
       " ['None', 'None', 'None', 'None', 'None'],\n",
       " ['Q5513433', 'None', 'None', 'None', 'None'],\n",
       " ['Q174044', 'Q726105', 'Q19002866', 'None', 'None'],\n",
       " ['Q1850', 'Q1854', 'Q1854', 'Q1850', 'Q19675'],\n",
       " ['Q83406', 'Q43718', 'Q524085', 'Q335064', 'None'],\n",
       " ['Q43718', 'Q7996', 'Q923', 'Q31034308', 'None'],\n",
       " ['Q830561', 'None', 'None', 'None', 'None'],\n",
       " ['Q704832', 'Q5794774', 'Q659592', 'None', 'None'],\n",
       " ['None', 'None', 'None', 'None', 'None'],\n",
       " ['None', 'Q4590630', 'None', 'None', 'Q4884552'],\n",
       " ['Q15180', 'Q46118', 'None', 'None', 'None'],\n",
       " ['Q394963', 'None', 'Q914218', 'None', 'None'],\n",
       " ['Q184535', 'None', 'None', 'None', 'None'],\n",
       " ['Q122263', 'Q2918819', 'Q2576', 'None', 'None'],\n",
       " ['Q3427', 'Q313', 'Q793510', 'Q5598740', 'None'],\n",
       " ['Q409760', 'None', 'None', 'Q318657', 'None'],\n",
       " ['Q630823', 'Q2650702', 'Q917829', 'Q4051134', 'None'],\n",
       " ['Q62272', 'None', 'None', 'None', 'None'],\n",
       " ['Q153319', 'None', 'None', 'None', 'None'],\n",
       " ['Q7200', 'Q7200', 'Q1975130', 'Q419866', 'None'],\n",
       " ['Q5582', 'Q39931', 'Q4492684', 'Q650519', 'Q21121474'],\n",
       " ['Q2623285', 'Q165721', 'None', 'Q2081557', 'None'],\n",
       " ['Q18110', 'None', 'None', 'None', 'None'],\n",
       " ['Q82925', 'Q1303942', 'Q5123750', 'None', 'None'],\n",
       " ['Q5284', 'Q4459167', 'None', 'None', 'None'],\n",
       " ['Q5513', 'Q5428', 'Q8060315', 'None', 'None'],\n",
       " ['Q171242', 'Q50309080', 'None', 'None', 'None'],\n",
       " ['Q218400', 'None', 'None', 'None', 'None'],\n",
       " ['None', 'Q7753486', 'None', 'None', 'None'],\n",
       " ['Q316861', 'None', 'None', 'None', 'None'],\n",
       " ['Q7327', 'None', 'None', 'None', 'None'],\n",
       " ['Q23664', 'Q7687', 'None', 'None', 'None'],\n",
       " ['Q148', 'Q422429', 'Q112568', 'None', 'None'],\n",
       " ['Q301219', 'None', 'None', 'Q7080062', 'None'],\n",
       " ['Q1563530', 'Q3918484', 'None', 'None', 'None'],\n",
       " ['Q262909', 'None', 'None', 'None', 'None'],\n",
       " ['Q2313948', 'None', 'None', 'None', 'None'],\n",
       " ['Q650324', 'Q219033', 'None', 'None', 'None'],\n",
       " ['Q17714', 'Q315059', 'Q4352362', 'Q219206', 'Q1823362']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q19660'],\n",
       " ['Q312480'],\n",
       " ['Q43'],\n",
       " ['Q49481'],\n",
       " ['Q1850'],\n",
       " ['Q1860923'],\n",
       " ['Q57966'],\n",
       " ['Q128790'],\n",
       " ['Q11419'],\n",
       " ['Q172911'],\n",
       " ['Q891'],\n",
       " ['Q790'],\n",
       " ['Q149067'],\n",
       " ['Q395', 'Q7754', 'Q41217', 'Q149999', 'Q56114489'],\n",
       " ['Q157623'],\n",
       " ['Q10484'],\n",
       " ['Q130498'],\n",
       " ['Q1918252'],\n",
       " ['Q739362'],\n",
       " ['Q240150'],\n",
       " ['Q192239', 'Q12799318'],\n",
       " ['Q4872'],\n",
       " ['Q1369676'],\n",
       " ['Q130531'],\n",
       " ['Q42831'],\n",
       " ['Q762'],\n",
       " ['Q162737'],\n",
       " ['Q320653'],\n",
       " ['Q8006'],\n",
       " ['Q715281'],\n",
       " ['Q267861', 'Q1323788'],\n",
       " ['Q269668'],\n",
       " ['Q912050', 'Q2453629'],\n",
       " ['Q69060'],\n",
       " ['Q182101'],\n",
       " ['Q711'],\n",
       " ['Q167997'],\n",
       " ['Q204138'],\n",
       " ['Q236132', 'Q456257'],\n",
       " ['Q17714']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_correct_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['Q19660', 'Q46852', 'Q168057', 'Q79808', 'Q143079']\n",
      "top_k_preds: ['Q19660', 'Q46852', 'Q168057', 'Q79808', 'Q143079']\n",
      "correct prediction ['Q19660']\n",
      "prediction: ['None', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['None', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q312480']\n",
      "prediction: ['Q5513433', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q5513433', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q43']\n",
      "prediction: ['Q174044', 'Q726105', 'Q19002866', 'None', 'None']\n",
      "top_k_preds: ['Q174044', 'Q726105', 'Q19002866', 'None', 'None']\n",
      "correct prediction ['Q49481']\n",
      "prediction: ['Q1850', 'Q1854', 'Q1854', 'Q1850', 'Q19675']\n",
      "top_k_preds: ['Q1850', 'Q1854', 'Q1854', 'Q1850', 'Q19675']\n",
      "correct prediction ['Q1850']\n",
      "prediction: ['Q83406', 'Q43718', 'Q524085', 'Q335064', 'None']\n",
      "top_k_preds: ['Q83406', 'Q43718', 'Q524085', 'Q335064', 'None']\n",
      "correct prediction ['Q1860923']\n",
      "prediction: ['Q43718', 'Q7996', 'Q923', 'Q31034308', 'None']\n",
      "top_k_preds: ['Q43718', 'Q7996', 'Q923', 'Q31034308', 'None']\n",
      "correct prediction ['Q57966']\n",
      "prediction: ['Q830561', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q830561', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q128790']\n",
      "prediction: ['Q704832', 'Q5794774', 'Q659592', 'None', 'None']\n",
      "top_k_preds: ['Q704832', 'Q5794774', 'Q659592', 'None', 'None']\n",
      "correct prediction ['Q11419']\n",
      "prediction: ['None', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['None', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q172911']\n",
      "prediction: ['None', 'Q4590630', 'None', 'None', 'Q4884552']\n",
      "top_k_preds: ['None', 'Q4590630', 'None', 'None', 'Q4884552']\n",
      "correct prediction ['Q891']\n",
      "prediction: ['Q15180', 'Q46118', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q15180', 'Q46118', 'None', 'None', 'None']\n",
      "correct prediction ['Q790']\n",
      "prediction: ['Q394963', 'None', 'Q914218', 'None', 'None']\n",
      "top_k_preds: ['Q394963', 'None', 'Q914218', 'None', 'None']\n",
      "correct prediction ['Q149067']\n",
      "prediction: ['Q184535', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q184535', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q395', 'Q7754', 'Q41217', 'Q149999', 'Q56114489']\n",
      "prediction: ['Q122263', 'Q2918819', 'Q2576', 'None', 'None']\n",
      "top_k_preds: ['Q122263', 'Q2918819', 'Q2576', 'None', 'None']\n",
      "correct prediction ['Q157623']\n",
      "prediction: ['Q3427', 'Q313', 'Q793510', 'Q5598740', 'None']\n",
      "top_k_preds: ['Q3427', 'Q313', 'Q793510', 'Q5598740', 'None']\n",
      "correct prediction ['Q10484']\n",
      "prediction: ['Q409760', 'None', 'None', 'Q318657', 'None']\n",
      "top_k_preds: ['Q409760', 'None', 'None', 'Q318657', 'None']\n",
      "correct prediction ['Q130498']\n",
      "prediction: ['Q630823', 'Q2650702', 'Q917829', 'Q4051134', 'None']\n",
      "top_k_preds: ['Q630823', 'Q2650702', 'Q917829', 'Q4051134', 'None']\n",
      "correct prediction ['Q1918252']\n",
      "prediction: ['Q62272', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q62272', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q739362']\n",
      "prediction: ['Q153319', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q153319', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q240150']\n",
      "prediction: ['Q7200', 'Q7200', 'Q1975130', 'Q419866', 'None']\n",
      "top_k_preds: ['Q7200', 'Q7200', 'Q1975130', 'Q419866', 'None']\n",
      "correct prediction ['Q192239', 'Q12799318']\n",
      "prediction: ['Q5582', 'Q39931', 'Q4492684', 'Q650519', 'Q21121474']\n",
      "top_k_preds: ['Q5582', 'Q39931', 'Q4492684', 'Q650519', 'Q21121474']\n",
      "correct prediction ['Q4872']\n",
      "prediction: ['Q2623285', 'Q165721', 'None', 'Q2081557', 'None']\n",
      "top_k_preds: ['Q2623285', 'Q165721', 'None', 'Q2081557', 'None']\n",
      "correct prediction ['Q1369676']\n",
      "prediction: ['Q18110', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q18110', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q130531']\n",
      "prediction: ['Q82925', 'Q1303942', 'Q5123750', 'None', 'None']\n",
      "top_k_preds: ['Q82925', 'Q1303942', 'Q5123750', 'None', 'None']\n",
      "correct prediction ['Q42831']\n",
      "prediction: ['Q5284', 'Q4459167', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q5284', 'Q4459167', 'None', 'None', 'None']\n",
      "correct prediction ['Q762']\n",
      "prediction: ['Q5513', 'Q5428', 'Q8060315', 'None', 'None']\n",
      "top_k_preds: ['Q5513', 'Q5428', 'Q8060315', 'None', 'None']\n",
      "correct prediction ['Q162737']\n",
      "prediction: ['Q171242', 'Q50309080', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q171242', 'Q50309080', 'None', 'None', 'None']\n",
      "correct prediction ['Q320653']\n",
      "prediction: ['Q218400', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q218400', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q8006']\n",
      "prediction: ['None', 'Q7753486', 'None', 'None', 'None']\n",
      "top_k_preds: ['None', 'Q7753486', 'None', 'None', 'None']\n",
      "correct prediction ['Q715281']\n",
      "prediction: ['Q316861', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q316861', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q267861', 'Q1323788']\n",
      "prediction: ['Q7327', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q7327', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q269668']\n",
      "prediction: ['Q23664', 'Q7687', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q23664', 'Q7687', 'None', 'None', 'None']\n",
      "correct prediction ['Q912050', 'Q2453629']\n",
      "prediction: ['Q148', 'Q422429', 'Q112568', 'None', 'None']\n",
      "top_k_preds: ['Q148', 'Q422429', 'Q112568', 'None', 'None']\n",
      "correct prediction ['Q69060']\n",
      "prediction: ['Q301219', 'None', 'None', 'Q7080062', 'None']\n",
      "top_k_preds: ['Q301219', 'None', 'None', 'Q7080062', 'None']\n",
      "correct prediction ['Q182101']\n",
      "prediction: ['Q1563530', 'Q3918484', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q1563530', 'Q3918484', 'None', 'None', 'None']\n",
      "correct prediction ['Q711']\n",
      "prediction: ['Q262909', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q262909', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q167997']\n",
      "prediction: ['Q2313948', 'None', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q2313948', 'None', 'None', 'None', 'None']\n",
      "correct prediction ['Q204138']\n",
      "prediction: ['Q650324', 'Q219033', 'None', 'None', 'None']\n",
      "top_k_preds: ['Q650324', 'Q219033', 'None', 'None', 'None']\n",
      "correct prediction ['Q236132', 'Q456257']\n",
      "prediction: ['Q17714', 'Q315059', 'Q4352362', 'Q219206', 'Q1823362']\n",
      "top_k_preds: ['Q17714', 'Q315059', 'Q4352362', 'Q219206', 'Q1823362']\n",
      "correct prediction ['Q17714']\n",
      "top 5 accuracy on the most certain by entropy 10% quantile =  8.0\n"
     ]
    }
   ],
   "source": [
    "#top k accuracy\n",
    "top_k = 5\n",
    "\n",
    "right=0\n",
    "for number_of_question, prediction in enumerate(list_of_predicted_ids):\n",
    "    print(\"prediction:\", prediction)\n",
    "    top_k_preds = prediction[:top_k]\n",
    "    print(\"top_k_preds:\", top_k_preds)\n",
    "    print(\"correct prediction\", list_of_correct_answers[number_of_question])\n",
    "    if any(item in top_k_preds for item in list_of_correct_answers[number_of_question]):\n",
    "        right += 1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "accuracy = np.round(right/len(list_of_predicted_ids), 2)*100\n",
    "print(f\"top {top_k} accuracy on the most certain by entropy {10*(quantile+1)}% quantile = \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(item in [4, 5] for item in [1, 5, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Experiments with baseline accuracy for different models (t5-3b-ssm, t5-3b-ssm-nq, t5-3b-ssm-nqo, t5-xl-ssm-nq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQ test T5-3b model QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_test_data = np.load(\"simple_questions_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = sq_test_data[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4751/4751 [23:36<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    input_ids = t5_tok(questions[i], return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "    answers.append(gen_output)\n",
    "    \n",
    "    \n",
    "preds_sq = []\n",
    "for x in answers:\n",
    "    preds_sq.append(t5_tok.decode(x, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_id_sq = []\n",
    "for i in range(len(preds_sq)):\n",
    "    try:\n",
    "        x = from_text_to_id(preds_sq[i])\n",
    "    except:\n",
    "        x = \"None\"\n",
    "    \n",
    "    preds_id_sq.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4751/4751 [00:00<00:00, 275339.40it/s]\n"
     ]
    }
   ],
   "source": [
    "right_sq = 0\n",
    "for i in tqdm(range(len(preds_id_sq))):\n",
    "    if preds_id_sq[i] == sq_test_data[i,2]:\n",
    "        right_sq += 1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01768048831824879"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_sq/len(preds_id_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"predictions_sq_test_t5_3b_vanilla.npy\", np.array(preds_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQ another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_t5_sq(t5_tok, t5_qa_model):\n",
    "    \n",
    "    sq_test_data = np.load(\"simple_questions_test.npy\")\n",
    "    questions = sq_test_data[:,3]\n",
    "\n",
    "\n",
    "    answers = []\n",
    "    for i in tqdm(range(len(questions))):\n",
    "        input_ids = t5_tok(questions[i], return_tensors=\"pt\").input_ids\n",
    "        input_ids = input_ids.to(device)\n",
    "        gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "        answers.append(gen_output)\n",
    "\n",
    "\n",
    "    preds_sq = []\n",
    "    for x in answers:\n",
    "        preds_sq.append(t5_tok.decode(x, skip_special_tokens=True))\n",
    "\n",
    "\n",
    "    preds_id_sq = []\n",
    "    for i in range(len(preds_sq)):\n",
    "        try:\n",
    "            x = from_text_to_id(preds_sq[i])\n",
    "        except:\n",
    "            x = \"None\"\n",
    "\n",
    "        preds_id_sq.append(x)\n",
    "\n",
    "    right_sq = 0\n",
    "    for i in tqdm(range(len(preds_id_sq))):\n",
    "        if preds_id_sq[i] == sq_test_data[i,2]:\n",
    "            right_sq += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    acc = right_sq/len(preds_id_sq)\n",
    "    \n",
    "    return acc, preds_id_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-3b-ssm-nq\")#\"google/t5-11b-ssm-tqa\")\n",
    "t5_tok = AutoTokenizer.from_pretrained(\"google/t5-3b-ssm-nq\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4751/4751 [10:18<00:00,  7.69it/s]\n",
      "100%|██████████| 4751/4751 [00:00<00:00, 852716.77it/s]\n"
     ]
    }
   ],
   "source": [
    "acc, preds_id_sq = check_t5_sq(t5_tok = t5_tok,\n",
    "                               t5_qa_model = t5_qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 accuracy =  0.06819616922753105\n"
     ]
    }
   ],
   "source": [
    "print(\"top1 accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Q7358590', 'P20', 'Q1637790', 'Where did roger marquis die?'],\n",
       "       ['Q154335', 'P509', 'Q12152',\n",
       "        'what was the cause of death of yves klein?'],\n",
       "       ['Q62498', 'P21', 'Q6581097',\n",
       "        'how does engelbert zaschka identify?'],\n",
       "       ...,\n",
       "       ['Q7142651', 'P495', 'Q145',\n",
       "        'which country filmed passing shadows?'],\n",
       "       ['Q445899', 'P19', 'Q1748',\n",
       "        'Where was gunnar johansen born in Denmark??'],\n",
       "       ['Q582715', 'P31', 'Q3863',\n",
       "        'what celestial object is 2974 holden?']], dtype='<U101')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"simple_questions_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rubq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-3b-ssm-nq\")#\"google/t5-11b-ssm-tqa\")\n",
    "t5_tok = AutoTokenizer.from_pretrained(\"google/t5-3b-ssm-nq\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [03:03<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q7944', 'Q60186', 'Q167903', 'Q2580904', 'Q5975740', 'Q7692360']\n",
      "['Q102513']\n",
      "['Q692']\n",
      "['Q19660']\n",
      "['Q6607', 'Q483994', 'Q626035', 'Q2643890', 'Q17172850']\n",
      "['Q142']\n",
      "['Q299687']\n",
      "['Q312480']\n",
      "['Q29']\n",
      "['Q4022']\n",
      "['Q796']\n",
      "['Q38768', 'Q201605', 'Q1676638']\n",
      "['Q22']\n",
      "['Q11420', 'Q106500']\n",
      "['Q4808485']\n",
      "['Q2838011']\n",
      "['Q9299872']\n",
      "['Q2674728']\n",
      "['Q1968651']\n",
      "['Q1088']\n",
      "['Q7737', 'Q29561']\n",
      "['Q36124']\n",
      "['Q43']\n",
      "['Q49481']\n",
      "['Q424', 'Q869', 'Q881']\n",
      "['Q148', 'Q837']\n",
      "['Q232']\n",
      "['Q408']\n",
      "['Q816']\n",
      "['Q847', 'Q5377']\n",
      "['Q30']\n",
      "['Q1792']\n",
      "['Q822290']\n",
      "['Q1603']\n",
      "['Q181306', 'Q213344', 'Q237367', 'Q1326237']\n",
      "['Q237800']\n",
      "['Q106151']\n",
      "['Q201598']\n",
      "['Q223134']\n",
      "['Q106010']\n",
      "['Q29445']\n",
      "['Q40591', 'Q58784', 'Q295347', 'Q470600']\n",
      "['Q1850']\n",
      "['Q4719']\n",
      "['Q157683']\n",
      "['Q158491']\n",
      "['Q62']\n",
      "['Q24861']\n",
      "['Q3787']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q55']\n",
      "['Q19675']\n",
      "['Q36180', 'Q82955', 'Q185351', 'Q333634', 'Q1209498', 'Q1297719', 'Q4964182', 'Q11774202', 'Q18814623']\n",
      "['Q22']\n",
      "['Q1048']\n",
      "['Q9191']\n",
      "['Q687']\n",
      "['Q1860923']\n",
      "['Q178577']\n",
      "['Q199588']\n",
      "['Q79759']\n",
      "['Q31628']\n",
      "['Q57966']\n",
      "['Q133622']\n",
      "['Q360292']\n",
      "['Q128790']\n",
      "['Q236233']\n",
      "['Q152293']\n",
      "['Q15862']\n",
      "['Q723764']\n",
      "['Q783']\n",
      "['Q767288']\n",
      "['Q31628']\n",
      "['Q142']\n",
      "['Q40357']\n",
      "['Q1048']\n",
      "['Q159']\n",
      "['Q2064699', 'Q4304132']\n",
      "['Q668']\n",
      "['Q112']\n",
      "['Q49111']\n",
      "['Q131026']\n",
      "['Q11419']\n",
      "['Q6502703']\n",
      "['Q172911']\n",
      "['Q212115']\n",
      "['Q1069868']\n",
      "['Q897']\n",
      "['Q869']\n",
      "['Q41']\n",
      "['Q10737']\n",
      "['Q6862']\n",
      "['Q40059']\n",
      "['Q35591']\n",
      "['Q2332']\n",
      "['Q1205']\n",
      "['Q31015', 'Q241214']\n",
      "['Q586']\n",
      "['Q891']\n",
      "['Q1472', 'Q12133', 'Q35869', 'Q41083', 'Q110315', 'Q131742', 'Q147778', 'Q193894', 'Q653078', 'Q2025687', 'Q2035074', 'Q3144986']\n",
      "['Q144144']\n",
      "['Q34981']\n",
      "['Q185027']\n",
      "['Q47369']\n",
      "['Q45']\n",
      "['Q81214']\n",
      "['Q51']\n",
      "['Q4964182']\n",
      "['Q46599']\n",
      "['Q6816']\n",
      "['Q46']\n",
      "['Q1875']\n",
      "['Q5470']\n",
      "['Q165503']\n",
      "['Q25261', 'Q46255']\n",
      "['Q925']\n",
      "['Q790']\n",
      "['Q13695']\n",
      "['Q24826']\n",
      "['Q1035', 'Q82122']\n",
      "['Q2568844']\n",
      "['Q149067']\n",
      "['Q170737']\n",
      "['Q626']\n",
      "['Q395', 'Q7754', 'Q41217', 'Q149999', 'Q56114489']\n",
      "['Q157623']\n",
      "['Q159']\n",
      "['Q5592']\n",
      "['Q626']\n",
      "['Q28244']\n",
      "['Q16559']\n",
      "['Q944527']\n",
      "['Q8027']\n",
      "['Q70']\n",
      "['Q10484']\n",
      "['Q47059']\n",
      "['Q93351']\n",
      "['Q762']\n",
      "['Q214196']\n",
      "['Q130498']\n",
      "['Q30204']\n",
      "['Q157623']\n",
      "['Q31']\n",
      "['Q854']\n",
      "['Q170513']\n",
      "['Q5806']\n",
      "['Q37853']\n",
      "['Q1918252']\n",
      "['Q34']\n",
      "['Q43106']\n",
      "['Q5422']\n",
      "['Q29445']\n",
      "['Q219']\n",
      "['Q664']\n",
      "['Q13989']\n",
      "['Q201330']\n",
      "['Q84']\n",
      "['Q2807']\n",
      "['Q40']\n",
      "['Q949424']\n",
      "['Q935']\n",
      "['Q4181867']\n",
      "['Q109676']\n",
      "['Q155626']\n",
      "['Q1981162']\n",
      "['Q33629']\n",
      "['Q739362']\n",
      "['Q211513', 'Q214666', 'Q319861']\n",
      "['Q38']\n",
      "['Q16']\n",
      "['Q240150']\n",
      "['Q192239', 'Q12799318']\n",
      "['Q2736']\n",
      "['Q2844']\n",
      "['Q804']\n",
      "['Q43105']\n",
      "['Q150445']\n",
      "['Q419']\n",
      "['Q258', 'Q1013', 'Q1030']\n",
      "['Q467118']\n",
      "['Q424']\n",
      "['Q739']\n",
      "['Q38337']\n",
      "['Q2044']\n",
      "['Q44703']\n",
      "['Q4872']\n",
      "['Q145']\n",
      "['Q4534523']\n",
      "['Q7315']\n",
      "['Q887']\n",
      "['Q3114']\n",
      "['Q16']\n",
      "['Q36', 'Q211274']\n",
      "['Q8743']\n",
      "['Q154269', 'Q316417', 'Q336810', 'Q432752', 'Q463833']\n",
      "['Q201330']\n",
      "['Q1265']\n",
      "['Q176371']\n",
      "['Q131233']\n",
      "['Q43279']\n",
      "['Q3904', 'Q101418']\n",
      "['Q9268']\n",
      "['Q408']\n",
      "['Q29']\n",
      "['Q1369676']\n",
      "['Q48103', 'Q857244', 'Q17232562']\n",
      "['Q30']\n",
      "['Q298', 'Q414']\n",
      "['Q191159']\n",
      "['Q9215']\n",
      "['Q183']\n",
      "['Q664']\n",
      "['Q1460']\n",
      "['Q851']\n",
      "['Q40909']\n",
      "['Q656']\n",
      "['Q203236']\n",
      "['Q14515330']\n",
      "['Q8810']\n",
      "['Q42941']\n",
      "['Q1524']\n",
      "['Q181114']\n",
      "['Q129352']\n",
      "['Q14773']\n",
      "['Q36600']\n",
      "['Q167420']\n",
      "['Q83186']\n",
      "['Q130531']\n",
      "['Q167646', 'Q171839', 'Q736813']\n",
      "['Q6585']\n",
      "['Q811']\n",
      "['Q835']\n",
      "['Q45']\n",
      "['Q408']\n",
      "['Q42831']\n",
      "['Q762']\n",
      "['Q10686']\n",
      "['Q1850']\n",
      "['Q15807']\n",
      "['Q1003']\n",
      "['Q183']\n",
      "['Q28']\n",
      "['Q1532068']\n",
      "['Q801']\n",
      "['Q3859']\n",
      "['Q170292', 'Q191105']\n",
      "['Q127888']\n",
      "['Q319708']\n",
      "['Q25328']\n",
      "['Q58035']\n",
      "['Q468621', 'Q15071896']\n",
      "['Q29', 'Q142']\n",
      "['Q9191']\n",
      "['Q38']\n",
      "['Q164761', 'Q165704', 'Q170737', 'Q178108', 'Q180935', 'Q182570', 'Q185027', 'Q191691', 'Q334734', 'Q537769']\n",
      "['Q43114']\n",
      "['Q1726', 'Q131610']\n",
      "['Q4412']\n",
      "['Q501']\n",
      "['Q205375', 'Q1281618', 'Q1930187']\n",
      "['Q134942']\n",
      "['Q4167647']\n",
      "['Q162737']\n",
      "['Q172089']\n",
      "['Q34038']\n",
      "['Q813']\n",
      "['Q7947']\n",
      "['Q215556']\n",
      "['Q6934']\n",
      "['Q33231', 'Q36180', 'Q49757', 'Q161944', 'Q170790', 'Q4853732', 'Q4964182', 'Q6625963', 'Q14565331', 'Q18814623', 'Q18939491']\n",
      "['Q15208']\n",
      "['Q916']\n",
      "['Q35881']\n",
      "['Q38']\n",
      "['Q948']\n",
      "['Q57479']\n",
      "['Q265']\n",
      "['Q320653']\n",
      "['Q275354']\n",
      "['Q8006']\n",
      "['Q8409']\n",
      "['Q60']\n",
      "['Q193592']\n",
      "['Q60']\n",
      "['Q8678']\n",
      "['Q718']\n",
      "['Q1186567']\n",
      "['Q1754954']\n",
      "['Q155856']\n",
      "['Q718']\n",
      "['Q48211', 'Q297032']\n",
      "['Q6574', 'Q6655']\n",
      "['Q715281']\n",
      "['Q47293']\n",
      "['Q47293']\n",
      "['Q4768']\n",
      "['Q110228']\n",
      "['Q193064']\n",
      "['Q762']\n",
      "['Q217128']\n",
      "['Q183']\n",
      "['Q170984', 'Q372254']\n",
      "['Q741157']\n",
      "['Q208008']\n",
      "['Q212']\n",
      "['Q131210']\n",
      "['Q27911']\n",
      "['Q34575']\n",
      "['Q11629']\n",
      "['Q83891']\n",
      "['Q78707']\n",
      "['Q9391']\n",
      "['Q3926', 'Q5465', 'Q37701']\n",
      "['Q44363', 'Q82586']\n",
      "['Q592289']\n",
      "['Q28603']\n",
      "['Q219']\n",
      "['Q32024']\n",
      "['Q10570']\n",
      "['Q188']\n",
      "['Q184222']\n",
      "['Q35657']\n",
      "['Q267861', 'Q1323788']\n",
      "['Q133026']\n",
      "['Q33999', 'Q36834', 'Q49757', 'Q177220', 'Q183945', 'Q488205', 'Q662729', 'Q753110', 'Q1028181', 'Q13235160', 'Q16323111', 'Q29017403']\n",
      "['Q148']\n",
      "['Q36']\n",
      "['Q28389', 'Q36180', 'Q49757', 'Q214917', 'Q482980', 'Q6625963']\n",
      "['Q185118', 'Q81200227']\n",
      "['Q38']\n",
      "['Q164714']\n",
      "['Q269668']\n",
      "['Q4257378']\n",
      "['Q151209']\n",
      "['Q315185']\n",
      "['Q716794']\n",
      "['Q912050', 'Q2453629']\n",
      "['Q6397066']\n",
      "['Q186083']\n",
      "['Q220437']\n",
      "['Q14435']\n",
      "['Q72']\n",
      "['Q69060']\n",
      "['Q182101']\n",
      "['Q403']\n",
      "['Q4202', 'Q5871']\n",
      "['Q302849']\n",
      "['Q326827']\n",
      "['Q192134']\n",
      "['Q183']\n",
      "['Q845210']\n",
      "['Q1773']\n",
      "['Q1205']\n",
      "['Q42574']\n",
      "['Q155']\n",
      "['Q333246']\n",
      "['Q230']\n",
      "['Q23124']\n",
      "['Q170513']\n",
      "['Q408']\n",
      "['Q108316']\n",
      "['Q819']\n",
      "['Q11930']\n",
      "['Q3711']\n",
      "['Q47154']\n",
      "['Q711']\n",
      "['Q5338']\n",
      "['Q200797']\n",
      "['Q7200']\n",
      "['Q21']\n",
      "['Q51641', 'Q2907211', 'Q7311705', 'Q7796966', 'Q7796967', 'Q7796969', 'Q12403826', 'Q12403830', 'Q12404028', 'Q12408472', 'Q12408583', 'Q12408584']\n",
      "['Q36834', 'Q486748']\n",
      "['Q142']\n",
      "['Q36215']\n",
      "['Q167997']\n",
      "['Q3915']\n",
      "['Q3919']\n",
      "['Q38111', 'Q41148', 'Q80966', 'Q160432', 'Q170572', 'Q179414', 'Q188772', 'Q192402', 'Q201842', 'Q223091', 'Q223110', 'Q233882', 'Q236613', 'Q241025', 'Q264996', 'Q310394', 'Q311453', 'Q357762', 'Q437752', 'Q481954', 'Q483379', 'Q536437', 'Q918404', 'Q1189169', 'Q1190406', 'Q1680304', 'Q2865151', 'Q3127916', 'Q3501718', 'Q3573721', 'Q25768136']\n",
      "['Q258']\n",
      "['Q183']\n",
      "['Q1541']\n",
      "['Q220']\n",
      "['Q27']\n",
      "['Q3844']\n",
      "['Q204138']\n",
      "['Q140001']\n",
      "['Q1761', 'Q135501', 'Q659895', 'Q1263215', 'Q1672830', 'Q1766409', 'Q2062702', 'Q2088319', 'Q2350741', 'Q5242183', 'Q5500969', 'Q7417543', 'Q13156901', 'Q28601860']\n",
      "['Q8338', 'Q17172850']\n",
      "['Q2092607']\n",
      "['Q236132', 'Q456257']\n",
      "['Q150']\n",
      "['Q683695']\n",
      "['Q17714']\n",
      "['Q69354']\n",
      "['Q229107']\n",
      "['Q17', 'Q188712']\n",
      "['Q623']\n",
      "['Q167646']\n",
      "['Q212']\n",
      "['Q34990']\n",
      "['Q255']\n",
      "['Q45765']\n",
      "['Q31966']\n",
      "['Q108429']\n",
      "['Q155327']\n",
      "['Q157065']\n",
      "['Q1151']\n",
      "['Q176371']\n",
      "['Q656043']\n",
      "['Q30']\n",
      "['Q133274']\n",
      "['Q935']\n",
      "['Q41484']\n",
      "['Q7364']\n",
      "['Q34404']\n",
      "['Q241']\n",
      "['Q8343']\n",
      "['Q40939']\n",
      "['Q204627']\n",
      "['Q894']\n",
      "['Q170737']\n",
      "['Q79']\n",
      "['Q1554208', 'Q1969437']\n",
      "['Q38']\n",
      "['Q35500']\n",
      "['Q1147806']\n",
      "['Q645']\n",
      "['Q5885', 'Q13267']\n",
      "['Q5776']\n",
      "['Q811']\n",
      "['Q843']\n",
      "['Q8667']\n",
      "['Q152513']\n",
      "['Q2133873']\n",
      "['Q557323']\n",
      "['Q695']\n",
      "['Q7200']\n",
      "['Q6607', 'Q17172850']\n",
      "['Q8686']\n",
      "['Q38']\n",
      "['Q829']\n",
      "['Q4214909']\n",
      "['Q239337']\n",
      "['Q42493']\n",
      "['Q30']\n",
      "['Q1069', 'Q8008', 'Q46255']\n",
      "['Q1016']\n",
      "['Q1029907']\n",
      "['Q92600']\n",
      "['Q326358']\n",
      "['Q19566']\n",
      "['Q25224', 'Q374453']\n",
      "['Q28']\n",
      "['Q2634']\n",
      "['Q90', 'Q1017', 'Q173219']\n",
      "['Q869']\n",
      "['Q884']\n",
      "['Q1472152']\n",
      "['Q847']\n",
      "['Q741710']\n",
      "['Q656']\n",
      "['Q368121']\n",
      "['Q215901']\n",
      "['Q1711']\n",
      "['Q211260']\n",
      "['Q1741']\n",
      "['Q237105']\n",
      "['Q714']\n",
      "['Q171852']\n",
      "['Q490']\n",
      "['Q328523']\n",
      "['Q129987']\n",
      "['Q1962550']\n",
      "['Q18013']\n",
      "['Q3808']\n",
      "['Q1533']\n",
      "['Q76420']\n",
      "['Q106151']\n",
      "['Q37701']\n",
      "['Q37137', 'Q186506']\n",
      "['Q212']\n",
      "['Q229']\n",
      "['Q4321335']\n",
      "['Q40901', 'Q44384']\n",
      "['Q56005']\n",
      "['Q129279']\n",
      "['Q656']\n",
      "['Q80137']\n",
      "['Q836']\n",
      "['Q43399']\n",
      "['Q230']\n",
      "['Q265']\n",
      "['Q47163']\n",
      "['Q53268']\n",
      "['Q6839']\n",
      "['Q408']\n",
      "['Q271398']\n",
      "['Q33999', 'Q36834', 'Q177220']\n",
      "['Q158688']\n",
      "['Q811']\n",
      "['Q499980', 'Q838611']\n",
      "['Q200905']\n",
      "['Q318427']\n",
      "['Q1542521', 'Q2419102']\n",
      "['Q52607']\n",
      "['Q37320']\n",
      "['Q130752']\n",
      "['Q408']\n",
      "['Q45765']\n",
      "['Q11895']\n",
      "['Q272029', 'Q324319', 'Q327717', 'Q333146']\n",
      "['Q8355']\n",
      "['Q367120']\n",
      "['Q460337']\n",
      "['Q148']\n",
      "['Q1213902', 'Q3129651']\n",
      "['Q619584']\n",
      "['Q3210067']\n",
      "['Q276354']\n",
      "['Q672936']\n",
      "['Q44204']\n",
      "['Q4214909']\n",
      "['Q19100']\n",
      "['Q298']\n",
      "['Q2684']\n",
      "['Q52535']\n",
      "['Q15878']\n",
      "['Q47190']\n",
      "['Q379053']\n",
      "['Q211']\n",
      "['Q9726']\n",
      "['Q924']\n",
      "['Q308657']\n",
      "['Q347685']\n",
      "['Q199943']\n",
      "['Q1043128']\n",
      "['Q178780']\n",
      "['Q47670']\n",
      "['Q156711']\n",
      "['Q545844']\n",
      "['Q656']\n",
      "['Q14712']\n",
      "['Q40912']\n",
      "['Q1930']\n",
      "['Q142']\n",
      "['Q914']\n",
      "['Q6955']\n",
      "['Q127429']\n",
      "['Q97']\n",
      "['Q3844557']\n",
      "['Q5426']\n",
      "['Q40640']\n",
      "['Q230']\n",
      "['Q149067', 'Q15072554', 'Q19799931']\n",
      "['Q37030']\n",
      "['Q41466']\n",
      "['Q419']\n",
      "['Q70981']\n",
      "['Q96']\n",
      "['Q2696558']\n",
      "['Q471726', 'Q918057', 'Q1815797', 'Q3284950', 'Q5575842', 'Q21532983', 'Q28406292']\n",
      "['Q502265']\n",
      "['Q1248784']\n",
      "['Q35610']\n",
      "['Q5369']\n",
      "['Q25344']\n",
      "['Q1519']\n",
      "['Q79804']\n",
      "['Q45656']\n",
      "['Q71']\n",
      "['Q48']\n",
      "['Q1780']\n",
      "['Q49080']\n",
      "['Q724254']\n",
      "['Q49686']\n",
      "['Q84']\n",
      "['Q468467']\n",
      "['Q228889']\n",
      "['Q97', 'Q788']\n",
      "['Q898']\n",
      "['Q656']\n",
      "['Q239']\n",
      "['Q41211']\n",
      "['Q668', 'Q843', 'Q889']\n",
      "['Q23436']\n",
      "['Q1218']\n",
      "['Q170649']\n",
      "['Q130777']\n",
      "['Q862992']\n",
      "['Q680161']\n",
      "['Q379612']\n",
      "['Q4329463']\n",
      "['Q597']\n",
      "['Q503166']\n",
      "['Q23661']\n",
      "['Q237']\n",
      "['Q193592']\n",
      "['Q41604']\n",
      "['Q8717']\n",
      "['Q1770']\n",
      "['Q1435']\n",
      "['Q201568']\n",
      "['Q681697']\n",
      "['Q7200']\n",
      "['Q258']\n",
      "['Q179620']\n",
      "['Q1449']\n",
      "['Q935']\n",
      "['Q44395']\n",
      "['Q159']\n",
      "['Q30']\n",
      "['Q9270']\n",
      "['Q183']\n",
      "['Q754837']\n",
      "['Q12100']\n",
      "['Q3783']\n",
      "['Q28']\n",
      "['Q156724']\n",
      "['Q55208']\n",
      "['Q4327225']\n",
      "['Q25363']\n",
      "['Q178']\n",
      "['Q2263']\n",
      "['Q753', 'Q1096']\n",
      "['Q127892']\n",
      "['Q146667']\n",
      "['Q966571', 'Q2026876']\n",
      "['Q1320718']\n",
      "['Q925']\n",
      "['Q727']\n",
      "['Q171416']\n",
      "['Q2625243']\n",
      "['Q33']\n",
      "['Q165769']\n",
      "['Q717']\n",
      "['Q30']\n",
      "['Q29108']\n",
      "['Q805221', 'Q805253', 'Q2490358', 'Q5716684', 'Q15296811', 'Q18939491']\n",
      "['Q765633']\n",
      "['Q571822']\n",
      "['Q9671', 'Q169898']\n",
      "['Q45']\n",
      "['Q47774']\n",
      "['Q913643']\n",
      "['Q16320']\n",
      "['Q2337']\n",
      "['Q83459']\n",
      "['Q36']\n",
      "['Q106807']\n",
      "['Q167551']\n",
      "['Q326499']\n",
      "['Q2981']\n",
      "['Q145']\n",
      "['Q21127485']\n",
      "['Q38']\n",
      "['Q15720844']\n",
      "['Q748296']\n",
      "['Q181678']\n",
      "['Q4925477']\n",
      "['Q155874']\n",
      "['Q215548']\n",
      "['Q140686', 'Q218295', 'Q842386', 'Q4109060', 'Q4127082', 'Q4399975', 'Q14805701', 'Q27494237', 'Q38715304', 'Q38715670', 'Q38715852']\n",
      "['Q193018']\n",
      "['Q202040']\n",
      "['Q50546603']\n",
      "['Q5254470']\n",
      "['Q232']\n",
      "['Q898795']\n",
      "['Q41466']\n",
      "['Q1615333', 'Q41795540']\n",
      "['Q42267']\n",
      "['Q271934']\n",
      "['Q1875']\n",
      "['Q18552177']\n",
      "['Q29']\n",
      "['Q1978556']\n",
      "['Q57327']\n",
      "['Q7205']\n",
      "['Q673075']\n",
      "['Q1417705']\n",
      "['Q96', 'Q115', 'Q774', 'Q800']\n",
      "['Q239']\n",
      "['Q33244']\n",
      "['Q926']\n",
      "['Q2723928']\n",
      "['Q645719']\n",
      "['Q810']\n",
      "['Q47064', 'Q82955']\n",
      "['Q1891']\n",
      "['Q159']\n",
      "['Q840829', 'Q2359372']\n",
      "['Q208588']\n",
      "['Q61']\n",
      "['Q902320']\n",
      "['Q7604']\n",
      "['Q3519259']\n",
      "['Q1741']\n",
      "['Q1761']\n",
      "['Q818467']\n",
      "['Q210287']\n",
      "['Q182059']\n",
      "['Q63991914']\n",
      "['Q2333']\n",
      "['Q35064']\n",
      "['Q34']\n",
      "['Q627508']\n",
      "['Q18502']\n",
      "['Q46']\n",
      "['Q46', 'Q48']\n",
      "['Q656']\n",
      "['Q4183061']\n",
      "['Q169898', 'Q171329', 'Q171367', 'Q172721']\n",
      "['Q2359372']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q17501806']\n",
      "['Q21891843', 'Q23820229', 'Q84499835', 'Q84565071', 'Q84566351', 'Q84572475', 'Q84572977', 'Q84593853', 'Q84599401', 'Q84682501', 'Q84763814', 'Q84947682', 'Q174248', 'Q378120', 'Q580728', 'Q600063', 'Q628212', 'Q662985', 'Q693350', 'Q744598', 'Q748211', 'Q753219', 'Q753289', 'Q753292', 'Q840751', 'Q868618', 'Q942842', 'Q1013032', 'Q1013035', 'Q1624461', 'Q1734030', 'Q1810336', 'Q1811143', 'Q1821473', 'Q1822800', 'Q1963689', 'Q1969345', 'Q1987157', 'Q1996280', 'Q2003486', 'Q2041885', 'Q2048241', 'Q2061921', 'Q2078708', 'Q2216373', 'Q2219104', 'Q2297365', 'Q2317527', 'Q2320562', 'Q2331979', 'Q2403918', 'Q2440414', 'Q2442419', 'Q2446033', 'Q2456160', 'Q2460331', 'Q2467285', 'Q2499127', 'Q2501433', 'Q2533951', 'Q2580968', 'Q2612318', 'Q2623877', 'Q2638290', 'Q2661930', 'Q2689681', 'Q2693443', 'Q2709316', 'Q2717469', 'Q2782104', 'Q2786011', 'Q2795720', 'Q2834321', 'Q3176913', 'Q3489924', 'Q3489932', 'Q3489935', 'Q3490214', 'Q3490254', 'Q3490377', 'Q3490395', 'Q3490530', 'Q3490542', 'Q3490548', 'Q3490702', 'Q3497283', 'Q3499350', 'Q3499380', 'Q3499395', 'Q3499402', 'Q3499406', 'Q3509023', 'Q3509048', 'Q3509354', 'Q3509373', 'Q3509425', 'Q3509446', 'Q3509457', 'Q3509657', 'Q3509772', 'Q3509780', 'Q3509815', 'Q3509834', 'Q3563089', 'Q3563100', 'Q3563133', 'Q3563146', 'Q3563211', 'Q3563232', 'Q3564567', 'Q3566327', 'Q3566606']\n",
      "['Q13641190']\n",
      "['Q2084341', 'Q3273932', 'Q4252909', 'Q4262671']\n",
      "['Q612907', 'Q654471', 'Q762844', 'Q1703180', 'Q1967942', 'Q1992013', 'Q1992153', 'Q1992181', 'Q2268261', 'Q3853593', 'Q3885141', 'Q4188115', 'Q4240311', 'Q4286712', 'Q4286829', 'Q4286849', 'Q4286882', 'Q4286937', 'Q4286990', 'Q4287015', 'Q4287082', 'Q4287097', 'Q4287144', 'Q4375455', 'Q4375533', 'Q12756735', 'Q16481642', 'Q16485587', 'Q18080427', 'Q18080429', 'Q18080612', 'Q19399024', 'Q19910703', 'Q21644047', 'Q24932811', 'Q25394795', 'Q57316823', 'Q95000245']\n",
      "['Q21', 'Q22', 'Q25', 'Q26']\n",
      "['Q20183']\n",
      "['Q4151339', 'Q17287317', 'Q17287320', 'Q17287321']\n",
      "['Q165503']\n",
      "['Q28835', 'Q1275243']\n",
      "['Q1396852']\n",
      "['Q70498154']\n",
      "['Q15288']\n",
      "['Q1444', 'Q5994', 'Q8355', 'Q80284', 'Q81982', 'Q191823', 'Q281460', 'Q1521313']\n",
      "['Q10478']\n",
      "['Q4480733']\n",
      "['Q202243']\n",
      "['Q204752']\n",
      "['Q15', 'Q48']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q90']\n",
      "['Q1982087']\n",
      "['Q239', 'Q12800833']\n",
      "['Q250', 'Q3966', 'Q5300', 'Q7397', 'Q9143', 'Q183484', 'Q2384798']\n",
      "['Q43421']\n",
      "['Q46', 'Q48']\n",
      "['Q5492408']\n",
      "['Q3964988']\n",
      "['Q579431', 'Q2000835']\n",
      "['Q665105']\n",
      "['Q184437']\n",
      "['Q190543']\n",
      "['Q55766251']\n",
      "['Q72614', 'Q104161', 'Q1384655', 'Q2721194']\n",
      "['Q4315520']\n",
      "['Q49481']\n",
      "['Q213067']\n",
      "['Q188', 'Q1860', 'Q7737', 'Q9027']\n",
      "['Q79082']\n",
      "['Q18']\n",
      "['Q46']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q739', 'Q8965', 'Q199821', 'Q232564', 'Q1055848', 'Q3591854']\n",
      "['Q902', 'Q330158', 'Q842931', 'Q1850485', 'Q2347909']\n",
      "['Q28']\n",
      "['Q162533']\n",
      "['Q48']\n",
      "['Q847']\n",
      "['Q485176']\n",
      "['Q157443', 'Q192881', 'Q319221', 'Q471839', 'Q761469', 'Q2973181', 'Q20443008']\n",
      "['Q98']\n",
      "['Q37068']\n",
      "['Q37853']\n",
      "['Q54111', 'Q170292']\n",
      "['Q332342', 'Q7744473']\n",
      "['Q13394']\n",
      "['Q324867']\n",
      "['Q4411519']\n",
      "['Q486860']\n",
      "['Q656']\n",
      "['Q1218', 'Q187702', 'Q540882', 'Q1494672', 'Q2280628', 'Q7818625']\n",
      "['Q1332307']\n",
      "['Q210398']\n",
      "['Q8261', 'Q128758', 'Q474090']\n",
      "['Q126399', 'Q621364', 'Q984047', 'Q2924461']\n",
      "['Q23633']\n",
      "['Q126399', 'Q2924461', 'Q3011161', 'Q31197934']\n",
      "['Q1200552', 'Q17343562', 'Q18155354', 'Q22807052']\n",
      "['Q13641190']\n",
      "['Q1589009']\n",
      "['Q75', 'Q880371', 'Q56611700']\n",
      "['Q6581097']\n",
      "['Q675765', 'Q845981', 'Q3984081']\n",
      "['Q1506552', 'Q1938341']\n",
      "['Q27621', 'Q322964', 'Q323681']\n",
      "['Q5994', 'Q8355']\n",
      "['Q165503']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q5064', 'Q12025', 'Q201873', 'Q207875', 'Q231390', 'Q586421']\n",
      "['Q159909', 'Q14906020']\n",
      "['Q299687']\n",
      "['Q124018']\n",
      "['Q778243']\n",
      "['Q158314']\n",
      "['Q62843', 'Q92743']\n",
      "['Q8743', 'Q315422']\n",
      "['Q76468']\n",
      "['Q34286', 'Q77124', 'Q273314', 'Q318449']\n",
      "['Q133544']\n",
      "['Q4143870']\n",
      "['Q552732']\n",
      "['Q5673']\n",
      "['Q4069095', 'Q4321371']\n",
      "['Q380156', 'Q1395520']\n",
      "['Q4934', 'Q92764']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q7738', 'Q12548', 'Q27306', 'Q33296', 'Q34266', 'Q45670', 'Q68518', 'Q70972', 'Q80702', 'Q127318', 'Q131706', 'Q131981', 'Q153136', 'Q156199', 'Q161885', 'Q168651', 'Q170604', 'Q215443', 'Q215530', 'Q256961', 'Q258532', 'Q310650', 'Q318806', 'Q706018', 'Q830084', 'Q4083686']\n",
      "['Q299687']\n",
      "['Q29637']\n",
      "['Q739711', 'Q1799063']\n",
      "['Q75079']\n",
      "['Q2628071']\n",
      "['Q152293']\n",
      "['Q79965', 'Q170770', 'Q1483495', 'Q4318679']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q26068']\n",
      "['Q22890', 'Q23666', 'Q38272']\n",
      "['Q76925']\n",
      "['Q76925']\n",
      "['Q538']\n",
      "['Q258896']\n",
      "['Q7603']\n",
      "['Q233282']\n",
      "['Q21', 'Q145']\n",
      "['Q380252']\n",
      "['Q42042', 'Q48362']\n",
      "['Q3333484']\n",
      "['Q25624', 'Q193026', 'Q1347099', 'Q1377980', 'Q2217063']\n",
      "['Q785828']\n",
      "['Q1065', 'Q4230', 'Q4264', 'Q7809', 'Q7817', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q47488', 'Q47539', 'Q123209', 'Q123759', 'Q151991', 'Q182500', 'Q191384', 'Q243630', 'Q340195', 'Q467938', 'Q471690', 'Q499151', 'Q535086', 'Q602399', 'Q605595', 'Q607301', 'Q656801', 'Q827525', 'Q838116', 'Q842490', 'Q943105', 'Q1025959', 'Q1043527', 'Q1045401', 'Q1072120', 'Q1480793', 'Q1484463', 'Q1570993', 'Q2836400', 'Q3369762', 'Q5611262', 'Q10283557']\n",
      "['Q9448']\n",
      "['Q41']\n",
      "['Q258748']\n",
      "['Q1781702']\n",
      "['Q260542']\n",
      "['Q49', 'Q538']\n",
      "['Q37068']\n",
      "['Q7291']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q2359372']\n",
      "['Q15804']\n",
      "['Q1256223']\n",
      "['Q649', 'Q656', 'Q891', 'Q900', 'Q1874', 'Q5332', 'Q5337', 'Q5540', 'Q5627', 'Q19566', 'Q21197', 'Q156648', 'Q4092262', 'Q4536541', 'Q4538749']\n",
      "['Q1130019']\n",
      "['Q97']\n",
      "['Q33629']\n",
      "['Q24826']\n",
      "['Q3426']\n",
      "['Q1130019']\n",
      "['Q1457437']\n",
      "['Q649']\n",
      "['Q1902692']\n",
      "['Q586']\n",
      "['Q649']\n",
      "['Q5776']\n",
      "['Q133838']\n",
      "['Q174097']\n",
      "['Q34433', 'Q1643454']\n",
      "['Q3630']\n",
      "['Q5994']\n",
      "['Q1990094']\n",
      "['Q4460646']\n",
      "['Q1422', 'Q8682', 'Q18656', 'Q75729', 'Q267245', 'Q1630430', 'Q1772776', 'Q3590754', 'Q3590758', 'Q21079208']\n",
      "['Q59488']\n",
      "['Q133602']\n",
      "['Q81589', 'Q645968']\n",
      "['Q156255']\n",
      "['Q242446']\n",
      "['Q126399', 'Q2924461']\n",
      "['Q159846', 'Q367466']\n",
      "['Q2914786', 'Q4444575']\n",
      "['Q126399', 'Q622668', 'Q3011161', 'Q31197934']\n",
      "['Q2628487']\n",
      "['Q141336']\n",
      "['Q95', 'Q20800404']\n",
      "['Q269792']\n",
      "['Q127552', 'Q191224']\n",
      "['Q20800404']\n",
      "['Q84']\n",
      "['Q16869', 'Q182009']\n",
      "['Q1533']\n",
      "['Q1957']\n",
      "['Q1858']\n",
      "['Q1353', 'Q11739', 'Q42941', 'Q179046', 'Q3242297']\n",
      "['Q2184', 'Q2895', 'Q130229', 'Q130276', 'Q130280', 'Q131337', 'Q132856', 'Q133356', 'Q168811', 'Q170895', 'Q173761', 'Q186888', 'Q192180', 'Q199707', 'Q199711', 'Q484578', 'Q545205']\n",
      "['Q93728', 'Q178473', 'Q185493', 'Q207826', 'Q208167', 'Q278798', 'Q337463', 'Q465316', 'Q530008', 'Q1069798', 'Q1081449', 'Q1710776', 'Q2297431', 'Q2634074', 'Q2760953', 'Q4137459', 'Q4286836', 'Q4335954', 'Q21292820', 'Q59351315', 'Q60130697', 'Q63975126']\n",
      "['Q37922', 'Q278798', 'Q603631', 'Q695106', 'Q950604', 'Q1026769', 'Q1081503', 'Q1340199', 'Q18200478']\n",
      "['Q475482', 'Q1463070']\n",
      "['Q152951']\n",
      "['Q152951']\n",
      "['Q493898']\n",
      "['Q172326']\n",
      "['Q8355', 'Q81982', 'Q281460']\n",
      "['Q27911']\n",
      "['Q31687']\n",
      "['Q27914']\n",
      "['Q1438774']\n",
      "['Q45700']\n",
      "['Q1425861', 'Q7268181']\n",
      "['Q186506']\n",
      "['Q379053']\n",
      "['Q180729', 'Q181951', 'Q1059510', 'Q1277249', 'Q2494846', 'Q4862955']\n",
      "['Q28989']\n",
      "['Q9268']\n",
      "['Q432', 'Q5043']\n",
      "['Q1394287']\n",
      "['Q2498026']\n",
      "['Q23759071']\n",
      "['Q345']\n",
      "['Q7041639']\n",
      "['Q95', 'Q20800404']\n",
      "['Q1966985']\n",
      "['Q1744']\n",
      "['Q377', 'Q191480']\n",
      "['Q42511']\n",
      "['Q15151625']\n",
      "['Q15151625']\n",
      "['Q4069095', 'Q4321371', 'Q4360695']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q5284', 'Q162005']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q44412']\n",
      "['Q37064']\n",
      "['Q50224531']\n",
      "['Q3140459']\n",
      "['Q1060165']\n",
      "['Q2283', 'Q1129295']\n",
      "['Q4132607']\n",
      "['Q195719']\n",
      "['Q42574']\n",
      "['Q4934', 'Q92764']\n",
      "['Q76368']\n",
      "['Q4419809', 'Q4498457']\n",
      "['Q929273', 'Q929285', 'Q2071256', 'Q16253333', 'Q57022061']\n",
      "['Q15072147']\n",
      "['Q315188']\n",
      "['Q191598']\n",
      "['Q97']\n",
      "['Q1406', 'Q5014725', 'Q13361286', 'Q64513817']\n",
      "['Q1406', 'Q5014725', 'Q13361286']\n",
      "['Q280658']\n",
      "['Q280658', 'Q8025128']\n",
      "['Q3542']\n",
      "['Q15243', 'Q203462']\n",
      "['Q2160']\n",
      "['Q19686', 'Q19914']\n",
      "['Q166162']\n",
      "['Q1457453']\n",
      "['Q4320732']\n",
      "['Q166162']\n",
      "['Q13199', 'Q15087', 'Q33754', 'Q387066']\n",
      "['Q80284']\n",
      "['Q31561', 'Q79838', 'Q178389', 'Q4501563', 'Q17172850']\n",
      "['Q8343']\n",
      "['Q3238057', 'Q13785927']\n",
      "['Q5710', 'Q809806', 'Q1092754', 'Q1390649', 'Q4479125', 'Q4479136', 'Q15190285']\n",
      "['Q408', 'Q3258', 'Q15577']\n",
      "['Q980', 'Q10544', 'Q10562']\n",
      "['Q1019', 'Q489821', 'Q5501842']\n",
      "['Q225', 'Q11196', 'Q11198', 'Q18276', 'Q208545', 'Q1274468', 'Q2055400']\n",
      "['Q252', 'Q3757', 'Q523435']\n",
      "['Q766', 'Q651453', 'Q2526023']\n",
      "['Q424', 'Q1054184', 'Q3173090']\n",
      "['Q40', 'Q12548', 'Q28513', 'Q42497', 'Q131964', 'Q153136', 'Q176495', 'Q268970', 'Q518101', 'Q699964', 'Q3624335', 'Q16056854']\n",
      "['Q5446', 'Q788066', 'Q2391775', 'Q6671523', 'Q14558462', 'Q18055588']\n",
      "['Q672', 'Q21815222']\n",
      "['Q854']\n",
      "['Q1008', 'Q845706']\n",
      "['Q1368300']\n",
      "['Q432']\n",
      "['Q775909']\n",
      "['Q4239246']\n",
      "['Q1497']\n",
      "['Q371828', 'Q1324152']\n",
      "['Q207706']\n",
      "['Q4218621']\n",
      "['Q2280', 'Q173822', 'Q185700', 'Q188732', 'Q189822', 'Q191061', 'Q192959']\n",
      "['Q5681011']\n",
      "['Q16157447']\n",
      "['Q361', 'Q2140994', 'Q4081756', 'Q4097857', 'Q4255538']\n",
      "['Q9448']\n",
      "['Q656', 'Q9248', 'Q155243', 'Q196388', 'Q1020157', 'Q4322358']\n",
      "['Q917830']\n",
      "['Q27621', 'Q2654435', 'Q4139211']\n",
      "['Q973']\n",
      "['Q1065', 'Q7184', 'Q7785', 'Q7809', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q37143', 'Q38130', 'Q41550', 'Q81299', 'Q123759', 'Q134102', 'Q170481', 'Q181574', 'Q188822', 'Q191384', 'Q233611', 'Q340195', 'Q376150', 'Q656801', 'Q674182', 'Q782942', 'Q826700', 'Q827525', 'Q842490', 'Q899770', 'Q1043527', 'Q1072120', 'Q1480793', 'Q1928989', 'Q2863003', 'Q3772571', 'Q3866537', 'Q4033111', 'Q4426267', 'Q5150848', 'Q5611262', 'Q7768229', 'Q7886981']\n",
      "['Q167541']\n",
      "['Q182165']\n",
      "['Q76751']\n",
      "['Q5284', 'Q162005']\n",
      "['Q557305', 'Q861967']\n",
      "['Q104898']\n",
      "['Q58792', 'Q80919']\n",
      "['Q1189073', 'Q6895015']\n",
      "['Q182994']\n",
      "['Q46']\n",
      "['Q207591']\n",
      "['Q10857409']\n",
      "['Q782363']\n",
      "['Q736587']\n",
      "['Q649', 'Q656', 'Q1731', 'Q4079059', 'Q4471180']\n",
      "['Q234460', 'Q1069725', 'Q1980247']\n",
      "['Q3642350']\n",
      "['Q101978']\n",
      "['Q49542', 'Q79797', 'Q482942', 'Q1129737', 'Q10290517']\n",
      "['Q19831455']\n",
      "['Q372657', 'Q505275', 'Q22032185']\n",
      "['Q134161', 'Q891723']\n",
      "['Q75745', 'Q248756', 'Q785531', 'Q808176', 'Q854686', 'Q1009177', 'Q1054311', 'Q2090382', 'Q2462900', 'Q2921573', 'Q3017105', 'Q3196524', 'Q4074592', 'Q4081114', 'Q4222569', 'Q4246441', 'Q4375034', 'Q4408691', 'Q4424133', 'Q4427701', 'Q4460344', 'Q14915363', 'Q14915364', 'Q14915365', 'Q14915367', 'Q14915368', 'Q14915369', 'Q14915370', 'Q14915425', 'Q14915428', 'Q14915447', 'Q14915448', 'Q14915449', 'Q14915450', 'Q14915451', 'Q14915452', 'Q14915453', 'Q14915454', 'Q14915455', 'Q14915456', 'Q14915457', 'Q14915458', 'Q14915459', 'Q14915460', 'Q14915461', 'Q14915462', 'Q14915463', 'Q14915464', 'Q14915465', 'Q14915466', 'Q14915467', 'Q14915468', 'Q14915469', 'Q14915470', 'Q14915471', 'Q14915472', 'Q14915473', 'Q14915474', 'Q14915475', 'Q14915476', 'Q14915477', 'Q14915478', 'Q14915479', 'Q14915480', 'Q14915481', 'Q14915482', 'Q14915483', 'Q14915484', 'Q14915485', 'Q14915486', 'Q14915489', 'Q14915490', 'Q14943318', 'Q14943338', 'Q14943342', 'Q21036227', 'Q21036228', 'Q21036229', 'Q21036230', 'Q27679334', 'Q35267412']\n",
      "['Q185493', 'Q208167', 'Q241821', 'Q278798', 'Q337463', 'Q530008', 'Q946626', 'Q1067644', 'Q1069798', 'Q1710776', 'Q2329480', 'Q2634074', 'Q4335936', 'Q4335954', 'Q4375624', 'Q21292820', 'Q56669004', 'Q60054123']\n",
      "['Q41144', 'Q41146', 'Q43269', 'Q43271', 'Q130343', 'Q165582', 'Q170453', 'Q190687', 'Q190922', 'Q191164', 'Q191174', 'Q191186', 'Q201121', 'Q201137', 'Q202068', 'Q202071', 'Q202075', 'Q204876', 'Q205460', 'Q205776', 'Q205784', 'Q205796', 'Q205824', 'Q205843', 'Q492791']\n",
      "['Q1085', 'Q46070', 'Q188373', 'Q188399', 'Q190550', 'Q190930', 'Q191091', 'Q192536', 'Q192697', 'Q192702', 'Q193266', 'Q193295', 'Q193307', 'Q193317']\n",
      "['Q1490', 'Q15701', 'Q44843', 'Q47896', 'Q48326', 'Q71699', 'Q71707', 'Q80011', 'Q80434', 'Q81863', 'Q83273', 'Q120730', 'Q122723', 'Q123258', 'Q123376', 'Q125863', 'Q127264', 'Q127513', 'Q127877', 'Q128186', 'Q128196', 'Q129499', 'Q130290', 'Q130300', 'Q130308', 'Q131277', 'Q131281', 'Q131287', 'Q131314', 'Q131320', 'Q131358', 'Q132705', 'Q132720', 'Q132751', 'Q132929', 'Q132936', 'Q133879', 'Q133924', 'Q133935', 'Q134093', 'Q160420', 'Q160734', 'Q161454', 'Q169376', 'Q617375', 'Q766445', 'Q1037393']\n",
      "['Q4156896']\n",
      "['Q7325']\n",
      "['Q6581097']\n",
      "['Q5256775']\n",
      "['Q10693']\n",
      "['Q12482', 'Q44455', 'Q189088', 'Q1554323', 'Q1766038', 'Q1970172', 'Q2895315', 'Q4056286', 'Q4358367', 'Q5498822']\n",
      "['Q928993']\n",
      "['Q20818052']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q67186598']\n",
      "['Q4035237']\n",
      "['Q52410688']\n",
      "['Q3772']\n",
      "['Q4417863']\n",
      "['Q60100']\n",
      "['Q41602']\n",
      "['Q217925', 'Q2873520']\n",
      "['Q23898959']\n",
      "['Q27621']\n",
      "['Q1566', 'Q199344', 'Q736556']\n",
      "['Q182994']\n",
      "['Q2532727']\n",
      "['Q65032731']\n",
      "['Q47591', 'Q4520962']\n",
      "['Q11297']\n",
      "['Q1370', 'Q523606', 'Q5425102']\n",
      "['Q3279650']\n",
      "['Q6635', 'Q645924']\n",
      "['Q11002', 'Q11254', 'Q41534', 'Q93189', 'Q815740', 'Q4739805', 'Q61503220']\n",
      "['Q50407282']\n",
      "['Q3739104']\n",
      "['Q171558']\n",
      "['Q3739104']\n",
      "['Q3739104']\n",
      "['Q337463']\n",
      "['Q756727', 'Q2747456']\n",
      "['Q202009', 'Q918052', 'Q1167442', 'Q1756055', 'Q3163406']\n",
      "['Q54111']\n",
      "['Q11366', 'Q188450', 'Q484641']\n",
      "['Q3273722']\n",
      "['Q40855']\n",
      "['Q73801', 'Q308913', 'Q611508', 'Q735267', 'Q1046593', 'Q1202130', 'Q2080076', 'Q2469781']\n",
      "['Q157802']\n",
      "['Q4204467']\n",
      "['Q483654']\n",
      "['Q483654', 'Q3333484']\n",
      "['Q547869']\n",
      "['Q27703517']\n",
      "['Q892']\n",
      "['Q1402143']\n",
      "['Q128267', 'Q186350']\n",
      "['Q3415248']\n",
      "['Q4418820']\n",
      "['Q1273278']\n",
      "['Q42574']\n",
      "['Q56008']\n",
      "['Q187364']\n",
      "['Q726105']\n",
      "['Q56005']\n",
      "['Q8877', 'Q6758800']\n",
      "['Q56005']\n",
      "['Q80135']\n",
      "['Q33629']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q626']\n",
      "['Q3447', 'Q27538353']\n",
      "['Q38', 'Q1282', 'Q18288160']\n",
      "['Q487003']\n",
      "['Q228986']\n",
      "['Q23746012']\n",
      "['Q4301841']\n",
      "['Q1711668']\n",
      "['Q1768082']\n",
      "['Q968028']\n",
      "['Q192239']\n",
      "['Q434841']\n",
      "['Q157802']\n",
      "['Q178473', 'Q185493', 'Q209896', 'Q478850', 'Q530008', 'Q534981', 'Q583881', 'Q612907', 'Q694401', 'Q728960', 'Q791135', 'Q1311063', 'Q1415232', 'Q1428575', 'Q1992013', 'Q2028781', 'Q2268261', 'Q2300740', 'Q2638119', 'Q2660844', 'Q4193236', 'Q9387384', 'Q18080427', 'Q18080429', 'Q18080431', 'Q21405589', 'Q89211387']\n",
      "['Q97']\n",
      "['Q27698']\n",
      "['Q946428']\n",
      "['Q33629']\n",
      "['Q834621']\n",
      "['Q4918']\n",
      "['Q1247']\n",
      "['Q17723']\n",
      "['Q515869', 'Q25060578']\n",
      "['Q44626']\n",
      "['Q393864']\n",
      "['Q4393561']\n",
      "['Q847', 'Q5377', 'Q80131']\n",
      "['Q134307', 'Q170571', 'Q191163']\n",
      "['Q207591']\n",
      "['Q130232', 'Q2254193', 'Q52207399']\n",
      "['Q393']\n",
      "['Q141336']\n",
      "['Q5168']\n",
      "['Q5222']\n",
      "['Q900']\n",
      "['Q33405']\n",
      "['Q3114']\n",
      "['Q748', 'Q427945', 'Q2279088']\n",
      "['Q299687']\n",
      "['Q49481']\n",
      "['Q7349']\n",
      "['Q49481']\n",
      "['Q150', 'Q188', 'Q652', 'Q13199']\n",
      "['Q188']\n",
      "['Q23438']\n",
      "['Q3616']\n",
      "['Q174193']\n",
      "['Q11399', 'Q187760', 'Q598929']\n",
      "['Q8341', 'Q9759', 'Q203775', 'Q207378', 'Q1196752', 'Q1530455']\n",
      "['Q37068']\n",
      "['Q39427']\n",
      "['Q37853']\n",
      "['Q4992220']\n",
      "['Q736587']\n",
      "['Q112707']\n",
      "['Q161179', 'Q177540', 'Q223197', 'Q583582', 'Q1055000']\n",
      "['Q8261']\n",
      "['Q189635']\n",
      "['Q181754']\n",
      "['Q181754']\n",
      "['Q125168', 'Q1501888']\n",
      "['Q1471878', 'Q3983766']\n",
      "['Q31687']\n",
      "['Q1218']\n",
      "['Q1520']\n",
      "['Q1930']\n",
      "['Q28218']\n",
      "['Q31687']\n",
      "['Q2618625']\n",
      "['Q739000']\n",
      "['Q767288']\n",
      "['Q51199', 'Q4228172']\n",
      "['Q240150']\n",
      "['Q8958']\n",
      "['Q762']\n",
      "['Q204138']\n",
      "['Q2382967']\n",
      "['Q358556']\n",
      "['Q700540']\n",
      "['Q314287']\n",
      "['Q4768']\n",
      "['Q1144905']\n",
      "['Q9217']\n",
      "['Q1568', 'Q1860']\n",
      "['Q150', 'Q1860']\n",
      "['Q150']\n",
      "['Q1682', 'Q1684', 'Q161455', 'Q300875', 'Q316287', 'Q324404', 'Q562206', 'Q671428', 'Q694789', 'Q697916', 'Q821135', 'Q1532109', 'Q1538524', 'Q1646276', 'Q3908364']\n",
      "['Q188', 'Q36668']\n",
      "['Q5146', 'Q750553', 'Q3436689']\n",
      "['Q13955']\n",
      "['Q8821']\n",
      "['Q809']\n",
      "['Q37217']\n",
      "['Q78994', 'Q858913', 'Q1025134', 'Q1088879', 'Q1194172', 'Q1347209', 'Q1985387', 'Q2234632', 'Q2372093', 'Q2914954']\n",
      "['Q30']\n",
      "['Q164800']\n",
      "['Q80113', 'Q166713']\n",
      "['Q217128']\n",
      "['Q762']\n",
      "['Q130777']\n",
      "['Q76432', 'Q76745', 'Q76747']\n",
      "['Q11570']\n",
      "Accuracy = 0.2765598650927487\n"
     ]
    }
   ],
   "source": [
    "rubq_test = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "\n",
    "answers = []\n",
    "for i in tqdm(range(len(rubq_test))):\n",
    "    input_ids = t5_tok(rubq_test[i], return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "    answers.append(gen_output)\n",
    "    \n",
    "    \n",
    "final = []\n",
    "for x in answers:\n",
    "    final.append(t5_tok.decode(x, skip_special_tokens=True))\n",
    "\n",
    "    \n",
    "#rubq_questions = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "entities_test_rubq = np.load(\"entities_test_rubq.npy\")\n",
    "rubq_test = pd.DataFrame({\"subject\":entities_test_rubq, \"question\":rubq_test})\n",
    "rubq_test_answers = np.load(\"all_rubq_test_answers_1_hop_uri.npy\", allow_pickle=True)\n",
    "\n",
    "# answers_rubq = []\n",
    "\n",
    "# for lis in rubq_test_answers:\n",
    "#     print(lis)\n",
    "#     new = []\n",
    "#     for element in lis:\n",
    "#         new.append(get_description_name(element))\n",
    "\n",
    "#     answers_rubq.append(new)\n",
    "    \n",
    "preds = []\n",
    "for i in range(len(final)):\n",
    "    try:\n",
    "        x = from_text_to_id(final[i])\n",
    "    except:\n",
    "        x = \"None\"\n",
    "    \n",
    "    preds.append(x)\n",
    "    \n",
    "np.save(\"predictions_rubq_test_t5_3b_ssm_nq.npy\", np.array(final))\n",
    "\n",
    "answers_rubq = []\n",
    "\n",
    "for lis in rubq_test_answers:\n",
    "    print(lis)\n",
    "    new = []\n",
    "    for element in lis:\n",
    "        new.append(element)\n",
    "\n",
    "    answers_rubq.append(new)\n",
    "\n",
    "right = 0\n",
    "\n",
    "for i, ans in enumerate(answers_rubq):\n",
    "    if preds[i] in ans:\n",
    "        right += 1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"Accuracy = {right/len(preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t5-3b-ssm-nqo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-3b-ssm-nqo\")#\"google/t5-11b-ssm-tqa\")\n",
    "t5_tok = AutoTokenizer.from_pretrained(\"google/t5-3b-ssm-nqo\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4751/4751 [11:25<00:00,  6.93it/s]\n",
      "100%|██████████| 4751/4751 [00:00<00:00, 827298.47it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_o, preds_id_sq_o = check_t5_sq(t5_tok = t5_tok, t5_qa_model = t5_qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 accuracy t5-3b-ssm-nqo SQ =  0.06735424121237635\n"
     ]
    }
   ],
   "source": [
    "print(\"top1 accuracy t5-3b-ssm-nqo SQ = \", acc_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [03:13<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q7944', 'Q60186', 'Q167903', 'Q2580904', 'Q5975740', 'Q7692360']\n",
      "['Q102513']\n",
      "['Q692']\n",
      "['Q19660']\n",
      "['Q6607', 'Q483994', 'Q626035', 'Q2643890', 'Q17172850']\n",
      "['Q142']\n",
      "['Q299687']\n",
      "['Q312480']\n",
      "['Q29']\n",
      "['Q4022']\n",
      "['Q796']\n",
      "['Q38768', 'Q201605', 'Q1676638']\n",
      "['Q22']\n",
      "['Q11420', 'Q106500']\n",
      "['Q4808485']\n",
      "['Q2838011']\n",
      "['Q9299872']\n",
      "['Q2674728']\n",
      "['Q1968651']\n",
      "['Q1088']\n",
      "['Q7737', 'Q29561']\n",
      "['Q36124']\n",
      "['Q43']\n",
      "['Q49481']\n",
      "['Q424', 'Q869', 'Q881']\n",
      "['Q148', 'Q837']\n",
      "['Q232']\n",
      "['Q408']\n",
      "['Q816']\n",
      "['Q847', 'Q5377']\n",
      "['Q30']\n",
      "['Q1792']\n",
      "['Q822290']\n",
      "['Q1603']\n",
      "['Q181306', 'Q213344', 'Q237367', 'Q1326237']\n",
      "['Q237800']\n",
      "['Q106151']\n",
      "['Q201598']\n",
      "['Q223134']\n",
      "['Q106010']\n",
      "['Q29445']\n",
      "['Q40591', 'Q58784', 'Q295347', 'Q470600']\n",
      "['Q1850']\n",
      "['Q4719']\n",
      "['Q157683']\n",
      "['Q158491']\n",
      "['Q62']\n",
      "['Q24861']\n",
      "['Q3787']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q55']\n",
      "['Q19675']\n",
      "['Q36180', 'Q82955', 'Q185351', 'Q333634', 'Q1209498', 'Q1297719', 'Q4964182', 'Q11774202', 'Q18814623']\n",
      "['Q22']\n",
      "['Q1048']\n",
      "['Q9191']\n",
      "['Q687']\n",
      "['Q1860923']\n",
      "['Q178577']\n",
      "['Q199588']\n",
      "['Q79759']\n",
      "['Q31628']\n",
      "['Q57966']\n",
      "['Q133622']\n",
      "['Q360292']\n",
      "['Q128790']\n",
      "['Q236233']\n",
      "['Q152293']\n",
      "['Q15862']\n",
      "['Q723764']\n",
      "['Q783']\n",
      "['Q767288']\n",
      "['Q31628']\n",
      "['Q142']\n",
      "['Q40357']\n",
      "['Q1048']\n",
      "['Q159']\n",
      "['Q2064699', 'Q4304132']\n",
      "['Q668']\n",
      "['Q112']\n",
      "['Q49111']\n",
      "['Q131026']\n",
      "['Q11419']\n",
      "['Q6502703']\n",
      "['Q172911']\n",
      "['Q212115']\n",
      "['Q1069868']\n",
      "['Q897']\n",
      "['Q869']\n",
      "['Q41']\n",
      "['Q10737']\n",
      "['Q6862']\n",
      "['Q40059']\n",
      "['Q35591']\n",
      "['Q2332']\n",
      "['Q1205']\n",
      "['Q31015', 'Q241214']\n",
      "['Q586']\n",
      "['Q891']\n",
      "['Q1472', 'Q12133', 'Q35869', 'Q41083', 'Q110315', 'Q131742', 'Q147778', 'Q193894', 'Q653078', 'Q2025687', 'Q2035074', 'Q3144986']\n",
      "['Q144144']\n",
      "['Q34981']\n",
      "['Q185027']\n",
      "['Q47369']\n",
      "['Q45']\n",
      "['Q81214']\n",
      "['Q51']\n",
      "['Q4964182']\n",
      "['Q46599']\n",
      "['Q6816']\n",
      "['Q46']\n",
      "['Q1875']\n",
      "['Q5470']\n",
      "['Q165503']\n",
      "['Q25261', 'Q46255']\n",
      "['Q925']\n",
      "['Q790']\n",
      "['Q13695']\n",
      "['Q24826']\n",
      "['Q1035', 'Q82122']\n",
      "['Q2568844']\n",
      "['Q149067']\n",
      "['Q170737']\n",
      "['Q626']\n",
      "['Q395', 'Q7754', 'Q41217', 'Q149999', 'Q56114489']\n",
      "['Q157623']\n",
      "['Q159']\n",
      "['Q5592']\n",
      "['Q626']\n",
      "['Q28244']\n",
      "['Q16559']\n",
      "['Q944527']\n",
      "['Q8027']\n",
      "['Q70']\n",
      "['Q10484']\n",
      "['Q47059']\n",
      "['Q93351']\n",
      "['Q762']\n",
      "['Q214196']\n",
      "['Q130498']\n",
      "['Q30204']\n",
      "['Q157623']\n",
      "['Q31']\n",
      "['Q854']\n",
      "['Q170513']\n",
      "['Q5806']\n",
      "['Q37853']\n",
      "['Q1918252']\n",
      "['Q34']\n",
      "['Q43106']\n",
      "['Q5422']\n",
      "['Q29445']\n",
      "['Q219']\n",
      "['Q664']\n",
      "['Q13989']\n",
      "['Q201330']\n",
      "['Q84']\n",
      "['Q2807']\n",
      "['Q40']\n",
      "['Q949424']\n",
      "['Q935']\n",
      "['Q4181867']\n",
      "['Q109676']\n",
      "['Q155626']\n",
      "['Q1981162']\n",
      "['Q33629']\n",
      "['Q739362']\n",
      "['Q211513', 'Q214666', 'Q319861']\n",
      "['Q38']\n",
      "['Q16']\n",
      "['Q240150']\n",
      "['Q192239', 'Q12799318']\n",
      "['Q2736']\n",
      "['Q2844']\n",
      "['Q804']\n",
      "['Q43105']\n",
      "['Q150445']\n",
      "['Q419']\n",
      "['Q258', 'Q1013', 'Q1030']\n",
      "['Q467118']\n",
      "['Q424']\n",
      "['Q739']\n",
      "['Q38337']\n",
      "['Q2044']\n",
      "['Q44703']\n",
      "['Q4872']\n",
      "['Q145']\n",
      "['Q4534523']\n",
      "['Q7315']\n",
      "['Q887']\n",
      "['Q3114']\n",
      "['Q16']\n",
      "['Q36', 'Q211274']\n",
      "['Q8743']\n",
      "['Q154269', 'Q316417', 'Q336810', 'Q432752', 'Q463833']\n",
      "['Q201330']\n",
      "['Q1265']\n",
      "['Q176371']\n",
      "['Q131233']\n",
      "['Q43279']\n",
      "['Q3904', 'Q101418']\n",
      "['Q9268']\n",
      "['Q408']\n",
      "['Q29']\n",
      "['Q1369676']\n",
      "['Q48103', 'Q857244', 'Q17232562']\n",
      "['Q30']\n",
      "['Q298', 'Q414']\n",
      "['Q191159']\n",
      "['Q9215']\n",
      "['Q183']\n",
      "['Q664']\n",
      "['Q1460']\n",
      "['Q851']\n",
      "['Q40909']\n",
      "['Q656']\n",
      "['Q203236']\n",
      "['Q14515330']\n",
      "['Q8810']\n",
      "['Q42941']\n",
      "['Q1524']\n",
      "['Q181114']\n",
      "['Q129352']\n",
      "['Q14773']\n",
      "['Q36600']\n",
      "['Q167420']\n",
      "['Q83186']\n",
      "['Q130531']\n",
      "['Q167646', 'Q171839', 'Q736813']\n",
      "['Q6585']\n",
      "['Q811']\n",
      "['Q835']\n",
      "['Q45']\n",
      "['Q408']\n",
      "['Q42831']\n",
      "['Q762']\n",
      "['Q10686']\n",
      "['Q1850']\n",
      "['Q15807']\n",
      "['Q1003']\n",
      "['Q183']\n",
      "['Q28']\n",
      "['Q1532068']\n",
      "['Q801']\n",
      "['Q3859']\n",
      "['Q170292', 'Q191105']\n",
      "['Q127888']\n",
      "['Q319708']\n",
      "['Q25328']\n",
      "['Q58035']\n",
      "['Q468621', 'Q15071896']\n",
      "['Q29', 'Q142']\n",
      "['Q9191']\n",
      "['Q38']\n",
      "['Q164761', 'Q165704', 'Q170737', 'Q178108', 'Q180935', 'Q182570', 'Q185027', 'Q191691', 'Q334734', 'Q537769']\n",
      "['Q43114']\n",
      "['Q1726', 'Q131610']\n",
      "['Q4412']\n",
      "['Q501']\n",
      "['Q205375', 'Q1281618', 'Q1930187']\n",
      "['Q134942']\n",
      "['Q4167647']\n",
      "['Q162737']\n",
      "['Q172089']\n",
      "['Q34038']\n",
      "['Q813']\n",
      "['Q7947']\n",
      "['Q215556']\n",
      "['Q6934']\n",
      "['Q33231', 'Q36180', 'Q49757', 'Q161944', 'Q170790', 'Q4853732', 'Q4964182', 'Q6625963', 'Q14565331', 'Q18814623', 'Q18939491']\n",
      "['Q15208']\n",
      "['Q916']\n",
      "['Q35881']\n",
      "['Q38']\n",
      "['Q948']\n",
      "['Q57479']\n",
      "['Q265']\n",
      "['Q320653']\n",
      "['Q275354']\n",
      "['Q8006']\n",
      "['Q8409']\n",
      "['Q60']\n",
      "['Q193592']\n",
      "['Q60']\n",
      "['Q8678']\n",
      "['Q718']\n",
      "['Q1186567']\n",
      "['Q1754954']\n",
      "['Q155856']\n",
      "['Q718']\n",
      "['Q48211', 'Q297032']\n",
      "['Q6574', 'Q6655']\n",
      "['Q715281']\n",
      "['Q47293']\n",
      "['Q47293']\n",
      "['Q4768']\n",
      "['Q110228']\n",
      "['Q193064']\n",
      "['Q762']\n",
      "['Q217128']\n",
      "['Q183']\n",
      "['Q170984', 'Q372254']\n",
      "['Q741157']\n",
      "['Q208008']\n",
      "['Q212']\n",
      "['Q131210']\n",
      "['Q27911']\n",
      "['Q34575']\n",
      "['Q11629']\n",
      "['Q83891']\n",
      "['Q78707']\n",
      "['Q9391']\n",
      "['Q3926', 'Q5465', 'Q37701']\n",
      "['Q44363', 'Q82586']\n",
      "['Q592289']\n",
      "['Q28603']\n",
      "['Q219']\n",
      "['Q32024']\n",
      "['Q10570']\n",
      "['Q188']\n",
      "['Q184222']\n",
      "['Q35657']\n",
      "['Q267861', 'Q1323788']\n",
      "['Q133026']\n",
      "['Q33999', 'Q36834', 'Q49757', 'Q177220', 'Q183945', 'Q488205', 'Q662729', 'Q753110', 'Q1028181', 'Q13235160', 'Q16323111', 'Q29017403']\n",
      "['Q148']\n",
      "['Q36']\n",
      "['Q28389', 'Q36180', 'Q49757', 'Q214917', 'Q482980', 'Q6625963']\n",
      "['Q185118', 'Q81200227']\n",
      "['Q38']\n",
      "['Q164714']\n",
      "['Q269668']\n",
      "['Q4257378']\n",
      "['Q151209']\n",
      "['Q315185']\n",
      "['Q716794']\n",
      "['Q912050', 'Q2453629']\n",
      "['Q6397066']\n",
      "['Q186083']\n",
      "['Q220437']\n",
      "['Q14435']\n",
      "['Q72']\n",
      "['Q69060']\n",
      "['Q182101']\n",
      "['Q403']\n",
      "['Q4202', 'Q5871']\n",
      "['Q302849']\n",
      "['Q326827']\n",
      "['Q192134']\n",
      "['Q183']\n",
      "['Q845210']\n",
      "['Q1773']\n",
      "['Q1205']\n",
      "['Q42574']\n",
      "['Q155']\n",
      "['Q333246']\n",
      "['Q230']\n",
      "['Q23124']\n",
      "['Q170513']\n",
      "['Q408']\n",
      "['Q108316']\n",
      "['Q819']\n",
      "['Q11930']\n",
      "['Q3711']\n",
      "['Q47154']\n",
      "['Q711']\n",
      "['Q5338']\n",
      "['Q200797']\n",
      "['Q7200']\n",
      "['Q21']\n",
      "['Q51641', 'Q2907211', 'Q7311705', 'Q7796966', 'Q7796967', 'Q7796969', 'Q12403826', 'Q12403830', 'Q12404028', 'Q12408472', 'Q12408583', 'Q12408584']\n",
      "['Q36834', 'Q486748']\n",
      "['Q142']\n",
      "['Q36215']\n",
      "['Q167997']\n",
      "['Q3915']\n",
      "['Q3919']\n",
      "['Q38111', 'Q41148', 'Q80966', 'Q160432', 'Q170572', 'Q179414', 'Q188772', 'Q192402', 'Q201842', 'Q223091', 'Q223110', 'Q233882', 'Q236613', 'Q241025', 'Q264996', 'Q310394', 'Q311453', 'Q357762', 'Q437752', 'Q481954', 'Q483379', 'Q536437', 'Q918404', 'Q1189169', 'Q1190406', 'Q1680304', 'Q2865151', 'Q3127916', 'Q3501718', 'Q3573721', 'Q25768136']\n",
      "['Q258']\n",
      "['Q183']\n",
      "['Q1541']\n",
      "['Q220']\n",
      "['Q27']\n",
      "['Q3844']\n",
      "['Q204138']\n",
      "['Q140001']\n",
      "['Q1761', 'Q135501', 'Q659895', 'Q1263215', 'Q1672830', 'Q1766409', 'Q2062702', 'Q2088319', 'Q2350741', 'Q5242183', 'Q5500969', 'Q7417543', 'Q13156901', 'Q28601860']\n",
      "['Q8338', 'Q17172850']\n",
      "['Q2092607']\n",
      "['Q236132', 'Q456257']\n",
      "['Q150']\n",
      "['Q683695']\n",
      "['Q17714']\n",
      "['Q69354']\n",
      "['Q229107']\n",
      "['Q17', 'Q188712']\n",
      "['Q623']\n",
      "['Q167646']\n",
      "['Q212']\n",
      "['Q34990']\n",
      "['Q255']\n",
      "['Q45765']\n",
      "['Q31966']\n",
      "['Q108429']\n",
      "['Q155327']\n",
      "['Q157065']\n",
      "['Q1151']\n",
      "['Q176371']\n",
      "['Q656043']\n",
      "['Q30']\n",
      "['Q133274']\n",
      "['Q935']\n",
      "['Q41484']\n",
      "['Q7364']\n",
      "['Q34404']\n",
      "['Q241']\n",
      "['Q8343']\n",
      "['Q40939']\n",
      "['Q204627']\n",
      "['Q894']\n",
      "['Q170737']\n",
      "['Q79']\n",
      "['Q1554208', 'Q1969437']\n",
      "['Q38']\n",
      "['Q35500']\n",
      "['Q1147806']\n",
      "['Q645']\n",
      "['Q5885', 'Q13267']\n",
      "['Q5776']\n",
      "['Q811']\n",
      "['Q843']\n",
      "['Q8667']\n",
      "['Q152513']\n",
      "['Q2133873']\n",
      "['Q557323']\n",
      "['Q695']\n",
      "['Q7200']\n",
      "['Q6607', 'Q17172850']\n",
      "['Q8686']\n",
      "['Q38']\n",
      "['Q829']\n",
      "['Q4214909']\n",
      "['Q239337']\n",
      "['Q42493']\n",
      "['Q30']\n",
      "['Q1069', 'Q8008', 'Q46255']\n",
      "['Q1016']\n",
      "['Q1029907']\n",
      "['Q92600']\n",
      "['Q326358']\n",
      "['Q19566']\n",
      "['Q25224', 'Q374453']\n",
      "['Q28']\n",
      "['Q2634']\n",
      "['Q90', 'Q1017', 'Q173219']\n",
      "['Q869']\n",
      "['Q884']\n",
      "['Q1472152']\n",
      "['Q847']\n",
      "['Q741710']\n",
      "['Q656']\n",
      "['Q368121']\n",
      "['Q215901']\n",
      "['Q1711']\n",
      "['Q211260']\n",
      "['Q1741']\n",
      "['Q237105']\n",
      "['Q714']\n",
      "['Q171852']\n",
      "['Q490']\n",
      "['Q328523']\n",
      "['Q129987']\n",
      "['Q1962550']\n",
      "['Q18013']\n",
      "['Q3808']\n",
      "['Q1533']\n",
      "['Q76420']\n",
      "['Q106151']\n",
      "['Q37701']\n",
      "['Q37137', 'Q186506']\n",
      "['Q212']\n",
      "['Q229']\n",
      "['Q4321335']\n",
      "['Q40901', 'Q44384']\n",
      "['Q56005']\n",
      "['Q129279']\n",
      "['Q656']\n",
      "['Q80137']\n",
      "['Q836']\n",
      "['Q43399']\n",
      "['Q230']\n",
      "['Q265']\n",
      "['Q47163']\n",
      "['Q53268']\n",
      "['Q6839']\n",
      "['Q408']\n",
      "['Q271398']\n",
      "['Q33999', 'Q36834', 'Q177220']\n",
      "['Q158688']\n",
      "['Q811']\n",
      "['Q499980', 'Q838611']\n",
      "['Q200905']\n",
      "['Q318427']\n",
      "['Q1542521', 'Q2419102']\n",
      "['Q52607']\n",
      "['Q37320']\n",
      "['Q130752']\n",
      "['Q408']\n",
      "['Q45765']\n",
      "['Q11895']\n",
      "['Q272029', 'Q324319', 'Q327717', 'Q333146']\n",
      "['Q8355']\n",
      "['Q367120']\n",
      "['Q460337']\n",
      "['Q148']\n",
      "['Q1213902', 'Q3129651']\n",
      "['Q619584']\n",
      "['Q3210067']\n",
      "['Q276354']\n",
      "['Q672936']\n",
      "['Q44204']\n",
      "['Q4214909']\n",
      "['Q19100']\n",
      "['Q298']\n",
      "['Q2684']\n",
      "['Q52535']\n",
      "['Q15878']\n",
      "['Q47190']\n",
      "['Q379053']\n",
      "['Q211']\n",
      "['Q9726']\n",
      "['Q924']\n",
      "['Q308657']\n",
      "['Q347685']\n",
      "['Q199943']\n",
      "['Q1043128']\n",
      "['Q178780']\n",
      "['Q47670']\n",
      "['Q156711']\n",
      "['Q545844']\n",
      "['Q656']\n",
      "['Q14712']\n",
      "['Q40912']\n",
      "['Q1930']\n",
      "['Q142']\n",
      "['Q914']\n",
      "['Q6955']\n",
      "['Q127429']\n",
      "['Q97']\n",
      "['Q3844557']\n",
      "['Q5426']\n",
      "['Q40640']\n",
      "['Q230']\n",
      "['Q149067', 'Q15072554', 'Q19799931']\n",
      "['Q37030']\n",
      "['Q41466']\n",
      "['Q419']\n",
      "['Q70981']\n",
      "['Q96']\n",
      "['Q2696558']\n",
      "['Q471726', 'Q918057', 'Q1815797', 'Q3284950', 'Q5575842', 'Q21532983', 'Q28406292']\n",
      "['Q502265']\n",
      "['Q1248784']\n",
      "['Q35610']\n",
      "['Q5369']\n",
      "['Q25344']\n",
      "['Q1519']\n",
      "['Q79804']\n",
      "['Q45656']\n",
      "['Q71']\n",
      "['Q48']\n",
      "['Q1780']\n",
      "['Q49080']\n",
      "['Q724254']\n",
      "['Q49686']\n",
      "['Q84']\n",
      "['Q468467']\n",
      "['Q228889']\n",
      "['Q97', 'Q788']\n",
      "['Q898']\n",
      "['Q656']\n",
      "['Q239']\n",
      "['Q41211']\n",
      "['Q668', 'Q843', 'Q889']\n",
      "['Q23436']\n",
      "['Q1218']\n",
      "['Q170649']\n",
      "['Q130777']\n",
      "['Q862992']\n",
      "['Q680161']\n",
      "['Q379612']\n",
      "['Q4329463']\n",
      "['Q597']\n",
      "['Q503166']\n",
      "['Q23661']\n",
      "['Q237']\n",
      "['Q193592']\n",
      "['Q41604']\n",
      "['Q8717']\n",
      "['Q1770']\n",
      "['Q1435']\n",
      "['Q201568']\n",
      "['Q681697']\n",
      "['Q7200']\n",
      "['Q258']\n",
      "['Q179620']\n",
      "['Q1449']\n",
      "['Q935']\n",
      "['Q44395']\n",
      "['Q159']\n",
      "['Q30']\n",
      "['Q9270']\n",
      "['Q183']\n",
      "['Q754837']\n",
      "['Q12100']\n",
      "['Q3783']\n",
      "['Q28']\n",
      "['Q156724']\n",
      "['Q55208']\n",
      "['Q4327225']\n",
      "['Q25363']\n",
      "['Q178']\n",
      "['Q2263']\n",
      "['Q753', 'Q1096']\n",
      "['Q127892']\n",
      "['Q146667']\n",
      "['Q966571', 'Q2026876']\n",
      "['Q1320718']\n",
      "['Q925']\n",
      "['Q727']\n",
      "['Q171416']\n",
      "['Q2625243']\n",
      "['Q33']\n",
      "['Q165769']\n",
      "['Q717']\n",
      "['Q30']\n",
      "['Q29108']\n",
      "['Q805221', 'Q805253', 'Q2490358', 'Q5716684', 'Q15296811', 'Q18939491']\n",
      "['Q765633']\n",
      "['Q571822']\n",
      "['Q9671', 'Q169898']\n",
      "['Q45']\n",
      "['Q47774']\n",
      "['Q913643']\n",
      "['Q16320']\n",
      "['Q2337']\n",
      "['Q83459']\n",
      "['Q36']\n",
      "['Q106807']\n",
      "['Q167551']\n",
      "['Q326499']\n",
      "['Q2981']\n",
      "['Q145']\n",
      "['Q21127485']\n",
      "['Q38']\n",
      "['Q15720844']\n",
      "['Q748296']\n",
      "['Q181678']\n",
      "['Q4925477']\n",
      "['Q155874']\n",
      "['Q215548']\n",
      "['Q140686', 'Q218295', 'Q842386', 'Q4109060', 'Q4127082', 'Q4399975', 'Q14805701', 'Q27494237', 'Q38715304', 'Q38715670', 'Q38715852']\n",
      "['Q193018']\n",
      "['Q202040']\n",
      "['Q50546603']\n",
      "['Q5254470']\n",
      "['Q232']\n",
      "['Q898795']\n",
      "['Q41466']\n",
      "['Q1615333', 'Q41795540']\n",
      "['Q42267']\n",
      "['Q271934']\n",
      "['Q1875']\n",
      "['Q18552177']\n",
      "['Q29']\n",
      "['Q1978556']\n",
      "['Q57327']\n",
      "['Q7205']\n",
      "['Q673075']\n",
      "['Q1417705']\n",
      "['Q96', 'Q115', 'Q774', 'Q800']\n",
      "['Q239']\n",
      "['Q33244']\n",
      "['Q926']\n",
      "['Q2723928']\n",
      "['Q645719']\n",
      "['Q810']\n",
      "['Q47064', 'Q82955']\n",
      "['Q1891']\n",
      "['Q159']\n",
      "['Q840829', 'Q2359372']\n",
      "['Q208588']\n",
      "['Q61']\n",
      "['Q902320']\n",
      "['Q7604']\n",
      "['Q3519259']\n",
      "['Q1741']\n",
      "['Q1761']\n",
      "['Q818467']\n",
      "['Q210287']\n",
      "['Q182059']\n",
      "['Q63991914']\n",
      "['Q2333']\n",
      "['Q35064']\n",
      "['Q34']\n",
      "['Q627508']\n",
      "['Q18502']\n",
      "['Q46']\n",
      "['Q46', 'Q48']\n",
      "['Q656']\n",
      "['Q4183061']\n",
      "['Q169898', 'Q171329', 'Q171367', 'Q172721']\n",
      "['Q2359372']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q17501806']\n",
      "['Q21891843', 'Q23820229', 'Q84499835', 'Q84565071', 'Q84566351', 'Q84572475', 'Q84572977', 'Q84593853', 'Q84599401', 'Q84682501', 'Q84763814', 'Q84947682', 'Q174248', 'Q378120', 'Q580728', 'Q600063', 'Q628212', 'Q662985', 'Q693350', 'Q744598', 'Q748211', 'Q753219', 'Q753289', 'Q753292', 'Q840751', 'Q868618', 'Q942842', 'Q1013032', 'Q1013035', 'Q1624461', 'Q1734030', 'Q1810336', 'Q1811143', 'Q1821473', 'Q1822800', 'Q1963689', 'Q1969345', 'Q1987157', 'Q1996280', 'Q2003486', 'Q2041885', 'Q2048241', 'Q2061921', 'Q2078708', 'Q2216373', 'Q2219104', 'Q2297365', 'Q2317527', 'Q2320562', 'Q2331979', 'Q2403918', 'Q2440414', 'Q2442419', 'Q2446033', 'Q2456160', 'Q2460331', 'Q2467285', 'Q2499127', 'Q2501433', 'Q2533951', 'Q2580968', 'Q2612318', 'Q2623877', 'Q2638290', 'Q2661930', 'Q2689681', 'Q2693443', 'Q2709316', 'Q2717469', 'Q2782104', 'Q2786011', 'Q2795720', 'Q2834321', 'Q3176913', 'Q3489924', 'Q3489932', 'Q3489935', 'Q3490214', 'Q3490254', 'Q3490377', 'Q3490395', 'Q3490530', 'Q3490542', 'Q3490548', 'Q3490702', 'Q3497283', 'Q3499350', 'Q3499380', 'Q3499395', 'Q3499402', 'Q3499406', 'Q3509023', 'Q3509048', 'Q3509354', 'Q3509373', 'Q3509425', 'Q3509446', 'Q3509457', 'Q3509657', 'Q3509772', 'Q3509780', 'Q3509815', 'Q3509834', 'Q3563089', 'Q3563100', 'Q3563133', 'Q3563146', 'Q3563211', 'Q3563232', 'Q3564567', 'Q3566327', 'Q3566606']\n",
      "['Q13641190']\n",
      "['Q2084341', 'Q3273932', 'Q4252909', 'Q4262671']\n",
      "['Q612907', 'Q654471', 'Q762844', 'Q1703180', 'Q1967942', 'Q1992013', 'Q1992153', 'Q1992181', 'Q2268261', 'Q3853593', 'Q3885141', 'Q4188115', 'Q4240311', 'Q4286712', 'Q4286829', 'Q4286849', 'Q4286882', 'Q4286937', 'Q4286990', 'Q4287015', 'Q4287082', 'Q4287097', 'Q4287144', 'Q4375455', 'Q4375533', 'Q12756735', 'Q16481642', 'Q16485587', 'Q18080427', 'Q18080429', 'Q18080612', 'Q19399024', 'Q19910703', 'Q21644047', 'Q24932811', 'Q25394795', 'Q57316823', 'Q95000245']\n",
      "['Q21', 'Q22', 'Q25', 'Q26']\n",
      "['Q20183']\n",
      "['Q4151339', 'Q17287317', 'Q17287320', 'Q17287321']\n",
      "['Q165503']\n",
      "['Q28835', 'Q1275243']\n",
      "['Q1396852']\n",
      "['Q70498154']\n",
      "['Q15288']\n",
      "['Q1444', 'Q5994', 'Q8355', 'Q80284', 'Q81982', 'Q191823', 'Q281460', 'Q1521313']\n",
      "['Q10478']\n",
      "['Q4480733']\n",
      "['Q202243']\n",
      "['Q204752']\n",
      "['Q15', 'Q48']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q90']\n",
      "['Q1982087']\n",
      "['Q239', 'Q12800833']\n",
      "['Q250', 'Q3966', 'Q5300', 'Q7397', 'Q9143', 'Q183484', 'Q2384798']\n",
      "['Q43421']\n",
      "['Q46', 'Q48']\n",
      "['Q5492408']\n",
      "['Q3964988']\n",
      "['Q579431', 'Q2000835']\n",
      "['Q665105']\n",
      "['Q184437']\n",
      "['Q190543']\n",
      "['Q55766251']\n",
      "['Q72614', 'Q104161', 'Q1384655', 'Q2721194']\n",
      "['Q4315520']\n",
      "['Q49481']\n",
      "['Q213067']\n",
      "['Q188', 'Q1860', 'Q7737', 'Q9027']\n",
      "['Q79082']\n",
      "['Q18']\n",
      "['Q46']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q739', 'Q8965', 'Q199821', 'Q232564', 'Q1055848', 'Q3591854']\n",
      "['Q902', 'Q330158', 'Q842931', 'Q1850485', 'Q2347909']\n",
      "['Q28']\n",
      "['Q162533']\n",
      "['Q48']\n",
      "['Q847']\n",
      "['Q485176']\n",
      "['Q157443', 'Q192881', 'Q319221', 'Q471839', 'Q761469', 'Q2973181', 'Q20443008']\n",
      "['Q98']\n",
      "['Q37068']\n",
      "['Q37853']\n",
      "['Q54111', 'Q170292']\n",
      "['Q332342', 'Q7744473']\n",
      "['Q13394']\n",
      "['Q324867']\n",
      "['Q4411519']\n",
      "['Q486860']\n",
      "['Q656']\n",
      "['Q1218', 'Q187702', 'Q540882', 'Q1494672', 'Q2280628', 'Q7818625']\n",
      "['Q1332307']\n",
      "['Q210398']\n",
      "['Q8261', 'Q128758', 'Q474090']\n",
      "['Q126399', 'Q621364', 'Q984047', 'Q2924461']\n",
      "['Q23633']\n",
      "['Q126399', 'Q2924461', 'Q3011161', 'Q31197934']\n",
      "['Q1200552', 'Q17343562', 'Q18155354', 'Q22807052']\n",
      "['Q13641190']\n",
      "['Q1589009']\n",
      "['Q75', 'Q880371', 'Q56611700']\n",
      "['Q6581097']\n",
      "['Q675765', 'Q845981', 'Q3984081']\n",
      "['Q1506552', 'Q1938341']\n",
      "['Q27621', 'Q322964', 'Q323681']\n",
      "['Q5994', 'Q8355']\n",
      "['Q165503']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q5064', 'Q12025', 'Q201873', 'Q207875', 'Q231390', 'Q586421']\n",
      "['Q159909', 'Q14906020']\n",
      "['Q299687']\n",
      "['Q124018']\n",
      "['Q778243']\n",
      "['Q158314']\n",
      "['Q62843', 'Q92743']\n",
      "['Q8743', 'Q315422']\n",
      "['Q76468']\n",
      "['Q34286', 'Q77124', 'Q273314', 'Q318449']\n",
      "['Q133544']\n",
      "['Q4143870']\n",
      "['Q552732']\n",
      "['Q5673']\n",
      "['Q4069095', 'Q4321371']\n",
      "['Q380156', 'Q1395520']\n",
      "['Q4934', 'Q92764']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q7738', 'Q12548', 'Q27306', 'Q33296', 'Q34266', 'Q45670', 'Q68518', 'Q70972', 'Q80702', 'Q127318', 'Q131706', 'Q131981', 'Q153136', 'Q156199', 'Q161885', 'Q168651', 'Q170604', 'Q215443', 'Q215530', 'Q256961', 'Q258532', 'Q310650', 'Q318806', 'Q706018', 'Q830084', 'Q4083686']\n",
      "['Q299687']\n",
      "['Q29637']\n",
      "['Q739711', 'Q1799063']\n",
      "['Q75079']\n",
      "['Q2628071']\n",
      "['Q152293']\n",
      "['Q79965', 'Q170770', 'Q1483495', 'Q4318679']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q26068']\n",
      "['Q22890', 'Q23666', 'Q38272']\n",
      "['Q76925']\n",
      "['Q76925']\n",
      "['Q538']\n",
      "['Q258896']\n",
      "['Q7603']\n",
      "['Q233282']\n",
      "['Q21', 'Q145']\n",
      "['Q380252']\n",
      "['Q42042', 'Q48362']\n",
      "['Q3333484']\n",
      "['Q25624', 'Q193026', 'Q1347099', 'Q1377980', 'Q2217063']\n",
      "['Q785828']\n",
      "['Q1065', 'Q4230', 'Q4264', 'Q7809', 'Q7817', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q47488', 'Q47539', 'Q123209', 'Q123759', 'Q151991', 'Q182500', 'Q191384', 'Q243630', 'Q340195', 'Q467938', 'Q471690', 'Q499151', 'Q535086', 'Q602399', 'Q605595', 'Q607301', 'Q656801', 'Q827525', 'Q838116', 'Q842490', 'Q943105', 'Q1025959', 'Q1043527', 'Q1045401', 'Q1072120', 'Q1480793', 'Q1484463', 'Q1570993', 'Q2836400', 'Q3369762', 'Q5611262', 'Q10283557']\n",
      "['Q9448']\n",
      "['Q41']\n",
      "['Q258748']\n",
      "['Q1781702']\n",
      "['Q260542']\n",
      "['Q49', 'Q538']\n",
      "['Q37068']\n",
      "['Q7291']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q2359372']\n",
      "['Q15804']\n",
      "['Q1256223']\n",
      "['Q649', 'Q656', 'Q891', 'Q900', 'Q1874', 'Q5332', 'Q5337', 'Q5540', 'Q5627', 'Q19566', 'Q21197', 'Q156648', 'Q4092262', 'Q4536541', 'Q4538749']\n",
      "['Q1130019']\n",
      "['Q97']\n",
      "['Q33629']\n",
      "['Q24826']\n",
      "['Q3426']\n",
      "['Q1130019']\n",
      "['Q1457437']\n",
      "['Q649']\n",
      "['Q1902692']\n",
      "['Q586']\n",
      "['Q649']\n",
      "['Q5776']\n",
      "['Q133838']\n",
      "['Q174097']\n",
      "['Q34433', 'Q1643454']\n",
      "['Q3630']\n",
      "['Q5994']\n",
      "['Q1990094']\n",
      "['Q4460646']\n",
      "['Q1422', 'Q8682', 'Q18656', 'Q75729', 'Q267245', 'Q1630430', 'Q1772776', 'Q3590754', 'Q3590758', 'Q21079208']\n",
      "['Q59488']\n",
      "['Q133602']\n",
      "['Q81589', 'Q645968']\n",
      "['Q156255']\n",
      "['Q242446']\n",
      "['Q126399', 'Q2924461']\n",
      "['Q159846', 'Q367466']\n",
      "['Q2914786', 'Q4444575']\n",
      "['Q126399', 'Q622668', 'Q3011161', 'Q31197934']\n",
      "['Q2628487']\n",
      "['Q141336']\n",
      "['Q95', 'Q20800404']\n",
      "['Q269792']\n",
      "['Q127552', 'Q191224']\n",
      "['Q20800404']\n",
      "['Q84']\n",
      "['Q16869', 'Q182009']\n",
      "['Q1533']\n",
      "['Q1957']\n",
      "['Q1858']\n",
      "['Q1353', 'Q11739', 'Q42941', 'Q179046', 'Q3242297']\n",
      "['Q2184', 'Q2895', 'Q130229', 'Q130276', 'Q130280', 'Q131337', 'Q132856', 'Q133356', 'Q168811', 'Q170895', 'Q173761', 'Q186888', 'Q192180', 'Q199707', 'Q199711', 'Q484578', 'Q545205']\n",
      "['Q93728', 'Q178473', 'Q185493', 'Q207826', 'Q208167', 'Q278798', 'Q337463', 'Q465316', 'Q530008', 'Q1069798', 'Q1081449', 'Q1710776', 'Q2297431', 'Q2634074', 'Q2760953', 'Q4137459', 'Q4286836', 'Q4335954', 'Q21292820', 'Q59351315', 'Q60130697', 'Q63975126']\n",
      "['Q37922', 'Q278798', 'Q603631', 'Q695106', 'Q950604', 'Q1026769', 'Q1081503', 'Q1340199', 'Q18200478']\n",
      "['Q475482', 'Q1463070']\n",
      "['Q152951']\n",
      "['Q152951']\n",
      "['Q493898']\n",
      "['Q172326']\n",
      "['Q8355', 'Q81982', 'Q281460']\n",
      "['Q27911']\n",
      "['Q31687']\n",
      "['Q27914']\n",
      "['Q1438774']\n",
      "['Q45700']\n",
      "['Q1425861', 'Q7268181']\n",
      "['Q186506']\n",
      "['Q379053']\n",
      "['Q180729', 'Q181951', 'Q1059510', 'Q1277249', 'Q2494846', 'Q4862955']\n",
      "['Q28989']\n",
      "['Q9268']\n",
      "['Q432', 'Q5043']\n",
      "['Q1394287']\n",
      "['Q2498026']\n",
      "['Q23759071']\n",
      "['Q345']\n",
      "['Q7041639']\n",
      "['Q95', 'Q20800404']\n",
      "['Q1966985']\n",
      "['Q1744']\n",
      "['Q377', 'Q191480']\n",
      "['Q42511']\n",
      "['Q15151625']\n",
      "['Q15151625']\n",
      "['Q4069095', 'Q4321371', 'Q4360695']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q5284', 'Q162005']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q44412']\n",
      "['Q37064']\n",
      "['Q50224531']\n",
      "['Q3140459']\n",
      "['Q1060165']\n",
      "['Q2283', 'Q1129295']\n",
      "['Q4132607']\n",
      "['Q195719']\n",
      "['Q42574']\n",
      "['Q4934', 'Q92764']\n",
      "['Q76368']\n",
      "['Q4419809', 'Q4498457']\n",
      "['Q929273', 'Q929285', 'Q2071256', 'Q16253333', 'Q57022061']\n",
      "['Q15072147']\n",
      "['Q315188']\n",
      "['Q191598']\n",
      "['Q97']\n",
      "['Q1406', 'Q5014725', 'Q13361286', 'Q64513817']\n",
      "['Q1406', 'Q5014725', 'Q13361286']\n",
      "['Q280658']\n",
      "['Q280658', 'Q8025128']\n",
      "['Q3542']\n",
      "['Q15243', 'Q203462']\n",
      "['Q2160']\n",
      "['Q19686', 'Q19914']\n",
      "['Q166162']\n",
      "['Q1457453']\n",
      "['Q4320732']\n",
      "['Q166162']\n",
      "['Q13199', 'Q15087', 'Q33754', 'Q387066']\n",
      "['Q80284']\n",
      "['Q31561', 'Q79838', 'Q178389', 'Q4501563', 'Q17172850']\n",
      "['Q8343']\n",
      "['Q3238057', 'Q13785927']\n",
      "['Q5710', 'Q809806', 'Q1092754', 'Q1390649', 'Q4479125', 'Q4479136', 'Q15190285']\n",
      "['Q408', 'Q3258', 'Q15577']\n",
      "['Q980', 'Q10544', 'Q10562']\n",
      "['Q1019', 'Q489821', 'Q5501842']\n",
      "['Q225', 'Q11196', 'Q11198', 'Q18276', 'Q208545', 'Q1274468', 'Q2055400']\n",
      "['Q252', 'Q3757', 'Q523435']\n",
      "['Q766', 'Q651453', 'Q2526023']\n",
      "['Q424', 'Q1054184', 'Q3173090']\n",
      "['Q40', 'Q12548', 'Q28513', 'Q42497', 'Q131964', 'Q153136', 'Q176495', 'Q268970', 'Q518101', 'Q699964', 'Q3624335', 'Q16056854']\n",
      "['Q5446', 'Q788066', 'Q2391775', 'Q6671523', 'Q14558462', 'Q18055588']\n",
      "['Q672', 'Q21815222']\n",
      "['Q854']\n",
      "['Q1008', 'Q845706']\n",
      "['Q1368300']\n",
      "['Q432']\n",
      "['Q775909']\n",
      "['Q4239246']\n",
      "['Q1497']\n",
      "['Q371828', 'Q1324152']\n",
      "['Q207706']\n",
      "['Q4218621']\n",
      "['Q2280', 'Q173822', 'Q185700', 'Q188732', 'Q189822', 'Q191061', 'Q192959']\n",
      "['Q5681011']\n",
      "['Q16157447']\n",
      "['Q361', 'Q2140994', 'Q4081756', 'Q4097857', 'Q4255538']\n",
      "['Q9448']\n",
      "['Q656', 'Q9248', 'Q155243', 'Q196388', 'Q1020157', 'Q4322358']\n",
      "['Q917830']\n",
      "['Q27621', 'Q2654435', 'Q4139211']\n",
      "['Q973']\n",
      "['Q1065', 'Q7184', 'Q7785', 'Q7809', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q37143', 'Q38130', 'Q41550', 'Q81299', 'Q123759', 'Q134102', 'Q170481', 'Q181574', 'Q188822', 'Q191384', 'Q233611', 'Q340195', 'Q376150', 'Q656801', 'Q674182', 'Q782942', 'Q826700', 'Q827525', 'Q842490', 'Q899770', 'Q1043527', 'Q1072120', 'Q1480793', 'Q1928989', 'Q2863003', 'Q3772571', 'Q3866537', 'Q4033111', 'Q4426267', 'Q5150848', 'Q5611262', 'Q7768229', 'Q7886981']\n",
      "['Q167541']\n",
      "['Q182165']\n",
      "['Q76751']\n",
      "['Q5284', 'Q162005']\n",
      "['Q557305', 'Q861967']\n",
      "['Q104898']\n",
      "['Q58792', 'Q80919']\n",
      "['Q1189073', 'Q6895015']\n",
      "['Q182994']\n",
      "['Q46']\n",
      "['Q207591']\n",
      "['Q10857409']\n",
      "['Q782363']\n",
      "['Q736587']\n",
      "['Q649', 'Q656', 'Q1731', 'Q4079059', 'Q4471180']\n",
      "['Q234460', 'Q1069725', 'Q1980247']\n",
      "['Q3642350']\n",
      "['Q101978']\n",
      "['Q49542', 'Q79797', 'Q482942', 'Q1129737', 'Q10290517']\n",
      "['Q19831455']\n",
      "['Q372657', 'Q505275', 'Q22032185']\n",
      "['Q134161', 'Q891723']\n",
      "['Q75745', 'Q248756', 'Q785531', 'Q808176', 'Q854686', 'Q1009177', 'Q1054311', 'Q2090382', 'Q2462900', 'Q2921573', 'Q3017105', 'Q3196524', 'Q4074592', 'Q4081114', 'Q4222569', 'Q4246441', 'Q4375034', 'Q4408691', 'Q4424133', 'Q4427701', 'Q4460344', 'Q14915363', 'Q14915364', 'Q14915365', 'Q14915367', 'Q14915368', 'Q14915369', 'Q14915370', 'Q14915425', 'Q14915428', 'Q14915447', 'Q14915448', 'Q14915449', 'Q14915450', 'Q14915451', 'Q14915452', 'Q14915453', 'Q14915454', 'Q14915455', 'Q14915456', 'Q14915457', 'Q14915458', 'Q14915459', 'Q14915460', 'Q14915461', 'Q14915462', 'Q14915463', 'Q14915464', 'Q14915465', 'Q14915466', 'Q14915467', 'Q14915468', 'Q14915469', 'Q14915470', 'Q14915471', 'Q14915472', 'Q14915473', 'Q14915474', 'Q14915475', 'Q14915476', 'Q14915477', 'Q14915478', 'Q14915479', 'Q14915480', 'Q14915481', 'Q14915482', 'Q14915483', 'Q14915484', 'Q14915485', 'Q14915486', 'Q14915489', 'Q14915490', 'Q14943318', 'Q14943338', 'Q14943342', 'Q21036227', 'Q21036228', 'Q21036229', 'Q21036230', 'Q27679334', 'Q35267412']\n",
      "['Q185493', 'Q208167', 'Q241821', 'Q278798', 'Q337463', 'Q530008', 'Q946626', 'Q1067644', 'Q1069798', 'Q1710776', 'Q2329480', 'Q2634074', 'Q4335936', 'Q4335954', 'Q4375624', 'Q21292820', 'Q56669004', 'Q60054123']\n",
      "['Q41144', 'Q41146', 'Q43269', 'Q43271', 'Q130343', 'Q165582', 'Q170453', 'Q190687', 'Q190922', 'Q191164', 'Q191174', 'Q191186', 'Q201121', 'Q201137', 'Q202068', 'Q202071', 'Q202075', 'Q204876', 'Q205460', 'Q205776', 'Q205784', 'Q205796', 'Q205824', 'Q205843', 'Q492791']\n",
      "['Q1085', 'Q46070', 'Q188373', 'Q188399', 'Q190550', 'Q190930', 'Q191091', 'Q192536', 'Q192697', 'Q192702', 'Q193266', 'Q193295', 'Q193307', 'Q193317']\n",
      "['Q1490', 'Q15701', 'Q44843', 'Q47896', 'Q48326', 'Q71699', 'Q71707', 'Q80011', 'Q80434', 'Q81863', 'Q83273', 'Q120730', 'Q122723', 'Q123258', 'Q123376', 'Q125863', 'Q127264', 'Q127513', 'Q127877', 'Q128186', 'Q128196', 'Q129499', 'Q130290', 'Q130300', 'Q130308', 'Q131277', 'Q131281', 'Q131287', 'Q131314', 'Q131320', 'Q131358', 'Q132705', 'Q132720', 'Q132751', 'Q132929', 'Q132936', 'Q133879', 'Q133924', 'Q133935', 'Q134093', 'Q160420', 'Q160734', 'Q161454', 'Q169376', 'Q617375', 'Q766445', 'Q1037393']\n",
      "['Q4156896']\n",
      "['Q7325']\n",
      "['Q6581097']\n",
      "['Q5256775']\n",
      "['Q10693']\n",
      "['Q12482', 'Q44455', 'Q189088', 'Q1554323', 'Q1766038', 'Q1970172', 'Q2895315', 'Q4056286', 'Q4358367', 'Q5498822']\n",
      "['Q928993']\n",
      "['Q20818052']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q67186598']\n",
      "['Q4035237']\n",
      "['Q52410688']\n",
      "['Q3772']\n",
      "['Q4417863']\n",
      "['Q60100']\n",
      "['Q41602']\n",
      "['Q217925', 'Q2873520']\n",
      "['Q23898959']\n",
      "['Q27621']\n",
      "['Q1566', 'Q199344', 'Q736556']\n",
      "['Q182994']\n",
      "['Q2532727']\n",
      "['Q65032731']\n",
      "['Q47591', 'Q4520962']\n",
      "['Q11297']\n",
      "['Q1370', 'Q523606', 'Q5425102']\n",
      "['Q3279650']\n",
      "['Q6635', 'Q645924']\n",
      "['Q11002', 'Q11254', 'Q41534', 'Q93189', 'Q815740', 'Q4739805', 'Q61503220']\n",
      "['Q50407282']\n",
      "['Q3739104']\n",
      "['Q171558']\n",
      "['Q3739104']\n",
      "['Q3739104']\n",
      "['Q337463']\n",
      "['Q756727', 'Q2747456']\n",
      "['Q202009', 'Q918052', 'Q1167442', 'Q1756055', 'Q3163406']\n",
      "['Q54111']\n",
      "['Q11366', 'Q188450', 'Q484641']\n",
      "['Q3273722']\n",
      "['Q40855']\n",
      "['Q73801', 'Q308913', 'Q611508', 'Q735267', 'Q1046593', 'Q1202130', 'Q2080076', 'Q2469781']\n",
      "['Q157802']\n",
      "['Q4204467']\n",
      "['Q483654']\n",
      "['Q483654', 'Q3333484']\n",
      "['Q547869']\n",
      "['Q27703517']\n",
      "['Q892']\n",
      "['Q1402143']\n",
      "['Q128267', 'Q186350']\n",
      "['Q3415248']\n",
      "['Q4418820']\n",
      "['Q1273278']\n",
      "['Q42574']\n",
      "['Q56008']\n",
      "['Q187364']\n",
      "['Q726105']\n",
      "['Q56005']\n",
      "['Q8877', 'Q6758800']\n",
      "['Q56005']\n",
      "['Q80135']\n",
      "['Q33629']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q626']\n",
      "['Q3447', 'Q27538353']\n",
      "['Q38', 'Q1282', 'Q18288160']\n",
      "['Q487003']\n",
      "['Q228986']\n",
      "['Q23746012']\n",
      "['Q4301841']\n",
      "['Q1711668']\n",
      "['Q1768082']\n",
      "['Q968028']\n",
      "['Q192239']\n",
      "['Q434841']\n",
      "['Q157802']\n",
      "['Q178473', 'Q185493', 'Q209896', 'Q478850', 'Q530008', 'Q534981', 'Q583881', 'Q612907', 'Q694401', 'Q728960', 'Q791135', 'Q1311063', 'Q1415232', 'Q1428575', 'Q1992013', 'Q2028781', 'Q2268261', 'Q2300740', 'Q2638119', 'Q2660844', 'Q4193236', 'Q9387384', 'Q18080427', 'Q18080429', 'Q18080431', 'Q21405589', 'Q89211387']\n",
      "['Q97']\n",
      "['Q27698']\n",
      "['Q946428']\n",
      "['Q33629']\n",
      "['Q834621']\n",
      "['Q4918']\n",
      "['Q1247']\n",
      "['Q17723']\n",
      "['Q515869', 'Q25060578']\n",
      "['Q44626']\n",
      "['Q393864']\n",
      "['Q4393561']\n",
      "['Q847', 'Q5377', 'Q80131']\n",
      "['Q134307', 'Q170571', 'Q191163']\n",
      "['Q207591']\n",
      "['Q130232', 'Q2254193', 'Q52207399']\n",
      "['Q393']\n",
      "['Q141336']\n",
      "['Q5168']\n",
      "['Q5222']\n",
      "['Q900']\n",
      "['Q33405']\n",
      "['Q3114']\n",
      "['Q748', 'Q427945', 'Q2279088']\n",
      "['Q299687']\n",
      "['Q49481']\n",
      "['Q7349']\n",
      "['Q49481']\n",
      "['Q150', 'Q188', 'Q652', 'Q13199']\n",
      "['Q188']\n",
      "['Q23438']\n",
      "['Q3616']\n",
      "['Q174193']\n",
      "['Q11399', 'Q187760', 'Q598929']\n",
      "['Q8341', 'Q9759', 'Q203775', 'Q207378', 'Q1196752', 'Q1530455']\n",
      "['Q37068']\n",
      "['Q39427']\n",
      "['Q37853']\n",
      "['Q4992220']\n",
      "['Q736587']\n",
      "['Q112707']\n",
      "['Q161179', 'Q177540', 'Q223197', 'Q583582', 'Q1055000']\n",
      "['Q8261']\n",
      "['Q189635']\n",
      "['Q181754']\n",
      "['Q181754']\n",
      "['Q125168', 'Q1501888']\n",
      "['Q1471878', 'Q3983766']\n",
      "['Q31687']\n",
      "['Q1218']\n",
      "['Q1520']\n",
      "['Q1930']\n",
      "['Q28218']\n",
      "['Q31687']\n",
      "['Q2618625']\n",
      "['Q739000']\n",
      "['Q767288']\n",
      "['Q51199', 'Q4228172']\n",
      "['Q240150']\n",
      "['Q8958']\n",
      "['Q762']\n",
      "['Q204138']\n",
      "['Q2382967']\n",
      "['Q358556']\n",
      "['Q700540']\n",
      "['Q314287']\n",
      "['Q4768']\n",
      "['Q1144905']\n",
      "['Q9217']\n",
      "['Q1568', 'Q1860']\n",
      "['Q150', 'Q1860']\n",
      "['Q150']\n",
      "['Q1682', 'Q1684', 'Q161455', 'Q300875', 'Q316287', 'Q324404', 'Q562206', 'Q671428', 'Q694789', 'Q697916', 'Q821135', 'Q1532109', 'Q1538524', 'Q1646276', 'Q3908364']\n",
      "['Q188', 'Q36668']\n",
      "['Q5146', 'Q750553', 'Q3436689']\n",
      "['Q13955']\n",
      "['Q8821']\n",
      "['Q809']\n",
      "['Q37217']\n",
      "['Q78994', 'Q858913', 'Q1025134', 'Q1088879', 'Q1194172', 'Q1347209', 'Q1985387', 'Q2234632', 'Q2372093', 'Q2914954']\n",
      "['Q30']\n",
      "['Q164800']\n",
      "['Q80113', 'Q166713']\n",
      "['Q217128']\n",
      "['Q762']\n",
      "['Q130777']\n",
      "['Q76432', 'Q76745', 'Q76747']\n",
      "['Q11570']\n",
      "top1 accuracy t5-3b-ssm-nqo RuBQ =  = 0.2765598650927487\n"
     ]
    }
   ],
   "source": [
    "rubq_test = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "\n",
    "answers = []\n",
    "for i in tqdm(range(len(rubq_test))):\n",
    "    input_ids = t5_tok(rubq_test[i], return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "    answers.append(gen_output)\n",
    "    \n",
    "    \n",
    "final = []\n",
    "for x in answers:\n",
    "    final.append(t5_tok.decode(x, skip_special_tokens=True))\n",
    "\n",
    "    \n",
    "#rubq_questions = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "entities_test_rubq = np.load(\"entities_test_rubq.npy\")\n",
    "rubq_test = pd.DataFrame({\"subject\":entities_test_rubq, \"question\":rubq_test})\n",
    "rubq_test_answers = np.load(\"all_rubq_test_answers_1_hop_uri.npy\", allow_pickle=True)\n",
    "\n",
    "# answers_rubq = []\n",
    "\n",
    "# for lis in rubq_test_answers:\n",
    "#     print(lis)\n",
    "#     new = []\n",
    "#     for element in lis:\n",
    "#         new.append(get_description_name(element))\n",
    "\n",
    "#     answers_rubq.append(new)\n",
    "    \n",
    "preds = []\n",
    "for i in range(len(final)):\n",
    "    try:\n",
    "        x = from_text_to_id(final[i])\n",
    "    except:\n",
    "        x = \"None\"\n",
    "    \n",
    "    preds.append(x)\n",
    "    \n",
    "np.save(\"predictions_rubq_test_t5_3b_ssm_nq.npy\", np.array(final))\n",
    "\n",
    "answers_rubq = []\n",
    "\n",
    "for lis in rubq_test_answers:\n",
    "    print(lis)\n",
    "    new = []\n",
    "    for element in lis:\n",
    "        new.append(element)\n",
    "\n",
    "    answers_rubq.append(new)\n",
    "\n",
    "right = 0\n",
    "\n",
    "for i, ans in enumerate(answers_rubq):\n",
    "    if preds[i] in ans:\n",
    "        right += 1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"top1 accuracy t5-3b-ssm-nqo RuBQ =  = {right/len(preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# google/t5-xl-ssm-nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver version: \u001b[1m510.85.02\u001b[m\r\n",
      "------------------- \u001b[1mDevice 0\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage:  4407MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m20C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 1\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage: 12387MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m20C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 2\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage: 13837MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m32C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 3\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 3090 Ti\u001b[m\r\n",
      "Memory usage:   316MiB / 24564MiB\r\n",
      "Temperature: \u001b[92m21C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 4\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  9196MiB / 11264MiB\r\n",
      "Temperature: \u001b[92m21C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n",
      "------------------- \u001b[1mDevice 5\u001b[m -------------------\r\n",
      "Name: \u001b[1mNVIDIA GeForce RTX 2080 Ti\u001b[m\r\n",
      "Memory usage:  9188MiB / 11264MiB\r\n",
      "Temperature: \u001b[92m21C\u001b[m\r\n",
      "\u001b[91mRunning processes not found\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc2da629e4e4b7c95e99f94dfb0f459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05490b35f1984feb9f2d2cb7b7f6a274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d00c0337f24ed19ffd75c000848c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcab0929dd343ec8d5d9e045eec5e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed19fbda32b64d90b54cdfa0461bf85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 2048)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 2048)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
       "              (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_qa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-xl-ssm-nq\")#\"google/t5-11b-ssm-tqa\")\n",
    "t5_tok = AutoTokenizer.from_pretrained(\"google/t5-xl-ssm-nq\")\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4751/4751 [11:02<00:00,  7.17it/s]\n",
      "100%|██████████| 4751/4751 [00:00<00:00, 811101.36it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_o, preds_id_sq_o = check_t5_sq(t5_tok = t5_tok, t5_qa_model = t5_qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 accuracy t5-xl-ssm-nq SQ =  0.07472111134498001\n"
     ]
    }
   ],
   "source": [
    "print(\"top1 accuracy t5-xl-ssm-nq SQ = \", acc_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [02:57<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q7944', 'Q60186', 'Q167903', 'Q2580904', 'Q5975740', 'Q7692360']\n",
      "['Q102513']\n",
      "['Q692']\n",
      "['Q19660']\n",
      "['Q6607', 'Q483994', 'Q626035', 'Q2643890', 'Q17172850']\n",
      "['Q142']\n",
      "['Q299687']\n",
      "['Q312480']\n",
      "['Q29']\n",
      "['Q4022']\n",
      "['Q796']\n",
      "['Q38768', 'Q201605', 'Q1676638']\n",
      "['Q22']\n",
      "['Q11420', 'Q106500']\n",
      "['Q4808485']\n",
      "['Q2838011']\n",
      "['Q9299872']\n",
      "['Q2674728']\n",
      "['Q1968651']\n",
      "['Q1088']\n",
      "['Q7737', 'Q29561']\n",
      "['Q36124']\n",
      "['Q43']\n",
      "['Q49481']\n",
      "['Q424', 'Q869', 'Q881']\n",
      "['Q148', 'Q837']\n",
      "['Q232']\n",
      "['Q408']\n",
      "['Q816']\n",
      "['Q847', 'Q5377']\n",
      "['Q30']\n",
      "['Q1792']\n",
      "['Q822290']\n",
      "['Q1603']\n",
      "['Q181306', 'Q213344', 'Q237367', 'Q1326237']\n",
      "['Q237800']\n",
      "['Q106151']\n",
      "['Q201598']\n",
      "['Q223134']\n",
      "['Q106010']\n",
      "['Q29445']\n",
      "['Q40591', 'Q58784', 'Q295347', 'Q470600']\n",
      "['Q1850']\n",
      "['Q4719']\n",
      "['Q157683']\n",
      "['Q158491']\n",
      "['Q62']\n",
      "['Q24861']\n",
      "['Q3787']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q55']\n",
      "['Q19675']\n",
      "['Q36180', 'Q82955', 'Q185351', 'Q333634', 'Q1209498', 'Q1297719', 'Q4964182', 'Q11774202', 'Q18814623']\n",
      "['Q22']\n",
      "['Q1048']\n",
      "['Q9191']\n",
      "['Q687']\n",
      "['Q1860923']\n",
      "['Q178577']\n",
      "['Q199588']\n",
      "['Q79759']\n",
      "['Q31628']\n",
      "['Q57966']\n",
      "['Q133622']\n",
      "['Q360292']\n",
      "['Q128790']\n",
      "['Q236233']\n",
      "['Q152293']\n",
      "['Q15862']\n",
      "['Q723764']\n",
      "['Q783']\n",
      "['Q767288']\n",
      "['Q31628']\n",
      "['Q142']\n",
      "['Q40357']\n",
      "['Q1048']\n",
      "['Q159']\n",
      "['Q2064699', 'Q4304132']\n",
      "['Q668']\n",
      "['Q112']\n",
      "['Q49111']\n",
      "['Q131026']\n",
      "['Q11419']\n",
      "['Q6502703']\n",
      "['Q172911']\n",
      "['Q212115']\n",
      "['Q1069868']\n",
      "['Q897']\n",
      "['Q869']\n",
      "['Q41']\n",
      "['Q10737']\n",
      "['Q6862']\n",
      "['Q40059']\n",
      "['Q35591']\n",
      "['Q2332']\n",
      "['Q1205']\n",
      "['Q31015', 'Q241214']\n",
      "['Q586']\n",
      "['Q891']\n",
      "['Q1472', 'Q12133', 'Q35869', 'Q41083', 'Q110315', 'Q131742', 'Q147778', 'Q193894', 'Q653078', 'Q2025687', 'Q2035074', 'Q3144986']\n",
      "['Q144144']\n",
      "['Q34981']\n",
      "['Q185027']\n",
      "['Q47369']\n",
      "['Q45']\n",
      "['Q81214']\n",
      "['Q51']\n",
      "['Q4964182']\n",
      "['Q46599']\n",
      "['Q6816']\n",
      "['Q46']\n",
      "['Q1875']\n",
      "['Q5470']\n",
      "['Q165503']\n",
      "['Q25261', 'Q46255']\n",
      "['Q925']\n",
      "['Q790']\n",
      "['Q13695']\n",
      "['Q24826']\n",
      "['Q1035', 'Q82122']\n",
      "['Q2568844']\n",
      "['Q149067']\n",
      "['Q170737']\n",
      "['Q626']\n",
      "['Q395', 'Q7754', 'Q41217', 'Q149999', 'Q56114489']\n",
      "['Q157623']\n",
      "['Q159']\n",
      "['Q5592']\n",
      "['Q626']\n",
      "['Q28244']\n",
      "['Q16559']\n",
      "['Q944527']\n",
      "['Q8027']\n",
      "['Q70']\n",
      "['Q10484']\n",
      "['Q47059']\n",
      "['Q93351']\n",
      "['Q762']\n",
      "['Q214196']\n",
      "['Q130498']\n",
      "['Q30204']\n",
      "['Q157623']\n",
      "['Q31']\n",
      "['Q854']\n",
      "['Q170513']\n",
      "['Q5806']\n",
      "['Q37853']\n",
      "['Q1918252']\n",
      "['Q34']\n",
      "['Q43106']\n",
      "['Q5422']\n",
      "['Q29445']\n",
      "['Q219']\n",
      "['Q664']\n",
      "['Q13989']\n",
      "['Q201330']\n",
      "['Q84']\n",
      "['Q2807']\n",
      "['Q40']\n",
      "['Q949424']\n",
      "['Q935']\n",
      "['Q4181867']\n",
      "['Q109676']\n",
      "['Q155626']\n",
      "['Q1981162']\n",
      "['Q33629']\n",
      "['Q739362']\n",
      "['Q211513', 'Q214666', 'Q319861']\n",
      "['Q38']\n",
      "['Q16']\n",
      "['Q240150']\n",
      "['Q192239', 'Q12799318']\n",
      "['Q2736']\n",
      "['Q2844']\n",
      "['Q804']\n",
      "['Q43105']\n",
      "['Q150445']\n",
      "['Q419']\n",
      "['Q258', 'Q1013', 'Q1030']\n",
      "['Q467118']\n",
      "['Q424']\n",
      "['Q739']\n",
      "['Q38337']\n",
      "['Q2044']\n",
      "['Q44703']\n",
      "['Q4872']\n",
      "['Q145']\n",
      "['Q4534523']\n",
      "['Q7315']\n",
      "['Q887']\n",
      "['Q3114']\n",
      "['Q16']\n",
      "['Q36', 'Q211274']\n",
      "['Q8743']\n",
      "['Q154269', 'Q316417', 'Q336810', 'Q432752', 'Q463833']\n",
      "['Q201330']\n",
      "['Q1265']\n",
      "['Q176371']\n",
      "['Q131233']\n",
      "['Q43279']\n",
      "['Q3904', 'Q101418']\n",
      "['Q9268']\n",
      "['Q408']\n",
      "['Q29']\n",
      "['Q1369676']\n",
      "['Q48103', 'Q857244', 'Q17232562']\n",
      "['Q30']\n",
      "['Q298', 'Q414']\n",
      "['Q191159']\n",
      "['Q9215']\n",
      "['Q183']\n",
      "['Q664']\n",
      "['Q1460']\n",
      "['Q851']\n",
      "['Q40909']\n",
      "['Q656']\n",
      "['Q203236']\n",
      "['Q14515330']\n",
      "['Q8810']\n",
      "['Q42941']\n",
      "['Q1524']\n",
      "['Q181114']\n",
      "['Q129352']\n",
      "['Q14773']\n",
      "['Q36600']\n",
      "['Q167420']\n",
      "['Q83186']\n",
      "['Q130531']\n",
      "['Q167646', 'Q171839', 'Q736813']\n",
      "['Q6585']\n",
      "['Q811']\n",
      "['Q835']\n",
      "['Q45']\n",
      "['Q408']\n",
      "['Q42831']\n",
      "['Q762']\n",
      "['Q10686']\n",
      "['Q1850']\n",
      "['Q15807']\n",
      "['Q1003']\n",
      "['Q183']\n",
      "['Q28']\n",
      "['Q1532068']\n",
      "['Q801']\n",
      "['Q3859']\n",
      "['Q170292', 'Q191105']\n",
      "['Q127888']\n",
      "['Q319708']\n",
      "['Q25328']\n",
      "['Q58035']\n",
      "['Q468621', 'Q15071896']\n",
      "['Q29', 'Q142']\n",
      "['Q9191']\n",
      "['Q38']\n",
      "['Q164761', 'Q165704', 'Q170737', 'Q178108', 'Q180935', 'Q182570', 'Q185027', 'Q191691', 'Q334734', 'Q537769']\n",
      "['Q43114']\n",
      "['Q1726', 'Q131610']\n",
      "['Q4412']\n",
      "['Q501']\n",
      "['Q205375', 'Q1281618', 'Q1930187']\n",
      "['Q134942']\n",
      "['Q4167647']\n",
      "['Q162737']\n",
      "['Q172089']\n",
      "['Q34038']\n",
      "['Q813']\n",
      "['Q7947']\n",
      "['Q215556']\n",
      "['Q6934']\n",
      "['Q33231', 'Q36180', 'Q49757', 'Q161944', 'Q170790', 'Q4853732', 'Q4964182', 'Q6625963', 'Q14565331', 'Q18814623', 'Q18939491']\n",
      "['Q15208']\n",
      "['Q916']\n",
      "['Q35881']\n",
      "['Q38']\n",
      "['Q948']\n",
      "['Q57479']\n",
      "['Q265']\n",
      "['Q320653']\n",
      "['Q275354']\n",
      "['Q8006']\n",
      "['Q8409']\n",
      "['Q60']\n",
      "['Q193592']\n",
      "['Q60']\n",
      "['Q8678']\n",
      "['Q718']\n",
      "['Q1186567']\n",
      "['Q1754954']\n",
      "['Q155856']\n",
      "['Q718']\n",
      "['Q48211', 'Q297032']\n",
      "['Q6574', 'Q6655']\n",
      "['Q715281']\n",
      "['Q47293']\n",
      "['Q47293']\n",
      "['Q4768']\n",
      "['Q110228']\n",
      "['Q193064']\n",
      "['Q762']\n",
      "['Q217128']\n",
      "['Q183']\n",
      "['Q170984', 'Q372254']\n",
      "['Q741157']\n",
      "['Q208008']\n",
      "['Q212']\n",
      "['Q131210']\n",
      "['Q27911']\n",
      "['Q34575']\n",
      "['Q11629']\n",
      "['Q83891']\n",
      "['Q78707']\n",
      "['Q9391']\n",
      "['Q3926', 'Q5465', 'Q37701']\n",
      "['Q44363', 'Q82586']\n",
      "['Q592289']\n",
      "['Q28603']\n",
      "['Q219']\n",
      "['Q32024']\n",
      "['Q10570']\n",
      "['Q188']\n",
      "['Q184222']\n",
      "['Q35657']\n",
      "['Q267861', 'Q1323788']\n",
      "['Q133026']\n",
      "['Q33999', 'Q36834', 'Q49757', 'Q177220', 'Q183945', 'Q488205', 'Q662729', 'Q753110', 'Q1028181', 'Q13235160', 'Q16323111', 'Q29017403']\n",
      "['Q148']\n",
      "['Q36']\n",
      "['Q28389', 'Q36180', 'Q49757', 'Q214917', 'Q482980', 'Q6625963']\n",
      "['Q185118', 'Q81200227']\n",
      "['Q38']\n",
      "['Q164714']\n",
      "['Q269668']\n",
      "['Q4257378']\n",
      "['Q151209']\n",
      "['Q315185']\n",
      "['Q716794']\n",
      "['Q912050', 'Q2453629']\n",
      "['Q6397066']\n",
      "['Q186083']\n",
      "['Q220437']\n",
      "['Q14435']\n",
      "['Q72']\n",
      "['Q69060']\n",
      "['Q182101']\n",
      "['Q403']\n",
      "['Q4202', 'Q5871']\n",
      "['Q302849']\n",
      "['Q326827']\n",
      "['Q192134']\n",
      "['Q183']\n",
      "['Q845210']\n",
      "['Q1773']\n",
      "['Q1205']\n",
      "['Q42574']\n",
      "['Q155']\n",
      "['Q333246']\n",
      "['Q230']\n",
      "['Q23124']\n",
      "['Q170513']\n",
      "['Q408']\n",
      "['Q108316']\n",
      "['Q819']\n",
      "['Q11930']\n",
      "['Q3711']\n",
      "['Q47154']\n",
      "['Q711']\n",
      "['Q5338']\n",
      "['Q200797']\n",
      "['Q7200']\n",
      "['Q21']\n",
      "['Q51641', 'Q2907211', 'Q7311705', 'Q7796966', 'Q7796967', 'Q7796969', 'Q12403826', 'Q12403830', 'Q12404028', 'Q12408472', 'Q12408583', 'Q12408584']\n",
      "['Q36834', 'Q486748']\n",
      "['Q142']\n",
      "['Q36215']\n",
      "['Q167997']\n",
      "['Q3915']\n",
      "['Q3919']\n",
      "['Q38111', 'Q41148', 'Q80966', 'Q160432', 'Q170572', 'Q179414', 'Q188772', 'Q192402', 'Q201842', 'Q223091', 'Q223110', 'Q233882', 'Q236613', 'Q241025', 'Q264996', 'Q310394', 'Q311453', 'Q357762', 'Q437752', 'Q481954', 'Q483379', 'Q536437', 'Q918404', 'Q1189169', 'Q1190406', 'Q1680304', 'Q2865151', 'Q3127916', 'Q3501718', 'Q3573721', 'Q25768136']\n",
      "['Q258']\n",
      "['Q183']\n",
      "['Q1541']\n",
      "['Q220']\n",
      "['Q27']\n",
      "['Q3844']\n",
      "['Q204138']\n",
      "['Q140001']\n",
      "['Q1761', 'Q135501', 'Q659895', 'Q1263215', 'Q1672830', 'Q1766409', 'Q2062702', 'Q2088319', 'Q2350741', 'Q5242183', 'Q5500969', 'Q7417543', 'Q13156901', 'Q28601860']\n",
      "['Q8338', 'Q17172850']\n",
      "['Q2092607']\n",
      "['Q236132', 'Q456257']\n",
      "['Q150']\n",
      "['Q683695']\n",
      "['Q17714']\n",
      "['Q69354']\n",
      "['Q229107']\n",
      "['Q17', 'Q188712']\n",
      "['Q623']\n",
      "['Q167646']\n",
      "['Q212']\n",
      "['Q34990']\n",
      "['Q255']\n",
      "['Q45765']\n",
      "['Q31966']\n",
      "['Q108429']\n",
      "['Q155327']\n",
      "['Q157065']\n",
      "['Q1151']\n",
      "['Q176371']\n",
      "['Q656043']\n",
      "['Q30']\n",
      "['Q133274']\n",
      "['Q935']\n",
      "['Q41484']\n",
      "['Q7364']\n",
      "['Q34404']\n",
      "['Q241']\n",
      "['Q8343']\n",
      "['Q40939']\n",
      "['Q204627']\n",
      "['Q894']\n",
      "['Q170737']\n",
      "['Q79']\n",
      "['Q1554208', 'Q1969437']\n",
      "['Q38']\n",
      "['Q35500']\n",
      "['Q1147806']\n",
      "['Q645']\n",
      "['Q5885', 'Q13267']\n",
      "['Q5776']\n",
      "['Q811']\n",
      "['Q843']\n",
      "['Q8667']\n",
      "['Q152513']\n",
      "['Q2133873']\n",
      "['Q557323']\n",
      "['Q695']\n",
      "['Q7200']\n",
      "['Q6607', 'Q17172850']\n",
      "['Q8686']\n",
      "['Q38']\n",
      "['Q829']\n",
      "['Q4214909']\n",
      "['Q239337']\n",
      "['Q42493']\n",
      "['Q30']\n",
      "['Q1069', 'Q8008', 'Q46255']\n",
      "['Q1016']\n",
      "['Q1029907']\n",
      "['Q92600']\n",
      "['Q326358']\n",
      "['Q19566']\n",
      "['Q25224', 'Q374453']\n",
      "['Q28']\n",
      "['Q2634']\n",
      "['Q90', 'Q1017', 'Q173219']\n",
      "['Q869']\n",
      "['Q884']\n",
      "['Q1472152']\n",
      "['Q847']\n",
      "['Q741710']\n",
      "['Q656']\n",
      "['Q368121']\n",
      "['Q215901']\n",
      "['Q1711']\n",
      "['Q211260']\n",
      "['Q1741']\n",
      "['Q237105']\n",
      "['Q714']\n",
      "['Q171852']\n",
      "['Q490']\n",
      "['Q328523']\n",
      "['Q129987']\n",
      "['Q1962550']\n",
      "['Q18013']\n",
      "['Q3808']\n",
      "['Q1533']\n",
      "['Q76420']\n",
      "['Q106151']\n",
      "['Q37701']\n",
      "['Q37137', 'Q186506']\n",
      "['Q212']\n",
      "['Q229']\n",
      "['Q4321335']\n",
      "['Q40901', 'Q44384']\n",
      "['Q56005']\n",
      "['Q129279']\n",
      "['Q656']\n",
      "['Q80137']\n",
      "['Q836']\n",
      "['Q43399']\n",
      "['Q230']\n",
      "['Q265']\n",
      "['Q47163']\n",
      "['Q53268']\n",
      "['Q6839']\n",
      "['Q408']\n",
      "['Q271398']\n",
      "['Q33999', 'Q36834', 'Q177220']\n",
      "['Q158688']\n",
      "['Q811']\n",
      "['Q499980', 'Q838611']\n",
      "['Q200905']\n",
      "['Q318427']\n",
      "['Q1542521', 'Q2419102']\n",
      "['Q52607']\n",
      "['Q37320']\n",
      "['Q130752']\n",
      "['Q408']\n",
      "['Q45765']\n",
      "['Q11895']\n",
      "['Q272029', 'Q324319', 'Q327717', 'Q333146']\n",
      "['Q8355']\n",
      "['Q367120']\n",
      "['Q460337']\n",
      "['Q148']\n",
      "['Q1213902', 'Q3129651']\n",
      "['Q619584']\n",
      "['Q3210067']\n",
      "['Q276354']\n",
      "['Q672936']\n",
      "['Q44204']\n",
      "['Q4214909']\n",
      "['Q19100']\n",
      "['Q298']\n",
      "['Q2684']\n",
      "['Q52535']\n",
      "['Q15878']\n",
      "['Q47190']\n",
      "['Q379053']\n",
      "['Q211']\n",
      "['Q9726']\n",
      "['Q924']\n",
      "['Q308657']\n",
      "['Q347685']\n",
      "['Q199943']\n",
      "['Q1043128']\n",
      "['Q178780']\n",
      "['Q47670']\n",
      "['Q156711']\n",
      "['Q545844']\n",
      "['Q656']\n",
      "['Q14712']\n",
      "['Q40912']\n",
      "['Q1930']\n",
      "['Q142']\n",
      "['Q914']\n",
      "['Q6955']\n",
      "['Q127429']\n",
      "['Q97']\n",
      "['Q3844557']\n",
      "['Q5426']\n",
      "['Q40640']\n",
      "['Q230']\n",
      "['Q149067', 'Q15072554', 'Q19799931']\n",
      "['Q37030']\n",
      "['Q41466']\n",
      "['Q419']\n",
      "['Q70981']\n",
      "['Q96']\n",
      "['Q2696558']\n",
      "['Q471726', 'Q918057', 'Q1815797', 'Q3284950', 'Q5575842', 'Q21532983', 'Q28406292']\n",
      "['Q502265']\n",
      "['Q1248784']\n",
      "['Q35610']\n",
      "['Q5369']\n",
      "['Q25344']\n",
      "['Q1519']\n",
      "['Q79804']\n",
      "['Q45656']\n",
      "['Q71']\n",
      "['Q48']\n",
      "['Q1780']\n",
      "['Q49080']\n",
      "['Q724254']\n",
      "['Q49686']\n",
      "['Q84']\n",
      "['Q468467']\n",
      "['Q228889']\n",
      "['Q97', 'Q788']\n",
      "['Q898']\n",
      "['Q656']\n",
      "['Q239']\n",
      "['Q41211']\n",
      "['Q668', 'Q843', 'Q889']\n",
      "['Q23436']\n",
      "['Q1218']\n",
      "['Q170649']\n",
      "['Q130777']\n",
      "['Q862992']\n",
      "['Q680161']\n",
      "['Q379612']\n",
      "['Q4329463']\n",
      "['Q597']\n",
      "['Q503166']\n",
      "['Q23661']\n",
      "['Q237']\n",
      "['Q193592']\n",
      "['Q41604']\n",
      "['Q8717']\n",
      "['Q1770']\n",
      "['Q1435']\n",
      "['Q201568']\n",
      "['Q681697']\n",
      "['Q7200']\n",
      "['Q258']\n",
      "['Q179620']\n",
      "['Q1449']\n",
      "['Q935']\n",
      "['Q44395']\n",
      "['Q159']\n",
      "['Q30']\n",
      "['Q9270']\n",
      "['Q183']\n",
      "['Q754837']\n",
      "['Q12100']\n",
      "['Q3783']\n",
      "['Q28']\n",
      "['Q156724']\n",
      "['Q55208']\n",
      "['Q4327225']\n",
      "['Q25363']\n",
      "['Q178']\n",
      "['Q2263']\n",
      "['Q753', 'Q1096']\n",
      "['Q127892']\n",
      "['Q146667']\n",
      "['Q966571', 'Q2026876']\n",
      "['Q1320718']\n",
      "['Q925']\n",
      "['Q727']\n",
      "['Q171416']\n",
      "['Q2625243']\n",
      "['Q33']\n",
      "['Q165769']\n",
      "['Q717']\n",
      "['Q30']\n",
      "['Q29108']\n",
      "['Q805221', 'Q805253', 'Q2490358', 'Q5716684', 'Q15296811', 'Q18939491']\n",
      "['Q765633']\n",
      "['Q571822']\n",
      "['Q9671', 'Q169898']\n",
      "['Q45']\n",
      "['Q47774']\n",
      "['Q913643']\n",
      "['Q16320']\n",
      "['Q2337']\n",
      "['Q83459']\n",
      "['Q36']\n",
      "['Q106807']\n",
      "['Q167551']\n",
      "['Q326499']\n",
      "['Q2981']\n",
      "['Q145']\n",
      "['Q21127485']\n",
      "['Q38']\n",
      "['Q15720844']\n",
      "['Q748296']\n",
      "['Q181678']\n",
      "['Q4925477']\n",
      "['Q155874']\n",
      "['Q215548']\n",
      "['Q140686', 'Q218295', 'Q842386', 'Q4109060', 'Q4127082', 'Q4399975', 'Q14805701', 'Q27494237', 'Q38715304', 'Q38715670', 'Q38715852']\n",
      "['Q193018']\n",
      "['Q202040']\n",
      "['Q50546603']\n",
      "['Q5254470']\n",
      "['Q232']\n",
      "['Q898795']\n",
      "['Q41466']\n",
      "['Q1615333', 'Q41795540']\n",
      "['Q42267']\n",
      "['Q271934']\n",
      "['Q1875']\n",
      "['Q18552177']\n",
      "['Q29']\n",
      "['Q1978556']\n",
      "['Q57327']\n",
      "['Q7205']\n",
      "['Q673075']\n",
      "['Q1417705']\n",
      "['Q96', 'Q115', 'Q774', 'Q800']\n",
      "['Q239']\n",
      "['Q33244']\n",
      "['Q926']\n",
      "['Q2723928']\n",
      "['Q645719']\n",
      "['Q810']\n",
      "['Q47064', 'Q82955']\n",
      "['Q1891']\n",
      "['Q159']\n",
      "['Q840829', 'Q2359372']\n",
      "['Q208588']\n",
      "['Q61']\n",
      "['Q902320']\n",
      "['Q7604']\n",
      "['Q3519259']\n",
      "['Q1741']\n",
      "['Q1761']\n",
      "['Q818467']\n",
      "['Q210287']\n",
      "['Q182059']\n",
      "['Q63991914']\n",
      "['Q2333']\n",
      "['Q35064']\n",
      "['Q34']\n",
      "['Q627508']\n",
      "['Q18502']\n",
      "['Q46']\n",
      "['Q46', 'Q48']\n",
      "['Q656']\n",
      "['Q4183061']\n",
      "['Q169898', 'Q171329', 'Q171367', 'Q172721']\n",
      "['Q2359372']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q17501806']\n",
      "['Q21891843', 'Q23820229', 'Q84499835', 'Q84565071', 'Q84566351', 'Q84572475', 'Q84572977', 'Q84593853', 'Q84599401', 'Q84682501', 'Q84763814', 'Q84947682', 'Q174248', 'Q378120', 'Q580728', 'Q600063', 'Q628212', 'Q662985', 'Q693350', 'Q744598', 'Q748211', 'Q753219', 'Q753289', 'Q753292', 'Q840751', 'Q868618', 'Q942842', 'Q1013032', 'Q1013035', 'Q1624461', 'Q1734030', 'Q1810336', 'Q1811143', 'Q1821473', 'Q1822800', 'Q1963689', 'Q1969345', 'Q1987157', 'Q1996280', 'Q2003486', 'Q2041885', 'Q2048241', 'Q2061921', 'Q2078708', 'Q2216373', 'Q2219104', 'Q2297365', 'Q2317527', 'Q2320562', 'Q2331979', 'Q2403918', 'Q2440414', 'Q2442419', 'Q2446033', 'Q2456160', 'Q2460331', 'Q2467285', 'Q2499127', 'Q2501433', 'Q2533951', 'Q2580968', 'Q2612318', 'Q2623877', 'Q2638290', 'Q2661930', 'Q2689681', 'Q2693443', 'Q2709316', 'Q2717469', 'Q2782104', 'Q2786011', 'Q2795720', 'Q2834321', 'Q3176913', 'Q3489924', 'Q3489932', 'Q3489935', 'Q3490214', 'Q3490254', 'Q3490377', 'Q3490395', 'Q3490530', 'Q3490542', 'Q3490548', 'Q3490702', 'Q3497283', 'Q3499350', 'Q3499380', 'Q3499395', 'Q3499402', 'Q3499406', 'Q3509023', 'Q3509048', 'Q3509354', 'Q3509373', 'Q3509425', 'Q3509446', 'Q3509457', 'Q3509657', 'Q3509772', 'Q3509780', 'Q3509815', 'Q3509834', 'Q3563089', 'Q3563100', 'Q3563133', 'Q3563146', 'Q3563211', 'Q3563232', 'Q3564567', 'Q3566327', 'Q3566606']\n",
      "['Q13641190']\n",
      "['Q2084341', 'Q3273932', 'Q4252909', 'Q4262671']\n",
      "['Q612907', 'Q654471', 'Q762844', 'Q1703180', 'Q1967942', 'Q1992013', 'Q1992153', 'Q1992181', 'Q2268261', 'Q3853593', 'Q3885141', 'Q4188115', 'Q4240311', 'Q4286712', 'Q4286829', 'Q4286849', 'Q4286882', 'Q4286937', 'Q4286990', 'Q4287015', 'Q4287082', 'Q4287097', 'Q4287144', 'Q4375455', 'Q4375533', 'Q12756735', 'Q16481642', 'Q16485587', 'Q18080427', 'Q18080429', 'Q18080612', 'Q19399024', 'Q19910703', 'Q21644047', 'Q24932811', 'Q25394795', 'Q57316823', 'Q95000245']\n",
      "['Q21', 'Q22', 'Q25', 'Q26']\n",
      "['Q20183']\n",
      "['Q4151339', 'Q17287317', 'Q17287320', 'Q17287321']\n",
      "['Q165503']\n",
      "['Q28835', 'Q1275243']\n",
      "['Q1396852']\n",
      "['Q70498154']\n",
      "['Q15288']\n",
      "['Q1444', 'Q5994', 'Q8355', 'Q80284', 'Q81982', 'Q191823', 'Q281460', 'Q1521313']\n",
      "['Q10478']\n",
      "['Q4480733']\n",
      "['Q202243']\n",
      "['Q204752']\n",
      "['Q15', 'Q48']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q90']\n",
      "['Q1982087']\n",
      "['Q239', 'Q12800833']\n",
      "['Q250', 'Q3966', 'Q5300', 'Q7397', 'Q9143', 'Q183484', 'Q2384798']\n",
      "['Q43421']\n",
      "['Q46', 'Q48']\n",
      "['Q5492408']\n",
      "['Q3964988']\n",
      "['Q579431', 'Q2000835']\n",
      "['Q665105']\n",
      "['Q184437']\n",
      "['Q190543']\n",
      "['Q55766251']\n",
      "['Q72614', 'Q104161', 'Q1384655', 'Q2721194']\n",
      "['Q4315520']\n",
      "['Q49481']\n",
      "['Q213067']\n",
      "['Q188', 'Q1860', 'Q7737', 'Q9027']\n",
      "['Q79082']\n",
      "['Q18']\n",
      "['Q46']\n",
      "['Q8338', 'Q202027', 'Q17172850']\n",
      "['Q739', 'Q8965', 'Q199821', 'Q232564', 'Q1055848', 'Q3591854']\n",
      "['Q902', 'Q330158', 'Q842931', 'Q1850485', 'Q2347909']\n",
      "['Q28']\n",
      "['Q162533']\n",
      "['Q48']\n",
      "['Q847']\n",
      "['Q485176']\n",
      "['Q157443', 'Q192881', 'Q319221', 'Q471839', 'Q761469', 'Q2973181', 'Q20443008']\n",
      "['Q98']\n",
      "['Q37068']\n",
      "['Q37853']\n",
      "['Q54111', 'Q170292']\n",
      "['Q332342', 'Q7744473']\n",
      "['Q13394']\n",
      "['Q324867']\n",
      "['Q4411519']\n",
      "['Q486860']\n",
      "['Q656']\n",
      "['Q1218', 'Q187702', 'Q540882', 'Q1494672', 'Q2280628', 'Q7818625']\n",
      "['Q1332307']\n",
      "['Q210398']\n",
      "['Q8261', 'Q128758', 'Q474090']\n",
      "['Q126399', 'Q621364', 'Q984047', 'Q2924461']\n",
      "['Q23633']\n",
      "['Q126399', 'Q2924461', 'Q3011161', 'Q31197934']\n",
      "['Q1200552', 'Q17343562', 'Q18155354', 'Q22807052']\n",
      "['Q13641190']\n",
      "['Q1589009']\n",
      "['Q75', 'Q880371', 'Q56611700']\n",
      "['Q6581097']\n",
      "['Q675765', 'Q845981', 'Q3984081']\n",
      "['Q1506552', 'Q1938341']\n",
      "['Q27621', 'Q322964', 'Q323681']\n",
      "['Q5994', 'Q8355']\n",
      "['Q165503']\n",
      "['Q27621', 'Q1978570', 'Q2387574', 'Q2495829', 'Q4525174', 'Q4534839', 'Q27430017']\n",
      "['Q5064', 'Q12025', 'Q201873', 'Q207875', 'Q231390', 'Q586421']\n",
      "['Q159909', 'Q14906020']\n",
      "['Q299687']\n",
      "['Q124018']\n",
      "['Q778243']\n",
      "['Q158314']\n",
      "['Q62843', 'Q92743']\n",
      "['Q8743', 'Q315422']\n",
      "['Q76468']\n",
      "['Q34286', 'Q77124', 'Q273314', 'Q318449']\n",
      "['Q133544']\n",
      "['Q4143870']\n",
      "['Q552732']\n",
      "['Q5673']\n",
      "['Q4069095', 'Q4321371']\n",
      "['Q380156', 'Q1395520']\n",
      "['Q4934', 'Q92764']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q7738', 'Q12548', 'Q27306', 'Q33296', 'Q34266', 'Q45670', 'Q68518', 'Q70972', 'Q80702', 'Q127318', 'Q131706', 'Q131981', 'Q153136', 'Q156199', 'Q161885', 'Q168651', 'Q170604', 'Q215443', 'Q215530', 'Q256961', 'Q258532', 'Q310650', 'Q318806', 'Q706018', 'Q830084', 'Q4083686']\n",
      "['Q299687']\n",
      "['Q29637']\n",
      "['Q739711', 'Q1799063']\n",
      "['Q75079']\n",
      "['Q2628071']\n",
      "['Q152293']\n",
      "['Q79965', 'Q170770', 'Q1483495', 'Q4318679']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q26068']\n",
      "['Q22890', 'Q23666', 'Q38272']\n",
      "['Q76925']\n",
      "['Q76925']\n",
      "['Q538']\n",
      "['Q258896']\n",
      "['Q7603']\n",
      "['Q233282']\n",
      "['Q21', 'Q145']\n",
      "['Q380252']\n",
      "['Q42042', 'Q48362']\n",
      "['Q3333484']\n",
      "['Q25624', 'Q193026', 'Q1347099', 'Q1377980', 'Q2217063']\n",
      "['Q785828']\n",
      "['Q1065', 'Q4230', 'Q4264', 'Q7809', 'Q7817', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q47488', 'Q47539', 'Q123209', 'Q123759', 'Q151991', 'Q182500', 'Q191384', 'Q243630', 'Q340195', 'Q467938', 'Q471690', 'Q499151', 'Q535086', 'Q602399', 'Q605595', 'Q607301', 'Q656801', 'Q827525', 'Q838116', 'Q842490', 'Q943105', 'Q1025959', 'Q1043527', 'Q1045401', 'Q1072120', 'Q1480793', 'Q1484463', 'Q1570993', 'Q2836400', 'Q3369762', 'Q5611262', 'Q10283557']\n",
      "['Q9448']\n",
      "['Q41']\n",
      "['Q258748']\n",
      "['Q1781702']\n",
      "['Q260542']\n",
      "['Q49', 'Q538']\n",
      "['Q37068']\n",
      "['Q7291']\n",
      "['Q2245347', 'Q2914850', 'Q72553200', 'Q72553961']\n",
      "['Q2359372']\n",
      "['Q15804']\n",
      "['Q1256223']\n",
      "['Q649', 'Q656', 'Q891', 'Q900', 'Q1874', 'Q5332', 'Q5337', 'Q5540', 'Q5627', 'Q19566', 'Q21197', 'Q156648', 'Q4092262', 'Q4536541', 'Q4538749']\n",
      "['Q1130019']\n",
      "['Q97']\n",
      "['Q33629']\n",
      "['Q24826']\n",
      "['Q3426']\n",
      "['Q1130019']\n",
      "['Q1457437']\n",
      "['Q649']\n",
      "['Q1902692']\n",
      "['Q586']\n",
      "['Q649']\n",
      "['Q5776']\n",
      "['Q133838']\n",
      "['Q174097']\n",
      "['Q34433', 'Q1643454']\n",
      "['Q3630']\n",
      "['Q5994']\n",
      "['Q1990094']\n",
      "['Q4460646']\n",
      "['Q1422', 'Q8682', 'Q18656', 'Q75729', 'Q267245', 'Q1630430', 'Q1772776', 'Q3590754', 'Q3590758', 'Q21079208']\n",
      "['Q59488']\n",
      "['Q133602']\n",
      "['Q81589', 'Q645968']\n",
      "['Q156255']\n",
      "['Q242446']\n",
      "['Q126399', 'Q2924461']\n",
      "['Q159846', 'Q367466']\n",
      "['Q2914786', 'Q4444575']\n",
      "['Q126399', 'Q622668', 'Q3011161', 'Q31197934']\n",
      "['Q2628487']\n",
      "['Q141336']\n",
      "['Q95', 'Q20800404']\n",
      "['Q269792']\n",
      "['Q127552', 'Q191224']\n",
      "['Q20800404']\n",
      "['Q84']\n",
      "['Q16869', 'Q182009']\n",
      "['Q1533']\n",
      "['Q1957']\n",
      "['Q1858']\n",
      "['Q1353', 'Q11739', 'Q42941', 'Q179046', 'Q3242297']\n",
      "['Q2184', 'Q2895', 'Q130229', 'Q130276', 'Q130280', 'Q131337', 'Q132856', 'Q133356', 'Q168811', 'Q170895', 'Q173761', 'Q186888', 'Q192180', 'Q199707', 'Q199711', 'Q484578', 'Q545205']\n",
      "['Q93728', 'Q178473', 'Q185493', 'Q207826', 'Q208167', 'Q278798', 'Q337463', 'Q465316', 'Q530008', 'Q1069798', 'Q1081449', 'Q1710776', 'Q2297431', 'Q2634074', 'Q2760953', 'Q4137459', 'Q4286836', 'Q4335954', 'Q21292820', 'Q59351315', 'Q60130697', 'Q63975126']\n",
      "['Q37922', 'Q278798', 'Q603631', 'Q695106', 'Q950604', 'Q1026769', 'Q1081503', 'Q1340199', 'Q18200478']\n",
      "['Q475482', 'Q1463070']\n",
      "['Q152951']\n",
      "['Q152951']\n",
      "['Q493898']\n",
      "['Q172326']\n",
      "['Q8355', 'Q81982', 'Q281460']\n",
      "['Q27911']\n",
      "['Q31687']\n",
      "['Q27914']\n",
      "['Q1438774']\n",
      "['Q45700']\n",
      "['Q1425861', 'Q7268181']\n",
      "['Q186506']\n",
      "['Q379053']\n",
      "['Q180729', 'Q181951', 'Q1059510', 'Q1277249', 'Q2494846', 'Q4862955']\n",
      "['Q28989']\n",
      "['Q9268']\n",
      "['Q432', 'Q5043']\n",
      "['Q1394287']\n",
      "['Q2498026']\n",
      "['Q23759071']\n",
      "['Q345']\n",
      "['Q7041639']\n",
      "['Q95', 'Q20800404']\n",
      "['Q1966985']\n",
      "['Q1744']\n",
      "['Q377', 'Q191480']\n",
      "['Q42511']\n",
      "['Q15151625']\n",
      "['Q15151625']\n",
      "['Q4069095', 'Q4321371', 'Q4360695']\n",
      "['Q19837', 'Q332591', 'Q483382']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q5284', 'Q162005']\n",
      "['Q40224', 'Q57098', 'Q70788']\n",
      "['Q44412']\n",
      "['Q37064']\n",
      "['Q50224531']\n",
      "['Q3140459']\n",
      "['Q1060165']\n",
      "['Q2283', 'Q1129295']\n",
      "['Q4132607']\n",
      "['Q195719']\n",
      "['Q42574']\n",
      "['Q4934', 'Q92764']\n",
      "['Q76368']\n",
      "['Q4419809', 'Q4498457']\n",
      "['Q929273', 'Q929285', 'Q2071256', 'Q16253333', 'Q57022061']\n",
      "['Q15072147']\n",
      "['Q315188']\n",
      "['Q191598']\n",
      "['Q97']\n",
      "['Q1406', 'Q5014725', 'Q13361286', 'Q64513817']\n",
      "['Q1406', 'Q5014725', 'Q13361286']\n",
      "['Q280658']\n",
      "['Q280658', 'Q8025128']\n",
      "['Q3542']\n",
      "['Q15243', 'Q203462']\n",
      "['Q2160']\n",
      "['Q19686', 'Q19914']\n",
      "['Q166162']\n",
      "['Q1457453']\n",
      "['Q4320732']\n",
      "['Q166162']\n",
      "['Q13199', 'Q15087', 'Q33754', 'Q387066']\n",
      "['Q80284']\n",
      "['Q31561', 'Q79838', 'Q178389', 'Q4501563', 'Q17172850']\n",
      "['Q8343']\n",
      "['Q3238057', 'Q13785927']\n",
      "['Q5710', 'Q809806', 'Q1092754', 'Q1390649', 'Q4479125', 'Q4479136', 'Q15190285']\n",
      "['Q408', 'Q3258', 'Q15577']\n",
      "['Q980', 'Q10544', 'Q10562']\n",
      "['Q1019', 'Q489821', 'Q5501842']\n",
      "['Q225', 'Q11196', 'Q11198', 'Q18276', 'Q208545', 'Q1274468', 'Q2055400']\n",
      "['Q252', 'Q3757', 'Q523435']\n",
      "['Q766', 'Q651453', 'Q2526023']\n",
      "['Q424', 'Q1054184', 'Q3173090']\n",
      "['Q40', 'Q12548', 'Q28513', 'Q42497', 'Q131964', 'Q153136', 'Q176495', 'Q268970', 'Q518101', 'Q699964', 'Q3624335', 'Q16056854']\n",
      "['Q5446', 'Q788066', 'Q2391775', 'Q6671523', 'Q14558462', 'Q18055588']\n",
      "['Q672', 'Q21815222']\n",
      "['Q854']\n",
      "['Q1008', 'Q845706']\n",
      "['Q1368300']\n",
      "['Q432']\n",
      "['Q775909']\n",
      "['Q4239246']\n",
      "['Q1497']\n",
      "['Q371828', 'Q1324152']\n",
      "['Q207706']\n",
      "['Q4218621']\n",
      "['Q2280', 'Q173822', 'Q185700', 'Q188732', 'Q189822', 'Q191061', 'Q192959']\n",
      "['Q5681011']\n",
      "['Q16157447']\n",
      "['Q361', 'Q2140994', 'Q4081756', 'Q4097857', 'Q4255538']\n",
      "['Q9448']\n",
      "['Q656', 'Q9248', 'Q155243', 'Q196388', 'Q1020157', 'Q4322358']\n",
      "['Q917830']\n",
      "['Q27621', 'Q2654435', 'Q4139211']\n",
      "['Q973']\n",
      "['Q1065', 'Q7184', 'Q7785', 'Q7809', 'Q7825', 'Q8475', 'Q17495', 'Q19771', 'Q37143', 'Q38130', 'Q41550', 'Q81299', 'Q123759', 'Q134102', 'Q170481', 'Q181574', 'Q188822', 'Q191384', 'Q233611', 'Q340195', 'Q376150', 'Q656801', 'Q674182', 'Q782942', 'Q826700', 'Q827525', 'Q842490', 'Q899770', 'Q1043527', 'Q1072120', 'Q1480793', 'Q1928989', 'Q2863003', 'Q3772571', 'Q3866537', 'Q4033111', 'Q4426267', 'Q5150848', 'Q5611262', 'Q7768229', 'Q7886981']\n",
      "['Q167541']\n",
      "['Q182165']\n",
      "['Q76751']\n",
      "['Q5284', 'Q162005']\n",
      "['Q557305', 'Q861967']\n",
      "['Q104898']\n",
      "['Q58792', 'Q80919']\n",
      "['Q1189073', 'Q6895015']\n",
      "['Q182994']\n",
      "['Q46']\n",
      "['Q207591']\n",
      "['Q10857409']\n",
      "['Q782363']\n",
      "['Q736587']\n",
      "['Q649', 'Q656', 'Q1731', 'Q4079059', 'Q4471180']\n",
      "['Q234460', 'Q1069725', 'Q1980247']\n",
      "['Q3642350']\n",
      "['Q101978']\n",
      "['Q49542', 'Q79797', 'Q482942', 'Q1129737', 'Q10290517']\n",
      "['Q19831455']\n",
      "['Q372657', 'Q505275', 'Q22032185']\n",
      "['Q134161', 'Q891723']\n",
      "['Q75745', 'Q248756', 'Q785531', 'Q808176', 'Q854686', 'Q1009177', 'Q1054311', 'Q2090382', 'Q2462900', 'Q2921573', 'Q3017105', 'Q3196524', 'Q4074592', 'Q4081114', 'Q4222569', 'Q4246441', 'Q4375034', 'Q4408691', 'Q4424133', 'Q4427701', 'Q4460344', 'Q14915363', 'Q14915364', 'Q14915365', 'Q14915367', 'Q14915368', 'Q14915369', 'Q14915370', 'Q14915425', 'Q14915428', 'Q14915447', 'Q14915448', 'Q14915449', 'Q14915450', 'Q14915451', 'Q14915452', 'Q14915453', 'Q14915454', 'Q14915455', 'Q14915456', 'Q14915457', 'Q14915458', 'Q14915459', 'Q14915460', 'Q14915461', 'Q14915462', 'Q14915463', 'Q14915464', 'Q14915465', 'Q14915466', 'Q14915467', 'Q14915468', 'Q14915469', 'Q14915470', 'Q14915471', 'Q14915472', 'Q14915473', 'Q14915474', 'Q14915475', 'Q14915476', 'Q14915477', 'Q14915478', 'Q14915479', 'Q14915480', 'Q14915481', 'Q14915482', 'Q14915483', 'Q14915484', 'Q14915485', 'Q14915486', 'Q14915489', 'Q14915490', 'Q14943318', 'Q14943338', 'Q14943342', 'Q21036227', 'Q21036228', 'Q21036229', 'Q21036230', 'Q27679334', 'Q35267412']\n",
      "['Q185493', 'Q208167', 'Q241821', 'Q278798', 'Q337463', 'Q530008', 'Q946626', 'Q1067644', 'Q1069798', 'Q1710776', 'Q2329480', 'Q2634074', 'Q4335936', 'Q4335954', 'Q4375624', 'Q21292820', 'Q56669004', 'Q60054123']\n",
      "['Q41144', 'Q41146', 'Q43269', 'Q43271', 'Q130343', 'Q165582', 'Q170453', 'Q190687', 'Q190922', 'Q191164', 'Q191174', 'Q191186', 'Q201121', 'Q201137', 'Q202068', 'Q202071', 'Q202075', 'Q204876', 'Q205460', 'Q205776', 'Q205784', 'Q205796', 'Q205824', 'Q205843', 'Q492791']\n",
      "['Q1085', 'Q46070', 'Q188373', 'Q188399', 'Q190550', 'Q190930', 'Q191091', 'Q192536', 'Q192697', 'Q192702', 'Q193266', 'Q193295', 'Q193307', 'Q193317']\n",
      "['Q1490', 'Q15701', 'Q44843', 'Q47896', 'Q48326', 'Q71699', 'Q71707', 'Q80011', 'Q80434', 'Q81863', 'Q83273', 'Q120730', 'Q122723', 'Q123258', 'Q123376', 'Q125863', 'Q127264', 'Q127513', 'Q127877', 'Q128186', 'Q128196', 'Q129499', 'Q130290', 'Q130300', 'Q130308', 'Q131277', 'Q131281', 'Q131287', 'Q131314', 'Q131320', 'Q131358', 'Q132705', 'Q132720', 'Q132751', 'Q132929', 'Q132936', 'Q133879', 'Q133924', 'Q133935', 'Q134093', 'Q160420', 'Q160734', 'Q161454', 'Q169376', 'Q617375', 'Q766445', 'Q1037393']\n",
      "['Q4156896']\n",
      "['Q7325']\n",
      "['Q6581097']\n",
      "['Q5256775']\n",
      "['Q10693']\n",
      "['Q12482', 'Q44455', 'Q189088', 'Q1554323', 'Q1766038', 'Q1970172', 'Q2895315', 'Q4056286', 'Q4358367', 'Q5498822']\n",
      "['Q928993']\n",
      "['Q20818052']\n",
      "['Q76754', 'Q186203', 'Q4349082']\n",
      "['Q67186598']\n",
      "['Q4035237']\n",
      "['Q52410688']\n",
      "['Q3772']\n",
      "['Q4417863']\n",
      "['Q60100']\n",
      "['Q41602']\n",
      "['Q217925', 'Q2873520']\n",
      "['Q23898959']\n",
      "['Q27621']\n",
      "['Q1566', 'Q199344', 'Q736556']\n",
      "['Q182994']\n",
      "['Q2532727']\n",
      "['Q65032731']\n",
      "['Q47591', 'Q4520962']\n",
      "['Q11297']\n",
      "['Q1370', 'Q523606', 'Q5425102']\n",
      "['Q3279650']\n",
      "['Q6635', 'Q645924']\n",
      "['Q11002', 'Q11254', 'Q41534', 'Q93189', 'Q815740', 'Q4739805', 'Q61503220']\n",
      "['Q50407282']\n",
      "['Q3739104']\n",
      "['Q171558']\n",
      "['Q3739104']\n",
      "['Q3739104']\n",
      "['Q337463']\n",
      "['Q756727', 'Q2747456']\n",
      "['Q202009', 'Q918052', 'Q1167442', 'Q1756055', 'Q3163406']\n",
      "['Q54111']\n",
      "['Q11366', 'Q188450', 'Q484641']\n",
      "['Q3273722']\n",
      "['Q40855']\n",
      "['Q73801', 'Q308913', 'Q611508', 'Q735267', 'Q1046593', 'Q1202130', 'Q2080076', 'Q2469781']\n",
      "['Q157802']\n",
      "['Q4204467']\n",
      "['Q483654']\n",
      "['Q483654', 'Q3333484']\n",
      "['Q547869']\n",
      "['Q27703517']\n",
      "['Q892']\n",
      "['Q1402143']\n",
      "['Q128267', 'Q186350']\n",
      "['Q3415248']\n",
      "['Q4418820']\n",
      "['Q1273278']\n",
      "['Q42574']\n",
      "['Q56008']\n",
      "['Q187364']\n",
      "['Q726105']\n",
      "['Q56005']\n",
      "['Q8877', 'Q6758800']\n",
      "['Q56005']\n",
      "['Q80135']\n",
      "['Q33629']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q8025128']\n",
      "['Q626']\n",
      "['Q3447', 'Q27538353']\n",
      "['Q38', 'Q1282', 'Q18288160']\n",
      "['Q487003']\n",
      "['Q228986']\n",
      "['Q23746012']\n",
      "['Q4301841']\n",
      "['Q1711668']\n",
      "['Q1768082']\n",
      "['Q968028']\n",
      "['Q192239']\n",
      "['Q434841']\n",
      "['Q157802']\n",
      "['Q178473', 'Q185493', 'Q209896', 'Q478850', 'Q530008', 'Q534981', 'Q583881', 'Q612907', 'Q694401', 'Q728960', 'Q791135', 'Q1311063', 'Q1415232', 'Q1428575', 'Q1992013', 'Q2028781', 'Q2268261', 'Q2300740', 'Q2638119', 'Q2660844', 'Q4193236', 'Q9387384', 'Q18080427', 'Q18080429', 'Q18080431', 'Q21405589', 'Q89211387']\n",
      "['Q97']\n",
      "['Q27698']\n",
      "['Q946428']\n",
      "['Q33629']\n",
      "['Q834621']\n",
      "['Q4918']\n",
      "['Q1247']\n",
      "['Q17723']\n",
      "['Q515869', 'Q25060578']\n",
      "['Q44626']\n",
      "['Q393864']\n",
      "['Q4393561']\n",
      "['Q847', 'Q5377', 'Q80131']\n",
      "['Q134307', 'Q170571', 'Q191163']\n",
      "['Q207591']\n",
      "['Q130232', 'Q2254193', 'Q52207399']\n",
      "['Q393']\n",
      "['Q141336']\n",
      "['Q5168']\n",
      "['Q5222']\n",
      "['Q900']\n",
      "['Q33405']\n",
      "['Q3114']\n",
      "['Q748', 'Q427945', 'Q2279088']\n",
      "['Q299687']\n",
      "['Q49481']\n",
      "['Q7349']\n",
      "['Q49481']\n",
      "['Q150', 'Q188', 'Q652', 'Q13199']\n",
      "['Q188']\n",
      "['Q23438']\n",
      "['Q3616']\n",
      "['Q174193']\n",
      "['Q11399', 'Q187760', 'Q598929']\n",
      "['Q8341', 'Q9759', 'Q203775', 'Q207378', 'Q1196752', 'Q1530455']\n",
      "['Q37068']\n",
      "['Q39427']\n",
      "['Q37853']\n",
      "['Q4992220']\n",
      "['Q736587']\n",
      "['Q112707']\n",
      "['Q161179', 'Q177540', 'Q223197', 'Q583582', 'Q1055000']\n",
      "['Q8261']\n",
      "['Q189635']\n",
      "['Q181754']\n",
      "['Q181754']\n",
      "['Q125168', 'Q1501888']\n",
      "['Q1471878', 'Q3983766']\n",
      "['Q31687']\n",
      "['Q1218']\n",
      "['Q1520']\n",
      "['Q1930']\n",
      "['Q28218']\n",
      "['Q31687']\n",
      "['Q2618625']\n",
      "['Q739000']\n",
      "['Q767288']\n",
      "['Q51199', 'Q4228172']\n",
      "['Q240150']\n",
      "['Q8958']\n",
      "['Q762']\n",
      "['Q204138']\n",
      "['Q2382967']\n",
      "['Q358556']\n",
      "['Q700540']\n",
      "['Q314287']\n",
      "['Q4768']\n",
      "['Q1144905']\n",
      "['Q9217']\n",
      "['Q1568', 'Q1860']\n",
      "['Q150', 'Q1860']\n",
      "['Q150']\n",
      "['Q1682', 'Q1684', 'Q161455', 'Q300875', 'Q316287', 'Q324404', 'Q562206', 'Q671428', 'Q694789', 'Q697916', 'Q821135', 'Q1532109', 'Q1538524', 'Q1646276', 'Q3908364']\n",
      "['Q188', 'Q36668']\n",
      "['Q5146', 'Q750553', 'Q3436689']\n",
      "['Q13955']\n",
      "['Q8821']\n",
      "['Q809']\n",
      "['Q37217']\n",
      "['Q78994', 'Q858913', 'Q1025134', 'Q1088879', 'Q1194172', 'Q1347209', 'Q1985387', 'Q2234632', 'Q2372093', 'Q2914954']\n",
      "['Q30']\n",
      "['Q164800']\n",
      "['Q80113', 'Q166713']\n",
      "['Q217128']\n",
      "['Q762']\n",
      "['Q130777']\n",
      "['Q76432', 'Q76745', 'Q76747']\n",
      "['Q11570']\n",
      "top1 accuracy t5-3b-ssm-nqo RuBQ =  = 0.33811129848229343\n"
     ]
    }
   ],
   "source": [
    "rubq_test = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "\n",
    "answers = []\n",
    "for i in tqdm(range(len(rubq_test))):\n",
    "    input_ids = t5_tok(rubq_test[i], return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    gen_output = t5_qa_model.generate(input_ids)[0]\n",
    "    answers.append(gen_output)\n",
    "    \n",
    "    \n",
    "final = []\n",
    "for x in answers:\n",
    "    final.append(t5_tok.decode(x, skip_special_tokens=True))\n",
    "\n",
    "    \n",
    "#rubq_questions = np.load(\"all_EN_rubq_test_questions_1_hop_uri.npy\")\n",
    "entities_test_rubq = np.load(\"entities_test_rubq.npy\")\n",
    "rubq_test = pd.DataFrame({\"subject\":entities_test_rubq, \"question\":rubq_test})\n",
    "rubq_test_answers = np.load(\"all_rubq_test_answers_1_hop_uri.npy\", allow_pickle=True)\n",
    "\n",
    "# answers_rubq = []\n",
    "\n",
    "# for lis in rubq_test_answers:\n",
    "#     print(lis)\n",
    "#     new = []\n",
    "#     for element in lis:\n",
    "#         new.append(get_description_name(element))\n",
    "\n",
    "#     answers_rubq.append(new)\n",
    "    \n",
    "preds = []\n",
    "for i in range(len(final)):\n",
    "    try:\n",
    "        x = from_text_to_id(final[i])\n",
    "    except:\n",
    "        x = \"None\"\n",
    "    \n",
    "    preds.append(x)\n",
    "    \n",
    "np.save(\"predictions_rubq_test_t5_3b_ssm_nq.npy\", np.array(final))\n",
    "\n",
    "answers_rubq = []\n",
    "\n",
    "for lis in rubq_test_answers:\n",
    "    print(lis)\n",
    "    new = []\n",
    "    for element in lis:\n",
    "        new.append(element)\n",
    "\n",
    "    answers_rubq.append(new)\n",
    "\n",
    "right = 0\n",
    "\n",
    "for i, ans in enumerate(answers_rubq):\n",
    "    if preds[i] in ans:\n",
    "        right += 1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(f\"top1 accuracy t5-xl-ssm-nq RuBQ =  = {right/len(preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
